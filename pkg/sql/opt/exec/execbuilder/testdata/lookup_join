# LogicTest: 5node

statement ok
CREATE TABLE abc (a INT, b INT, c INT, PRIMARY KEY (a, c))

statement ok
CREATE TABLE def (d INT, e INT, f INT, PRIMARY KEY (f, e), INDEX desc_idx (f, e DESC) STORING (d))

statement ok
CREATE TABLE def_e_decimal (d INT, e DECIMAL, f INT, PRIMARY KEY (f, e), INDEX desc_idx (f, e DESC) STORING (d))

# Set up the statistics as if the first table is much smaller than the second.
# This will make lookup join into the second table be the best plan.
statement ok
ALTER TABLE abc INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE def INJECT STATISTICS '[
  {
    "columns": ["f"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

statement ok
ALTER TABLE def_e_decimal INJECT STATISTICS '[
  {
    "columns": ["f"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 99
│ table: def@def_pkey
│ equality: (b) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b AND e = c
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 0
│ table: def@def_pkey
│ equality: (b, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b WHERE a > 1 AND e > 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@def_pkey
│ lookup condition: (b = f) AND (e > 1)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def@desc_idx ON f = b WHERE a > 1 AND e > 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@desc_idx
│ lookup condition: (b = f) AND (e > 1)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

# The filter on 'e' is a contradiction. The optimizer should be smart enough to
# avoid execution altogether, #80402.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b WHERE a > 1 AND e > 9223372036854775807
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@def_pkey
│ lookup condition: (b = f) AND (e > 9223372036854775807)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

# Decimals don't support Next / Prev calls, but the index column is ASC so
# we can still use the (e > 1) filter in the lookup condition.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal ON f = b WHERE a > 1 AND e > 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def_e_decimal@def_e_decimal_pkey
│ lookup condition: (b = f) AND (e > 1)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

# Decimals don't support Next / Prev calls, but the inequality is inclusive so
# we can still use the (e >= 1) filter in the lookup condition.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal@desc_idx ON f = b WHERE a > 1 AND e >= 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def_e_decimal@desc_idx
│ lookup condition: (b = f) AND (e >= 1)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

# Decimals don't support Next / Prev calls and the index column is DESC so
# we handle the (e < 1) filter in the ON expression.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal@desc_idx ON f = b WHERE a > 1 AND e < 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def_e_decimal@desc_idx
│ equality: (b) = (f)
│ pred: e < 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = a WHERE f > 1
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@def_pkey
│ equality: (a) = (f)
│ pred: f > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33 (33% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: /2-

# Inclusive inequality referencing an input column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b WHERE a >= e
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@def_pkey
│ lookup condition: (b = f) AND (a >= e)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Inclusive inequality on a descending index column referencing an input column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def@desc_idx ON f = b WHERE a >= e
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@desc_idx
│ lookup condition: (b = f) AND (a >= e)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Exclusive inequality referencing an input column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b AND a > e
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@def_pkey
│ lookup condition: (b = f) AND (a > e)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Exclusive inequality on a descending index column referencing an input column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def@desc_idx ON f = b AND a > e
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@desc_idx
│ lookup condition: (b = f) AND (a > e)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Inequality on a decimal column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal ON f = b AND a::DECIMAL >= e
----
distribution: local
vectorized: true
·
• project
│ columns: (a, b, c, d, e, f)
│
└── • lookup join (inner)
    │ columns: (column11, a, b, c, d, e, f)
    │ estimated row count: 33
    │ table: def_e_decimal@def_e_decimal_pkey
    │ lookup condition: (b = f) AND (column11 >= e)
    │
    └── • render
        │ columns: (column11, a, b, c)
        │ render column11: a::DECIMAL
        │ render a: a
        │ render b: b
        │ render c: c
        │
        └── • scan
              columns: (a, b, c)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: abc@abc_pkey
              spans: FULL SCAN

# Inequality on a descending decimal index column.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal@desc_idx ON f = b AND a::DECIMAL >= e
----
distribution: local
vectorized: true
·
• project
│ columns: (a, b, c, d, e, f)
│
└── • lookup join (inner)
    │ columns: (column11, a, b, c, d, e, f)
    │ estimated row count: 33
    │ table: def_e_decimal@desc_idx
    │ lookup condition: (b = f) AND (column11 >= e)
    │
    └── • render
        │ columns: (column11, a, b, c)
        │ render column11: a::DECIMAL
        │ render a: a
        │ render b: b
        │ render c: c
        │
        └── • scan
              columns: (a, b, c)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: abc@abc_pkey
              spans: FULL SCAN

# The inequality has to be in the ON condition because the columns are
# different types.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal ON f = b AND a >= e
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def_e_decimal@def_e_decimal_pkey
│ equality: (b) = (f)
│ pred: a >= e
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# The inequality has to be in the ON condition because decimals don't support
# Prev calls.
query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def_e_decimal@desc_idx ON f = b AND a::DECIMAL > e
----
distribution: local
vectorized: true
·
• project
│ columns: (a, b, c, d, e, f)
│
└── • lookup join (inner)
    │ columns: (column11, a, b, c, d, e, f)
    │ estimated row count: 33
    │ table: def_e_decimal@desc_idx
    │ equality: (b) = (f)
    │ pred: column11 > e
    │
    └── • render
        │ columns: (column11, a, b, c)
        │ render column11: a::DECIMAL
        │ render a: a
        │ render b: b
        │ render c: c
        │
        └── • scan
              columns: (a, b, c)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: abc@abc_pkey
              spans: FULL SCAN

# Verify a distsql plan.
statement ok
CREATE TABLE data (a INT, b INT, c INT, d INT, PRIMARY KEY (a, b, c, d))

# Split into ten parts.
statement ok
ALTER TABLE data SPLIT AT SELECT i FROM generate_series(1, 9) AS g(i)

statement ok
ALTER TABLE data INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100000,
    "distinct_count": 100000
  }
]'

# Relocate the ten parts to the five nodes.
statement ok
ALTER TABLE data EXPERIMENTAL_RELOCATE
  SELECT ARRAY[i%5+1], i FROM generate_series(0, 9) AS g(i)

# Verify data placement.
query TTTI colnames,rowsort
SELECT start_key, end_key, replicas, lease_holder from [SHOW RANGES FROM TABLE data WITH DETAILS]
----
start_key           end_key       replicas  lease_holder
<before:/Table/57>  …/1/1         {1}       1
…/1/1               …/1/2         {2}       2
…/1/2               …/1/3         {3}       3
…/1/3               …/1/4         {4}       4
…/1/4               …/1/5         {5}       5
…/1/5               …/1/6         {1}       1
…/1/6               …/1/7         {2}       2
…/1/7               …/1/8         {3}       3
…/1/8               …/1/9         {4}       4
…/1/9               <after:/Max>  {5}       5

query T
EXPLAIN (VERBOSE)
SELECT *
FROM (SELECT * FROM data WHERE c = 1) AS l
NATURAL JOIN (SELECT * FROM data WHERE c > 0) AS r
----
distribution: full
vectorized: true
·
• project
│ columns: (a, b, c, d)
│
└── • lookup join (inner)
    │ columns: (a, b, c, d, a, b, c, d)
    │ estimated row count: 0
    │ table: data@data_pkey
    │ equality: (a, b, c, d) = (a,b,c,d)
    │ equality cols are key
    │ pred: c > 0
    │
    └── • filter
        │ columns: (a, b, c, d)
        │ estimated row count: 10
        │ filter: c = 1
        │
        └── • scan
              columns: (a, b, c, d)
              estimated row count: 100,000 (100% of the table; stats collected <hidden> ago)
              table: data@data_pkey
              spans: FULL SCAN

query T
EXPLAIN (DISTSQL)
SELECT *
FROM (SELECT * FROM data WHERE c = 1) AS l
NATURAL JOIN (SELECT * FROM data WHERE c > 0) AS r
----
distribution: full
vectorized: true
·
• lookup join
│ estimated row count: 0
│ table: data@data_pkey
│ equality: (a, b, c, d) = (a,b,c,d)
│ equality cols are key
│ pred: c > 0
│
└── • filter
    │ estimated row count: 10
    │ filter: c = 1
    │
    └── • scan
          estimated row count: 100,000 (100% of the table; stats collected <hidden> ago)
          table: data@data_pkey
          spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzMll9rm1AYxu_3KV7eq3acoMc_bXpgYOhSlpKZLsnYYAvD6qFztR53VNgo-e5D3dJYmnNczEVuAh59fJ73_T0QHzH_mSDD8eeb6Wjiw8nbyWK5-DA9hcV4Or5cwmu4ms_ew0n7MgqKAD69G8_HEMIboKcwWkAC_mj5cT6awvWsepVC8rU0TZuDWeskEkxFxP3ggefIviBFghYStJGggwRdXBHMpAh5ngtZPfJYCybRL2QmwTjNyqI6XhEMheTIHrGIi4Qjw2Vwm_A5DyIuDRMJRrwI4qS2qRJ51c-37J7_RoKXIikf0pxBQOCWQEggQoKLLKjOBgaFII2Agii-c4mrNUFRFk_OeRHccWR0Tbqnu4qTgksuDbcdrTln4NnVdhljE3853Glp_Y_ltYjTv_uguoVMhbgvM_gh4hREysCjxLOIZxOvwjLzwTvfoPwXctcaZ2XRfsGuaeyd0zwNUaZCRlzyqDXAav3CvL4YiMyg7rMnX_Z2Wt60e7Von2oZdGBYe5RLk29TrrPDlUtjuV0u3UqOoFxWd8BWL8DWwLD3AKzJtwF8fjjAGsttwLqVHAFguztguxdge2A4ewDW5NsAHh4OsMZyG7BuJUcA2OkO2OkF2BkY7h6ANfk2gC8OB1hjuQ1Yt5IjAKz5mpnzPBNpzjv9u5vV9wGP7njzMZGLUob8RoqwtmkuZ7WuPoh4XjR3aXMxSZtbVcBtMVWKLbXYUortlpg-F9vq2Gdqa0epdtViVynWOJ_1GfpcKR6qnYdK8YVafNEnNtV0TFcydcuopma0V8-opmiOxlzdNKqpGlV37Xn21frVnwAAAP__SgWtFg==

statement ok
CREATE TABLE books (title STRING, edition INT, shelf INT, PRIMARY KEY (title, edition))

statement ok
CREATE TABLE books2 (title STRING, edition INT, shelf INT, PRIMARY KEY (title, edition))

statement ok
ALTER TABLE books INJECT STATISTICS '[
  {
    "columns": ["title"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE books2 INJECT STATISTICS '[
  {
    "columns": ["title"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 1000
  }
]'

query T
EXPLAIN (VERBOSE) SELECT DISTINCT b1.title FROM books as b1 JOIN books2 as b2 ON b1.title = b2.title WHERE b1.shelf <> b2.shelf
----
distribution: local
vectorized: true
·
• distinct
│ columns: (title)
│ estimated row count: 100
│ distinct on: title
│ order key: title
│
└── • project
    │ columns: (title)
    │ ordering: +title
    │
    └── • lookup join (inner)
        │ columns: (title, shelf, title, shelf)
        │ ordering: +title
        │ estimated row count: 327
        │ table: books2@books2_pkey
        │ equality: (title) = (title)
        │ pred: shelf != shelf
        │
        └── • scan
              columns: (title, shelf)
              ordering: +title
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: books@books_pkey
              spans: FULL SCAN

statement ok
CREATE TABLE authors (name STRING, book STRING)

statement ok
ALTER TABLE authors INJECT STATISTICS '[
  {
    "columns": ["name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

query T
EXPLAIN (VERBOSE) SELECT DISTINCT authors.name FROM books AS b1, books2 AS b2, authors WHERE b1.title = b2.title AND authors.book = b1.title AND b1.shelf <> b2.shelf
----
distribution: local
vectorized: true
·
• distinct
│ columns: (name)
│ estimated row count: 96
│ distinct on: name
│
└── • project
    │ columns: (name)
    │
    └── • lookup join (inner)
        │ columns: (title, shelf, name, book, title, shelf)
        │ estimated row count: 323
        │ table: books2@books2_pkey
        │ equality: (book) = (title)
        │ pred: shelf != shelf
        │
        └── • hash join (inner)
            │ columns: (title, shelf, name, book)
            │ estimated row count: 99
            │ equality: (title) = (book)
            │
            ├── • scan
            │     columns: (title, shelf)
            │     estimated row count: 100 (100% of the table; stats collected <hidden> ago)
            │     table: books@books_pkey
            │     spans: FULL SCAN
            │
            └── • scan
                  columns: (name, book)
                  estimated row count: 100 (100% of the table; stats collected <hidden> ago)
                  table: authors@authors_pkey
                  spans: FULL SCAN

# Verify data placement.
query TTTI colnames
SELECT start_key, end_key, replicas, lease_holder from [SHOW RANGES FROM TABLE books WITH DETAILS]
----
start_key                end_key       replicas  lease_holder
<before:/Table/109/1/9>  <after:/Max>  {5}       5

query T
EXPLAIN (DISTSQL) SELECT DISTINCT authors.name FROM books AS b1, books2 AS b2, authors WHERE b1.title = b2.title AND authors.book = b1.title AND b1.shelf <> b2.shelf
----
distribution: local
vectorized: true
·
• distinct
│ estimated row count: 96
│ distinct on: name
│
└── • lookup join
    │ estimated row count: 323
    │ table: books2@books2_pkey
    │ equality: (book) = (title)
    │ pred: shelf != shelf
    │
    └── • hash join
        │ estimated row count: 99
        │ equality: (title) = (book)
        │
        ├── • scan
        │     estimated row count: 100 (100% of the table; stats collected <hidden> ago)
        │     table: books@books_pkey
        │     spans: FULL SCAN
        │
        └── • scan
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: authors@authors_pkey
              spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyck2-L2k4Qx5__XsX85lGErZpN9EHgYEUtZ7F6VaGFIiUxc5oas2l2Ay3iey-7Ua5aTc97ojs785n9zp_sUf1IMcDhl6dxbzQBZzCaL-afxg2YD8fD_gKMPZr0FxCWeiML1czCHcH72fQjRFJuFfTmELmsMri1ODsFw-fH4WwIjhO5TZ3olOABIl4dG9CbDMA5pTW88R4DG0d35DbVhtJn-N-S9txAhpmMaRLuSGHwFV1cMswLuSKlZGGu9jZgFP_EoM0wyfJSm-slw5UsCIM92lcwwEUYpTSjMKai1UaGMekwSW1aW5Kwv9_yLf1Chn2ZlrtMBWBxBlYPMpznobl9h8sDQ1nql_eUDteEgXtgb9Pknms6tksc___SZaZTDeM1qvhNVS9iykwWMRUUnwlZGvJfIVdKewzV5oNMMipa_LyylJ61I9zGQ5GsN9oR3Ix5WuoAhMsEZ8Jjwr9ZiXdPf42AY3u9KyPn1cz5qbljKbdlDt9lkoHMAhC-UTYBwc1Wim7NXlT6vZuy_XtkDxKlk2ylW_65aOHezN95U_7Oq_N378k_I5XLTNHlIl3N3DbbQ_Gaqm1UsixW9FTIlX2mMqeWsxcxKV15eWWMMuuy392fsHsHzC9hXgt7Z3D7EvZqYb8e9mvhTj3cqYW7F_Dy8N_vAAAA___MoPuW

query T
EXPLAIN (VERBOSE) SELECT a.name FROM authors AS a JOIN books2 AS b2 ON a.book = b2.title ORDER BY a.name
----
distribution: local
vectorized: true
·
• project
│ columns: (name)
│ ordering: +name
│
└── • lookup join (inner)
    │ columns: (name, book, title)
    │ ordering: +name
    │ estimated row count: 990
    │ table: books2@books2_pkey
    │ equality: (book) = (title)
    │
    └── • sort
        │ columns: (name, book)
        │ ordering: +name
        │ estimated row count: 100
        │ order: +name
        │
        └── • scan
              columns: (name, book)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: authors@authors_pkey
              spans: FULL SCAN

# Cross joins should not be planned as lookup joins.
query T
EXPLAIN (VERBOSE) SELECT * FROM books CROSS JOIN books2
----
distribution: local
vectorized: true
·
• cross join (inner)
│ columns: (title, edition, shelf, title, edition, shelf)
│ estimated row count: 1,000,000
│
├── • scan
│     columns: (title, edition, shelf)
│     estimated row count: 10,000 (100% of the table; stats collected <hidden> ago)
│     table: books2@books2_pkey
│     spans: FULL SCAN
│
└── • scan
      columns: (title, edition, shelf)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: books@books_pkey
      spans: FULL SCAN

query T
EXPLAIN (DISTSQL) SELECT * FROM authors INNER JOIN books2 ON books2.edition = 1 WHERE books2.title = authors.book
----
distribution: local
vectorized: true
·
• lookup join
│ estimated row count: 99
│ table: books2@books2_pkey
│ equality: (book, lookup_join_const_col_@7) = (title,edition)
│ equality cols are key
│
└── • render
    │
    └── • scan
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: authors@authors_pkey
          spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyUkm9r1EAQxt_7KYZ5pTJtb3MqslBYqRFTzqTmDhQkSHoZ23i5nbi7AeW47y75c9gKPdpXm3kmzzO_SXaH_leDGuOvV4t3SQrP3yfL1fLz4gUs40V8sYKX8CHPPkHZhVtxHpI0jXO4zJIUrkU2PoLs8HTKVR1qsXAOCr58jPP40Ah1aBjODyGnvYyEVipOyy171N9QYUHYOlmz9-J6aTe8kFS_Uc8Ia9t2oZcLwrU4Rr3DIRc1rsrrhnMuK3ZnMySsOJR1M8ROI810fm83_AcJL6TpttZrsOWWCSagZVv22gkS5mwrdhqU1jpJV28JjCIwERZ7QunCPxgfyhtGrfb0eOBLqe3Eq-7zjl_MjMeBdiGy6Vr4KbUFsRrMnIy6u8WQSzD9AAJ_y80PJMy6oMFE1BtekXlN5s2DC0RPWSCVE2nPonvsDwXPnxKcs2_Fen5U8mxfEHJ1w-N18dK5NV85WQ9jxjIbfINQsQ9jV41FYsdWD3jXrI6ao-Pm6Kh5_p-52D_7GwAA___rWSOM

####################################
#  LOOKUP JOIN ON SECONDARY INDEX  #
####################################

statement ok
CREATE TABLE small (a INT PRIMARY KEY, b INT, c INT, d INT)

statement ok
CREATE TABLE large (a INT, b INT, c INT, d INT, PRIMARY KEY (a, b), INDEX bc (b) STORING (c))

statement ok
ALTER TABLE small SPLIT AT SELECT i FROM generate_series(1, 9) AS g(i)

statement ok
ALTER TABLE small EXPERIMENTAL_RELOCATE
  SELECT ARRAY[i%5+1], i FROM generate_series(0, 9) AS g(i)

statement ok
INSERT INTO small SELECT x, 2*x, 3*x, 4*x FROM
  generate_series(1, 10) AS a(x)

statement ok
ALTER TABLE small INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE large INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

# Lookup join on covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.a, large.c FROM small JOIN large ON small.a = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (a, c)
│
└── • lookup join (inner)
    │ columns: (a, b, c)
    │ estimated row count: 1,000
    │ table: large@bc
    │ equality: (a) = (b)
    │
    └── • scan
          columns: (a)
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: small@small_pkey
          spans: FULL SCAN

# Lookup join on non-covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.a, large.d FROM small JOIN large ON small.a = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (a, d)
│
└── • project
    │ columns: (a, b, d)
    │
    └── • lookup join (inner)
        │ columns: (a, a, b, d)
        │ estimated row count: 1,000
        │ table: large@large_pkey
        │ equality: (a, b) = (a,b)
        │ equality cols are key
        │
        └── • lookup join (inner)
            │ columns: (a, a, b)
            │ estimated row count: 1,000
            │ table: large@bc
            │ equality: (a) = (b)
            │
            └── • scan
                  columns: (a)
                  estimated row count: 100 (100% of the table; stats collected <hidden> ago)
                  table: small@small_pkey
                  spans: FULL SCAN

############################
#  LEFT OUTER LOOKUP JOIN  #
############################

# Left join against primary index
query T
EXPLAIN (VERBOSE) SELECT small.b, large.a FROM small LEFT JOIN large ON small.b = large.a
----
distribution: full
vectorized: true
·
• lookup join (left outer)
│ columns: (b, a)
│ estimated row count: 100
│ table: large@large_pkey
│ equality: (b) = (a)
│
└── • scan
      columns: (b)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: small@small_pkey
      spans: FULL SCAN

# Left join should preserve input order.
query T
EXPLAIN (VERBOSE) SELECT t1.a, t2.b FROM small t1 LEFT JOIN large t2 ON t1.a = t2.a AND t2.b % 6 = 0 ORDER BY t1.a
----
distribution: full
vectorized: true
·
• project
│ columns: (a, b)
│ ordering: +a
│
└── • lookup join (left outer)
    │ columns: (a, a, b)
    │ ordering: +a
    │ estimated row count: 100
    │ table: large@large_pkey
    │ equality: (a) = (a)
    │ pred: (b % 6) = 0
    │
    └── • scan
          columns: (a)
          ordering: +a
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: small@small_pkey
          spans: FULL SCAN

query T
EXPLAIN (DISTSQL) SELECT t1.a, t2.b FROM small t1 LEFT JOIN large t2 ON t1.a = t2.a AND t2.b % 6 = 0 ORDER BY t1.a
----
distribution: full
vectorized: true
·
• lookup join (left outer)
│ estimated row count: 100
│ table: large@large_pkey
│ equality: (a) = (a)
│ pred: (b % 6) = 0
│
└── • scan
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: small@small_pkey
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzMlV9r2zAUxd_3KS4XBglT6sh20lRQcNe64JLZnePBxgjDjUWX1bU8W4aVku8-JHc0LosdnJe8GP3x0Tn3dwV6xvJ3igzdr7fzC8-HwZW3iBaf50NYuHP3MgJJT2IC0jy5g-sw-ATlY5ymcLEASWHuXkdwE3g-pHFxz_WqCYEPA6WCcyWLh3DhX8FgoI94D9MhnMN4CEF45Ybw8Zs2QIKZSLgfP_IS2XekSNBEghYStJHgBJcE80KseFmKQv3yrAVe8gfZmOA6yyuplpcEV6LgyJ5RrmXKkWEU36U85HHCC2OMBBMu43WqbXQtjv7-yB_4ExK8FGn1mJUMVKZFHqvhyKAQZwlQEPInL3C5ISgq-WpZyvieI6Mbsn-sG7HOXlJNmqmip5yzmm3wJXJDTRgJasaO_v5LOxfiocrhl1hnIDIGjgKn-DuWQs0Y8_xopom_jBslErjbWYy5s5jXGkSR8IInzfgO_YDLzX8q9sVI5AZ904Ogkio3caydUaxGFLp_u2mvdht0ZJg9Gt4RbKvh0-NvuLk_ZbMfZXNkWD0odwTbonx6_JSt_Slb_ShbI8PuQbkj2Bbl2fFTtvenbPejbI-MSQ_KHcG2KJ8dP-WO9y7kZS6ykjcK2XXyWL0fPLnn9XtTiqpY8dtCrLRNPQ20Ti8kvJT1Lq0nXlZvqYDbYtoqNhti-lZstjt3WFutartdbB-Se9IqnrY7Tw9xPm0Vz9qdZ4c4n7X3atxxTdov2Vvv5ebd3wAAAP__UXyRgQ==

# Left join against covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.c FROM small LEFT JOIN large ON small.c = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (c, c)
│
└── • lookup join (left outer)
    │ columns: (c, b, c)
    │ estimated row count: 1,000
    │ table: large@bc
    │ equality: (c) = (b)
    │
    └── • scan
          columns: (c)
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: small@small_pkey
          spans: FULL SCAN

# Left join against non-covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.d FROM small LEFT JOIN large ON small.c = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (c, d)
│
└── • project
    │ columns: (c, b, d)
    │
    └── • lookup join (left outer)
        │ columns: (c, a, b, d)
        │ estimated row count: 1,000
        │ table: large@large_pkey
        │ equality: (a, b) = (a,b)
        │ equality cols are key
        │
        └── • lookup join (left outer)
            │ columns: (c, a, b)
            │ estimated row count: 1,000
            │ table: large@bc
            │ equality: (c) = (b)
            │
            └── • scan
                  columns: (c)
                  estimated row count: 100 (100% of the table; stats collected <hidden> ago)
                  table: small@small_pkey
                  spans: FULL SCAN

# Left join with ON filter on covering index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.c FROM small LEFT JOIN large ON small.c = large.b AND large.c < 20
----
distribution: full
vectorized: true
·
• project
│ columns: (c, c)
│
└── • lookup join (left outer)
    │ columns: (c, b, c)
    │ estimated row count: 336
    │ table: large@bc
    │ equality: (c) = (b)
    │ pred: c < 20
    │
    └── • scan
          columns: (c)
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: small@small_pkey
          spans: FULL SCAN

# Left join with ON filter on non-covering index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.d FROM small LEFT JOIN large ON small.c = large.b AND large.d < 30
----
distribution: full
vectorized: true
·
• project
│ columns: (c, d)
│
└── • project
    │ columns: (c, b, d)
    │
    └── • lookup join (left outer)
        │ columns: (c, a, b, cont, b, d)
        │ estimated row count: 336
        │ table: large@large_pkey
        │ equality: (a, b) = (a,b)
        │ equality cols are key
        │ pred: d < 30
        │
        └── • lookup join (left outer)
            │ columns: (c, a, b, cont)
            │ estimated row count: 1,000
            │ table: large@bc
            │ equality: (c) = (b)
            │
            └── • scan
                  columns: (c)
                  estimated row count: 100 (100% of the table; stats collected <hidden> ago)
                  table: small@small_pkey
                  spans: FULL SCAN

# Left semi-join with ON filter on non-covering index
query T
EXPLAIN (VERBOSE) SELECT small.c FROM small WHERE EXISTS(SELECT 1 FROM large WHERE small.c = large.b AND large.d < 30)
----
distribution: full
vectorized: true
·
• project
│ columns: (c)
│
└── • lookup join (semi)
    │ columns: (c, a, b, cont)
    │ estimated row count: 100
    │ table: large@large_pkey
    │ equality: (a, b) = (a,b)
    │ equality cols are key
    │ pred: d < 30
    │
    └── • lookup join (inner)
        │ columns: (c, a, b, cont)
        │ estimated row count: 990
        │ table: large@bc
        │ equality: (c) = (b)
        │
        └── • scan
              columns: (c)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: small@small_pkey
              spans: FULL SCAN

# Left anti-join with ON filter on non-covering index
query T
EXPLAIN (VERBOSE) SELECT small.c FROM small WHERE NOT EXISTS(SELECT 1 FROM large WHERE small.c = large.b AND large.d < 30)
----
distribution: full
vectorized: true
·
• project
│ columns: (c)
│
└── • lookup join (anti)
    │ columns: (c, a, b, cont)
    │ estimated row count: 0
    │ table: large@large_pkey
    │ equality: (a, b) = (a,b)
    │ equality cols are key
    │ pred: d < 30
    │
    └── • lookup join (left outer)
        │ columns: (c, a, b, cont)
        │ estimated row count: 1,000
        │ table: large@bc
        │ equality: (c) = (b)
        │
        └── • scan
              columns: (c)
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: small@small_pkey
              spans: FULL SCAN

###########################################################
#  LOOKUP JOINS ON IMPLICIT INDEX KEY COLUMNS             #
#  https://github.com/cockroachdb/cockroach/issues/31777  #
###########################################################
statement ok
CREATE TABLE t (a INT, b INT, c INT, d INT, e INT)

statement ok
CREATE TABLE u (a INT, b INT, c INT, d INT, e INT, PRIMARY KEY (a DESC, b, c))

# Test index with all primary key columns implicit.
statement ok
CREATE INDEX idx ON u (d)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 1 (missing stats)
    │ table: u@idx
    │ equality: (d, a) = (d,a)
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@t_pkey
              spans: FULL SCAN

# Test unique version of same index. (Lookup join should not use column a.)
statement ok
DROP INDEX u@idx

statement ok
CREATE UNIQUE INDEX idx ON u (d)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d) = (d)
    │ equality cols are key
    │ pred: a = a
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@t_pkey
              spans: FULL SCAN

# Test index with first primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx CASCADE

statement ok
CREATE INDEX idx ON u (d, a)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.b = u.b WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│
└── • lookup join (inner)
    │ columns: (a, b, d, e, a, b, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d, a, b) = (d,a,b)
    │
    └── • filter
        │ columns: (a, b, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, b, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@t_pkey
              spans: FULL SCAN

# Test index with middle primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx

statement ok
CREATE INDEX idx ON u (d, b)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.b = u.b WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│
└── • lookup join (inner)
    │ columns: (a, b, d, e, a, b, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d, b, a) = (d,b,a)
    │
    └── • filter
        │ columns: (a, b, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, b, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@t_pkey
              spans: FULL SCAN

# Test index with last primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx

statement ok
CREATE INDEX idx ON u (d, c)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.d = u.d WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 1 (missing stats)
    │ table: u@idx
    │ equality: (d) = (d)
    │ pred: a = a
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@t_pkey
              spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM def JOIN abc ON a=f ORDER BY a
----
distribution: local
vectorized: true
·
• lookup join (inner)
│ columns: (d, e, f, a, b, c)
│ ordering: +a
│ estimated row count: 100
│ table: def@def_pkey
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      ordering: +a
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Test that we don't get a lookup join if we force a merge join.
query T
EXPLAIN (VERBOSE) SELECT * FROM def INNER MERGE JOIN abc ON a=f ORDER BY a
----
distribution: local
vectorized: true
·
• merge join (inner)
│ columns: (d, e, f, a, b, c)
│ ordering: +f
│ estimated row count: 100
│ equality: (f) = (a)
│ merge ordering: +"(f=a)"
│
├── • scan
│     columns: (d, e, f)
│     ordering: +f
│     estimated row count: 10,000 (100% of the table; stats collected <hidden> ago)
│     table: def@def_pkey
│     spans: FULL SCAN
│
└── • scan
      columns: (a, b, c)
      ordering: +a
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

# Test that we don't get a lookup join if we force a hash join.
query T
EXPLAIN (VERBOSE) SELECT * FROM def INNER HASH JOIN abc ON a=f ORDER BY a
----
distribution: local
vectorized: true
·
• sort
│ columns: (d, e, f, a, b, c)
│ ordering: +f
│ estimated row count: 100
│ order: +f
│
└── • hash join (inner)
    │ columns: (d, e, f, a, b, c)
    │ estimated row count: 100
    │ equality: (f) = (a)
    │
    ├── • scan
    │     columns: (d, e, f)
    │     estimated row count: 10,000 (100% of the table; stats collected <hidden> ago)
    │     table: def@def_pkey
    │     spans: FULL SCAN
    │
    └── • scan
          columns: (a, b, c)
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: abc@abc_pkey
          spans: FULL SCAN

# Test lookup semi and anti join.
query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f)
----
distribution: local
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 100
│ table: def@def_pkey
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f)
----
distribution: local
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 0
│ table: def@def_pkey
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f AND c=e)
----
distribution: local
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 100
│ table: def@def_pkey
│ equality: (a, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f AND c=e)
----
distribution: local
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 0
│ table: def@def_pkey
│ equality: (a, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f AND d+b>1)
----
distribution: local
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 33
│ table: def@def_pkey
│ equality: (a) = (f)
│ pred: (d + b) > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f AND d+b>1)
----
distribution: local
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 67
│ table: def@def_pkey
│ equality: (a) = (f)
│ pred: (d + b) > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: abc@abc_pkey
      spans: FULL SCAN

query T
 EXPLAIN (DISTSQL)
  SELECT a,b from small WHERE EXISTS (SELECT a FROM data WHERE small.a=data.a) ORDER BY a
----
distribution: full
vectorized: true
·
• lookup join (semi)
│ estimated row count: 100
│ table: data@data_pkey
│ equality: (a) = (a)
│
└── • scan
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: small@small_pkey
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzMlNFr2zAQxt_3Vxz31DK5jmwnTQ2DbK3LXNKkcwLrGGGo8dFldSzPcmAl5H8ftlsal0Y2zkP6IpB0H99P34lbo_oboYve7c3wsz-Cowt_Mp18Gx7DxBt651MQDO7gMhhfg1qKKILvX73AA-82L4Oj56KyIhSZeCooik8EfCoOT8QxjIMLL4AvP0Agw1iGNBJLUuj-RI4MLWRoI0MHGXZxxjBJ5ZyUkmlesi4EfvgP3Q7DRZyssvx4xnAuU0J3jdkiiwhdnIq7iAISIaVmBxmGlIlFVNgUSINi_ZU80CMyPJfRahkrt3glMpwkIt8ZJgcRh8BBZr8pxdmGoVxlL64qE_eELt-w5mRXchE_gXWrYNPHhFwYepdTmHjXPlyN_VFeITIxyJdn2qGUD6sE_shFDDJ2YcArT9iJae3EfKGTaUgphVWwAf-Is80bbxlJQyYmrwa8y96u2PPm_eNt-2dyw7RadLCGbauDvUN20GoeodU6Qssw7RYR1rBtRXh6yAjt5hHarSO0DdNpEWEN21aE_UNG6DSP0GkdoWOY3RYR1rBtRXj2XkbxG5gBqUTGihpN2U4-pym8p3KuK7lK53STynlhU27Hha44CEll5S0vN35cXuWA22KuFVsVMX8ttvTONda2Vu3oxc4-3F2tuKd37u3jfKoV9_XO_X2cz_S96tR8E_0ne-0923z4HwAA__-XZmPv

query T
 EXPLAIN (DISTSQL)
  SELECT a,b from small WHERE a+b<20 AND EXISTS (SELECT a FROM data WHERE small.a=data.a AND small.b+data.c>15) ORDER BY a
----
distribution: full
vectorized: true
·
• lookup join (semi)
│ estimated row count: 11
│ table: data@data_pkey
│ equality: (a) = (a)
│ pred: (b + c) > 15
│
└── • filter
    │ estimated row count: 33
    │ filter: (a + b) < 20
    │
    └── • scan
          estimated row count: 100 (100% of the table; stats collected <hidden> ago)
          table: small@small_pkey
          spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzMlmFrm14Uxt__P8XhvDLkpuaqaVPhD3atZZbUdElgHVsYN3rpslqvUwMrJd99qE1qynJvZgjkTcCjj89zz--B-ILZrwhtdO_vBheeD9qVN56MPw1aMHYH7uUEGIEZXI-Gt5A9sSiCzx_dkQuaxqANsxZ8W3S7ZgBGtwUX_hW494UctJW4UoYsZyth-ZYTBv-X0xNW6bTX-Qza1Tx4fTUH2mu1YDi6ckfw4QswJBiLkPvsiWdof0WKBA0kaCJBCwn2cEowSUXAs0ykxSMvpcALf6PdJTiPk0VejKcEA5FytF8wn-cRRxsnbBbxEWchT_UuEgx5zuZRaVPGc8rf78kjf0aClyJaPMWZXa4ICY4TVlx1dAosDoGCyH_wFKdLgmKRv7lmOXvgaNMl2T3Z9TzKecpTvbcZq5rboDkU2uAYNSC2bXv-pL_V3_gX_xsxj18XQ99tZvKccBsG7vUExu6tBzdDzy-eYDlzip_VugZCPC4S-CnmMYjYBqcgN_RBc4wiulUDvoq-ueNg61HMrUd5O4FIQ57ycDO7Q9s4Xf7lvL7oiESnm9veZm9t2NPdO0abdkynHd1o0DJFtnXLTg_UMoV_vWX0yFtm7I7ZaIzZ6OhmA8yKbGvMZwfCrPCvYzaOHLO5O2azMWazo1sNMCuyrTH3D4RZ4V_HbB45Zmt3zFZjzFZH7zXArMi2xnx-IMwK_zpm68gxK75yRjxLRJzxnf71u8V3Aw8fePWdkYlFGvC7VASlTXU5LHXlIORZXt2l1YUXV7eKgHUxlYoNudiQis0NMX0vNuWxT-XWllTdk4t7UrHC-XSfQ59JxX25c18qPpeLz_eJTRUdU5VM3jKqqBndq2dUUTRLYS5vGlVUjcq79j77dPnfnwAAAP__dDHHAA==

# Regression test for #40562.

statement ok
CREATE TABLE public.region
(
    r_regionkey int PRIMARY KEY,
    r_name char(25) NOT NULL,
    r_comment varchar(152)
)

statement ok
ALTER TABLE public.region INJECT STATISTICS '[
  {
    "columns": ["r_regionkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  },
  {
    "columns": ["r_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  },
  {
    "columns": ["r_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  }
]'

statement ok
CREATE TABLE public.nation
(
    n_nationkey int PRIMARY KEY,
    n_name char(25) NOT NULL,
    n_regionkey int NOT NULL,
    n_comment varchar(152),
    INDEX n_rk (n_regionkey ASC),
    CONSTRAINT nation_fkey_region FOREIGN KEY (n_regionkey) references public.region (r_regionkey)
)

statement ok
ALTER TABLE public.nation INJECT STATISTICS '[
  {
    "columns": ["n_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  },
  {
    "columns": ["n_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  },
  {
    "columns": ["n_regionkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 5
  },
  {
    "columns": ["n_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  }
]'

statement ok
CREATE TABLE public.supplier
(
    s_suppkey int PRIMARY KEY,
    s_name char(25) NOT NULL,
    s_address varchar(40) NOT NULL,
    s_nationkey int NOT NULL,
    s_phone char(15) NOT NULL,
    s_acctbal float NOT NULL,
    s_comment varchar(101) NOT NULL,
    INDEX s_nk (s_nationkey ASC),
    CONSTRAINT supplier_fkey_nation FOREIGN KEY (s_nationkey) references public.nation (n_nationkey)
)

statement ok
ALTER TABLE public.supplier INJECT STATISTICS '[
  {
    "columns": ["s_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_address"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 25
  },
  {
    "columns": ["s_phone"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_acctbal"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

statement ok
CREATE TABLE public.part
(
    p_partkey int PRIMARY KEY,
    p_name varchar(55) NOT NULL,
    p_mfgr char(25) NOT NULL,
    p_brand char(10) NOT NULL,
    p_type varchar(25) NOT NULL,
    p_size int NOT NULL,
    p_container char(10) NOT NULL,
    p_retailprice float NOT NULL,
    p_comment varchar(23) NOT NULL
)

statement ok
ALTER TABLE public.part INJECT STATISTICS '[
  {
    "columns": ["p_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 200000
  },
  {
    "columns": ["p_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 200000
  },
  {
    "columns": ["p_mfgr"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 5
  },
  {
    "columns": ["p_brand"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 25
  },
  {
    "columns": ["p_type"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 150
  },
  {
    "columns": ["p_size"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 50
  },
  {
    "columns": ["p_container"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 40
  },
  {
    "columns": ["p_retailprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 20000
  },
  {
    "columns": ["p_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 130000
  }
]'

statement ok
CREATE TABLE public.partsupp
(
    ps_partkey int NOT NULL,
    ps_suppkey int NOT NULL,
    ps_availqty int NOT NULL,
    ps_supplycost float NOT NULL,
    ps_comment varchar(199) NOT NULL,
    PRIMARY KEY (ps_partkey, ps_suppkey),
    INDEX ps_sk (ps_suppkey ASC),
    CONSTRAINT partsupp_fkey_part FOREIGN KEY (ps_partkey) references public.part (p_partkey),
    CONSTRAINT partsupp_fkey_supplier FOREIGN KEY (ps_suppkey) references public.supplier (s_suppkey)
)

statement ok
ALTER TABLE public.partsupp INJECT STATISTICS '[
  {
    "columns": ["ps_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 200000
  },
  {
    "columns": ["ps_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 10000
  },
  {
    "columns": ["ps_availqty"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 10000
  },
  {
    "columns": ["ps_supplycost"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 100000
  },
  {
    "columns": ["ps_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 800000
  }
]'

statement ok
CREATE TABLE public.customer
(
    c_custkey int PRIMARY KEY,
    c_name varchar(25) NOT NULL,
    c_address varchar(40) NOT NULL,
    c_nationkey int NOT NULL NOT NULL,
    c_phone char(15) NOT NULL,
    c_acctbal float NOT NULL,
    c_mktsegment char(10) NOT NULL,
    c_comment varchar(117) NOT NULL,
    INDEX c_nk (c_nationkey ASC),
    CONSTRAINT customer_fkey_nation FOREIGN KEY (c_nationkey) references public.nation (n_nationkey)
)

statement ok
ALTER TABLE public.customer INJECT STATISTICS '[
  {
    "columns": ["c_custkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_address"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 25
  },
  {
    "columns": ["c_phone"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_acctbal"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_mktsegment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 5
  },
  {
    "columns": ["c_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  }
]'

statement ok
CREATE TABLE public.orders
(
    o_orderkey int PRIMARY KEY,
    o_custkey int NOT NULL,
    o_orderstatus char(1) NOT NULL,
    o_totalprice float NOT NULL,
    o_orderdate date NOT NULL,
    o_orderpriority char(15) NOT NULL,
    o_clerk char(15) NOT NULL,
    o_shippriority int NOT NULL,
    o_comment varchar(79) NOT NULL,
    INDEX o_ck (o_custkey ASC),
    INDEX o_od (o_orderdate ASC),
    CONSTRAINT orders_fkey_customer FOREIGN KEY (o_custkey) references public.customer (c_custkey)
)

statement ok
ALTER TABLE public.orders INJECT STATISTICS '[
  {
    "columns": ["o_orderkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  },
  {
    "columns": ["o_custkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 100000
  },
  {
    "columns": ["o_orderstatus"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 3
  },
  {
    "columns": ["o_totalprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  },
  {
    "columns": ["o_orderdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 2500
  },
  {
    "columns": ["o_orderpriority"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 5
  },
  {
    "columns": ["o_clerk"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1000
  },
  {
    "columns": ["o_shippriority"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1
  },
  {
    "columns": ["o_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  }
]'

statement ok
CREATE TABLE public.lineitem
(
    l_orderkey int NOT NULL,
    l_partkey int NOT NULL,
    l_suppkey int NOT NULL,
    l_linenumber int NOT NULL,
    l_quantity float NOT NULL,
    l_extendedprice float NOT NULL,
    l_discount float NOT NULL,
    l_tax float NOT NULL,
    l_returnflag char(1) NOT NULL,
    l_linestatus char(1) NOT NULL,
    l_shipdate date NOT NULL,
    l_commitdate date NOT NULL,
    l_receiptdate date NOT NULL,
    l_shipinstruct char(25) NOT NULL,
    l_shipmode char(10) NOT NULL,
    l_comment varchar(44) NOT NULL,
    PRIMARY KEY (l_orderkey, l_linenumber),
    INDEX l_ok (l_orderkey ASC),
    INDEX l_pk (l_partkey ASC),
    INDEX l_sk (l_suppkey ASC),
    INDEX l_sd (l_shipdate ASC),
    INDEX l_cd (l_commitdate ASC),
    INDEX l_rd (l_receiptdate ASC),
    INDEX l_pk_sk (l_partkey ASC, l_suppkey ASC),
    INDEX l_sk_pk (l_suppkey ASC, l_partkey ASC),
    CONSTRAINT lineitem_fkey_orders FOREIGN KEY (l_orderkey) references public.orders (o_orderkey),
    CONSTRAINT lineitem_fkey_part FOREIGN KEY (l_partkey) references public.part (p_partkey),
    CONSTRAINT lineitem_fkey_supplier FOREIGN KEY (l_suppkey) references public.supplier (s_suppkey)
)

statement ok
ALTER TABLE public.lineitem INJECT STATISTICS '[
  {
    "columns": ["l_orderkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 1500000
  },
  {
    "columns": ["l_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 200000
  },
  {
    "columns": ["l_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 10000
  },
  {
    "columns": ["l_linenumber"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 7
  },
  {
    "columns": ["l_quantity"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 50
  },
  {
    "columns": ["l_extendedprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 1000000
  },
  {
    "columns": ["l_discount"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 11
  },
  {
    "columns": ["l_tax"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 9
  },
  {
    "columns": ["l_returnflag"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 3
  },
  {
    "columns": ["l_linestatus"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2
  },
  {
    "columns": ["l_shipdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_commitdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_receiptdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_shipinstruct"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 4
  },
  {
    "columns": ["l_shipmode"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 7
  },
  {
    "columns": ["l_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 4500000
  }
]'

query T
EXPLAIN SELECT s_name, count(*) AS numwait
    FROM supplier, lineitem AS l1, orders, nation
   WHERE s_suppkey = l1.l_suppkey
     AND o_orderkey = l1.l_orderkey
     AND o_orderstatus = 'F'
     AND l1.l_receiptdate > l1.l_commitdate
     AND EXISTS(
            SELECT *
              FROM lineitem AS l2
             WHERE l2.l_orderkey = l1.l_orderkey
               AND l2.l_suppkey != l1.l_suppkey
         )
     AND NOT EXISTS(
                SELECT *
                  FROM lineitem AS l3
                 WHERE l3.l_orderkey = l1.l_orderkey
                   AND l3.l_receiptdate > l3.l_commitdate
             )
     AND s_nationkey = n_nationkey
     AND n_name = 'SAUDI ARABIA'
GROUP BY s_name
ORDER BY numwait DESC, s_name
   LIMIT 100;
----
distribution: full
vectorized: true
·
• top-k
│ estimated row count: 0
│ order: -count_rows,+s_name
│ k: 100
│
└── • group (hash)
    │ estimated row count: 0
    │ group by: s_name
    │
    └── • lookup join (semi)
        │ estimated row count: 0
        │ table: lineitem@lineitem_pkey
        │ equality: (l_orderkey) = (l_orderkey)
        │ pred: l_suppkey != l_suppkey
        │
        └── • lookup join
            │ estimated row count: 0
            │ table: orders@orders_pkey
            │ equality: (l_orderkey) = (o_orderkey)
            │ equality cols are key
            │ pred: o_orderstatus = 'F'
            │
            └── • lookup join (anti)
                │ estimated row count: 0
                │ table: lineitem@lineitem_pkey
                │ equality: (l_orderkey) = (l_orderkey)
                │ pred: l_receiptdate > l_commitdate
                │
                └── • lookup join
                    │ estimated row count: 80,016
                    │ table: lineitem@lineitem_pkey
                    │ equality: (l_orderkey, l_linenumber) = (l_orderkey,l_linenumber)
                    │ equality cols are key
                    │ pred: l_receiptdate > l_commitdate
                    │
                    └── • lookup join
                        │ estimated row count: 240,049
                        │ table: lineitem@l_sk
                        │ equality: (s_suppkey) = (l_suppkey)
                        │
                        └── • lookup join
                            │ estimated row count: 400
                            │ table: supplier@supplier_pkey
                            │ equality: (s_suppkey) = (s_suppkey)
                            │ equality cols are key
                            │
                            └── • lookup join
                                │ estimated row count: 400
                                │ table: supplier@s_nk
                                │ equality: (n_nationkey) = (s_nationkey)
                                │
                                └── • filter
                                    │ estimated row count: 1
                                    │ filter: n_name = 'SAUDI ARABIA'
                                    │
                                    └── • scan
                                          estimated row count: 25 (100% of the table; stats collected <hidden> ago)
                                          table: nation@nation_pkey
                                          spans: FULL SCAN

# Regression test for #50964.
statement ok
CREATE TABLE tab4 (
  pk INT8 PRIMARY KEY, col0 INT8, col1 FLOAT8, col2 STRING, col3 INT8, col4 FLOAT8, col5 STRING,
  UNIQUE (col3 DESC, col4 DESC)
)

query T
EXPLAIN (VERBOSE)
  SELECT pk FROM tab4 WHERE col0 IN (SELECT col3 FROM tab4 WHERE col4 = 495.6) AND (col3 IS NULL)
----
distribution: full
vectorized: true
·
• project
│ columns: (pk)
│
└── • project
    │ columns: (pk, col0, col3)
    │
    └── • lookup join (semi)
        │ columns: ("lookup_join_const_col_@15", pk, col0, col3)
        │ estimated row count: 10 (missing stats)
        │ table: tab4@tab4_col3_col4_key
        │ equality: (col0, lookup_join_const_col_@15) = (col3,col4)
        │ equality cols are key
        │
        └── • render
            │ columns: ("lookup_join_const_col_@15", pk, col0, col3)
            │ render lookup_join_const_col_@15: 495.6
            │ render pk: pk
            │ render col0: col0
            │ render col3: col3
            │
            └── • index join
                │ columns: (pk, col0, col3)
                │ estimated row count: 10 (missing stats)
                │ table: tab4@tab4_pkey
                │ key columns: pk
                │
                └── • scan
                      columns: (pk, col3)
                      estimated row count: 10 (missing stats)
                      table: tab4@tab4_col3_col4_key
                      spans: /NULL-

###########################################################
#  LOOKUP JOINS WITH LOOKUP EXPRESSIONS                   #
#  https://github.com/cockroachdb/cockroach/issues/59615  #
###########################################################

# Regression test for #59615. Ensure that invalid lookup joins are not created
# for left and anti joins.
statement ok
CREATE TABLE t59615 (
  x INT NOT NULL CHECK (x in (1, 3)),
  y INT NOT NULL,
  z INT,
  PRIMARY KEY (x, y)
)

query T
EXPLAIN (DISTSQL) SELECT * FROM (VALUES (1), (2)) AS u(y) LEFT JOIN t59615 t ON u.y = t.y
----
distribution: local
vectorized: true
·
• lookup join (left outer)
│ table: t59615@t59615_pkey
│ lookup condition: (x IN (1, 3)) AND (column1 = y)
│
└── • values
      size: 1 column, 2 rows
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyUkdFr1TAUxt_9Kw7nKZWw3XRONDDodeugo7az7YYgRUp7mPV2SW0SWL3c_13aCDrhij6155x858vvyx7NtwElxh9v022SAbtKyqr8kAZQxml8WcFLuC7y98Dut-ldXAITAQcWBgFsS3DA5gDS-LqCmzzJwJ6_fS3Ol4mFPAN3MsMF2JMZOSrdUdY8kkH5CQXWHMdJt2SMnpbWfj2QdE8oNxx7NTq7tGuOrZ4I5R5tbwdCiffN4MicbpBjR7bph3XjK3gHLIT2i1M7E2B94Kid_bXF2OaBUG4O_N-dbnSvCmo6mk7Fc7dqHkl67vyuiouVHjl6_sh_Po87WshTrXduhK-6V6CVBBaFsAQtpJRJVr3hcPbzbwk1uwIWCbiA6CxAjpd6cI_KSHjiMHP4fpRM_A9ZQWbUytAzquOZ1RypeyD_Tka7qaXbSberjS_zVbc2OjLWT4UvEuVHywV_F4u_isM_xPXhxY8AAAD__xke0OM=

query T
EXPLAIN (DISTSQL) SELECT * FROM (VALUES (1), (2)) AS u(y) WHERE NOT EXISTS (
  SELECT * FROM t59615 t WHERE u.y = t.y
)
----
distribution: local
vectorized: true
·
• lookup join (anti)
│ table: t59615@t59615_pkey
│ lookup condition: (x IN (1, 3)) AND (column1 = y)
│
└── • values
      size: 1 column, 2 rows
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyUkW9r1EAQxt_7KYZ5tZGlvb1a0YXCne0WU2KuJrEWJEhIhhov3Y3ZXWg47rvLJgU94URfJfPnN7PPMzu0PzqUqO5vk3WcAruK8yL_mESQq0RdFvASrrPNB2B36-STyoGJiANbRhGsc_DAxgg-v1eZgnRTgLoPMLBD1J2_fS3OQ7977vUnI1yAOxkj5KhNQ2n1SBblFxRYcuwHU5O1Zgip3dQQN08oFxxb3XsX0iXH2gyEcoeudR2hxLuq82RPF8ixIVe13TTxFbwDtoT6m9dbG2G552i8-zXFuuqBUC72_N833ZhWZ1Q1NJyKw23F2JOERF0XsE6LGG42cYocZwtW8-drv6UROSbGbH0P302rwWgJbLWEcAEhpYzT4g2Hs-e_4HZ6BWwl4AJWZ8G1S9P5R20lPHEYj6oS_6MqI9sbbelA0XG_So7UPNB8I2v8UNPtYOppzRxuJm5KNGTdXBVzEOu5FB74Oyz-Ci__gMv9i58BAAD__yZh1ng=

statement ok
CREATE TABLE lookup_expr (
  r STRING NOT NULL CHECK (r IN ('east', 'west')),
  v INT NOT NULL,
  w INT,
  x INT,
  y INT NOT NULL CHECK (y IN (10, 20)),
  z INT NOT NULL CHECK (z = 5),
  PRIMARY KEY (r, v),
  INDEX (r, x, y, z, w)
)

query T
EXPLAIN (DISTSQL) SELECT * FROM (VALUES (1, 10), (2, 20), (3, NULL)) AS u(w, x) LEFT JOIN lookup_expr t
ON u.w = t.w AND u.x = t.x
----
distribution: local
vectorized: true
·
• lookup join (left outer)
│ table: lookup_expr@lookup_expr_r_x_y_z_w_idx
│ lookup condition: ((((r IN ('east', 'west')) AND (column2 = x)) AND (y IN (10, 20))) AND ("lookup_join_const_col_@8" = z)) AND (column1 = w)
│
└── • render
    │
    └── • values
          size: 2 columns, 3 rows
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyUkm9rnEAQxt_3UwzzJlqG5PTydyGw18QUg9VUvVAoh8g5pDbGta72vBz33YvaXi-FlPbdPDPz7Ay_nQ3qbwUKdD7deTPXB-PajeLoo2dC5HjOVQxv4SYMPoBxP_PmTgSGRWBNTALDJrCHYErgzz3PNGEWQQvGiqAzwXNuYrgNXB8KpR7bKuGuqvuOBgIfjPZwBZfQHK5MmPnXve4G3ZlIWKqM_fSJNYrPaOGCsKrVkrVWdZ_aDA1u1qGYEOZl1TZ9ekG4VDWj2GCTNwWjwPu0aFkfTZAw4ybNi_FFC96BMYXll7Z81P3AkMuMawEnQgjXj88JpEUgbVxsCVXb_J6gm_SBUUy29O9b3Kq8DDnNuD6yXm4SrysWI6pgHjvhAAwJ95DJvTipky5ZJ8_JKsmzDgm9oQZfVV6CKgUYhmHIY-j_8YBT3RwIIaI4dP33BAcr3k-YP8HLKVyCPNvJ88FtTXYk7F-hueuxesvFTtq9PO05XqmifSq1gJrgO0F_CQRrgmckDNpGgLRJTkkekzwheUryjOQ5yYtXOVv_wzlkXalS8wvGr__ggpCzBx4vSqu2XvJdrZbDmFEGg29IZKybsWqNwi3HUr_gvtn6q9n-w7zYvvkRAAD__74CCoU=

query T
EXPLAIN (DISTSQL) SELECT * FROM (VALUES (1, 10), (2, 20), (3, NULL)) AS u(w, x) WHERE NOT EXISTS (
  SELECT * FROM lookup_expr t WHERE u.w = t.w AND u.x = t.x
)
----
distribution: local
vectorized: true
·
• lookup join (anti)
│ table: lookup_expr@lookup_expr_r_x_y_z_w_idx
│ lookup condition: ((((r IN ('east', 'west')) AND (column2 = x)) AND (y IN (10, 20))) AND ("lookup_join_const_col_@8" = z)) AND (column1 = w)
│
└── • render
    │
    └── • values
          size: 2 columns, 3 rows
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyUklFrnEAQx9_7KYZ5yVqG5PSaNiwEvCamNVgvVZMGyiFyDqmNca2rnMlx372spte7Qkr7Nv-Z_c0M_5016h8lSvRur4KZH4I49-Mk_hxYEHuBd5bAa7iI5p9A3MyCay8GYRPYE4tAOATOEEwJwusgsCyYxdCBWBH0Fnz56EUehPMEvFvTEsR-w1Kp-65Oua8bw7XPgOgOV3AK7eHKgll4bnQ_6N6ykLBSOYfZA2uUX9HGBWHdqCVrrRqTWg8P_LxHOSEsqrprTXpBuFQNo1xjW7Qlo8SbrOxYH02QMOc2K8qxow3vQUxh-a2r7rUZGHGVcyPhWErph8kJgWsTuA4uNoSqa39P0G12xygnG_r3LS5VUUWc5dwc2fubJI81Swi8iwRmYeLD5dwPkXDHNXcnTpu0Tx_Tp3SVFnmPhMFQg--qqEBVEoQQwn0D5oMPONPtgZQyTiI__EBwsOLdhPVsvDuFU3DfbuW7gbYnWyOcX6G1fWMb5GQrHSOPjY1nquweKi2hITD3QfBI8ISE866V4DrkTl901P4fRyPWtao077n58l8tCDm_4_F2tOqaJV81ajmMGeV84IZEzrodq_Yo_GosmQV3YfuvsPMHvNi8-hkAAP__j1EMSw==

# The following tests check that if the joiners can separate a row request
# into separate families that it does, and generates spans for each family
# instead of reading the entire row when it doesn't need to.

statement ok
CREATE TABLE family_split_1 (x INT, PRIMARY KEY (x))

statement ok
INSERT INTO family_split_1 VALUES (1)

statement ok
CREATE TABLE family_split_2 (x INT, y INT, z INT, PRIMARY KEY (x), FAMILY f1 (x), FAMILY f2 (y), FAMILY f3 (z))

statement ok
INSERT INTO family_split_2 VALUES (1, 2, 3)

query T kvtrace(Scan)
SELECT family_split_2.x, family_split_2.z FROM family_split_1 INNER LOOKUP JOIN family_split_2 ON family_split_1.x = family_split_2.x; SET tracing = off
----
Scan /Table/128/{1-2}
Scan /Table/129/1/1/0, /Table/129/1/1/2/1

statement ok
CREATE TABLE family_index_join (x INT PRIMARY KEY, y INT, z INT, w INT, INDEX (y), FAMILY f1 (x), FAMILY f2 (y), FAMILY f3 (z), FAMILY f4(w))

statement ok
INSERT INTO family_index_join VALUES (1, 2, 3, 4)

query T kvtrace(Scan)
SELECT y,w FROM family_index_join@family_index_join_y_idx WHERE y = 2
----
Scan /Table/130/2/{2-3}
Scan /Table/130/1/1/{0-1/2}, /Table/130/1/1/3/1

statement ok
SET variable_inequality_lookup_join_enabled=false

query T
EXPLAIN SELECT * FROM abc INNER LOOKUP JOIN def_e_decimal ON f = b AND e <= a::DECIMAL ORDER BY a, b, c, d, e, f
----
distribution: local
vectorized: true
·
• sort
│ estimated row count: 33
│ order: +a,+b,+c,+d,+e
│ already ordered: +a
│
└── • lookup join
    │ estimated row count: 33
    │ table: def_e_decimal@def_e_decimal_pkey
    │ equality: (b) = (f)
    │ pred: column11 >= e
    │
    └── • render
        │
        └── • scan
              estimated row count: 100 (100% of the table; stats collected <hidden> ago)
              table: abc@abc_pkey
              spans: FULL SCAN

statement ok
RESET variable_inequality_lookup_join_enabled
