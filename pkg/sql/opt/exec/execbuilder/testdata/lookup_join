# LogicTest: 5node

statement ok
CREATE TABLE abc (a INT, b INT, c INT, PRIMARY KEY (a, c))

statement ok
CREATE TABLE def (d INT, e INT, f INT, PRIMARY KEY (f, e))

# Set up the statistics as if the first table is much smaller than the second.
# This will make lookup join into the second table be the best plan.
statement ok
ALTER TABLE abc INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE def INJECT STATISTICS '[
  {
    "columns": ["f"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 99
│ table: def@primary
│ equality: (b) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b AND e = c
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 0
│ table: def@primary
│ equality: (b, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b WHERE a > 1 AND e > 1
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@primary
│ equality: (b) = (f)
│ pred: e > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33
      table: abc@primary
      spans: /2-

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = a WHERE f > 1
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@primary
│ equality: (a) = (f)
│ pred: f > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 33
      table: abc@primary
      spans: /2-

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b WHERE a >= e
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@primary
│ equality: (b) = (f)
│ pred: a >= e
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM abc JOIN def ON f = b AND a >= e
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (a, b, c, d, e, f)
│ estimated row count: 33
│ table: def@primary
│ equality: (b) = (f)
│ pred: a >= e
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

# Verify a distsql plan.
statement ok
CREATE TABLE data (a INT, b INT, c INT, d INT, PRIMARY KEY (a, b, c, d))

# Split into ten parts.
statement ok
ALTER TABLE data SPLIT AT SELECT i FROM generate_series(1, 9) AS g(i)

statement ok
ALTER TABLE data INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100000,
    "distinct_count": 100000
  }
]'

# Relocate the ten parts to the five nodes.
statement ok
ALTER TABLE data EXPERIMENTAL_RELOCATE
  SELECT ARRAY[i%5+1], i FROM generate_series(0, 9) AS g(i)

# Verify data placement.
query TTTI colnames,rowsort
SELECT start_key, end_key, replicas, lease_holder from [SHOW RANGES FROM TABLE data]
----
start_key  end_key  replicas  lease_holder
NULL       /1       {1}       1
/1         /2       {2}       2
/2         /3       {3}       3
/3         /4       {4}       4
/4         /5       {5}       5
/5         /6       {1}       1
/6         /7       {2}       2
/7         /8       {3}       3
/8         /9       {4}       4
/9         NULL     {5}       5

query T
EXPLAIN (VERBOSE)
SELECT *
FROM (SELECT * FROM data WHERE c = 1) AS l
NATURAL JOIN (SELECT * FROM data WHERE c > 0) AS r
----
distribution: full
vectorized: true
·
• project
│ columns: (a, b, c, d)
│ estimated row count: 0
│
└── • lookup join (inner)
    │ columns: (a, b, c, d, a, b, c, d)
    │ estimated row count: 0
    │ table: data@primary
    │ equality: (a, b, c, d) = (a,b,c,d)
    │ equality cols are key
    │ pred: c > 0
    │
    └── • filter
        │ columns: (a, b, c, d)
        │ estimated row count: 10
        │ filter: c = 1
        │
        └── • scan
              columns: (a, b, c, d)
              estimated row count: 100,000
              table: data@primary
              spans: FULL SCAN

query T
SELECT url FROM [EXPLAIN (DISTSQL)
SELECT *
FROM (SELECT * FROM data WHERE c = 1) AS l
NATURAL JOIN (SELECT * FROM data WHERE c > 0) AS r]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJzEld9r2z4Uxd-_f8XlPrVfZGz5R5sKBg5bylIyp0syNuj84MWi8-ZanmzDRsn_Pmx3aVwSyUtC9ijlnpxz_TmgRyx-pMhwPpqMXi-gkilcz6bv4G706XYyHAdw9mY8X8zfT87haeT_duCse4yjMoKPb0ezESzhFdBzGM4hhWC4-DAbTuBmWv-VQvK5siyHg9XoZIgEMxHzIHrgBbI7pEjQRoIOEnSRoIchwVyKJS8KIeuRx0Ywjn8iswgmWV6V9XVIcCkkR_aIZVKmHBkuoi8pn_Eo5tK0kGDMyyhJG5s6kp_L5CGSv5DgPI-ygoFhUoiyGCiI8iuXGK4Iiqp8dijK6J4joyvSP8V1kpZccml63QjtPQPfqT8jY2wcLAY7Le2_sbwRSfa0N1UvPhHie5XDN5FkIDIGPiW-TXyH-PXHnwbgX66J_YlIcFqV3dFdqZ2dqZ_DVpmQMZc87gQNV1v2CoQhcpN6Lya3e7sdb9q_KrRPVUxqmPYeZdHkWJfl4nhl0VhulkW9-knLYvcHZvcCZhumswcwTY41sMvjAdNYbgJTr35SYE5_YE4vYI5hunsA0-RYAxscD5jGchOYevWTAnP7A3N7AXMN09sDmCbHGtjV8YBpLDeBqVf_Z-_nltQzXuQiK3iv19Gq31ce3_P2MS5EJZf8VoplY9Mep42uuYh5Uba_0vYwztqf6oCbYqoU22qxrRQ7HTF9KXbUsS_U1q5S7anFnlKscb44ZOlLpXigdh4oxVdq8dUhsammY7qSqVtGNTWjB_WMaormaszVTaOaqlF1115mD1f__Q4AAP__Rs1urw==

statement ok
CREATE TABLE books (title STRING, edition INT, shelf INT, PRIMARY KEY (title, edition))

statement ok
CREATE TABLE books2 (title STRING, edition INT, shelf INT, PRIMARY KEY (title, edition))

statement ok
ALTER TABLE books INJECT STATISTICS '[
  {
    "columns": ["title"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE books2 INJECT STATISTICS '[
  {
    "columns": ["title"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 1000
  }
]'

query T
EXPLAIN (VERBOSE) SELECT DISTINCT b1.title FROM books as b1 JOIN books2 as b2 ON b1.title = b2.title WHERE b1.shelf <> b2.shelf
----
distribution: full
vectorized: true
·
• distinct
│ columns: (title)
│ estimated row count: 100
│ distinct on: title
│ order key: title
│
└── • project
    │ columns: (title)
    │ ordering: +title
    │
    └── • lookup join (inner)
        │ columns: (title, shelf, title, shelf)
        │ ordering: +title
        │ estimated row count: 327
        │ table: books2@primary
        │ equality: (title) = (title)
        │ pred: shelf != shelf
        │
        └── • scan
              columns: (title, shelf)
              ordering: +title
              estimated row count: 100
              table: books@primary
              spans: FULL SCAN

statement ok
CREATE TABLE authors (name STRING, book STRING)

statement ok
ALTER TABLE authors INJECT STATISTICS '[
  {
    "columns": ["name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

query T
EXPLAIN (VERBOSE) SELECT DISTINCT authors.name FROM books AS b1, books2 AS b2, authors WHERE b1.title = b2.title AND authors.book = b1.title AND b1.shelf <> b2.shelf
----
distribution: full
vectorized: true
·
• distinct
│ columns: (name)
│ estimated row count: 96
│ distinct on: name
│
└── • project
    │ columns: (name)
    │
    └── • lookup join (inner)
        │ columns: (title, shelf, name, book, title, shelf)
        │ estimated row count: 323
        │ table: books2@primary
        │ equality: (book) = (title)
        │ pred: shelf != shelf
        │
        └── • hash join (inner)
            │ columns: (title, shelf, name, book)
            │ estimated row count: 99
            │ equality: (title) = (book)
            │
            ├── • scan
            │     columns: (title, shelf)
            │     estimated row count: 100
            │     table: books@primary
            │     spans: FULL SCAN
            │
            └── • scan
                  columns: (name, book)
                  estimated row count: 100
                  table: authors@primary
                  spans: FULL SCAN

# Verify data placement.
query TTTI colnames
SELECT start_key, end_key, replicas, lease_holder from [SHOW RANGES FROM TABLE books]
----
start_key  end_key  replicas  lease_holder
NULL       NULL     {5}       5

query T
SELECT url FROM [EXPLAIN (DISTSQL) SELECT DISTINCT authors.name FROM books AS b1, books2 AS b2, authors WHERE b1.title = b2.title AND authors.book = b1.title AND b1.shelf <> b2.shelf]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJyck1Fv2jAQx9_3Kbx7SiS34CRQKVIlo8JUJhY6QNqkioeEXCFrsDPbkTYhvvuUhK4ENaH0zee739__O9s70L9T8GE-mozuFiRXKfkym34jj6OfD5PBOCDWcDxfzL9PbHIoKeJxcLcgYW42UulrEW6xgiIpnzUZzEnEaBU4ZeTQl2Ly4340GxHLiti1SUyK5JZETrW0ySAYEutFtuCL7KHQPqQjdq03mD6RzyVZru0lUBAyxiDcogb_ERhQ6MGSQqbkCrWWqtjelUXj-A_4XQqJyHJTbC8prKRC8HdQHgU-BPJKZp0-UIjRhElalu0pyNy8QtqEawT_Zk-PhFm78CKMUpxhGKPqdGvyUA6MZyrZhuovUJhnodA-uQIK09z4hDPKXWhywT7qgtVdHMZ_xofT6MNp9PF6fC6kilFhfDrf8yVvNHMf6s1XmQhUHafeS4pPxuLMvlXJemMs7ti1Hih3KfcaO3EvmWhh4DBQ941rdY7mOZHyOc_IL5kIIoVPuFe4Cgh3ijfNb_57bL5s7xJrw0SbRKxMx6sb46xRv_ch_d679fs1_TN_cYY6k0Ljuz5jt3ghGK-xenFa5mqFD0quymOqcFpy5UaM2lTZmyoYiypVGDyGWSvs1mB2CjsXwM4p7LbCXrttrxXutcO9VrjfDvdb4e4JvNx_-hcAAP__NdMdAw==

query T
EXPLAIN (VERBOSE) SELECT a.name FROM authors AS a JOIN books2 AS b2 ON a.book = b2.title ORDER BY a.name
----
distribution: full
vectorized: true
·
• project
│ columns: (name)
│ ordering: +name
│ estimated row count: 990
│
└── • lookup join (inner)
    │ columns: (name, book, title)
    │ ordering: +name
    │ estimated row count: 990
    │ table: books2@primary
    │ equality: (book) = (title)
    │
    └── • sort
        │ columns: (name, book)
        │ ordering: +name
        │ estimated row count: 100
        │ order: +name
        │
        └── • scan
              columns: (name, book)
              estimated row count: 100
              table: authors@primary
              spans: FULL SCAN

# Cross joins should not be planned as lookup joins.
query T
EXPLAIN (VERBOSE) SELECT * FROM books CROSS JOIN books2
----
distribution: full
vectorized: true
·
• cross join (inner)
│ columns: (title, edition, shelf, title, edition, shelf)
│ estimated row count: 1,000,000
│
├── • scan
│     columns: (title, edition, shelf)
│     estimated row count: 10,000
│     table: books2@primary
│     spans: FULL SCAN
│
└── • scan
      columns: (title, edition, shelf)
      estimated row count: 100
      table: books@primary
      spans: FULL SCAN

query T
SELECT url FROM [EXPLAIN (DISTSQL) SELECT * FROM authors INNER JOIN books2 ON books2.edition = 1 WHERE books2.title = authors.book]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJyUkd9r1EAQx9_9K4Z5Upm2l5wVWShENGLKmdTcgULJQ3o71LXpTtzdgHLc_y5J7vBOuGjfMj8-33yS2aD_0aDCZbpI362gcw18KItPcJt-vVm8zXJ4_j5brpafFy9gt_JyXKi78E2chyzP0xKuiyyHO5EHH0OxfzpnbYIRC1cQwZePaZnuB8GEhuFqH3LetysktKI5rx_Zo7rFCAkvsSJsnazZe3F9ezMsZfonqhmhsW0X-nZFuBbHqDY4hKPCXM6kvYiRUHOoTTOsbQmlC38gH-p7RjXf0kFwNB28qu8aLrnW7C5mR_G4-6Ckdeaxdr-QcNnW1is4Q8KSrWanIFJKZfnqDUESESQxnrKKnmJ1LcbupKJjqfGnHzgtRB66Fr6LsSBWQTKnpGeKLihIYurrV5RcUvL6pFt85PaPU5TsW7Ge_-sWs21FyPqex3N76dyab5ysh9eMZTFwQ0OzD-N0PhaZHUe94CEcTcLxNBxPwrO_4Gr77HcAAAD__0XeE20=

####################################
#  LOOKUP JOIN ON SECONDARY INDEX  #
####################################

statement ok
CREATE TABLE small (a INT PRIMARY KEY, b INT, c INT, d INT)

statement ok
CREATE TABLE large (a INT, b INT, c INT, d INT, PRIMARY KEY (a, b), INDEX bc (b) STORING (c))

statement ok
ALTER TABLE small SPLIT AT SELECT i FROM generate_series(1, 9) AS g(i)

statement ok
ALTER TABLE small EXPERIMENTAL_RELOCATE
  SELECT ARRAY[i%5+1], i FROM generate_series(0, 9) AS g(i)

statement ok
INSERT INTO small SELECT x, 2*x, 3*x, 4*x FROM
  generate_series(1, 10) AS a(x)

statement ok
ALTER TABLE small INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

statement ok
ALTER TABLE large INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

# Lookup join on covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.a, large.c FROM small JOIN large ON small.a = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (a, c)
│ estimated row count: 1,000
│
└── • lookup join (inner)
    │ columns: (a, b, c)
    │ estimated row count: 1,000
    │ table: large@bc
    │ equality: (a) = (b)
    │
    └── • scan
          columns: (a)
          estimated row count: 100
          table: small@primary
          spans: FULL SCAN

# Lookup join on non-covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.a, large.d FROM small JOIN large ON small.a = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (a, d)
│ estimated row count: 1,000
│
└── • project
    │ columns: (a, b, d)
    │ estimated row count: 1,000
    │
    └── • lookup join (inner)
        │ columns: (a, a, b, d)
        │ table: large@primary
        │ equality: (a, b) = (a,b)
        │ equality cols are key
        │
        └── • lookup join (inner)
            │ columns: (a, a, b)
            │ estimated row count: 1,000
            │ table: large@bc
            │ equality: (a) = (b)
            │
            └── • scan
                  columns: (a)
                  estimated row count: 100
                  table: small@primary
                  spans: FULL SCAN

############################
#  LEFT OUTER LOOKUP JOIN  #
############################

# Left join against primary index
query T
EXPLAIN (VERBOSE) SELECT small.b, large.a FROM small LEFT JOIN large ON small.b = large.a
----
distribution: full
vectorized: true
·
• lookup join (left outer)
│ columns: (b, a)
│ estimated row count: 100
│ table: large@primary
│ equality: (b) = (a)
│
└── • scan
      columns: (b)
      estimated row count: 100
      table: small@primary
      spans: FULL SCAN

# Left join should preserve input order.
query T
EXPLAIN (VERBOSE) SELECT t1.a, t2.b FROM small t1 LEFT JOIN large t2 ON t1.a = t2.a AND t2.b % 6 = 0 ORDER BY t1.a
----
distribution: full
vectorized: true
·
• project
│ columns: (a, b)
│ ordering: +a
│ estimated row count: 100
│
└── • lookup join (left outer)
    │ columns: (a, a, b)
    │ ordering: +a
    │ estimated row count: 100
    │ table: large@primary
    │ equality: (a) = (a)
    │ pred: (b % 6) = 0
    │
    └── • scan
          columns: (a)
          ordering: +a
          estimated row count: 100
          table: small@primary
          spans: FULL SCAN

query T
SELECT url FROM [EXPLAIN (DISTSQL) SELECT t1.a, t2.b FROM small t1 LEFT JOIN large t2 ON t1.a = t2.a AND t2.b % 6 = 0 ORDER BY t1.a]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJzMlV9r2zwUxu_fT3E48ELClDqynTQVFNKtKaRkdud4sFF8ocai8-ZanizDSsl3H5YLdcpiG3yTu-jPk-c5vyN8XrD4nSLD7Wqz-hRCqVK4CfzPcL_6dre5Wnswul5vw-2XzRher2h6xglo--yhvlk88TSFqy1oCpvVTQi3_tqDlKtHYXZt8D0YVSq4rGR8DFfeNYxG5i_-h_kYLmE6Bj-4XgXw8bsxiJBgJmPh8SdRILtHigRtJOggQRcJzjAimCu5E0UhVXXlxQjW8R9kU4JJlpe62o4I7qQSyF5QJzoVyDDkD6kIBI-FsqZIMBaaJ6mxMcUsc5U8cfWMBLc5zwoGE4sCz2KgIPUPoZCgX2oGS4rRnqAs9ZtZofmjQEb3pH-gW5lkr3lmh3nC51ywGqv_NVwFBi4SNHgbOTdS_ipz-CmTDGRmkhGsuC-dCjFjbO2FC0P69fdbDWTpHC3DPlrGW3qpYqFEfBh8ST9gtP9HrZ6cyNyih9yP2TsH9rR_W2mvtlp0YtmDGtsRqdHY-Sk31u5P1u5H1p5YziCyHZEaZM9PmazTn6zTj6wzsdxBZDsiNcguTpms25-s24-sO7Fmg8h2RGqQvThlsh3TKhBFLrNC9PqCT6sZIOJHUc-MQpZqJ-6U3BmbeukbndmIRaHrU1ov1ll9VAVsimmr2D4Q0_diu925w9ppVbvtYndI7lmreN7uPB_ifN4qXrQ7L4Y4X7T3atrxTNof2XvvaP_f3wAAAP__d9J4OQ==

# Left join against covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.c FROM small LEFT JOIN large ON small.c = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (c, c)
│ estimated row count: 1,000
│
└── • lookup join (left outer)
    │ columns: (c, b, c)
    │ estimated row count: 1,000
    │ table: large@bc
    │ equality: (c) = (b)
    │
    └── • scan
          columns: (c)
          estimated row count: 100
          table: small@primary
          spans: FULL SCAN

# Left join against non-covering secondary index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.d FROM small LEFT JOIN large ON small.c = large.b
----
distribution: full
vectorized: true
·
• project
│ columns: (c, d)
│ estimated row count: 1,000
│
└── • project
    │ columns: (c, b, d)
    │ estimated row count: 1,000
    │
    └── • lookup join (left outer)
        │ columns: (c, a, b, d)
        │ table: large@primary
        │ equality: (a, b) = (a,b)
        │ equality cols are key
        │
        └── • lookup join (left outer)
            │ columns: (c, a, b)
            │ estimated row count: 1,000
            │ table: large@bc
            │ equality: (c) = (b)
            │
            └── • scan
                  columns: (c)
                  estimated row count: 100
                  table: small@primary
                  spans: FULL SCAN

# Left join with ON filter on covering index
query T
EXPLAIN (VERBOSE) SELECT small.c, large.c FROM small LEFT JOIN large ON small.c = large.b AND large.c < 20
----
distribution: full
vectorized: true
·
• project
│ columns: (c, c)
│ estimated row count: 336
│
└── • lookup join (left outer)
    │ columns: (c, b, c)
    │ estimated row count: 336
    │ table: large@bc
    │ equality: (c) = (b)
    │ pred: c < 20
    │
    └── • scan
          columns: (c)
          estimated row count: 100
          table: small@primary
          spans: FULL SCAN

# Left join with ON filter on non-covering index
# TODO(radu): this doesn't use lookup join yet, the current rules don't cover
# left join with ON condition on columns that are not covered by the index.
query T
EXPLAIN (VERBOSE) SELECT small.c, large.d FROM small LEFT JOIN large ON small.c = large.b AND large.d < 30
----
distribution: full
vectorized: true
·
• project
│ columns: (c, d)
│ estimated row count: 336
│
└── • hash join (right outer)
    │ columns: (b, d, c)
    │ estimated row count: 336
    │ equality: (b) = (c)
    │
    ├── • filter
    │   │ columns: (b, d)
    │   │ estimated row count: 3,303
    │   │ filter: d < 30
    │   │
    │   └── • scan
    │         columns: (b, d)
    │         estimated row count: 10,000
    │         table: large@primary
    │         spans: FULL SCAN
    │
    └── • scan
          columns: (c)
          estimated row count: 100
          table: small@primary
          spans: FULL SCAN

###########################################################
#  LOOKUP JOINS ON IMPLICIT INDEX KEY COLUMNS             #
#  https://github.com/cockroachdb/cockroach/issues/31777  #
###########################################################
statement ok
CREATE TABLE t (a INT, b INT, c INT, d INT, e INT)

statement ok
CREATE TABLE u (a INT, b INT, c INT, d INT, e INT, PRIMARY KEY (a DESC, b, c))

# Test index with all primary key columns implicit.
statement ok
CREATE INDEX idx ON u (d)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│ estimated row count: 1 (missing stats)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 1 (missing stats)
    │ table: u@idx
    │ equality: (d, a) = (d,a)
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@primary
              spans: FULL SCAN

# Test unique version of same index. (Lookup join should not use column a.)
statement ok
DROP INDEX u@idx

statement ok
CREATE UNIQUE INDEX idx ON u (d)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│ estimated row count: 0 (missing stats)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d) = (d)
    │ equality cols are key
    │ pred: a = a
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@primary
              spans: FULL SCAN

# Test index with first primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx CASCADE

statement ok
CREATE INDEX idx ON u (d, a)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.b = u.b WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│ estimated row count: 0 (missing stats)
│
└── • lookup join (inner)
    │ columns: (a, b, d, e, a, b, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d, a, b) = (d,a,b)
    │
    └── • filter
        │ columns: (a, b, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, b, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@primary
              spans: FULL SCAN

# Test index with middle primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx

statement ok
CREATE INDEX idx ON u (d, b)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.b = u.b WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│ estimated row count: 0 (missing stats)
│
└── • lookup join (inner)
    │ columns: (a, b, d, e, a, b, d)
    │ estimated row count: 0 (missing stats)
    │ table: u@idx
    │ equality: (d, b, a) = (d,b,a)
    │
    └── • filter
        │ columns: (a, b, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, b, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@primary
              spans: FULL SCAN

# Test index with last primary key column explicit and the rest implicit.
statement ok
DROP INDEX u@idx

statement ok
CREATE INDEX idx ON u (d, c)

query T
EXPLAIN (VERBOSE) SELECT u.a FROM t JOIN u ON t.d = u.d AND t.a = u.a AND t.d = u.d WHERE t.e = 5
----
distribution: full
vectorized: true
·
• project
│ columns: (a)
│ estimated row count: 1 (missing stats)
│
└── • lookup join (inner)
    │ columns: (a, d, e, a, d)
    │ estimated row count: 1 (missing stats)
    │ table: u@idx
    │ equality: (d) = (d)
    │ pred: a = a
    │
    └── • filter
        │ columns: (a, d, e)
        │ estimated row count: 10 (missing stats)
        │ filter: e = 5
        │
        └── • scan
              columns: (a, d, e)
              estimated row count: 1,000 (missing stats)
              table: t@primary
              spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * FROM def JOIN abc ON a=f ORDER BY a
----
distribution: full
vectorized: true
·
• lookup join (inner)
│ columns: (d, e, f, a, b, c)
│ ordering: +a
│ estimated row count: 100
│ table: def@primary
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      ordering: +a
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

# Test that we don't get a lookup join if we force a merge join.
query T
EXPLAIN (VERBOSE) SELECT * FROM def INNER MERGE JOIN abc ON a=f ORDER BY a
----
distribution: full
vectorized: true
·
• merge join (inner)
│ columns: (d, e, f, a, b, c)
│ ordering: +f
│ estimated row count: 100
│ equality: (f) = (a)
│ merge ordering: +"(f=a)"
│
├── • scan
│     columns: (d, e, f)
│     ordering: +f
│     estimated row count: 10,000
│     table: def@primary
│     spans: FULL SCAN
│
└── • scan
      columns: (a, b, c)
      ordering: +a
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

# Test that we don't get a lookup join if we force a hash join.
query T
EXPLAIN (VERBOSE) SELECT * FROM def INNER HASH JOIN abc ON a=f ORDER BY a
----
distribution: full
vectorized: true
·
• sort
│ columns: (d, e, f, a, b, c)
│ ordering: +f
│ estimated row count: 100
│ order: +f
│
└── • hash join (inner)
    │ columns: (d, e, f, a, b, c)
    │ estimated row count: 100
    │ equality: (f) = (a)
    │
    ├── • scan
    │     columns: (d, e, f)
    │     estimated row count: 10,000
    │     table: def@primary
    │     spans: FULL SCAN
    │
    └── • scan
          columns: (a, b, c)
          estimated row count: 100
          table: abc@primary
          spans: FULL SCAN

# Test lookup semi and anti join.
query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f)
----
distribution: full
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 100
│ table: def@primary
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f)
----
distribution: full
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 0
│ table: def@primary
│ equality: (a) = (f)
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f AND c=e)
----
distribution: full
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 100
│ table: def@primary
│ equality: (a, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f AND c=e)
----
distribution: full
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 0
│ table: def@primary
│ equality: (a, c) = (f,e)
│ equality cols are key
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE EXISTS (SELECT * FROM def WHERE a=f AND d+b>1)
----
distribution: full
vectorized: true
·
• lookup join (semi)
│ columns: (a, b, c)
│ estimated row count: 33
│ table: def@primary
│ equality: (a) = (f)
│ pred: (d + b) > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
EXPLAIN (VERBOSE) SELECT * from abc WHERE NOT EXISTS (SELECT * FROM def WHERE a=f AND d+b>1)
----
distribution: full
vectorized: true
·
• lookup join (anti)
│ columns: (a, b, c)
│ estimated row count: 67
│ table: def@primary
│ equality: (a) = (f)
│ pred: (d + b) > 1
│
└── • scan
      columns: (a, b, c)
      estimated row count: 100
      table: abc@primary
      spans: FULL SCAN

query T
SELECT url FROM [ EXPLAIN (DISTSQL)
  SELECT a,b from small WHERE EXISTS (SELECT a FROM data WHERE small.a=data.a) ORDER BY a
]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJzMlF9vmzAUxd_3Ka7uU6uZEgPpH6RJ2VaqUaVJRyKtU8WDG6yOjWBmG2lVlO8-AZlKqhYs8ZA9Yp-j8-Nc625Q_c7Qx0UwDT4voZQZXEXzG7gP7m6nH8MZHF2Gi-Xi6_QYdhJG4KHRqDXLMvj2JYgCCO4qGRz9EzWKhGm2E9TiEwYf6sMTdgzz6DKI4NN3YDESzEXCZ2zNFfr3SJGggwRdJOghwTHGBAspVlwpISvJpjaEyR_0RwTTvCh1dRwTXAnJ0d-gTnXG0ccle8h4xFnCpT1CggnXLM3qmJppUsh0zeQTElwULFc-WDYFlidAQegfXCLBeal9mFAycTDeEhSlfs5Tmj1y9OmWmDNdizTfIY33kZZPBfdhGlwtYRHchHA9D2eVgmnWAp0K8ass4KdIcxB5hWYG6bwJ-cwmZMIlT_axJvQ9xttX_mQmLFHYdL_Yt-LdvXhqPjdqNDebWrYzdHI9VK3JnR5uco55dY5ZdY5lu0Or66FqVXd2uOpc8-pcs-pcy_aGVtdD1aru_HDVeebVeWbVeZY9HlpdD1Wruov_Y9W-AhlxVYhccaMtOqr2ME8eebO3lSjlit9Ksapjms957asPEq50c0ubjzBvrirAtpl2mp09M31pdrqTe6LdTrfXbfaGcI87zafdyadDks86zefdyedDki-6ZzXqeSbdj-xldrx99zcAAP__MnFS0w==

query T
SELECT url FROM [ EXPLAIN (DISTSQL)
  SELECT a,b from small WHERE a+b<20 AND EXISTS (SELECT a FROM data WHERE small.a=data.a AND small.b+data.c>15) ORDER BY a
]
----
https://cockroachdb.github.io/distsqlplan/decode.html#eJzMllFvmz4Uxd__n-LqPiWKU2IgbYr0l9KtVKNKSZdEWqcuD06wOjaKmQFpVZXvPgFpSqrVZkKR8piLD-dwf0eKnzH9FaGDc3fiflxALiO4mk1v4N69u51ceD50Lr35Yv550oXtEUZgVZ1JH1kUwZdP7syFTodBD1Zd-JYPBtYazEEXLvxLcO8KOXRexJUyYBl7EZZvOWHwfzk9YZWus52voFfN19tXc6DDbhems0t3Bh--AlsiwVgE3GePPEXnHikSNJGghQRtJDjEJcFEijVPUyGLI8-lwAt-ozMgGMZJnhXjJcG1kBydZ8zCLOLo4IKtIj7jLODSGCDBgGcsjEqbMt84keEjk09IcJ6wOHWgb1BgcQAURPadSyQ4zTMHxpSMTVxuCIo8e_VLM_bA0aEb0jzTVRhlXHJpDPcDVXMHOmMKPRibNRaO43j-YvSuv_kv_tcijLcroW92snhKuAMT92oBc_fGg-up5xcnWMZqm5oI8TNP4IcIYxBxsZtiSz50xmYRfFgj_RK80Ratd7_iNbyQAZc82I89pj1cbv7yqb7oi8Sg-4t-z97es6fNi0UbFcugfcNsWy1Nql21Tg9ULY1_vVr0eKtlNmdrNmNr9g2rLVtNqh3bswOx1fjX2ZrHy9ZqztZqxtbqG3ZbtppUO7ajA7HV-NfZWsfL1m7O1m7G1u4bw7ZsNal2bM8PxFbjX2drHy9bzaVlxtNExClv9E8-KO4CPHjg1d0hFblc81sp1qVN9XNa6spBwNOsekqrH15cPSoC1sVUKTbVYlMptvbE9K3YUsc-VVvbSvVQLR4qxRrn0zYffaYUj9TOI6X4XC0-bxObajqmK5m6ZVRTM9qqZ1RTNFtjrm4a1VSNqrv2Nvty89-fAAAA___XIrJ-

# Regression test for #35950: Make sure that lookup joins use a batch limit.

statement ok
CREATE TABLE a (a INT, b INT, PRIMARY KEY (a, b))

statement ok
CREATE TABLE b (a INT PRIMARY KEY)

# We insert over 10k rows, which is the currently configured batch limit.

statement ok
INSERT INTO a SELECT 1, g FROM generate_series(1,11000) g

statement ok
INSERT INTO b VALUES(1)

query T
EXPLAIN SELECT count(*) FROM (SELECT * FROM b NATURAL INNER LOOKUP JOIN a)
----
distribution: full
vectorized: true
·
• group (scalar)
│
└── • lookup join
    │ table: a@primary
    │ equality: (a) = (a)
    │
    └── • scan
          missing stats
          table: b@primary
          spans: FULL SCAN

statement ok
SET tracing = on

query I
SELECT count(*) FROM (SELECT * FROM b NATURAL INNER LOOKUP JOIN a)
----
11000

statement ok
SET tracing = off

let $lookupTableID
SELECT 'a'::regclass::oid

# Now assert that we get more than 1 separate batch request into the lookup
# table, since the first one wouldn't have returned all of the results.

query T
SELECT message FROM [SHOW TRACE FOR SESSION] WHERE message LIKE 'Scan /Table/$lookupTableID%'
----
Scan /Table/63/1/{1-2}
Scan /Table/63/1/{1/10001/0-2}


# Regression test for #40562.

statement ok
CREATE TABLE public.region
(
    r_regionkey int PRIMARY KEY,
    r_name char(25) NOT NULL,
    r_comment varchar(152)
)

statement ok
ALTER TABLE public.region INJECT STATISTICS '[
  {
    "columns": ["r_regionkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  },
  {
    "columns": ["r_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  },
  {
    "columns": ["r_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 5,
    "distinct_count": 5
  }
]'

statement ok
CREATE TABLE public.nation
(
    n_nationkey int PRIMARY KEY,
    n_name char(25) NOT NULL,
    n_regionkey int NOT NULL,
    n_comment varchar(152),
    INDEX n_rk (n_regionkey ASC),
    CONSTRAINT nation_fkey_region FOREIGN KEY (n_regionkey) references public.region (r_regionkey)
)

statement ok
ALTER TABLE public.nation INJECT STATISTICS '[
  {
    "columns": ["n_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  },
  {
    "columns": ["n_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  },
  {
    "columns": ["n_regionkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 5
  },
  {
    "columns": ["n_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 25,
    "distinct_count": 25
  }
]'

statement ok
CREATE TABLE public.supplier
(
    s_suppkey int PRIMARY KEY,
    s_name char(25) NOT NULL,
    s_address varchar(40) NOT NULL,
    s_nationkey int NOT NULL,
    s_phone char(15) NOT NULL,
    s_acctbal float NOT NULL,
    s_comment varchar(101) NOT NULL,
    INDEX s_nk (s_nationkey ASC),
    CONSTRAINT supplier_fkey_nation FOREIGN KEY (s_nationkey) references public.nation (n_nationkey)
)

statement ok
ALTER TABLE public.supplier INJECT STATISTICS '[
  {
    "columns": ["s_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_address"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 25
  },
  {
    "columns": ["s_phone"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_acctbal"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  },
  {
    "columns": ["s_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 10000,
    "distinct_count": 10000
  }
]'

statement ok
CREATE TABLE public.part
(
    p_partkey int PRIMARY KEY,
    p_name varchar(55) NOT NULL,
    p_mfgr char(25) NOT NULL,
    p_brand char(10) NOT NULL,
    p_type varchar(25) NOT NULL,
    p_size int NOT NULL,
    p_container char(10) NOT NULL,
    p_retailprice float NOT NULL,
    p_comment varchar(23) NOT NULL
)

statement ok
ALTER TABLE public.part INJECT STATISTICS '[
  {
    "columns": ["p_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 200000
  },
  {
    "columns": ["p_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 200000
  },
  {
    "columns": ["p_mfgr"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 5
  },
  {
    "columns": ["p_brand"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 25
  },
  {
    "columns": ["p_type"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 150
  },
  {
    "columns": ["p_size"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 50
  },
  {
    "columns": ["p_container"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 40
  },
  {
    "columns": ["p_retailprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 20000
  },
  {
    "columns": ["p_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 200000,
    "distinct_count": 130000
  }
]'

statement ok
CREATE TABLE public.partsupp
(
    ps_partkey int NOT NULL,
    ps_suppkey int NOT NULL,
    ps_availqty int NOT NULL,
    ps_supplycost float NOT NULL,
    ps_comment varchar(199) NOT NULL,
    PRIMARY KEY (ps_partkey, ps_suppkey),
    INDEX ps_sk (ps_suppkey ASC),
    CONSTRAINT partsupp_fkey_part FOREIGN KEY (ps_partkey) references public.part (p_partkey),
    CONSTRAINT partsupp_fkey_supplier FOREIGN KEY (ps_suppkey) references public.supplier (s_suppkey)
)

statement ok
ALTER TABLE public.partsupp INJECT STATISTICS '[
  {
    "columns": ["ps_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 200000
  },
  {
    "columns": ["ps_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 10000
  },
  {
    "columns": ["ps_availqty"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 10000
  },
  {
    "columns": ["ps_supplycost"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 100000
  },
  {
    "columns": ["ps_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 800000,
    "distinct_count": 800000
  }
]'

statement ok
CREATE TABLE public.customer
(
    c_custkey int PRIMARY KEY,
    c_name varchar(25) NOT NULL,
    c_address varchar(40) NOT NULL,
    c_nationkey int NOT NULL NOT NULL,
    c_phone char(15) NOT NULL,
    c_acctbal float NOT NULL,
    c_mktsegment char(10) NOT NULL,
    c_comment varchar(117) NOT NULL,
    INDEX c_nk (c_nationkey ASC),
    CONSTRAINT customer_fkey_nation FOREIGN KEY (c_nationkey) references public.nation (n_nationkey)
)

statement ok
ALTER TABLE public.customer INJECT STATISTICS '[
  {
    "columns": ["c_custkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_name"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_address"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_nationkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 25
  },
  {
    "columns": ["c_phone"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_acctbal"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  },
  {
    "columns": ["c_mktsegment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 5
  },
  {
    "columns": ["c_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 150000,
    "distinct_count": 150000
  }
]'

statement ok
CREATE TABLE public.orders
(
    o_orderkey int PRIMARY KEY,
    o_custkey int NOT NULL,
    o_orderstatus char(1) NOT NULL,
    o_totalprice float NOT NULL,
    o_orderdate date NOT NULL,
    o_orderpriority char(15) NOT NULL,
    o_clerk char(15) NOT NULL,
    o_shippriority int NOT NULL,
    o_comment varchar(79) NOT NULL,
    INDEX o_ck (o_custkey ASC),
    INDEX o_od (o_orderdate ASC),
    CONSTRAINT orders_fkey_customer FOREIGN KEY (o_custkey) references public.customer (c_custkey)
)

statement ok
ALTER TABLE public.orders INJECT STATISTICS '[
  {
    "columns": ["o_orderkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  },
  {
    "columns": ["o_custkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 100000
  },
  {
    "columns": ["o_orderstatus"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 3
  },
  {
    "columns": ["o_totalprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  },
  {
    "columns": ["o_orderdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 2500
  },
  {
    "columns": ["o_orderpriority"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 5
  },
  {
    "columns": ["o_clerk"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1000
  },
  {
    "columns": ["o_shippriority"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1
  },
  {
    "columns": ["o_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1500000,
    "distinct_count": 1500000
  }
]'

statement ok
CREATE TABLE public.lineitem
(
    l_orderkey int NOT NULL,
    l_partkey int NOT NULL,
    l_suppkey int NOT NULL,
    l_linenumber int NOT NULL,
    l_quantity float NOT NULL,
    l_extendedprice float NOT NULL,
    l_discount float NOT NULL,
    l_tax float NOT NULL,
    l_returnflag char(1) NOT NULL,
    l_linestatus char(1) NOT NULL,
    l_shipdate date NOT NULL,
    l_commitdate date NOT NULL,
    l_receiptdate date NOT NULL,
    l_shipinstruct char(25) NOT NULL,
    l_shipmode char(10) NOT NULL,
    l_comment varchar(44) NOT NULL,
    PRIMARY KEY (l_orderkey, l_linenumber),
    INDEX l_ok (l_orderkey ASC),
    INDEX l_pk (l_partkey ASC),
    INDEX l_sk (l_suppkey ASC),
    INDEX l_sd (l_shipdate ASC),
    INDEX l_cd (l_commitdate ASC),
    INDEX l_rd (l_receiptdate ASC),
    INDEX l_pk_sk (l_partkey ASC, l_suppkey ASC),
    INDEX l_sk_pk (l_suppkey ASC, l_partkey ASC),
    CONSTRAINT lineitem_fkey_orders FOREIGN KEY (l_orderkey) references public.orders (o_orderkey),
    CONSTRAINT lineitem_fkey_part FOREIGN KEY (l_partkey) references public.part (p_partkey),
    CONSTRAINT lineitem_fkey_supplier FOREIGN KEY (l_suppkey) references public.supplier (s_suppkey)
)

statement ok
ALTER TABLE public.lineitem INJECT STATISTICS '[
  {
    "columns": ["l_orderkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 1500000
  },
  {
    "columns": ["l_partkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 200000
  },
  {
    "columns": ["l_suppkey"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 10000
  },
  {
    "columns": ["l_linenumber"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 7
  },
  {
    "columns": ["l_quantity"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 50
  },
  {
    "columns": ["l_extendedprice"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 1000000
  },
  {
    "columns": ["l_discount"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 11
  },
  {
    "columns": ["l_tax"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 9
  },
  {
    "columns": ["l_returnflag"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 3
  },
  {
    "columns": ["l_linestatus"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2
  },
  {
    "columns": ["l_shipdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_commitdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_receiptdate"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 2500
  },
  {
    "columns": ["l_shipinstruct"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 4
  },
  {
    "columns": ["l_shipmode"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 7
  },
  {
    "columns": ["l_comment"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 6001215,
    "distinct_count": 4500000
  }
]'

query T
EXPLAIN SELECT s_name, count(*) AS numwait
    FROM supplier, lineitem AS l1, orders, nation
   WHERE s_suppkey = l1.l_suppkey
     AND o_orderkey = l1.l_orderkey
     AND o_orderstatus = 'F'
     AND l1.l_receiptdate > l1.l_commitdate
     AND EXISTS(
            SELECT *
              FROM lineitem AS l2
             WHERE l2.l_orderkey = l1.l_orderkey
               AND l2.l_suppkey != l1.l_suppkey
         )
     AND NOT EXISTS(
                SELECT *
                  FROM lineitem AS l3
                 WHERE l3.l_orderkey = l1.l_orderkey
                   AND l3.l_receiptdate > l3.l_commitdate
             )
     AND s_nationkey = n_nationkey
     AND n_name = 'SAUDI ARABIA'
GROUP BY s_name
ORDER BY numwait DESC, s_name
   LIMIT 100;
----
distribution: full
vectorized: true
·
• limit
│ count: 100
│
└── • sort
    │ order: -count_rows,+s_name
    │
    └── • group
        │ group by: s_name
        │
        └── • lookup join (semi)
            │ table: lineitem@primary
            │ equality: (l_orderkey) = (l_orderkey)
            │ pred: l_suppkey != l_suppkey
            │
            └── • lookup join
                │ table: orders@primary
                │ equality: (l_orderkey) = (o_orderkey)
                │ equality cols are key
                │ pred: o_orderstatus = 'F'
                │
                └── • lookup join (anti)
                    │ table: lineitem@primary
                    │ equality: (l_orderkey) = (l_orderkey)
                    │ pred: l_receiptdate > l_commitdate
                    │
                    └── • lookup join
                        │ table: lineitem@primary
                        │ equality: (l_orderkey, l_linenumber) = (l_orderkey,l_linenumber)
                        │ equality cols are key
                        │ pred: l_receiptdate > l_commitdate
                        │
                        └── • lookup join
                            │ table: lineitem@l_sk
                            │ equality: (s_suppkey) = (l_suppkey)
                            │
                            └── • lookup join
                                │ table: supplier@primary
                                │ equality: (s_suppkey) = (s_suppkey)
                                │ equality cols are key
                                │
                                └── • lookup join
                                    │ table: supplier@s_nk
                                    │ equality: (n_nationkey) = (s_nationkey)
                                    │
                                    └── • filter
                                        │ filter: n_name = 'SAUDI ARABIA'
                                        │
                                        └── • scan
                                              estimated row count: 25
                                              table: nation@primary
                                              spans: FULL SCAN

# Regression test for #50964.
statement ok
CREATE TABLE tab4 (
  pk INT8 PRIMARY KEY, col0 INT8, col1 FLOAT8, col2 STRING, col3 INT8, col4 FLOAT8, col5 STRING,
  UNIQUE (col3 DESC, col4 DESC)
)

query T
EXPLAIN (VERBOSE)
  SELECT pk FROM tab4 WHERE col0 IN (SELECT col3 FROM tab4 WHERE col4 = 495.6) AND (col3 IS NULL)
----
distribution: full
vectorized: true
·
• project
│ columns: (pk)
│ estimated row count: 10 (missing stats)
│
└── • project
    │ columns: (pk, col0, col3)
    │ estimated row count: 10 (missing stats)
    │
    └── • lookup join (semi)
        │ columns: ("project_const_col_@15", pk, col0, col3)
        │ table: tab4@tab4_col3_col4_key
        │ equality: (col0, project_const_col_@15) = (col3,col4)
        │ equality cols are key
        │
        └── • render
            │ columns: ("project_const_col_@15", pk, col0, col3)
            │ estimated row count: 10 (missing stats)
            │ render 0: 495.6
            │ render 1: pk
            │ render 2: col0
            │ render 3: col3
            │
            └── • index join
                │ columns: (pk, col0, col3)
                │ estimated row count: 10 (missing stats)
                │ table: tab4@primary
                │ key columns: pk
                │
                └── • scan
                      columns: (pk, col3)
                      estimated row count: 10 (missing stats)
                      table: tab4@tab4_col3_col4_key
                      spans: /NULL-

# The following tests check that if the joiners can separate a row request
# into separate families that it does, and generates spans for each family
# instead of reading the entire row when it doesn't need to.

statement ok
CREATE TABLE family_split_1 (x INT, PRIMARY KEY (x))

statement ok
INSERT INTO family_split_1 VALUES (1)

statement ok
CREATE TABLE family_split_2 (x INT, y INT, z INT, PRIMARY KEY (x), FAMILY f1 (x), FAMILY f2 (y), FAMILY f3 (z))

statement ok
INSERT INTO family_split_2 VALUES (1, 2, 3)

query T kvtrace(Scan)
SELECT family_split_2.x, family_split_2.z FROM family_split_1 INNER LOOKUP JOIN family_split_2 ON family_split_1.x = family_split_2.x; SET tracing = off
----
Scan /Table/74/{1-2}
Scan /Table/75/1/1/{0-1}, /Table/75/1/1/2/{1-2}

statement ok
CREATE TABLE family_index_join (x INT PRIMARY KEY, y INT, z INT, w INT, INDEX (y), FAMILY f1 (x), FAMILY f2 (y), FAMILY f3 (z), FAMILY f4(w))

statement ok
INSERT INTO family_index_join VALUES (1, 2, 3, 4)

query T kvtrace(Scan)
SELECT y,w FROM family_index_join@family_index_join_y_idx WHERE y = 2
----
Scan /Table/76/2/{2-3}
Scan /Table/76/1/1/{0-1/2}, /Table/76/1/1/3/{1-2}

# Test generating tighter spans on interleaved tables.
statement ok
CREATE TABLE family_interleave_1 (x INT, y INT, z INT, PRIMARY KEY (x), FAMILY f1 (x), FAMILY f2 (y), FAMILY f3 (z))

statement ok
CREATE TABLE family_interleave_2 (x INT, y INT, PRIMARY KEY (x, y)) INTERLEAVE IN PARENT family_interleave_1 (x)

statement ok
INSERT INTO family_interleave_1 VALUES (1, 2, 3)

statement ok
INSERT INTO family_interleave_2 VALUES (1, 3)

query T kvtrace(Scan)
SELECT family_interleave_1.x, family_interleave_1.z FROM family_interleave_2 INNER LOOKUP JOIN family_interleave_1 ON family_interleave_1.x = family_interleave_2.x
----
Scan /Table/77/{1-2}
Scan /Table/77/1/1/{0-1}, /Table/77/1/1/2/{1-2}
