# LogicTest: local

statement ok
CREATE TABLE a (a INT, b INT, c INT4, PRIMARY KEY (a, b))

statement ok
CREATE TABLE c (a INT, b INT, c INT, d INT, PRIMARY KEY (a, c), INDEX sec (b))

statement ok
CREATE TABLE d (a INT, b INT, PRIMARY KEY (b, a))

statement ok
INSERT INTO a SELECT g//2, g, g FROM generate_series(0,2000) g(g)

statement ok
INSERT INTO c VALUES (1, 1, 1, 0), (2, 1, 2, 0)

statement ok
ALTER TABLE c INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1,
    "distinct_count": 1
  }
]'

statement ok
INSERT INTO d VALUES (1, 1), (1, 2)

# Test that vectorized stats are collected correctly.
statement ok
SET vectorize = on

statement ok
SET distsql = on

query T
EXPLAIN ANALYZE (DISTSQL) SELECT a FROM a
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows decoded from KV: 2,001 (16 KiB, 4,002 KVs, 2,001 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
·
• scan
  nodes: <hidden>
  regions: <hidden>
  actual row count: 2,001
  KV time: 0µs
  KV contention time: 0µs
  KV rows decoded: 2,001
  KV pairs read: 4,002
  KV bytes read: 16 KiB
  KV gRPC calls: 2,001
  estimated max memory allocated: 0 B
  missing stats
  table: a@a_pkey
  spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyMkc9q3DAQxu99imFOLahEDqUHnUpNCiFNE5yQSzFlVhq2JrLkasZ0l8WP1RfokxVbzSGUQG-e7_t5_ug7ofyI6PDu4vNFew8En7qbayA0mHLgLzSyoPuKDfYGp5I9i-SySqcNuAwHdNbgkKZZV7k36HNhdCfUQSOjw3vaRe6YApcziwYDKw1xa0sf6Nv0yEc02OY4j0ncNvtuovXzLRq8egAdRnZgf_-SWvuclJMOOf1jlfxTILDPgYODc2NtU43dUVmgMAUHzXu4Gj5Wfd_dtuApRnmGTzSUJ_ydsfYcDV4_tC2I8gQ-z0nhNR_0bEj6xoHdDqsA8-NLwEgHGHnM5QgUY_ak65YW1l12pP47C-RZp1kdrPx2zZNQt-sXg1X5-9qitGd0zWL-P5GOZcpJ-FkYL3W2S2-Qw55r6pLn4vm2ZL-NqeXN9t8mBBatblOLy1StpV9e_QkAAP__SmDEtw==

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c JOIN d ON d.b = c.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows decoded from KV: 3 (24 B, 6 KVs, 3 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
·
• lookup join
│ nodes: <hidden>
│ regions: <hidden>
│ actual row count: 2
│ KV time: 0µs
│ KV contention time: 0µs
│ KV rows decoded: 1
│ KV pairs read: 2
│ KV bytes read: 8 B
│ KV gRPC calls: 1
│ estimated max memory allocated: 0 B
│ table: d@d_pkey
│ equality: (b) = (b)
│
└── • scan
      nodes: <hidden>
      regions: <hidden>
      actual row count: 2
      KV time: 0µs
      KV contention time: 0µs
      KV rows decoded: 2
      KV pairs read: 4
      KV bytes read: 16 B
      KV gRPC calls: 2
      estimated max memory allocated: 0 B
      estimated row count: 1 (100% of the table; stats collected <hidden> ago)
      table: c@sec
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJy0U-FqE00U_f89xeX--oQx3V1EZEAIhgqpbVLS0j8SZDJziWtm564zs5gQ8li-gE8mM9NKa6yo6M9z5tx7z57D7jF8tCjx6vT8dHINeqTg9WJ-ARrO5tMZGJjPwIxW8BL0aIUCHRuaqY4CyrdY41Jg71lTCOwTtc-CqdmirAS2rh9iopcCNXtCucfYRkso8VqtLC1IGfInFQo0FFVr81o9DqRR4ITt0LkgQQlIt696ldBTFPjmBmLbkYTqy-dQsGYXycWW3dGT508BDGk2ZCQ0hVztIgXwpIyE-jm8Kux6cTkBrawN34S9av2d8BkKvLiZTCBE6kHz4CL8T9t40rr4REKVP6UIiDaPCTq1hY469jtQ1rJWMfmqsoeVivo9BeAh9kOUkPTZ_x3R4PIgsKDbbENUa0JZH8Sv53_GrbuNv34Yvxmbd_2GdijwnHkz9PCBWwfsJIyb-7WkTubJ0jhtyMdy1CW5gkNU1h4V8sfd1cfdvfhRdfVxdc1fqY62pIdjo_-o0eZ3Gl1Q6NkFetDmY5urw1IgmTWVvzbw4DVdetb5TIHzPJcJQyGW17qAqStPyeD94fqnw813w8vDf18DAAD__xqpcEE=

query T
EXPLAIN (OPT, VERBOSE) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
project
 ├── columns: a:1
 ├── stats: [rows=10]
 ├── cost: 1129.989
 ├── distribution: test
 ├── prune: (1)
 └── inner-join (merge)
      ├── columns: c.a:1 d.b:8
      ├── flags: force merge join
      ├── left ordering: +1
      ├── right ordering: +8
      ├── stats: [rows=10, distinct(1)=1, null(1)=0, distinct(8)=1, null(8)=0]
      ├── cost: 1129.869
      ├── fd: (1)==(8), (8)==(1)
      ├── distribution: test
      ├── scan c
      │    ├── columns: c.a:1
      │    ├── stats: [rows=1, distinct(1)=1, null(1)=0]
      │    ├── cost: 30.12
      │    ├── ordering: +1
      │    ├── distribution: test
      │    ├── prune: (1)
      │    ├── interesting orderings: (+1)
      │    └── unfiltered-cols: (1-6)
      ├── scan d
      │    ├── columns: d.b:8
      │    ├── stats: [rows=1000, distinct(8)=100, null(8)=0]
      │    ├── cost: 1088.62
      │    ├── ordering: +8
      │    ├── distribution: test
      │    ├── prune: (8)
      │    ├── interesting orderings: (+8)
      │    └── unfiltered-cols: (7-10)
      └── filters (true)

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows decoded from KV: 4 (32 B, 8 KVs, 4 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
·
• merge join
│ nodes: <hidden>
│ regions: <hidden>
│ actual row count: 2
│ estimated max memory allocated: 0 B
│ estimated max sql temp disk usage: 0 B
│ equality: (a) = (b)
│
├── • scan
│     nodes: <hidden>
│     regions: <hidden>
│     actual row count: 2
│     KV time: 0µs
│     KV contention time: 0µs
│     KV rows decoded: 2
│     KV pairs read: 4
│     KV bytes read: 16 B
│     KV gRPC calls: 2
│     estimated max memory allocated: 0 B
│     estimated row count: 1 (100% of the table; stats collected <hidden> ago)
│     table: c@c_pkey
│     spans: FULL SCAN
│
└── • scan
      nodes: <hidden>
      regions: <hidden>
      actual row count: 2
      KV time: 0µs
      KV contention time: 0µs
      KV rows decoded: 2
      KV pairs read: 4
      KV bytes read: 16 B
      KV gRPC calls: 2
      estimated max memory allocated: 0 B
      missing stats
      table: d@d_pkey
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzsk89uEzEQxu88xWhOrTDt7hZxsFQpIgoohSTVtuoFRcixh-0qXntre0WiKI_FC_BkaG0KpOkfFXHk5vnm-5zxb7Ib9DcaOV6MPo6GlyCPBLwrZxOQMJ5ORyVMRuX7EZzNxlNQMJtGwymoowUyNFbRVDTkkX_CHOcMW2cleW9dL22iYaxWyDOGtWm70MtzhtI6Qr7BUAdNyPFSLDSVJBS54wwZKgqi1vFaOZCf2yWtkeHQ6q4xnoNAhhet6I-vkOGHKwh1Qxyy7998qqU1gUyordlrOfvVgyJpFSkORRIX60AeHAnFIX8Db5NaledDkEJr_8vYitrdGl8jw8nVcAg-UAvSdibAAa3CcW3CIYcsPiUZiJYPGRqxgoYa69YgtLZShH6uLM6wEEFekwfbhbYLHHp_nP9WKHC-ZZiqn2x9EBUhz7fs7_jnu_zVQO3xX_zn_yT_4kH-v7F3xjpFjtQO8nmffMpyzxIn5Co6s7Uhd1zsLlHTl3AwyF8enrq6uk5HZDjrnzDoF04rkt3-uh5j0_f8jYZATQuq9kvovKjoH6A7ec5ftyTfWuPpLsJ7b856bqQqSnvwtnOSzp2V8WdSOYu5KCjyIXWLVIxNbMVv689w_oxwcTdcPBo-2Qln2_n2xY8AAAD__yYe1DU=

statement ok
RESET vectorize; RESET distsql

statement ok
SET tracing=off

# Making sure that colBatchScan operator can parallelize scans.
# This test is similar to that in testplannerlogic/select
statement ok
CREATE TABLE tpar (
    a INT PRIMARY KEY, item STRING, price FLOAT, FAMILY (a, item, price),
    UNIQUE INDEX item (item), UNIQUE INDEX p (price)
)

statement ok
ALTER TABLE tpar SPLIT AT VALUES(5)

# Run a select to prime the range cache to simplify the trace below.
statement ok
SELECT * FROM tpar

# Make sure that the scan actually gets parallelized.
statement ok
SET tracing = on; SELECT * FROM tpar WHERE a = 0 OR a = 10

statement ok
SET tracing = off

# The span "sending partial batch" means that the scan was parallelized.
#
# Most of the time we're seeing duplicate "querying next range" entries because
# we first use the range cache to try to partition the spans in order to have
# parallel TableReaders (we end up with a single partition though), and then we
# have a single TableReader performing the scan of two spans in parallel.
# However, occasionally the duplicate "querying next range at /Table/109/1/10/0"
# message is either dropped entirely or replaced with another
# "querying next range at /Table/109/1/0/0". It's not clear why that happens, so
# we deduplicate the messages to make the test non-flaky.
query T rowsort
SELECT DISTINCT message FROM [SHOW TRACE FOR SESSION]
WHERE message LIKE 'querying next range at %' OR
      message = '=== SPAN START: kv.DistSender: sending partial batch ==='
----
querying next range at /Table/109/1/0/0
=== SPAN START: kv.DistSender: sending partial batch ===
querying next range at /Table/109/1/10/0

# Regression test for #46123 (rowexec.TableReader not implementing
# execopnode.OpNode interface).
statement ok
CREATE TABLE t46123(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev(0) FROM t46123 WHERE ('' COLLATE en)::BOOL
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colexecbase.constInt64Op
      └ *rowexec.filtererProcessor
        └ *colfetcher.ColBatchScan

# Regression test for #46122.
statement ok
CREATE TABLE t46122_0(c0 STRING); CREATE TABLE t46122_1(c0 STRING)

query T
EXPLAIN (VEC) SELECT t46122_0.c0 FROM t46122_0, t46122_1
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t46404_0(c0 INT); CREATE TABLE t46404_1(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev((t46404_1.c0 > ANY (0, 0))::INT) FROM t46404_0, t46404_1 GROUP BY t46404_0.rowid
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colexecbase.castBoolIntOp
      └ *colexecprojconst.defaultCmpRConstProjOp
        └ *colexecjoin.crossJoiner
          ├ *colfetcher.ColBatchScan
          └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE xyz (
  x INT,
  y INT,
  z TEXT
)

# Check that we fallback gracefully to row-by-row engine on a join type with
# ON expression that we don't support.
query T
EXPLAIN (VEC) SELECT * FROM xyz AS t1 FULL OUTER JOIN xyz AS t2 ON t1.x = t2.x AND t1.x + t2.x = 0
----
│
└ Node 1
  └ *rowexec.hashJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

# Verify that the vectorized engine is used (there is a mismatch between
# argument type width and the result).
query T
EXPLAIN (VEC) SELECT max(c) FROM a
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colfetcher.ColBatchScan

# Verify that binary operations on integers of any width return INT8.
statement ok
CREATE TABLE ints (_int2 INT2, _int4 INT4, _int8 INT8);
INSERT INTO ints VALUES (1, 1, 1), (2, 2, 2)

query T
EXPLAIN (VEC) SELECT _int2 * _int2 FROM ints WHERE _int4 + _int4 = _int8 + 2
----
│
└ Node 1
  └ *colexecproj.projMultInt16Int16Op
    └ *colexecsel.selEQInt64Int64Op
      └ *colexecprojconst.projPlusInt64Int64ConstOp
        └ *colexecproj.projPlusInt32Int32Op
          └ *colfetcher.ColBatchScan

# Check that joinReader core is wrapped into the plan when vectorize is set to
# `experimental_always` - that core is the only exception to disabling of
# wrapping.

query T
EXPLAIN (VEC) SELECT c.a FROM c JOIN d ON d.b = c.b
----
│
└ Node 1
  └ *rowexec.joinReader
    └ *colfetcher.ColBatchScan

statement ok
SET vectorize = experimental_always

statement ok
SELECT c.a FROM c JOIN d ON d.b = c.b

statement ok
RESET vectorize

statement ok
CREATE TABLE bytes_string(_group INT, _bytes BYTES, _string STRING)

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string GROUP BY _group
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colfetcher.ColBatchScan

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t63792 (c INT);
INSERT INTO t63792 VALUES (NULL), (1), (2)

# Check that casts of constants are pre-evaluated (which allows us to use
# colexec.isNullProjOp instead of colexecproj.defaultCmpProjOp).
query T
EXPLAIN (VEC) SELECT c = c FROM t63792
----
│
└ Node 1
  └ *colexec.orProjOp
    ├ *colfetcher.ColBatchScan
    ├ *colexec.isNullProjOp
    └ *colexecbase.castOpNullAny
      └ *colexecbase.constNullOp

# Regression test that we can run EXPLAIN (VEC) on a mutation that utilizes the
# vectorized engine for some internal operations (#66568).
statement ok
CREATE TABLE t66568 (c INT PRIMARY KEY);

query T
EXPLAIN (VEC) INSERT INTO t66568 VALUES (1) ON CONFLICT DO NOTHING
----
│
└ Node 1
  └ *sql.planNodeToRowSource
    └ *colexecjoin.crossJoiner
      ├ *sql.planNodeToRowSource
      └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t_string (a STRING);
INSERT INTO t_string VALUES (NULL)

# Check that IN expression with non-constant right-hand side is handled via the
# default comparison operator.
query T
EXPLAIN (VEC) SELECT 'b' IN ('b', a, 'a') FROM t_string
----
│
└ Node 1
  └ *colexecproj.defaultCmpProjOp
    └ *colexec.tupleProjOp
      └ *colexecbase.constBytesOp
        └ *colexecbase.constBytesOp
          └ *colexecbase.constBytesOp
            └ *colfetcher.ColBatchScan

# Regression test for calling Release() before Close() on a vectorized index
# joiner (#70000).
statement ok
CREATE TABLE table70000_1 (i INT PRIMARY KEY);
CREATE TABLE table70000_2 (f FLOAT, b BOOL, INDEX f_idx(f));

query T
EXPLAIN (VEC)
  SELECT
    CASE WHEN b THEN (SELECT f FROM table70000_1 LIMIT 1) ELSE f END
  FROM
    table70000_2@f_idx;
----
│
└ Node 1
  └ *colexec.caseOp
    ├ *colexec.bufferOp
    │ └ *sql.planNodeToRowSource
    │   └ *colfetcher.ColIndexJoin
    │     └ *colfetcher.ColBatchScan
    ├ *colexec.bufferOp
    └ *colexec.bufferOp

# Regression test for releasing operators before closing them with EXPLAIN (VEC)
# (#70438).
statement ok
CREATE TABLE t70438 (k INT PRIMARY KEY, v INT, UNIQUE INDEX foo (v));
INSERT INTO t70438 VALUES (1, 2), (3, 4), (5, 6), (7, 8);

query T
EXPLAIN (VEC) DELETE FROM t70438 WHERE k=3 OR v=6
----
│
└ Node 1
  └ *sql.planNodeToRowSource
    └ *colexec.UnorderedDistinct
      └ *colexec.SerialUnorderedSynchronizer
        ├ *colfetcher.ColBatchScan
        └ *colfetcher.ColBatchScan

# Some tests for set-op cross joins.
statement ok
CREATE TABLE t ();
CREATE TABLE u ();
INSERT INTO t (rowid) VALUES (1), (2);
INSERT INTO u (rowid) VALUES (1);

query T
EXPLAIN (VEC) SELECT * FROM t INTERSECT ALL SELECT * FROM u
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

query T
EXPLAIN (VEC) SELECT * FROM t EXCEPT ALL SELECT * FROM u
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan
