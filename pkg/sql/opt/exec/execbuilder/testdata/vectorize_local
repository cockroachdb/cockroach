# LogicTest: local

statement ok
CREATE TABLE a (a INT, b INT, c INT4, PRIMARY KEY (a, b))

statement ok
CREATE TABLE c (a INT, b INT, c INT, d INT, PRIMARY KEY (a, c), INDEX sec (b))

statement ok
CREATE TABLE d (a INT, b INT, PRIMARY KEY (b, a))

statement ok
INSERT INTO a SELECT g//2, g, g FROM generate_series(0,2000) g(g)

statement ok
INSERT INTO c VALUES (1, 1, 1, 0), (2, 1, 2, 0)

statement ok
ALTER TABLE c INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1,
    "distinct_count": 1
  }
]'

statement ok
INSERT INTO d VALUES (1, 1), (1, 2)

# Test that vectorized stats are collected correctly.
statement ok
SET vectorize = on

statement ok
SET distsql = on

query T
EXPLAIN ANALYZE (DISTSQL) SELECT a FROM a
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
plan type: custom
rows decoded from KV: 2,001 (16 KiB, 4,002 KVs, 2,001 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
isolation level: serializable
priority: normal
quality of service: regular
·
• scan
  nodes: <hidden>
  regions: <hidden>
  actual row count: 2,001
  KV time: 0µs
  KV contention time: 0µs
  KV rows decoded: 2,001
  KV pairs read: 4,002
  KV bytes read: 16 KiB
  KV gRPC calls: 2,001
  estimated max memory allocated: 0 B
  missing stats
  table: a@a_pkey
  spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyMUsFqGzEQvfcrxJxakIk2lB50Kt2kYFI3wTa5lCWMpYkjrJW20iy2MftZ_YF-WdlVDE3bQOew7Lz3NPNGoxPk7x40rK6_XNdrgeLz8nYhECSEaOkrtpRBf4MKGgldioZyjmmETpNgbg-glQQXup5HuJFgYiLQJ2DHnkDDGjeeloSW0oUCCZYYnZ_K4kd86HZ0BAl19H0bsp56rzocf2cg4eZesGtJC_XzRy65iYEpsIvhLyrFfRaWTLRktbiUSlWF2ByZskiEVovqg7hxnwq-Xd7VwqD3-YW8Q5fO8vdSqUuQsLiva5GZOmFiH1i8pQNfuMDvtFDTYEVAtHtN0OJBtNTGdBTofTTIo0slRi8bZPNEWcSeu561GPXTNGeguGsGCQV5vu3MuCXQ1W_rmV-BVoP8_w0tKXcxZHqxnNc6qT86zaqhkUB2S-VZ5NgnQ3cpmklb0tup0ARYylzYqiTzcKYyJ8K22G8kPPq4f3AWNKjnmP3jcw4YD-A2j4OtnuJ-Krs-dqOtR_SZJCxwR1fElFoXXGZnQHPqaRje_AoAAP__MxfzJg==

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c JOIN d ON d.b = c.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
plan type: custom
rows decoded from KV: 3 (24 B, 6 KVs, 3 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
isolation level: serializable
priority: normal
quality of service: regular
·
• lookup join (streamer)
│ nodes: <hidden>
│ regions: <hidden>
│ actual row count: 2
│ KV time: 0µs
│ KV contention time: 0µs
│ KV rows decoded: 1
│ KV pairs read: 2
│ KV bytes read: 8 B
│ KV gRPC calls: 1
│ estimated max memory allocated: 0 B
│ table: d@d_pkey
│ equality: (b) = (b)
│
└── • scan
      nodes: <hidden>
      regions: <hidden>
      actual row count: 2
      KV time: 0µs
      KV contention time: 0µs
      KV rows decoded: 2
      KV pairs read: 4
      KV bytes read: 16 B
      KV gRPC calls: 2
      estimated max memory allocated: 0 B
      estimated row count: 1 (100% of the table; stats collected <hidden> ago)
      table: c@sec
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJy0k9FqGzsQhu_PUwxzdQpKsruUUgQFUycFp0kcnJCbYoIsTRzVWmkrabGN8WP1BfpkRSs7OHES2tLqYmFm_v1nNN_uCsM3gxyvTs5O-tcgDwV8Gg3PQcLpcHABCoYXoA4n8AHk4QQZWqfoQtQUkH_BEscMG-8kheB8Sq06wUAtkBcMtW3amNJjhtJ5Qr7CqKMh5HgtJoZGJBT5owIZKopCm85W9gJJZNh3pq1t4CAYpN5XjUjRATL8fANR18Sh-PE95Fg6G8lG7exeybt5AEXSKVIcqpycLCMF8CQUh_IdfMzZ6eiyD1IYEx6EjdB-K3yLDM9v-n0IkRqQrrUR_qdFPNI2vuFQdFfJAqLZS4JaLKCm2vklCGOcFDHNVXQzTESU9xTAtbFpI4ek7-bfJiocrxnmaLPbEMWUkJc7MAbHyIs1-3Uep07bDY7yMQ7VU7fNjJbI8My5WdvAV6ctOMuhV-1iSoyGacRecuiadavPm8xxiMKYPUB_zLLcZ_n-OZTlPsrqr6BsAykI0ZOoySNDWpBs9wf_R8SrJ8TL3yE-otA4G-gR7Zc6FU86HZTrMUNSU8q_fXCtl3Tpney0ORx2Rl1CUYi5WuZgYLelvL2HD3bXqXzVqXrNaczwzrj5rVbIsdicg2ce24PpBTENaUVX927e2V4vm3TBO2ECMTwXMzqmSL7WVoeoJfLoW1qv__sZAAD__9uqrY8=

# Regression test for using the Streamer API when we have a cast to an Oid type
# for which DistSQL is prohibited (#122274). (Note that, unlike above, we don't
# have 'lookup join (streamer)' here - that's the test.)
query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a::REGNAMESPACE FROM c JOIN d ON d.b = c.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
plan type: custom
rows decoded from KV: 2 (16 B, 4 KVs, 2 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
isolation level: serializable
priority: normal
quality of service: regular
·
• render
│
└── • lookup join
    │ nodes: <hidden>
    │ regions: <hidden>
    │ actual row count: 2
    │ table: d@d_pkey
    │ equality: (b) = (b)
    │
    └── • scan
          nodes: <hidden>
          regions: <hidden>
          actual row count: 2
          KV time: 0µs
          KV contention time: 0µs
          KV rows decoded: 2
          KV pairs read: 4
          KV bytes read: 16 B
          KV gRPC calls: 2
          estimated max memory allocated: 0 B
          estimated row count: 1 (100% of the table; stats collected <hidden> ago)
          table: c@sec
          spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJykU91q2zAYvd9TfHxXG6itHcYuBIN0bjbSNT84oTcjFEX6mmqRJU-SSULIY-0F9mTDdlKSdi0b04XhHB2fTzrH3mL4YZDjpHfTy6YgzwXnee_L8HLQm4wvsx58zkcDkHA96g9BwWgI6nwOH0Gez5GhdYqGoqCA_BumOGNYeicpBOdratsI-mqNPGGobVnFmp4xlM4T8i1GHQ0hx6mYG8pJKPIXCTJUFIU2ja3sBpLIMHOmKmzgIBjUsyelqNEZMvx6C1EXxCH59TO0WDobyUbt7LMt71YBFEmnSHHotOR8EymAJ6E4pB_gU8su8nEGUhgTHoWl0P4gfI8MB7dZBiFSCdJVNsJbWscLbeM7DklzlVZAtHxJUIg1FFQ4vwFhjJMi1udKmjPMRZQPFMBVsawih1rfnP9AdHC2Y9iifbYhigUhT4_K6F8hT3bs7_u4dtru60hP61BddVcuaYMMb5xbViV8d9qCsxy6neOa6o5ysoo8h256-lXhfnrTRRtti0MUxpw2RmuS1fMi_yOZzpNk0n9JJqdQOhvoJJWXJiVPJp2luxlDUgtqf4_gKi9p7J1stC0cNUYNoSjEdjdtQd8etkL0JIrHYo-d0ledOq85zRjeG7e60wo5Jvt19ofHYWH9gliEOqLJg1s1ttNNWV_wXphADAdiSVcUyRfa6hC1RB59Rbvdm98BAAD__1zHbaw=

query T
EXPLAIN (OPT, VERBOSE) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
project
 ├── columns: a:1
 ├── stats: [rows=10]
 ├── cost: 1129.989
 ├── distribution: test
 ├── prune: (1)
 └── inner-join (merge)
      ├── columns: c.a:1 d.b:8
      ├── flags: force merge join
      ├── left ordering: +1
      ├── right ordering: +8
      ├── stats: [rows=10, distinct(1)=1, null(1)=0, distinct(8)=1, null(8)=0]
      ├── cost: 1129.869
      ├── fd: (1)==(8), (8)==(1)
      ├── distribution: test
      ├── scan c
      │    ├── columns: c.a:1
      │    ├── stats: [rows=1, distinct(1)=1, null(1)=0]
      │    ├── cost: 30.12
      │    ├── ordering: +1
      │    ├── distribution: test
      │    ├── prune: (1)
      │    ├── interesting orderings: (+1)
      │    └── unfiltered-cols: (1-6)
      ├── scan d
      │    ├── columns: d.b:8
      │    ├── stats: [rows=1000, distinct(8)=100, null(8)=0]
      │    ├── cost: 1088.62
      │    ├── ordering: +8
      │    ├── distribution: test
      │    ├── prune: (8)
      │    ├── interesting orderings: (+8)
      │    └── unfiltered-cols: (7-10)
      └── filters (true)

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
plan type: custom
rows decoded from KV: 4 (32 B, 8 KVs, 4 gRPC calls)
maximum memory usage: <hidden>
network usage: <hidden>
regions: <hidden>
isolation level: serializable
priority: normal
quality of service: regular
·
• merge join
│ nodes: <hidden>
│ regions: <hidden>
│ actual row count: 2
│ estimated max memory allocated: 0 B
│ estimated max sql temp disk usage: 0 B
│ equality: (a) = (b)
│
├── • scan
│     nodes: <hidden>
│     regions: <hidden>
│     actual row count: 2
│     KV time: 0µs
│     KV contention time: 0µs
│     KV rows decoded: 2
│     KV pairs read: 4
│     KV bytes read: 16 B
│     KV gRPC calls: 2
│     estimated max memory allocated: 0 B
│     estimated row count: 1 (100% of the table; stats collected <hidden> ago)
│     table: c@c_pkey
│     spans: FULL SCAN
│
└── • scan
      nodes: <hidden>
      regions: <hidden>
      actual row count: 2
      KV time: 0µs
      KV contention time: 0µs
      KV rows decoded: 2
      KV pairs read: 4
      KV bytes read: 16 B
      KV gRPC calls: 2
      estimated max memory allocated: 0 B
      missing stats
      table: d@d_pkey
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzsU81OIzkQvu9TlOoEWgPdzWoPlpCiDdlRmEmCAuIyipBjF40Vt93YbpEI5bHmBebJRu4GhoQ_MZrj-NByVX3-qvx97jsMNwY5ng2-DPrnIPcF_D-djEDCcDweTGE0mH4awMlkOAYFk3ELOAK1P0eG1ikai4oC8q-Y44xh7Z2kEJxPqbsWMFRL5BlDbesmpvSMoXSekN9h1NEQcjwXc0NTEor8QYYMFUWhTUsre_KyXtAKGfadaSobOAhkeFaLtN1Dhp8vIOqKOGTfv4Uuls5GslE7-6zk3W0ARdIpUhyKLjlfRQrgSSgO-b_wX5ctp6d9kMKY8AishfYPwH-Q4eii34cQqQbpGhthh5bxQNu4yyFrr9IBiBavASqxhIoq51cgjHFSxDRX1s4wF1FeUwDXxLqJHBK-nf8hUeBszbCL7rUNUZSEPH9ixvAYebZmv-ZHvumH6qlnfsz_-PGuH8WWH_mrfvy0obHOK_KkNiyYpZPvQV4wdUS-pBOnLfmDYtNUQ1dxp5f_vXvkdXndbZHhJF2plx4ALUk2z-17S6tUCzcGIlU1KB0W0ARR0m-Q8nBLyuIjT3tKoXY20LakL3bKtjrt5UlYUiV1RgXXeEmn3skW24WTlqhNKAqxqxZdMLRtKU8dPInq8c98ypR_gKl4ypRvMxVvMh1uMGWbM80YXhl3e6kVcszu194Ln4eF6YAoQxL77NrdtrTnqzpJdSVMIIYjsaBjiuQrbXWIWiKPvqH1-q8fAQAA__9OjRUr

statement ok
RESET vectorize; RESET distsql

statement ok
SET tracing=off

# Making sure that colBatchScan operator can parallelize scans.
# This test is similar to that in testplannerlogic/select
statement ok
CREATE TABLE tpar (
    a INT PRIMARY KEY, item STRING, price FLOAT, FAMILY (a, item, price),
    UNIQUE INDEX item (item), UNIQUE INDEX p (price)
)

statement ok
ALTER TABLE tpar SPLIT AT VALUES(5)

# Run a select to prime the range cache to simplify the trace below.
statement ok
SELECT * FROM tpar

# Make sure that the scan actually gets parallelized.
statement ok
SET tracing = on; SELECT * FROM tpar WHERE a = 0 OR a = 10

statement ok
SET tracing = off

# The span "sending partial batch" means that the scan was parallelized.
#
# Most of the time we're seeing duplicate "querying next range" entries because
# we first use the range cache to try to partition the spans in order to have
# parallel TableReaders (we end up with a single partition though), and then we
# have a single TableReader performing the scan of two spans in parallel.
# However, occasionally the duplicate "querying next range at /Table/109/1/10/0"
# message is either dropped entirely or replaced with another
# "querying next range at /Table/109/1/0/0". It's not clear why that happens, so
# we deduplicate the messages to make the test non-flaky.
query T rowsort
SELECT DISTINCT message FROM [SHOW TRACE FOR SESSION]
WHERE message LIKE 'querying next range at %' OR
      message = '=== SPAN START: kv.DistSender: sending partial batch ==='
----
querying next range at /Table/109/1/0/0
=== SPAN START: kv.DistSender: sending partial batch ===
querying next range at /Table/109/1/10/0

# Used to be a regression test for #46123 (rowexec.TableReader not implementing
# execopnode.OpNode interface).
statement ok
CREATE TABLE t46123(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev(0) FROM t46123 WHERE ('' COLLATE en)::BOOL
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colexecbase.constInt64Op
      └ *colexecbase.castDatumBoolOp
        └ *colexecbase.constDatumOp
          └ *colfetcher.ColBatchScan

# Regression test for #46122.
statement ok
CREATE TABLE t46122_0(c0 STRING); CREATE TABLE t46122_1(c0 STRING)

query T
EXPLAIN (VEC) SELECT t46122_0.c0 FROM t46122_0, t46122_1
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t46404_0(c0 INT); CREATE TABLE t46404_1(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev((t46404_1.c0 > ANY (0, 0))::INT) FROM t46404_0, t46404_1 GROUP BY t46404_0.rowid
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colexecbase.castBoolIntOp
      └ *colexecprojconst.defaultCmpRConstProjOp
        └ *colexecjoin.crossJoiner
          ├ *colfetcher.ColBatchScan
          └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE xyz (
  x INT,
  y INT,
  z TEXT
)

# Check that we fallback gracefully to row-by-row engine on a join type with
# ON expression that we don't support.
query T
EXPLAIN (VEC) SELECT * FROM xyz AS t1 FULL OUTER JOIN xyz AS t2 ON t1.x = t2.x AND t1.x + t2.x = 0
----
│
└ Node 1
  └ *rowexec.hashJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

# Verify that the vectorized engine is used (there is a mismatch between
# argument type width and the result).
query T
EXPLAIN (VEC) SELECT max(c) FROM a
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colfetcher.ColBatchScan

# Verify that binary operations on integers of any width return INT8.
statement ok
CREATE TABLE ints (_int2 INT2, _int4 INT4, _int8 INT8);
INSERT INTO ints VALUES (1, 1, 1), (2, 2, 2)

query T
EXPLAIN (VEC) SELECT _int2 * _int2 FROM ints WHERE _int4 + _int4 = _int8 + 2
----
│
└ Node 1
  └ *colexecproj.projMultInt16Int16Op
    └ *colexecsel.selEQInt64Int64Op
      └ *colexecprojconst.projPlusInt64Int64ConstOp
        └ *colexecproj.projPlusInt32Int32Op
          └ *colfetcher.ColBatchScan

# Check that joinReader core is wrapped into the plan when vectorize is set to
# `experimental_always` - that core is the only exception to disabling of
# wrapping.

query T
EXPLAIN (VEC) SELECT c.a FROM c JOIN d ON d.b = c.b
----
│
└ Node 1
  └ *rowexec.joinReader
    └ *colfetcher.ColBatchScan

statement ok
SET vectorize = experimental_always

statement ok
SELECT c.a FROM c JOIN d ON d.b = c.b

statement ok
RESET vectorize

statement ok
CREATE TABLE bytes_string(_group INT, _bytes BYTES, _string STRING)

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string GROUP BY _group
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colfetcher.ColBatchScan

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t63792 (c INT);
INSERT INTO t63792 VALUES (NULL), (1), (2)

# Check that casts of constants are pre-evaluated (which allows us to use
# colexec.isNullProjOp instead of colexecproj.defaultCmpProjOp).
query T
EXPLAIN (VEC) SELECT c = c FROM t63792
----
│
└ Node 1
  └ *colexec.orProjOp
    ├ *colfetcher.ColBatchScan
    ├ *colexec.isNullProjOp
    └ *colexecbase.castOpNullAny
      └ *colexecbase.constNullOp

# Regression test that we can run EXPLAIN (VEC) on a mutation that utilizes the
# vectorized engine for some internal operations (#66568).
statement ok
CREATE TABLE t66568 (c INT PRIMARY KEY);

query T
EXPLAIN (VEC) INSERT INTO t66568 VALUES (1) ON CONFLICT DO NOTHING
----
│
└ Node 1
  └ *sql.planNodeToRowSource
    └ *colexecjoin.crossJoiner
      ├ *sql.planNodeToRowSource
      └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t_string (a STRING);
INSERT INTO t_string VALUES (NULL)

# Check that IN expression with non-constant right-hand side is handled via the
# default comparison operator.
query T
EXPLAIN (VEC) SELECT 'b' IN ('b', a, 'a') FROM t_string
----
│
└ Node 1
  └ *colexecproj.defaultCmpProjOp
    └ *colexec.tupleProjOp
      └ *colexecbase.constBytesOp
        └ *colexecbase.constBytesOp
          └ *colexecbase.constBytesOp
            └ *colfetcher.ColBatchScan

# Regression test for calling Release() before Close() on a vectorized index
# joiner (#70000).
statement ok
CREATE TABLE table70000_1 (i INT PRIMARY KEY);
CREATE TABLE table70000_2 (f FLOAT, b BOOL, INDEX f_idx(f));

query T
EXPLAIN (VEC)
  SELECT
    CASE WHEN b THEN (SELECT f FROM table70000_1 LIMIT 1) ELSE f END
  FROM
    table70000_2@f_idx;
----
│
└ Node 1
  └ *colexec.caseOp
    ├ *colexec.bufferOp
    │ └ *sql.planNodeToRowSource
    │   └ *colfetcher.ColIndexJoin
    │     └ *colfetcher.ColBatchScan
    ├ *colexec.bufferOp
    └ *colexec.bufferOp

# Regression test for releasing operators before closing them with EXPLAIN (VEC)
# (#70438).
statement ok
CREATE TABLE t70438 (k INT PRIMARY KEY, v INT, UNIQUE INDEX foo (v));
INSERT INTO t70438 VALUES (1, 2), (3, 4), (5, 6), (7, 8);

query T
EXPLAIN (VEC) DELETE FROM t70438 WHERE k=3 OR v=6
----
│
└ Node 1
  └ *sql.planNodeToRowSource
    └ *colexec.UnorderedDistinct
      └ *colexec.SerialUnorderedSynchronizer
        ├ *colfetcher.ColBatchScan
        └ *colfetcher.ColBatchScan

# Some tests for set-op cross joins.
statement ok
CREATE TABLE t ();
CREATE TABLE u ();
INSERT INTO t (rowid) VALUES (1), (2);
INSERT INTO u (rowid) VALUES (1);

query T
EXPLAIN (VEC) SELECT * FROM t INTERSECT ALL SELECT * FROM u
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

query T
EXPLAIN (VEC) SELECT * FROM t EXCEPT ALL SELECT * FROM u
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan
