// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: sql/distsqlrun/processors.proto

package distsqlrun

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"
import cockroach_roachpb4 "github.com/cockroachdb/cockroach/pkg/roachpb"
import cockroach_roachpb1 "github.com/cockroachdb/cockroach/pkg/roachpb"
import cockroach_sql_sqlbase1 "github.com/cockroachdb/cockroach/pkg/sql/sqlbase"
import cockroach_util_hlc "github.com/cockroachdb/cockroach/pkg/util/hlc"

import time "time"
import github_com_cockroachdb_cockroach_pkg_roachpb "github.com/cockroachdb/cockroach/pkg/roachpb"
import github_com_cockroachdb_cockroach_pkg_sql_sqlbase "github.com/cockroachdb/cockroach/pkg/sql/sqlbase"

import sortkeys "github.com/gogo/protobuf/sortkeys"
import binary "encoding/binary"

import io "io"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf
var _ = time.Kitchen

type JoinType int32

const (
	JoinType_INNER       JoinType = 0
	JoinType_LEFT_OUTER  JoinType = 1
	JoinType_RIGHT_OUTER JoinType = 2
	JoinType_FULL_OUTER  JoinType = 3
	JoinType_LEFT_SEMI   JoinType = 4
	JoinType_LEFT_ANTI   JoinType = 5
	// INTERSECT_ALL is a special JoinType that is only used for INTERSECT ALL and
	// INTERSECT operations. It only allows equality columns to be output, and
	// does not allow ON conditions. It returns every row from the left side that
	// has a match on the right side, but does not allow multiple rows from the
	// left side to match the same row on the right.
	JoinType_INTERSECT_ALL JoinType = 6
	// EXCEPT_ALL is a special JoinType that is only used for EXCEPT ALL and
	// EXCEPT operations. It only allows equality columns to be output, and
	// does not allow ON conditions. It matches every row on the left side with
	// at most one row on the right side, and does not allow multiple rows from
	// the left to match the same row on the right. It returns every row from the
	// left side that, after row matching, does not have a match on the right side.
	JoinType_EXCEPT_ALL JoinType = 7
)

var JoinType_name = map[int32]string{
	0: "INNER",
	1: "LEFT_OUTER",
	2: "RIGHT_OUTER",
	3: "FULL_OUTER",
	4: "LEFT_SEMI",
	5: "LEFT_ANTI",
	6: "INTERSECT_ALL",
	7: "EXCEPT_ALL",
}
var JoinType_value = map[string]int32{
	"INNER":         0,
	"LEFT_OUTER":    1,
	"RIGHT_OUTER":   2,
	"FULL_OUTER":    3,
	"LEFT_SEMI":     4,
	"LEFT_ANTI":     5,
	"INTERSECT_ALL": 6,
	"EXCEPT_ALL":    7,
}

func (x JoinType) Enum() *JoinType {
	p := new(JoinType)
	*p = x
	return p
}
func (x JoinType) String() string {
	return proto.EnumName(JoinType_name, int32(x))
}
func (x *JoinType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(JoinType_value, data, "JoinType")
	if err != nil {
		return err
	}
	*x = JoinType(value)
	return nil
}
func (JoinType) EnumDescriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{0} }

type SketchType int32

const (
	// This is the github.com/axiomhq/hyperloglog binary format
	// (as of commit 730eea1) for a sketch with precision 14.
	SketchType_HLL_PLUS_PLUS_V1 SketchType = 0
)

var SketchType_name = map[int32]string{
	0: "HLL_PLUS_PLUS_V1",
}
var SketchType_value = map[string]int32{
	"HLL_PLUS_PLUS_V1": 0,
}

func (x SketchType) Enum() *SketchType {
	p := new(SketchType)
	*p = x
	return p
}
func (x SketchType) String() string {
	return proto.EnumName(SketchType_name, int32(x))
}
func (x *SketchType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(SketchType_value, data, "SketchType")
	if err != nil {
		return err
	}
	*x = SketchType(value)
	return nil
}
func (SketchType) EnumDescriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{1} }

// These mirror the aggregate functions supported by sql/parser. See
// sql/parser/aggregate_builtins.go.
type AggregatorSpec_Func int32

const (
	// The identity function is set to be the default zero-value function,
	// returning the last value added.
	AggregatorSpec_IDENT          AggregatorSpec_Func = 0
	AggregatorSpec_AVG            AggregatorSpec_Func = 1
	AggregatorSpec_BOOL_AND       AggregatorSpec_Func = 2
	AggregatorSpec_BOOL_OR        AggregatorSpec_Func = 3
	AggregatorSpec_CONCAT_AGG     AggregatorSpec_Func = 4
	AggregatorSpec_COUNT          AggregatorSpec_Func = 5
	AggregatorSpec_MAX            AggregatorSpec_Func = 7
	AggregatorSpec_MIN            AggregatorSpec_Func = 8
	AggregatorSpec_STDDEV         AggregatorSpec_Func = 9
	AggregatorSpec_SUM            AggregatorSpec_Func = 10
	AggregatorSpec_SUM_INT        AggregatorSpec_Func = 11
	AggregatorSpec_VARIANCE       AggregatorSpec_Func = 12
	AggregatorSpec_XOR_AGG        AggregatorSpec_Func = 13
	AggregatorSpec_COUNT_ROWS     AggregatorSpec_Func = 14
	AggregatorSpec_SQRDIFF        AggregatorSpec_Func = 15
	AggregatorSpec_FINAL_VARIANCE AggregatorSpec_Func = 16
	AggregatorSpec_FINAL_STDDEV   AggregatorSpec_Func = 17
	AggregatorSpec_ARRAY_AGG      AggregatorSpec_Func = 18
	AggregatorSpec_JSON_AGG       AggregatorSpec_Func = 19
	// JSONB_AGG is an alias for JSON_AGG, they do the same thing.
	AggregatorSpec_JSONB_AGG AggregatorSpec_Func = 20
)

var AggregatorSpec_Func_name = map[int32]string{
	0:  "IDENT",
	1:  "AVG",
	2:  "BOOL_AND",
	3:  "BOOL_OR",
	4:  "CONCAT_AGG",
	5:  "COUNT",
	7:  "MAX",
	8:  "MIN",
	9:  "STDDEV",
	10: "SUM",
	11: "SUM_INT",
	12: "VARIANCE",
	13: "XOR_AGG",
	14: "COUNT_ROWS",
	15: "SQRDIFF",
	16: "FINAL_VARIANCE",
	17: "FINAL_STDDEV",
	18: "ARRAY_AGG",
	19: "JSON_AGG",
	20: "JSONB_AGG",
}
var AggregatorSpec_Func_value = map[string]int32{
	"IDENT":          0,
	"AVG":            1,
	"BOOL_AND":       2,
	"BOOL_OR":        3,
	"CONCAT_AGG":     4,
	"COUNT":          5,
	"MAX":            7,
	"MIN":            8,
	"STDDEV":         9,
	"SUM":            10,
	"SUM_INT":        11,
	"VARIANCE":       12,
	"XOR_AGG":        13,
	"COUNT_ROWS":     14,
	"SQRDIFF":        15,
	"FINAL_VARIANCE": 16,
	"FINAL_STDDEV":   17,
	"ARRAY_AGG":      18,
	"JSON_AGG":       19,
	"JSONB_AGG":      20,
}

func (x AggregatorSpec_Func) Enum() *AggregatorSpec_Func {
	p := new(AggregatorSpec_Func)
	*p = x
	return p
}
func (x AggregatorSpec_Func) String() string {
	return proto.EnumName(AggregatorSpec_Func_name, int32(x))
}
func (x *AggregatorSpec_Func) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(AggregatorSpec_Func_value, data, "AggregatorSpec_Func")
	if err != nil {
		return err
	}
	*x = AggregatorSpec_Func(value)
	return nil
}
func (AggregatorSpec_Func) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{12, 0}
}

type BackfillerSpec_Type int32

const (
	BackfillerSpec_Invalid BackfillerSpec_Type = 0
	BackfillerSpec_Column  BackfillerSpec_Type = 1
	BackfillerSpec_Index   BackfillerSpec_Type = 2
)

var BackfillerSpec_Type_name = map[int32]string{
	0: "Invalid",
	1: "Column",
	2: "Index",
}
var BackfillerSpec_Type_value = map[string]int32{
	"Invalid": 0,
	"Column":  1,
	"Index":   2,
}

func (x BackfillerSpec_Type) Enum() *BackfillerSpec_Type {
	p := new(BackfillerSpec_Type)
	*p = x
	return p
}
func (x BackfillerSpec_Type) String() string {
	return proto.EnumName(BackfillerSpec_Type_name, int32(x))
}
func (x *BackfillerSpec_Type) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(BackfillerSpec_Type_value, data, "BackfillerSpec_Type")
	if err != nil {
		return err
	}
	*x = BackfillerSpec_Type(value)
	return nil
}
func (BackfillerSpec_Type) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{13, 0}
}

type AlgebraicSetOpSpec_SetOpType int32

const (
	AlgebraicSetOpSpec_Except_all AlgebraicSetOpSpec_SetOpType = 0
)

var AlgebraicSetOpSpec_SetOpType_name = map[int32]string{
	0: "Except_all",
}
var AlgebraicSetOpSpec_SetOpType_value = map[string]int32{
	"Except_all": 0,
}

func (x AlgebraicSetOpSpec_SetOpType) Enum() *AlgebraicSetOpSpec_SetOpType {
	p := new(AlgebraicSetOpSpec_SetOpType)
	*p = x
	return p
}
func (x AlgebraicSetOpSpec_SetOpType) String() string {
	return proto.EnumName(AlgebraicSetOpSpec_SetOpType_name, int32(x))
}
func (x *AlgebraicSetOpSpec_SetOpType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(AlgebraicSetOpSpec_SetOpType_value, data, "AlgebraicSetOpSpec_SetOpType")
	if err != nil {
		return err
	}
	*x = AlgebraicSetOpSpec_SetOpType(value)
	return nil
}
func (AlgebraicSetOpSpec_SetOpType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{15, 0}
}

// Each processor has the following components:
//  - one or more input synchronizers; each one merges rows between one or more
//    input streams;
//
//  - a processor "core" which encapsulates the inner logic of each processor;
//
//  - a post-processing stage which allows "inline" post-processing on results
//    (like projection or filtering);
//
//  - one or more output synchronizers; each one directs rows to one or more
//  output streams.
//
//
// == Internal columns ==
//
// The core outputs rows of a certain schema to the post-processing stage. We
// call this the "internal schema" (or "internal columns") and it differs for
// each type of core. Column indices in a PostProcessSpec refers to these
// internal columns. Some columns may be unused by the post-processing stage;
// processor implementations are internally optimized to not produce values for
// such unneded columns.
type ProcessorSpec struct {
	// In most cases, there is one input.
	Input []InputSyncSpec    `protobuf:"bytes,1,rep,name=input" json:"input"`
	Core  ProcessorCoreUnion `protobuf:"bytes,2,opt,name=core" json:"core"`
	Post  PostProcessSpec    `protobuf:"bytes,4,opt,name=post" json:"post"`
	// In most cases, there is one output.
	Output []OutputRouterSpec `protobuf:"bytes,3,rep,name=output" json:"output"`
	// An optional identifier that can be used to correlate processors that are
	// part of the same stage (e.g. multiple joiners that are part of a
	// distributed join). This has no consequence on the running of flows, but is
	// useful for plan diagrams.
	StageID int32 `protobuf:"varint,5,opt,name=stage_id,json=stageId" json:"stage_id"`
}

func (m *ProcessorSpec) Reset()                    { *m = ProcessorSpec{} }
func (m *ProcessorSpec) String() string            { return proto.CompactTextString(m) }
func (*ProcessorSpec) ProtoMessage()               {}
func (*ProcessorSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{0} }

// PostProcessSpec describes the processing required to obtain the output
// (filtering, projection). It operates on the internal schema of the processor
// (see ProcessorSpec).
type PostProcessSpec struct {
	// A filtering expression which references the internal columns of the
	// processor via ordinal references (@1, @2, etc).
	Filter Expression `protobuf:"bytes,1,opt,name=filter" json:"filter"`
	// If true, output_columns describes a projection. Used to differentiate
	// between an empty projection and no projection.
	//
	// Cannot be set at the same time with render expressions.
	Projection bool `protobuf:"varint,2,opt,name=projection" json:"projection"`
	// The output columns describe a projection on the internal set of columns;
	// only the columns in this list will be emitted.
	//
	// Can only be set if projection is true. Cannot be set at the same time with
	// render expressions.
	OutputColumns []uint32 `protobuf:"varint,3,rep,packed,name=output_columns,json=outputColumns" json:"output_columns,omitempty"`
	// If set, the output is the result of rendering these expressions. The
	// expressions reference the internal columns of the processor.
	//
	// Cannot be set at the same time with output columns.
	RenderExprs []Expression `protobuf:"bytes,4,rep,name=render_exprs,json=renderExprs" json:"render_exprs"`
	// If nonzero, the first <offset> rows will be suppressed.
	Offset uint64 `protobuf:"varint,5,opt,name=offset" json:"offset"`
	// If nonzero, the processor will stop after emitting this many rows. The rows
	// suppressed by <offset>, if any, do not count towards this limit.
	Limit uint64 `protobuf:"varint,6,opt,name=limit" json:"limit"`
}

func (m *PostProcessSpec) Reset()                    { *m = PostProcessSpec{} }
func (m *PostProcessSpec) String() string            { return proto.CompactTextString(m) }
func (*PostProcessSpec) ProtoMessage()               {}
func (*PostProcessSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{1} }

type ProcessorCoreUnion struct {
	Noop                    *NoopCoreSpec                `protobuf:"bytes,1,opt,name=noop" json:"noop,omitempty"`
	TableReader             *TableReaderSpec             `protobuf:"bytes,2,opt,name=tableReader" json:"tableReader,omitempty"`
	JoinReader              *JoinReaderSpec              `protobuf:"bytes,3,opt,name=joinReader" json:"joinReader,omitempty"`
	Sorter                  *SorterSpec                  `protobuf:"bytes,4,opt,name=sorter" json:"sorter,omitempty"`
	Aggregator              *AggregatorSpec              `protobuf:"bytes,5,opt,name=aggregator" json:"aggregator,omitempty"`
	Distinct                *DistinctSpec                `protobuf:"bytes,7,opt,name=distinct" json:"distinct,omitempty"`
	MergeJoiner             *MergeJoinerSpec             `protobuf:"bytes,8,opt,name=mergeJoiner" json:"mergeJoiner,omitempty"`
	HashJoiner              *HashJoinerSpec              `protobuf:"bytes,9,opt,name=hashJoiner" json:"hashJoiner,omitempty"`
	Values                  *ValuesCoreSpec              `protobuf:"bytes,10,opt,name=values" json:"values,omitempty"`
	Backfiller              *BackfillerSpec              `protobuf:"bytes,11,opt,name=backfiller" json:"backfiller,omitempty"`
	SetOp                   *AlgebraicSetOpSpec          `protobuf:"bytes,12,opt,name=setOp" json:"setOp,omitempty"`
	ReadCSV                 *ReadCSVSpec                 `protobuf:"bytes,13,opt,name=readCSV" json:"readCSV,omitempty"`
	SSTWriter               *SSTWriterSpec               `protobuf:"bytes,14,opt,name=SSTWriter" json:"SSTWriter,omitempty"`
	Sampler                 *SamplerSpec                 `protobuf:"bytes,15,opt,name=Sampler" json:"Sampler,omitempty"`
	SampleAggregator        *SampleAggregatorSpec        `protobuf:"bytes,16,opt,name=SampleAggregator" json:"SampleAggregator,omitempty"`
	InterleavedReaderJoiner *InterleavedReaderJoinerSpec `protobuf:"bytes,17,opt,name=interleavedReaderJoiner" json:"interleavedReaderJoiner,omitempty"`
}

func (m *ProcessorCoreUnion) Reset()                    { *m = ProcessorCoreUnion{} }
func (m *ProcessorCoreUnion) String() string            { return proto.CompactTextString(m) }
func (*ProcessorCoreUnion) ProtoMessage()               {}
func (*ProcessorCoreUnion) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{2} }

// NoopCoreSpec indicates a "no-op" processor core. This is used when we just
// need post-processing or when only a synchronizer is required (e.g. at the
// final endpoint).
type NoopCoreSpec struct {
}

func (m *NoopCoreSpec) Reset()                    { *m = NoopCoreSpec{} }
func (m *NoopCoreSpec) String() string            { return proto.CompactTextString(m) }
func (*NoopCoreSpec) ProtoMessage()               {}
func (*NoopCoreSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{3} }

// ValuesCoreSpec is the core of a processor that has no inputs and generates
// "pre-canned" rows. This is not intended to be used for very large datasets.
type ValuesCoreSpec struct {
	// There is one DatumInfo for each element in a row.
	Columns []DatumInfo `protobuf:"bytes,1,rep,name=columns" json:"columns"`
	// Each raw block encodes one or more data rows; each datum is encoded
	// according to the corresponding DatumInfo.
	RawBytes [][]byte `protobuf:"bytes,2,rep,name=raw_bytes,json=rawBytes" json:"raw_bytes,omitempty"`
}

func (m *ValuesCoreSpec) Reset()                    { *m = ValuesCoreSpec{} }
func (m *ValuesCoreSpec) String() string            { return proto.CompactTextString(m) }
func (*ValuesCoreSpec) ProtoMessage()               {}
func (*ValuesCoreSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{4} }

type TableReaderSpan struct {
	// TODO(radu): the dist_sql APIs should be agnostic to how we map tables to
	// KVs. The span should be described as starting and ending lists of values
	// for a prefix of the index columns, along with inclusive/exclusive flags.
	Span cockroach_roachpb1.Span `protobuf:"bytes,1,opt,name=span" json:"span"`
}

func (m *TableReaderSpan) Reset()                    { *m = TableReaderSpan{} }
func (m *TableReaderSpan) String() string            { return proto.CompactTextString(m) }
func (*TableReaderSpan) ProtoMessage()               {}
func (*TableReaderSpan) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{5} }

// TableReaderSpec is the specification for a "table reader". A table reader
// performs KV operations to retrieve rows for a table and outputs the desired
// columns of the rows that pass a filter expression.
//
// The "internal columns" of a TableReader (see ProcessorSpec) are all the
// columns of the table. Internally, only the values for the columns needed by
// the post-processing stage are be populated. If is_check is set, the
// TableReader will run additional data checking procedures and the
// "internal columns" are:
//  - Error type (string).
//  - Primary key as a string, if it was obtainable.
//  - JSON of all decoded column values.
type TableReaderSpec struct {
	Table cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,1,opt,name=table" json:"table"`
	// If 0, we use the primary index. If non-zero, we use the index_idx-th index,
	// i.e. table.indexes[index_idx-1]
	IndexIdx uint32            `protobuf:"varint,2,opt,name=index_idx,json=indexIdx" json:"index_idx"`
	Reverse  bool              `protobuf:"varint,3,opt,name=reverse" json:"reverse"`
	Spans    []TableReaderSpan `protobuf:"bytes,4,rep,name=spans" json:"spans"`
	// A hint for how many rows the consumer of the table reader output might
	// need. This is used to size the initial KV batches to try to avoid reading
	// many more rows than needed by the processor receiving the output.
	//
	// Not used if there is a limit set in the PostProcessSpec of this processor
	// (that value will be used for sizing batches instead).
	LimitHint int64 `protobuf:"varint,5,opt,name=limit_hint,json=limitHint" json:"limit_hint"`
	// Indicates whether the TableReader is being run as an exhaustive
	// check. This is only true during SCRUB commands.
	IsCheck bool `protobuf:"varint,6,opt,name=is_check,json=isCheck" json:"is_check"`
}

func (m *TableReaderSpec) Reset()                    { *m = TableReaderSpec{} }
func (m *TableReaderSpec) String() string            { return proto.CompactTextString(m) }
func (*TableReaderSpec) ProtoMessage()               {}
func (*TableReaderSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{6} }

// JoinReaderSpec is the specification for a "join reader". A join reader
// performs KV operations to retrieve specific rows that correspond to the
// values in the input stream (join by lookup).
//
// The "internal columns" of a JoinReader (see ProcessorSpec) are either the
// columns of the table or the concatenation of the columns of the input stream
// with the table columns, depending on the lookup columns specified.
// Internally, only the values for the columns needed by the post-processing
// stage are be populated.
//
// Example:
// Input stream columns: | a | b |              Table columns: | c |
//
// If performing a lookup join on a = c (lookup columns are [0, 2]):
//        Internal columns: | a | b | c |
//
// If performing an index join (lookup columns is []):
//        Internal columns: | c |
type JoinReaderSpec struct {
	Table cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,1,opt,name=table" json:"table"`
	// If 0, we use the primary index; each row in the input stream has a value
	// for each primary key.
	// TODO(radu): figure out the correct semantics when joining with an index.
	IndexIdx uint32 `protobuf:"varint,2,opt,name=index_idx,json=indexIdx" json:"index_idx"`
	// Column indicies in the input stream specifying the columns which match with
	// the index columns. These are the equality columns of the join.
	// If empty, the start of the input stream schema is assumed to match the index
	// columns. The joinReader will perform an index join and the "internal
	// columns" will be the columns of the table.
	// If populated, the `joinReader` will perform a lookup join and the "internal
	// columns" will be the concatenation of the input stream columns followed by
	// the table columns.
	LookupColumns []uint32 `protobuf:"varint,3,rep,packed,name=lookup_columns,json=lookupColumns" json:"lookup_columns,omitempty"`
}

func (m *JoinReaderSpec) Reset()                    { *m = JoinReaderSpec{} }
func (m *JoinReaderSpec) String() string            { return proto.CompactTextString(m) }
func (*JoinReaderSpec) ProtoMessage()               {}
func (*JoinReaderSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{7} }

// SorterSpec is the specification for a "sorting aggregator". A sorting
// processor sorts elements in the input stream providing a certain output
// order guarantee regardless of the input ordering. The output ordering is
// according to a configurable set of columns.
//
// The "internal columns" of a Sorter (see ProcessorSpec) are the same as the
// input columns.
type SorterSpec struct {
	OutputOrdering Ordering `protobuf:"bytes,1,opt,name=output_ordering,json=outputOrdering" json:"output_ordering"`
	// Ordering match length, specifying that the input is already sorted by the
	// first 'n' output ordering columns, can be optionally specified for
	// possible speed-ups taking advantage of the partial orderings.
	OrderingMatchLen uint32 `protobuf:"varint,2,opt,name=ordering_match_len,json=orderingMatchLen" json:"ordering_match_len"`
}

func (m *SorterSpec) Reset()                    { *m = SorterSpec{} }
func (m *SorterSpec) String() string            { return proto.CompactTextString(m) }
func (*SorterSpec) ProtoMessage()               {}
func (*SorterSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{8} }

type DistinctSpec struct {
	// The ordered columns in the input stream can be optionally specified for
	// possible optimizations. The specific ordering (ascending/descending) of
	// the column itself is not important nor is the order in which the columns
	// are specified.
	OrderedColumns []uint32 `protobuf:"varint,1,rep,name=ordered_columns,json=orderedColumns" json:"ordered_columns,omitempty"`
	// The distinct columns in the input stream are those columns on which we
	// check for distinct rows. If A,B,C are in distinct_columns and there is a
	// 4th column D which is not included in distinct_columns, its values are not
	// considered, so rows A1,B1,C1,D1 and A1,B1,C1,D2 are considered equal and
	// only one of them (the first) is output.
	DistinctColumns []uint32 `protobuf:"varint,2,rep,name=distinct_columns,json=distinctColumns" json:"distinct_columns,omitempty"`
}

func (m *DistinctSpec) Reset()                    { *m = DistinctSpec{} }
func (m *DistinctSpec) String() string            { return proto.CompactTextString(m) }
func (*DistinctSpec) ProtoMessage()               {}
func (*DistinctSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{9} }

// MergeJoinerSpec is the specification for a merge join processor. The processor
// has two inputs and one output. The inputs must have the same ordering on the
// columns that have equality constraints. For example:
//   SELECT * FROM T1 INNER JOIN T2 ON T1.C1 = T2.C5 AND T1.C2 = T2.C4
//
// To perform a merge join, the streams corresponding to T1 and T2 must have the
// same ordering on columns C1, C2 and C5, C4 respectively. For example: C1+,C2-
// and C5+,C4-.
//
// The "internal columns" of a MergeJoiner (see ProcessorSpec) are the
// concatenation of left input columns and right input columns. If the left
// input has N columns and the right input has M columns, the first N columns
// contain values from the left side and the following M columns contain values
// from the right side.
type MergeJoinerSpec struct {
	// The streams must be ordered according to the columns that have equality
	// constraints. The first column of the left ordering is constrained to be
	// equal to the first column in the right ordering and so on. The ordering
	// lengths and directions must match.
	// In the example above, left ordering describes C1+,C2- and right ordering
	// describes C5+,C4-.
	LeftOrdering  Ordering `protobuf:"bytes,1,opt,name=left_ordering,json=leftOrdering" json:"left_ordering"`
	RightOrdering Ordering `protobuf:"bytes,2,opt,name=right_ordering,json=rightOrdering" json:"right_ordering"`
	// "ON" expression (in addition to the equality constraints captured by the
	// orderings). Assuming that the left stream has N columns and the right
	// stream has M columns, in this expression ordinal references @1 to @N refer
	// to columns of the left stream and variables @(N+1) to @(N+M) refer to
	// columns in the right stream.
	OnExpr Expression `protobuf:"bytes,5,opt,name=on_expr,json=onExpr" json:"on_expr"`
	Type   JoinType   `protobuf:"varint,6,opt,name=type,enum=cockroach.sql.distsqlrun.JoinType" json:"type"`
	// NullEquality indicates that NULL = NULL should be considered true.
	// This allows OUTER JOINs to consider NULL values meaningfully. An
	// example of this is during SCRUB checks on secondary indexes.
	NullEquality bool `protobuf:"varint,7,opt,name=null_equality,json=nullEquality" json:"null_equality"`
}

func (m *MergeJoinerSpec) Reset()                    { *m = MergeJoinerSpec{} }
func (m *MergeJoinerSpec) String() string            { return proto.CompactTextString(m) }
func (*MergeJoinerSpec) ProtoMessage()               {}
func (*MergeJoinerSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{10} }

// HashJoinerSpec is the specification for a hash join processor. The processor
// has two inputs and one output.
//
// The processor works by reading the entire right input and putting it in a hash
// table. Thus, there is no guarantee on the ordering of results that stem only
// from the right input (in the case of RIGHT_OUTER, FULL_OUTER). However, it is
// guaranteed that results that involve the left stream preserve the ordering;
// i.e. all results that stem from left row (i) precede results that stem from
// left row (i+1).
//
// The "internal columns" of a HashJoiner (see ProcessorSpec) are the
// concatenation of merged columns (if present), left input columns and right
// input columns. Each merged column corresponds to a left and a right equality
// column; its value is the value on the left if it is not NULL, otherwise it is
// the value on the right. There are either zero or
// E=len(left_eq_columns)=len(right_eq_columns) merged columns.
//
// If the left input has N columns and the right input has M columns, the
// first N columns contain values from the left side and the following M columns
// contain values from the right side. If merged columns are present, they
// occupy first E positions followed by N values from the left side and M values
// from the right side.
type HashJoinerSpec struct {
	// The join constraints certain columns from the left stream to equal
	// corresponding columns on the right stream. These must have the same length.
	LeftEqColumns  []uint32 `protobuf:"varint,1,rep,packed,name=left_eq_columns,json=leftEqColumns" json:"left_eq_columns,omitempty"`
	RightEqColumns []uint32 `protobuf:"varint,2,rep,packed,name=right_eq_columns,json=rightEqColumns" json:"right_eq_columns,omitempty"`
	// "ON" expression (in addition to the equality constraints captured by the
	// orderings). Assuming that the left stream has N columns and the right
	// stream has M columns, in this expression variables @1 to @N refer to
	// columns of the left stream and variables @N to @(N+M) refer to columns in
	// the right stream.
	// Having "ON" expression implies no merged columns.
	OnExpr Expression `protobuf:"bytes,5,opt,name=on_expr,json=onExpr" json:"on_expr"`
	Type   JoinType   `protobuf:"varint,6,opt,name=type,enum=cockroach.sql.distsqlrun.JoinType" json:"type"`
	// DEPRECATED
	//
	// Extra merged columns that are added in case of OUTER JOINS. These
	// columns occupy first positions in a row amd it's the left value if it's not
	// NULL, otherwise it's the right value. In INNER JOIN case no merged columns are
	// needed since left stream values are guaranteed to be not NULL.
	//
	// This has been deprecated; the distsqlrun layer still supports it for
	// backward compatibility during upgrade.
	MergedColumns bool `protobuf:"varint,7,opt,name=merged_columns,json=mergedColumns" json:"merged_columns"`
}

func (m *HashJoinerSpec) Reset()                    { *m = HashJoinerSpec{} }
func (m *HashJoinerSpec) String() string            { return proto.CompactTextString(m) }
func (*HashJoinerSpec) ProtoMessage()               {}
func (*HashJoinerSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{11} }

// AggregatorSpec is the specification for an "aggregator" (processor core
// type, not the logical plan computation stage). An aggregator performs
// 'aggregation' in the SQL sense in that it groups rows and computes an aggregate
// for each group. The group is configured using the group key. The aggregator
// can be configured with one or more aggregation functions.
//
// The "internal columns" of an Aggregator map 1-1 to the aggregations.
type AggregatorSpec struct {
	// The group key is a subset of the columns in the input stream schema on the
	// basis of which we define our groups.
	GroupCols    []uint32                     `protobuf:"varint,2,rep,packed,name=group_cols,json=groupCols" json:"group_cols,omitempty"`
	Aggregations []AggregatorSpec_Aggregation `protobuf:"bytes,3,rep,name=aggregations" json:"aggregations"`
}

func (m *AggregatorSpec) Reset()                    { *m = AggregatorSpec{} }
func (m *AggregatorSpec) String() string            { return proto.CompactTextString(m) }
func (*AggregatorSpec) ProtoMessage()               {}
func (*AggregatorSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{12} }

type AggregatorSpec_Aggregation struct {
	Func AggregatorSpec_Func `protobuf:"varint,1,opt,name=func,enum=cockroach.sql.distsqlrun.AggregatorSpec_Func" json:"func"`
	// Aggregation functions with distinct = true functions like you would
	// expect '<FUNC> DISTINCT' to operate, the default behavior would be
	// the '<FUNC> ALL' operation.
	Distinct bool `protobuf:"varint,2,opt,name=distinct" json:"distinct"`
	// The column index specifies the argument(s) to the aggregator function.
	//
	// Most aggregations take one argument
	// COUNT_ROWS takes no arguments.
	// FINAL_STDDEV and FINAL_VARIANCE take three arguments (SQRDIFF, SUM,
	// COUNT).
	ColIdx []uint32 `protobuf:"varint,5,rep,name=col_idx,json=colIdx" json:"col_idx,omitempty"`
	// If set, this column index specifies a boolean argument; rows for which
	// this value is not true don't contribute to this aggregation. This enables
	// the filter clause, e.g.:
	//   SELECT SUM(x) FILTER (WHERE y > 1), SUM(x) FILTER (WHERE y < 1) FROM t
	FilterColIdx *uint32 `protobuf:"varint,4,opt,name=filter_col_idx,json=filterColIdx" json:"filter_col_idx,omitempty"`
}

func (m *AggregatorSpec_Aggregation) Reset()         { *m = AggregatorSpec_Aggregation{} }
func (m *AggregatorSpec_Aggregation) String() string { return proto.CompactTextString(m) }
func (*AggregatorSpec_Aggregation) ProtoMessage()    {}
func (*AggregatorSpec_Aggregation) Descriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{12, 0}
}

// BackfillerSpec is the specification for a "schema change backfiller".
// The created backfill processor runs a backfill for the first mutations in
// the table descriptor mutation list with the same mutation id and type.
// A backfiller processor performs KV operations to retrieve rows for a
// table and backfills the new indexes/columns contained in the table
// descriptor. It checkpoints its progress by updating the table
// descriptor in the database, and doesn't emit any rows nor support
// any post-processing.
type BackfillerSpec struct {
	Type  BackfillerSpec_Type                    `protobuf:"varint,1,opt,name=type,enum=cockroach.sql.distsqlrun.BackfillerSpec_Type" json:"type"`
	Table cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,2,opt,name=table" json:"table"`
	// Sections of the table to be backfilled.
	Spans []TableReaderSpan `protobuf:"bytes,3,rep,name=spans" json:"spans"`
	// Run the backfill for approximately this duration.
	// The backfill will always process at least one backfill chunk.
	Duration time.Duration `protobuf:"varint,4,opt,name=duration,casttype=time.Duration" json:"duration"`
	// The backfill involves a complete table scan in chunks,
	// where each chunk is a transactional read of a set of rows
	// along with a backfill for the rows. This is the maximum number
	// of entries backfilled per chunk.
	ChunkSize int64 `protobuf:"varint,5,opt,name=chunk_size,json=chunkSize" json:"chunk_size"`
	// Any other (leased) table descriptors necessary for the
	// backfiller to do its job, such as the descriptors for tables with fk
	// relationships to the table being modified.
	OtherTables []cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,6,rep,name=other_tables,json=otherTables" json:"other_tables"`
	// The timestamp to perform index backfill historical scans at.
	ReadAsOf cockroach_util_hlc.Timestamp `protobuf:"bytes,7,opt,name=readAsOf" json:"readAsOf"`
}

func (m *BackfillerSpec) Reset()                    { *m = BackfillerSpec{} }
func (m *BackfillerSpec) String() string            { return proto.CompactTextString(m) }
func (*BackfillerSpec) ProtoMessage()               {}
func (*BackfillerSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{13} }

// FlowSpec describes a "flow" which is a subgraph of a distributed SQL
// computation consisting of processors and streams.
type FlowSpec struct {
	FlowID FlowID `protobuf:"bytes,1,opt,name=flow_id,json=flowId,customtype=FlowID" json:"flow_id"`
	// The NodeID of the gateway that planned this Flow. Used for debugging.
	Gateway    github_com_cockroachdb_cockroach_pkg_roachpb.NodeID `protobuf:"varint,3,opt,name=gateway,casttype=github.com/cockroachdb/cockroach/pkg/roachpb.NodeID" json:"gateway"`
	Processors []ProcessorSpec                                     `protobuf:"bytes,2,rep,name=processors" json:"processors"`
}

func (m *FlowSpec) Reset()                    { *m = FlowSpec{} }
func (m *FlowSpec) String() string            { return proto.CompactTextString(m) }
func (*FlowSpec) ProtoMessage()               {}
func (*FlowSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{14} }

// AlgebraicSetOpSpec is a specification for algebraic set operations currently
// only the EXCEPT ALL set operation, but extensible to other set operations.
// INTERSECT ALL is implemented with HashJoinerSpec, and UNION ALL with
// a no-op processor. EXCEPT/INTERSECT/UNION use a DISTINCT processor at
// the end. The two input streams should have the same schema. The ordering
// of the left stream will be preserved in the output stream.
type AlgebraicSetOpSpec struct {
	// If the two input streams are both ordered by a common column ordering,
	// that ordering can be used to optimize resource usage in the processor.
	Ordering Ordering                     `protobuf:"bytes,1,opt,name=ordering" json:"ordering"`
	OpType   AlgebraicSetOpSpec_SetOpType `protobuf:"varint,2,opt,name=op_type,json=opType,enum=cockroach.sql.distsqlrun.AlgebraicSetOpSpec_SetOpType" json:"op_type"`
}

func (m *AlgebraicSetOpSpec) Reset()                    { *m = AlgebraicSetOpSpec{} }
func (m *AlgebraicSetOpSpec) String() string            { return proto.CompactTextString(m) }
func (*AlgebraicSetOpSpec) ProtoMessage()               {}
func (*AlgebraicSetOpSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{15} }

// JobProgress identifies the job to report progress on. This reporting
// happens outside this package.
type JobProgress struct {
	JobID int64 `protobuf:"varint,1,opt,name=job_id,json=jobId" json:"job_id"`
	// contribution is the percent of work of the total this processor will
	// process.
	Contribution float32 `protobuf:"fixed32,2,opt,name=contribution" json:"contribution"`
	// slot is the index into the job details for this processor's completion.
	Slot int32 `protobuf:"varint,3,opt,name=slot" json:"slot"`
}

func (m *JobProgress) Reset()                    { *m = JobProgress{} }
func (m *JobProgress) String() string            { return proto.CompactTextString(m) }
func (*JobProgress) ProtoMessage()               {}
func (*JobProgress) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{16} }

// ReadCSVSpec is the specification for a processor that reads a CSV
// file at uri with descriptor table_desc, specified delimiter (comma),
// optional comment rune, and optional nullif string (which is nullable to
// differentiate between not set (nil) and the empty string (which could be
// used as the null marker). It outputs rows that are a sampling of the file
// at a rate of (row size) / sample_size.
// See ccs/sqlccl/csv.go for implementation.
type ReadCSVSpec struct {
	Options cockroach_roachpb4.CSVOptions `protobuf:"bytes,1,opt,name=options" json:"options"`
	// sample_size is the rate at which to output rows, based on an input row's size.
	SampleSize int32 `protobuf:"varint,2,opt,name=sample_size,json=sampleSize" json:"sample_size"`
	// table_desc is the table descriptor of the CSV file.
	TableDesc cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,3,opt,name=table_desc,json=tableDesc" json:"table_desc"`
	// uri is a storageccl.ExportStorage URI pointing to the CSV files to be
	// read. The map key must be unique across the entire IMPORT job.
	Uri      map[int32]string `protobuf:"bytes,7,rep,name=uri" json:"uri,omitempty" protobuf_key:"varint,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Progress JobProgress      `protobuf:"bytes,6,opt,name=progress" json:"progress"`
}

func (m *ReadCSVSpec) Reset()                    { *m = ReadCSVSpec{} }
func (m *ReadCSVSpec) String() string            { return proto.CompactTextString(m) }
func (*ReadCSVSpec) ProtoMessage()               {}
func (*ReadCSVSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{17} }

// SSTWriterSpec is the specification for a processor that consumes rows, uses
// tempStorage to sort them, then writes them to SST files at uri. walltime is
// used as the MVCC timestamp. It outputs one row per span containing the file
// name, size, checksum, observed start and end keys. See ccs/sqlccl/csv.go
// for implementation.
type SSTWriterSpec struct {
	// destination as a storageccl.ExportStorage URI pointing to an export store
	// location (directory).
	Destination string `protobuf:"bytes,1,opt,name=destination" json:"destination"`
	// walltimeNanos is the MVCC time at which the created KVs will be written.
	WalltimeNanos int64 `protobuf:"varint,3,opt,name=walltimeNanos" json:"walltimeNanos"`
	// spans is an array of span boundaries and corresponding filenames.
	Spans    []SSTWriterSpec_SpanName `protobuf:"bytes,4,rep,name=spans" json:"spans"`
	Progress JobProgress              `protobuf:"bytes,5,opt,name=progress" json:"progress"`
}

func (m *SSTWriterSpec) Reset()                    { *m = SSTWriterSpec{} }
func (m *SSTWriterSpec) String() string            { return proto.CompactTextString(m) }
func (*SSTWriterSpec) ProtoMessage()               {}
func (*SSTWriterSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{18} }

type SSTWriterSpec_SpanName struct {
	// name is the file name that will be written by the export store.
	Name string `protobuf:"bytes,1,opt,name=name" json:"name"`
	// end is the end key of a span.
	End []byte `protobuf:"bytes,2,opt,name=end" json:"end,omitempty"`
}

func (m *SSTWriterSpec_SpanName) Reset()         { *m = SSTWriterSpec_SpanName{} }
func (m *SSTWriterSpec_SpanName) String() string { return proto.CompactTextString(m) }
func (*SSTWriterSpec_SpanName) ProtoMessage()    {}
func (*SSTWriterSpec_SpanName) Descriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{18, 0}
}

// SketchSpec contains the specification for a generated statistic.
type SketchSpec struct {
	SketchType SketchType `protobuf:"varint,1,opt,name=sketch_type,json=sketchType,enum=cockroach.sql.distsqlrun.SketchType" json:"sketch_type"`
	// Each value is an index identifying a column in the input stream.
	// TODO(radu): currently only one column is supported.
	Columns []uint32 `protobuf:"varint,2,rep,name=columns" json:"columns,omitempty"`
	// If set, we generate a histogram for the first column in the sketch.
	// Only used by the SampleAggregator.
	GenerateHistogram bool `protobuf:"varint,3,opt,name=generate_histogram,json=generateHistogram" json:"generate_histogram"`
	// Controls the maximum number of buckets in the histogram.
	// Only used by the SampleAggregator.
	HistogramMaxBuckets uint32 `protobuf:"varint,4,opt,name=histogram_max_buckets,json=histogramMaxBuckets" json:"histogram_max_buckets"`
	// Only used by the SampleAggregator.
	StatName string `protobuf:"bytes,5,opt,name=stat_name,json=statName" json:"stat_name"`
}

func (m *SketchSpec) Reset()                    { *m = SketchSpec{} }
func (m *SketchSpec) String() string            { return proto.CompactTextString(m) }
func (*SketchSpec) ProtoMessage()               {}
func (*SketchSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{19} }

// SamplerSpec is the specification of a "sampler" processor which
// returns a sample (random subset) of the input columns and computes
// cardinality estimation sketches on sets of columns.
//
// The sampler is configured with a sample size and sets of columns
// for the sketches. It produces one row with global statistics, one
// row with sketch information for each sketch plus at most
// sample_size sampled rows.
//
// The following method is used to do reservoir sampling: we generate a
// "rank" for each row, which is just a random, uniformly distributed
// 64-bit value. The rows with the smallest <sample_size> ranks are selected.
// This method is chosen because it allows to combine sample sets very easily.
//
// The internal schema of the processor is formed of two column
// groups:
//   1. sampled row columns:
//       - columns that map 1-1 to the columns in the input (same
//         schema as the input).
//       - an INT column with the "rank" of the row; this is a random value
//         associated with the row (necessary for combining sample sets).
//   2. sketch columns:
//       - an INT column indicating the sketch index
//         (0 to len(sketches) - 1).
//       - an INT column indicating the number of rows processed
//       - an INT column indicating the number of NULL values
//         on the first column of the sketch.
//       - a BYTES column with the binary sketch data (format
//         dependent on the sketch type).
// Rows have NULLs on either all the sampled row columns or on all the
// sketch columns.
type SamplerSpec struct {
	Sketches   []SketchSpec `protobuf:"bytes,1,rep,name=sketches" json:"sketches"`
	SampleSize uint32       `protobuf:"varint,2,opt,name=sample_size,json=sampleSize" json:"sample_size"`
}

func (m *SamplerSpec) Reset()                    { *m = SamplerSpec{} }
func (m *SamplerSpec) String() string            { return proto.CompactTextString(m) }
func (*SamplerSpec) ProtoMessage()               {}
func (*SamplerSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{20} }

// SampleAggregatorSpec is the specification of a processor that aggregates the
// results from multiple sampler processors and writes out the statistics to
// system.table_statistics.
//
// The input schema it expects matches the output schema of a sampler spec (see
// the comment for SamplerSpec for all the details):
//  1. sampled row columns:
//    - sampled columns
//    - row rank
//  2. sketch columns:
//    - sketch index
//    - number of rows processed
//    - number of NULL values encountered on the first column of the sketch
//    - binary sketch data
type SampleAggregatorSpec struct {
	Sketches []SketchSpec `protobuf:"bytes,1,rep,name=sketches" json:"sketches"`
	// The processor merges reservoir sample sets into a single
	// sample set of this size. This must match the sample size
	// used for each Sampler.
	SampleSize uint32 `protobuf:"varint,2,opt,name=sample_size,json=sampleSize" json:"sample_size"`
	// The i-th value indicates the ColumnID of the i-th sampled row column.
	// These are necessary for writing out the statistic data.
	SampledColumnIDs []github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ColumnID `protobuf:"varint,3,rep,name=sampled_column_ids,json=sampledColumnIds,casttype=github.com/cockroachdb/cockroach/pkg/sql/sqlbase.ColumnID" json:"sampled_column_ids,omitempty"`
	TableID          github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ID         `protobuf:"varint,4,opt,name=table_id,json=tableId,casttype=github.com/cockroachdb/cockroach/pkg/sql/sqlbase.ID" json:"table_id"`
}

func (m *SampleAggregatorSpec) Reset()                    { *m = SampleAggregatorSpec{} }
func (m *SampleAggregatorSpec) String() string            { return proto.CompactTextString(m) }
func (*SampleAggregatorSpec) ProtoMessage()               {}
func (*SampleAggregatorSpec) Descriptor() ([]byte, []int) { return fileDescriptorProcessors, []int{21} }

// InterleavedReaderJoinerSpec is the specification for a processor that performs
// KV operations to retrieve rows from 2+ tables from an interleaved hierarchy,
// performs intermediate filtering on rows from each table, and performs a
// join on the rows from the 2+ tables.
//
// Limitations: the InterleavedReaderJoiner currently supports only equality INNER joins
// on the full interleave prefix.
// See https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20171025_interleaved_table_joins.md.
//
// The "internal columns" of an InterleavedReaderJoiner are the
// concatenation of left input columns and right input columns. If the left
// table has N columns and the right table has M columns, the first N columns
// contain values from the left table and the following M columns contain values
// from the right table.
type InterleavedReaderJoinerSpec struct {
	// For the common case of two tables, table at index 0 is the left/parent
	// table and table at index 1 is the right/child table.
	Tables  []InterleavedReaderJoinerSpec_Table `protobuf:"bytes,1,rep,name=tables" json:"tables"`
	Reverse bool                                `protobuf:"varint,2,opt,name=reverse" json:"reverse"`
	// A hint for how many joined rows from the tables the consumer of the
	// interleavedReaderJoiner might need. This is used to size the initial KV
	// batches to try to avoid reading many more rows than needed by the
	// processor receiving the output.
	// // Not used if there is a limit set in the PostProcessSpec of this processor // (that value will be used for sizing batches instead).
	LimitHint int64 `protobuf:"varint,3,opt,name=limit_hint,json=limitHint" json:"limit_hint"`
	// "ON" expression (in addition to the equality constraints captured by the
	// orderings). Assuming that the left table has N columns and the second
	// table stream has M columns, in this expression ordinal references @1 to @N
	// refer to columns of the left table and variables @(N+1) to @(N+M) refer to
	// columns in the right table.
	OnExpr Expression `protobuf:"bytes,4,opt,name=on_expr,json=onExpr" json:"on_expr"`
	Type   JoinType   `protobuf:"varint,5,opt,name=type,enum=cockroach.sql.distsqlrun.JoinType" json:"type"`
}

func (m *InterleavedReaderJoinerSpec) Reset()         { *m = InterleavedReaderJoinerSpec{} }
func (m *InterleavedReaderJoinerSpec) String() string { return proto.CompactTextString(m) }
func (*InterleavedReaderJoinerSpec) ProtoMessage()    {}
func (*InterleavedReaderJoinerSpec) Descriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{22}
}

type InterleavedReaderJoinerSpec_Table struct {
	Desc cockroach_sql_sqlbase1.TableDescriptor `protobuf:"bytes,1,opt,name=desc" json:"desc"`
	// If 0, we use the primary index. If non-zero, we use the index_idx-th index,
	// i.e. desc.indexes[index_idx-1]
	IndexIdx uint32 `protobuf:"varint,2,opt,name=index_idx,json=indexIdx" json:"index_idx"`
	// The PostProcessSpecs of the corresponding TableReaderSpecs of each table
	// are fed as arguments to InterleavedReaderJoiner.
	//
	// This is required to properly post-process the rows (i.e. filtering and
	// projections) after reading from the table but before joining.
	// It may be necessary to modify/introduce additional intermediate filters
	// for correctness (see comment above 'spans' under
	// InterleavedReaderJoinerSpec).
	Post PostProcessSpec `protobuf:"bytes,3,opt,name=post" json:"post"`
	// The tables must be ordered according to the columns that have equality
	// constraints. The first column of the first table's ordering is constrained
	// to be equal to the first column in the second table's ordering and so on
	// for the other tables and their corresponding columns.
	Ordering Ordering `protobuf:"bytes,4,opt,name=ordering" json:"ordering"`
	// The span covering the rows from this table to join. Note the
	// InterleavedReaderJoiner processor will taking the union of all spans across
	// all tables to do a single pass-through scan. InterleavedReaderJoiner will
	// then check if a given row for a table is within any of its spans.
	// There must exist at least one non-empty set of spans for some table.
	Spans []TableReaderSpan `protobuf:"bytes,5,rep,name=spans" json:"spans"`
}

func (m *InterleavedReaderJoinerSpec_Table) Reset()         { *m = InterleavedReaderJoinerSpec_Table{} }
func (m *InterleavedReaderJoinerSpec_Table) String() string { return proto.CompactTextString(m) }
func (*InterleavedReaderJoinerSpec_Table) ProtoMessage()    {}
func (*InterleavedReaderJoinerSpec_Table) Descriptor() ([]byte, []int) {
	return fileDescriptorProcessors, []int{22, 0}
}

func init() {
	proto.RegisterType((*ProcessorSpec)(nil), "cockroach.sql.distsqlrun.ProcessorSpec")
	proto.RegisterType((*PostProcessSpec)(nil), "cockroach.sql.distsqlrun.PostProcessSpec")
	proto.RegisterType((*ProcessorCoreUnion)(nil), "cockroach.sql.distsqlrun.ProcessorCoreUnion")
	proto.RegisterType((*NoopCoreSpec)(nil), "cockroach.sql.distsqlrun.NoopCoreSpec")
	proto.RegisterType((*ValuesCoreSpec)(nil), "cockroach.sql.distsqlrun.ValuesCoreSpec")
	proto.RegisterType((*TableReaderSpan)(nil), "cockroach.sql.distsqlrun.TableReaderSpan")
	proto.RegisterType((*TableReaderSpec)(nil), "cockroach.sql.distsqlrun.TableReaderSpec")
	proto.RegisterType((*JoinReaderSpec)(nil), "cockroach.sql.distsqlrun.JoinReaderSpec")
	proto.RegisterType((*SorterSpec)(nil), "cockroach.sql.distsqlrun.SorterSpec")
	proto.RegisterType((*DistinctSpec)(nil), "cockroach.sql.distsqlrun.DistinctSpec")
	proto.RegisterType((*MergeJoinerSpec)(nil), "cockroach.sql.distsqlrun.MergeJoinerSpec")
	proto.RegisterType((*HashJoinerSpec)(nil), "cockroach.sql.distsqlrun.HashJoinerSpec")
	proto.RegisterType((*AggregatorSpec)(nil), "cockroach.sql.distsqlrun.AggregatorSpec")
	proto.RegisterType((*AggregatorSpec_Aggregation)(nil), "cockroach.sql.distsqlrun.AggregatorSpec.Aggregation")
	proto.RegisterType((*BackfillerSpec)(nil), "cockroach.sql.distsqlrun.BackfillerSpec")
	proto.RegisterType((*FlowSpec)(nil), "cockroach.sql.distsqlrun.FlowSpec")
	proto.RegisterType((*AlgebraicSetOpSpec)(nil), "cockroach.sql.distsqlrun.AlgebraicSetOpSpec")
	proto.RegisterType((*JobProgress)(nil), "cockroach.sql.distsqlrun.JobProgress")
	proto.RegisterType((*ReadCSVSpec)(nil), "cockroach.sql.distsqlrun.ReadCSVSpec")
	proto.RegisterType((*SSTWriterSpec)(nil), "cockroach.sql.distsqlrun.SSTWriterSpec")
	proto.RegisterType((*SSTWriterSpec_SpanName)(nil), "cockroach.sql.distsqlrun.SSTWriterSpec.SpanName")
	proto.RegisterType((*SketchSpec)(nil), "cockroach.sql.distsqlrun.SketchSpec")
	proto.RegisterType((*SamplerSpec)(nil), "cockroach.sql.distsqlrun.SamplerSpec")
	proto.RegisterType((*SampleAggregatorSpec)(nil), "cockroach.sql.distsqlrun.SampleAggregatorSpec")
	proto.RegisterType((*InterleavedReaderJoinerSpec)(nil), "cockroach.sql.distsqlrun.InterleavedReaderJoinerSpec")
	proto.RegisterType((*InterleavedReaderJoinerSpec_Table)(nil), "cockroach.sql.distsqlrun.InterleavedReaderJoinerSpec.Table")
	proto.RegisterEnum("cockroach.sql.distsqlrun.JoinType", JoinType_name, JoinType_value)
	proto.RegisterEnum("cockroach.sql.distsqlrun.SketchType", SketchType_name, SketchType_value)
	proto.RegisterEnum("cockroach.sql.distsqlrun.AggregatorSpec_Func", AggregatorSpec_Func_name, AggregatorSpec_Func_value)
	proto.RegisterEnum("cockroach.sql.distsqlrun.BackfillerSpec_Type", BackfillerSpec_Type_name, BackfillerSpec_Type_value)
	proto.RegisterEnum("cockroach.sql.distsqlrun.AlgebraicSetOpSpec_SetOpType", AlgebraicSetOpSpec_SetOpType_name, AlgebraicSetOpSpec_SetOpType_value)
}
func (m *ProcessorSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ProcessorSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Input) > 0 {
		for _, msg := range m.Input {
			dAtA[i] = 0xa
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x12
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Core.Size()))
	n1, err := m.Core.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n1
	if len(m.Output) > 0 {
		for _, msg := range m.Output {
			dAtA[i] = 0x1a
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x22
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Post.Size()))
	n2, err := m.Post.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n2
	dAtA[i] = 0x28
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.StageID))
	return i, nil
}

func (m *PostProcessSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PostProcessSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Filter.Size()))
	n3, err := m.Filter.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n3
	dAtA[i] = 0x10
	i++
	if m.Projection {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	if len(m.OutputColumns) > 0 {
		dAtA5 := make([]byte, len(m.OutputColumns)*10)
		var j4 int
		for _, num := range m.OutputColumns {
			for num >= 1<<7 {
				dAtA5[j4] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j4++
			}
			dAtA5[j4] = uint8(num)
			j4++
		}
		dAtA[i] = 0x1a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(j4))
		i += copy(dAtA[i:], dAtA5[:j4])
	}
	if len(m.RenderExprs) > 0 {
		for _, msg := range m.RenderExprs {
			dAtA[i] = 0x22
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x28
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Offset))
	dAtA[i] = 0x30
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Limit))
	return i, nil
}

func (m *ProcessorCoreUnion) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ProcessorCoreUnion) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Noop != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Noop.Size()))
		n6, err := m.Noop.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n6
	}
	if m.TableReader != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.TableReader.Size()))
		n7, err := m.TableReader.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n7
	}
	if m.JoinReader != nil {
		dAtA[i] = 0x1a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.JoinReader.Size()))
		n8, err := m.JoinReader.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n8
	}
	if m.Sorter != nil {
		dAtA[i] = 0x22
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Sorter.Size()))
		n9, err := m.Sorter.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n9
	}
	if m.Aggregator != nil {
		dAtA[i] = 0x2a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Aggregator.Size()))
		n10, err := m.Aggregator.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n10
	}
	if m.Distinct != nil {
		dAtA[i] = 0x3a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Distinct.Size()))
		n11, err := m.Distinct.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n11
	}
	if m.MergeJoiner != nil {
		dAtA[i] = 0x42
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.MergeJoiner.Size()))
		n12, err := m.MergeJoiner.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n12
	}
	if m.HashJoiner != nil {
		dAtA[i] = 0x4a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.HashJoiner.Size()))
		n13, err := m.HashJoiner.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n13
	}
	if m.Values != nil {
		dAtA[i] = 0x52
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Values.Size()))
		n14, err := m.Values.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n14
	}
	if m.Backfiller != nil {
		dAtA[i] = 0x5a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Backfiller.Size()))
		n15, err := m.Backfiller.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n15
	}
	if m.SetOp != nil {
		dAtA[i] = 0x62
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.SetOp.Size()))
		n16, err := m.SetOp.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n16
	}
	if m.ReadCSV != nil {
		dAtA[i] = 0x6a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.ReadCSV.Size()))
		n17, err := m.ReadCSV.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n17
	}
	if m.SSTWriter != nil {
		dAtA[i] = 0x72
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.SSTWriter.Size()))
		n18, err := m.SSTWriter.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n18
	}
	if m.Sampler != nil {
		dAtA[i] = 0x7a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.Sampler.Size()))
		n19, err := m.Sampler.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n19
	}
	if m.SampleAggregator != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.SampleAggregator.Size()))
		n20, err := m.SampleAggregator.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n20
	}
	if m.InterleavedReaderJoiner != nil {
		dAtA[i] = 0x8a
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(m.InterleavedReaderJoiner.Size()))
		n21, err := m.InterleavedReaderJoiner.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n21
	}
	return i, nil
}

func (m *NoopCoreSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NoopCoreSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ValuesCoreSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ValuesCoreSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Columns) > 0 {
		for _, msg := range m.Columns {
			dAtA[i] = 0xa
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.RawBytes) > 0 {
		for _, b := range m.RawBytes {
			dAtA[i] = 0x12
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(len(b)))
			i += copy(dAtA[i:], b)
		}
	}
	return i, nil
}

func (m *TableReaderSpan) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TableReaderSpan) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Span.Size()))
	n22, err := m.Span.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n22
	return i, nil
}

func (m *TableReaderSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TableReaderSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Table.Size()))
	n23, err := m.Table.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n23
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.IndexIdx))
	dAtA[i] = 0x18
	i++
	if m.Reverse {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	if len(m.Spans) > 0 {
		for _, msg := range m.Spans {
			dAtA[i] = 0x22
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x28
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.LimitHint))
	dAtA[i] = 0x30
	i++
	if m.IsCheck {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	return i, nil
}

func (m *JoinReaderSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *JoinReaderSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Table.Size()))
	n24, err := m.Table.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n24
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.IndexIdx))
	if len(m.LookupColumns) > 0 {
		dAtA26 := make([]byte, len(m.LookupColumns)*10)
		var j25 int
		for _, num := range m.LookupColumns {
			for num >= 1<<7 {
				dAtA26[j25] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j25++
			}
			dAtA26[j25] = uint8(num)
			j25++
		}
		dAtA[i] = 0x1a
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(j25))
		i += copy(dAtA[i:], dAtA26[:j25])
	}
	return i, nil
}

func (m *SorterSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SorterSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OutputOrdering.Size()))
	n27, err := m.OutputOrdering.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n27
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OrderingMatchLen))
	return i, nil
}

func (m *DistinctSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *DistinctSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.OrderedColumns) > 0 {
		for _, num := range m.OrderedColumns {
			dAtA[i] = 0x8
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(num))
		}
	}
	if len(m.DistinctColumns) > 0 {
		for _, num := range m.DistinctColumns {
			dAtA[i] = 0x10
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(num))
		}
	}
	return i, nil
}

func (m *MergeJoinerSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MergeJoinerSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.LeftOrdering.Size()))
	n28, err := m.LeftOrdering.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n28
	dAtA[i] = 0x12
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.RightOrdering.Size()))
	n29, err := m.RightOrdering.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n29
	dAtA[i] = 0x2a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OnExpr.Size()))
	n30, err := m.OnExpr.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n30
	dAtA[i] = 0x30
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Type))
	dAtA[i] = 0x38
	i++
	if m.NullEquality {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	return i, nil
}

func (m *HashJoinerSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *HashJoinerSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.LeftEqColumns) > 0 {
		dAtA32 := make([]byte, len(m.LeftEqColumns)*10)
		var j31 int
		for _, num := range m.LeftEqColumns {
			for num >= 1<<7 {
				dAtA32[j31] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j31++
			}
			dAtA32[j31] = uint8(num)
			j31++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(j31))
		i += copy(dAtA[i:], dAtA32[:j31])
	}
	if len(m.RightEqColumns) > 0 {
		dAtA34 := make([]byte, len(m.RightEqColumns)*10)
		var j33 int
		for _, num := range m.RightEqColumns {
			for num >= 1<<7 {
				dAtA34[j33] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j33++
			}
			dAtA34[j33] = uint8(num)
			j33++
		}
		dAtA[i] = 0x12
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(j33))
		i += copy(dAtA[i:], dAtA34[:j33])
	}
	dAtA[i] = 0x2a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OnExpr.Size()))
	n35, err := m.OnExpr.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n35
	dAtA[i] = 0x30
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Type))
	dAtA[i] = 0x38
	i++
	if m.MergedColumns {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	return i, nil
}

func (m *AggregatorSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AggregatorSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.GroupCols) > 0 {
		dAtA37 := make([]byte, len(m.GroupCols)*10)
		var j36 int
		for _, num := range m.GroupCols {
			for num >= 1<<7 {
				dAtA37[j36] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j36++
			}
			dAtA37[j36] = uint8(num)
			j36++
		}
		dAtA[i] = 0x12
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(j36))
		i += copy(dAtA[i:], dAtA37[:j36])
	}
	if len(m.Aggregations) > 0 {
		for _, msg := range m.Aggregations {
			dAtA[i] = 0x1a
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *AggregatorSpec_Aggregation) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AggregatorSpec_Aggregation) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0x8
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Func))
	dAtA[i] = 0x10
	i++
	if m.Distinct {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	if m.FilterColIdx != nil {
		dAtA[i] = 0x20
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(*m.FilterColIdx))
	}
	if len(m.ColIdx) > 0 {
		for _, num := range m.ColIdx {
			dAtA[i] = 0x28
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(num))
		}
	}
	return i, nil
}

func (m *BackfillerSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackfillerSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0x8
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Type))
	dAtA[i] = 0x12
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Table.Size()))
	n38, err := m.Table.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n38
	if len(m.Spans) > 0 {
		for _, msg := range m.Spans {
			dAtA[i] = 0x1a
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x20
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Duration))
	dAtA[i] = 0x28
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.ChunkSize))
	if len(m.OtherTables) > 0 {
		for _, msg := range m.OtherTables {
			dAtA[i] = 0x32
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x3a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.ReadAsOf.Size()))
	n39, err := m.ReadAsOf.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n39
	return i, nil
}

func (m *FlowSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *FlowSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.FlowID.Size()))
	n40, err := m.FlowID.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n40
	if len(m.Processors) > 0 {
		for _, msg := range m.Processors {
			dAtA[i] = 0x12
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x18
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Gateway))
	return i, nil
}

func (m *AlgebraicSetOpSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AlgebraicSetOpSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Ordering.Size()))
	n41, err := m.Ordering.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n41
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OpType))
	return i, nil
}

func (m *JobProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *JobProgress) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0x8
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.JobID))
	dAtA[i] = 0x15
	i++
	binary.LittleEndian.PutUint32(dAtA[i:], uint32(math.Float32bits(float32(m.Contribution))))
	i += 4
	dAtA[i] = 0x18
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Slot))
	return i, nil
}

func (m *ReadCSVSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ReadCSVSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Options.Size()))
	n42, err := m.Options.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n42
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.SampleSize))
	dAtA[i] = 0x1a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.TableDesc.Size()))
	n43, err := m.TableDesc.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n43
	dAtA[i] = 0x32
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Progress.Size()))
	n44, err := m.Progress.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n44
	if len(m.Uri) > 0 {
		keysForUri := make([]int32, 0, len(m.Uri))
		for k := range m.Uri {
			keysForUri = append(keysForUri, int32(k))
		}
		sortkeys.Int32s(keysForUri)
		for _, k := range keysForUri {
			dAtA[i] = 0x3a
			i++
			v := m.Uri[int32(k)]
			mapSize := 1 + sovProcessors(uint64(k)) + 1 + len(v) + sovProcessors(uint64(len(v)))
			i = encodeVarintProcessors(dAtA, i, uint64(mapSize))
			dAtA[i] = 0x8
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(k))
			dAtA[i] = 0x12
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(len(v)))
			i += copy(dAtA[i:], v)
		}
	}
	return i, nil
}

func (m *SSTWriterSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SSTWriterSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(len(m.Destination)))
	i += copy(dAtA[i:], m.Destination)
	dAtA[i] = 0x18
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.WalltimeNanos))
	if len(m.Spans) > 0 {
		for _, msg := range m.Spans {
			dAtA[i] = 0x22
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x2a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Progress.Size()))
	n45, err := m.Progress.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n45
	return i, nil
}

func (m *SSTWriterSpec_SpanName) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SSTWriterSpec_SpanName) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(len(m.Name)))
	i += copy(dAtA[i:], m.Name)
	if m.End != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintProcessors(dAtA, i, uint64(len(m.End)))
		i += copy(dAtA[i:], m.End)
	}
	return i, nil
}

func (m *SketchSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SketchSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0x8
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.SketchType))
	if len(m.Columns) > 0 {
		for _, num := range m.Columns {
			dAtA[i] = 0x10
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(num))
		}
	}
	dAtA[i] = 0x18
	i++
	if m.GenerateHistogram {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	dAtA[i] = 0x20
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.HistogramMaxBuckets))
	dAtA[i] = 0x2a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(len(m.StatName)))
	i += copy(dAtA[i:], m.StatName)
	return i, nil
}

func (m *SamplerSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SamplerSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Sketches) > 0 {
		for _, msg := range m.Sketches {
			dAtA[i] = 0xa
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.SampleSize))
	return i, nil
}

func (m *SampleAggregatorSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SampleAggregatorSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Sketches) > 0 {
		for _, msg := range m.Sketches {
			dAtA[i] = 0xa
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.SampleSize))
	if len(m.SampledColumnIDs) > 0 {
		for _, num := range m.SampledColumnIDs {
			dAtA[i] = 0x18
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(num))
		}
	}
	dAtA[i] = 0x20
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.TableID))
	return i, nil
}

func (m *InterleavedReaderJoinerSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InterleavedReaderJoinerSpec) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Tables) > 0 {
		for _, msg := range m.Tables {
			dAtA[i] = 0xa
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	dAtA[i] = 0x10
	i++
	if m.Reverse {
		dAtA[i] = 1
	} else {
		dAtA[i] = 0
	}
	i++
	dAtA[i] = 0x18
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.LimitHint))
	dAtA[i] = 0x22
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.OnExpr.Size()))
	n46, err := m.OnExpr.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n46
	dAtA[i] = 0x28
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Type))
	return i, nil
}

func (m *InterleavedReaderJoinerSpec_Table) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InterleavedReaderJoinerSpec_Table) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	dAtA[i] = 0xa
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Desc.Size()))
	n47, err := m.Desc.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n47
	dAtA[i] = 0x10
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.IndexIdx))
	dAtA[i] = 0x1a
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Post.Size()))
	n48, err := m.Post.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n48
	dAtA[i] = 0x22
	i++
	i = encodeVarintProcessors(dAtA, i, uint64(m.Ordering.Size()))
	n49, err := m.Ordering.MarshalTo(dAtA[i:])
	if err != nil {
		return 0, err
	}
	i += n49
	if len(m.Spans) > 0 {
		for _, msg := range m.Spans {
			dAtA[i] = 0x2a
			i++
			i = encodeVarintProcessors(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func encodeVarintProcessors(dAtA []byte, offset int, v uint64) int {
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return offset + 1
}
func (m *ProcessorSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.Input) > 0 {
		for _, e := range m.Input {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	l = m.Core.Size()
	n += 1 + l + sovProcessors(uint64(l))
	if len(m.Output) > 0 {
		for _, e := range m.Output {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	l = m.Post.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.StageID))
	return n
}

func (m *PostProcessSpec) Size() (n int) {
	var l int
	_ = l
	l = m.Filter.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 2
	if len(m.OutputColumns) > 0 {
		l = 0
		for _, e := range m.OutputColumns {
			l += sovProcessors(uint64(e))
		}
		n += 1 + sovProcessors(uint64(l)) + l
	}
	if len(m.RenderExprs) > 0 {
		for _, e := range m.RenderExprs {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.Offset))
	n += 1 + sovProcessors(uint64(m.Limit))
	return n
}

func (m *ProcessorCoreUnion) Size() (n int) {
	var l int
	_ = l
	if m.Noop != nil {
		l = m.Noop.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.TableReader != nil {
		l = m.TableReader.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.JoinReader != nil {
		l = m.JoinReader.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Sorter != nil {
		l = m.Sorter.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Aggregator != nil {
		l = m.Aggregator.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Distinct != nil {
		l = m.Distinct.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.MergeJoiner != nil {
		l = m.MergeJoiner.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.HashJoiner != nil {
		l = m.HashJoiner.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Values != nil {
		l = m.Values.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Backfiller != nil {
		l = m.Backfiller.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.SetOp != nil {
		l = m.SetOp.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.ReadCSV != nil {
		l = m.ReadCSV.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.SSTWriter != nil {
		l = m.SSTWriter.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.Sampler != nil {
		l = m.Sampler.Size()
		n += 1 + l + sovProcessors(uint64(l))
	}
	if m.SampleAggregator != nil {
		l = m.SampleAggregator.Size()
		n += 2 + l + sovProcessors(uint64(l))
	}
	if m.InterleavedReaderJoiner != nil {
		l = m.InterleavedReaderJoiner.Size()
		n += 2 + l + sovProcessors(uint64(l))
	}
	return n
}

func (m *NoopCoreSpec) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ValuesCoreSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.Columns) > 0 {
		for _, e := range m.Columns {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	if len(m.RawBytes) > 0 {
		for _, b := range m.RawBytes {
			l = len(b)
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	return n
}

func (m *TableReaderSpan) Size() (n int) {
	var l int
	_ = l
	l = m.Span.Size()
	n += 1 + l + sovProcessors(uint64(l))
	return n
}

func (m *TableReaderSpec) Size() (n int) {
	var l int
	_ = l
	l = m.Table.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.IndexIdx))
	n += 2
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.LimitHint))
	n += 2
	return n
}

func (m *JoinReaderSpec) Size() (n int) {
	var l int
	_ = l
	l = m.Table.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.IndexIdx))
	if len(m.LookupColumns) > 0 {
		l = 0
		for _, e := range m.LookupColumns {
			l += sovProcessors(uint64(e))
		}
		n += 1 + sovProcessors(uint64(l)) + l
	}
	return n
}

func (m *SorterSpec) Size() (n int) {
	var l int
	_ = l
	l = m.OutputOrdering.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.OrderingMatchLen))
	return n
}

func (m *DistinctSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.OrderedColumns) > 0 {
		for _, e := range m.OrderedColumns {
			n += 1 + sovProcessors(uint64(e))
		}
	}
	if len(m.DistinctColumns) > 0 {
		for _, e := range m.DistinctColumns {
			n += 1 + sovProcessors(uint64(e))
		}
	}
	return n
}

func (m *MergeJoinerSpec) Size() (n int) {
	var l int
	_ = l
	l = m.LeftOrdering.Size()
	n += 1 + l + sovProcessors(uint64(l))
	l = m.RightOrdering.Size()
	n += 1 + l + sovProcessors(uint64(l))
	l = m.OnExpr.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.Type))
	n += 2
	return n
}

func (m *HashJoinerSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.LeftEqColumns) > 0 {
		l = 0
		for _, e := range m.LeftEqColumns {
			l += sovProcessors(uint64(e))
		}
		n += 1 + sovProcessors(uint64(l)) + l
	}
	if len(m.RightEqColumns) > 0 {
		l = 0
		for _, e := range m.RightEqColumns {
			l += sovProcessors(uint64(e))
		}
		n += 1 + sovProcessors(uint64(l)) + l
	}
	l = m.OnExpr.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.Type))
	n += 2
	return n
}

func (m *AggregatorSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.GroupCols) > 0 {
		l = 0
		for _, e := range m.GroupCols {
			l += sovProcessors(uint64(e))
		}
		n += 1 + sovProcessors(uint64(l)) + l
	}
	if len(m.Aggregations) > 0 {
		for _, e := range m.Aggregations {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	return n
}

func (m *AggregatorSpec_Aggregation) Size() (n int) {
	var l int
	_ = l
	n += 1 + sovProcessors(uint64(m.Func))
	n += 2
	if m.FilterColIdx != nil {
		n += 1 + sovProcessors(uint64(*m.FilterColIdx))
	}
	if len(m.ColIdx) > 0 {
		for _, e := range m.ColIdx {
			n += 1 + sovProcessors(uint64(e))
		}
	}
	return n
}

func (m *BackfillerSpec) Size() (n int) {
	var l int
	_ = l
	n += 1 + sovProcessors(uint64(m.Type))
	l = m.Table.Size()
	n += 1 + l + sovProcessors(uint64(l))
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.Duration))
	n += 1 + sovProcessors(uint64(m.ChunkSize))
	if len(m.OtherTables) > 0 {
		for _, e := range m.OtherTables {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	l = m.ReadAsOf.Size()
	n += 1 + l + sovProcessors(uint64(l))
	return n
}

func (m *FlowSpec) Size() (n int) {
	var l int
	_ = l
	l = m.FlowID.Size()
	n += 1 + l + sovProcessors(uint64(l))
	if len(m.Processors) > 0 {
		for _, e := range m.Processors {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.Gateway))
	return n
}

func (m *AlgebraicSetOpSpec) Size() (n int) {
	var l int
	_ = l
	l = m.Ordering.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.OpType))
	return n
}

func (m *JobProgress) Size() (n int) {
	var l int
	_ = l
	n += 1 + sovProcessors(uint64(m.JobID))
	n += 5
	n += 1 + sovProcessors(uint64(m.Slot))
	return n
}

func (m *ReadCSVSpec) Size() (n int) {
	var l int
	_ = l
	l = m.Options.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.SampleSize))
	l = m.TableDesc.Size()
	n += 1 + l + sovProcessors(uint64(l))
	l = m.Progress.Size()
	n += 1 + l + sovProcessors(uint64(l))
	if len(m.Uri) > 0 {
		for k, v := range m.Uri {
			_ = k
			_ = v
			mapEntrySize := 1 + sovProcessors(uint64(k)) + 1 + len(v) + sovProcessors(uint64(len(v)))
			n += mapEntrySize + 1 + sovProcessors(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *SSTWriterSpec) Size() (n int) {
	var l int
	_ = l
	l = len(m.Destination)
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.WalltimeNanos))
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	l = m.Progress.Size()
	n += 1 + l + sovProcessors(uint64(l))
	return n
}

func (m *SSTWriterSpec_SpanName) Size() (n int) {
	var l int
	_ = l
	l = len(m.Name)
	n += 1 + l + sovProcessors(uint64(l))
	if m.End != nil {
		l = len(m.End)
		n += 1 + l + sovProcessors(uint64(l))
	}
	return n
}

func (m *SketchSpec) Size() (n int) {
	var l int
	_ = l
	n += 1 + sovProcessors(uint64(m.SketchType))
	if len(m.Columns) > 0 {
		for _, e := range m.Columns {
			n += 1 + sovProcessors(uint64(e))
		}
	}
	n += 2
	n += 1 + sovProcessors(uint64(m.HistogramMaxBuckets))
	l = len(m.StatName)
	n += 1 + l + sovProcessors(uint64(l))
	return n
}

func (m *SamplerSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.Sketches) > 0 {
		for _, e := range m.Sketches {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.SampleSize))
	return n
}

func (m *SampleAggregatorSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.Sketches) > 0 {
		for _, e := range m.Sketches {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 1 + sovProcessors(uint64(m.SampleSize))
	if len(m.SampledColumnIDs) > 0 {
		for _, e := range m.SampledColumnIDs {
			n += 1 + sovProcessors(uint64(e))
		}
	}
	n += 1 + sovProcessors(uint64(m.TableID))
	return n
}

func (m *InterleavedReaderJoinerSpec) Size() (n int) {
	var l int
	_ = l
	if len(m.Tables) > 0 {
		for _, e := range m.Tables {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	n += 2
	n += 1 + sovProcessors(uint64(m.LimitHint))
	l = m.OnExpr.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.Type))
	return n
}

func (m *InterleavedReaderJoinerSpec_Table) Size() (n int) {
	var l int
	_ = l
	l = m.Desc.Size()
	n += 1 + l + sovProcessors(uint64(l))
	n += 1 + sovProcessors(uint64(m.IndexIdx))
	l = m.Post.Size()
	n += 1 + l + sovProcessors(uint64(l))
	l = m.Ordering.Size()
	n += 1 + l + sovProcessors(uint64(l))
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovProcessors(uint64(l))
		}
	}
	return n
}

func sovProcessors(x uint64) (n int) {
	for {
		n++
		x >>= 7
		if x == 0 {
			break
		}
	}
	return n
}
func sozProcessors(x uint64) (n int) {
	return sovProcessors(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *ProcessorCoreUnion) GetValue() interface{} {
	if this.Noop != nil {
		return this.Noop
	}
	if this.TableReader != nil {
		return this.TableReader
	}
	if this.JoinReader != nil {
		return this.JoinReader
	}
	if this.Sorter != nil {
		return this.Sorter
	}
	if this.Aggregator != nil {
		return this.Aggregator
	}
	if this.Distinct != nil {
		return this.Distinct
	}
	if this.MergeJoiner != nil {
		return this.MergeJoiner
	}
	if this.HashJoiner != nil {
		return this.HashJoiner
	}
	if this.Values != nil {
		return this.Values
	}
	if this.Backfiller != nil {
		return this.Backfiller
	}
	if this.SetOp != nil {
		return this.SetOp
	}
	if this.ReadCSV != nil {
		return this.ReadCSV
	}
	if this.SSTWriter != nil {
		return this.SSTWriter
	}
	if this.Sampler != nil {
		return this.Sampler
	}
	if this.SampleAggregator != nil {
		return this.SampleAggregator
	}
	if this.InterleavedReaderJoiner != nil {
		return this.InterleavedReaderJoiner
	}
	return nil
}

func (this *ProcessorCoreUnion) SetValue(value interface{}) bool {
	switch vt := value.(type) {
	case *NoopCoreSpec:
		this.Noop = vt
	case *TableReaderSpec:
		this.TableReader = vt
	case *JoinReaderSpec:
		this.JoinReader = vt
	case *SorterSpec:
		this.Sorter = vt
	case *AggregatorSpec:
		this.Aggregator = vt
	case *DistinctSpec:
		this.Distinct = vt
	case *MergeJoinerSpec:
		this.MergeJoiner = vt
	case *HashJoinerSpec:
		this.HashJoiner = vt
	case *ValuesCoreSpec:
		this.Values = vt
	case *BackfillerSpec:
		this.Backfiller = vt
	case *AlgebraicSetOpSpec:
		this.SetOp = vt
	case *ReadCSVSpec:
		this.ReadCSV = vt
	case *SSTWriterSpec:
		this.SSTWriter = vt
	case *SamplerSpec:
		this.Sampler = vt
	case *SampleAggregatorSpec:
		this.SampleAggregator = vt
	case *InterleavedReaderJoinerSpec:
		this.InterleavedReaderJoiner = vt
	default:
		return false
	}
	return true
}
func (m *ProcessorSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ProcessorSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ProcessorSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Input", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Input = append(m.Input, InputSyncSpec{})
			if err := m.Input[len(m.Input)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Core", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Core.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Output", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Output = append(m.Output, OutputRouterSpec{})
			if err := m.Output[len(m.Output)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Post", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Post.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StageID", wireType)
			}
			m.StageID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StageID |= (int32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PostProcessSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PostProcessSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PostProcessSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Filter", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Filter.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Projection", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Projection = bool(v != 0)
		case 3:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.OutputColumns = append(m.OutputColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.OutputColumns = append(m.OutputColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputColumns", wireType)
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RenderExprs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RenderExprs = append(m.RenderExprs, Expression{})
			if err := m.RenderExprs[len(m.RenderExprs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Offset", wireType)
			}
			m.Offset = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Offset |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Limit", wireType)
			}
			m.Limit = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Limit |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ProcessorCoreUnion) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ProcessorCoreUnion: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ProcessorCoreUnion: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Noop", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Noop == nil {
				m.Noop = &NoopCoreSpec{}
			}
			if err := m.Noop.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableReader", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TableReader == nil {
				m.TableReader = &TableReaderSpec{}
			}
			if err := m.TableReader.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field JoinReader", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.JoinReader == nil {
				m.JoinReader = &JoinReaderSpec{}
			}
			if err := m.JoinReader.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Sorter", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Sorter == nil {
				m.Sorter = &SorterSpec{}
			}
			if err := m.Sorter.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Aggregator", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Aggregator == nil {
				m.Aggregator = &AggregatorSpec{}
			}
			if err := m.Aggregator.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Distinct", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Distinct == nil {
				m.Distinct = &DistinctSpec{}
			}
			if err := m.Distinct.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MergeJoiner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.MergeJoiner == nil {
				m.MergeJoiner = &MergeJoinerSpec{}
			}
			if err := m.MergeJoiner.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 9:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HashJoiner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.HashJoiner == nil {
				m.HashJoiner = &HashJoinerSpec{}
			}
			if err := m.HashJoiner.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Values", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Values == nil {
				m.Values = &ValuesCoreSpec{}
			}
			if err := m.Values.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Backfiller", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Backfiller == nil {
				m.Backfiller = &BackfillerSpec{}
			}
			if err := m.Backfiller.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SetOp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SetOp == nil {
				m.SetOp = &AlgebraicSetOpSpec{}
			}
			if err := m.SetOp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReadCSV", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ReadCSV == nil {
				m.ReadCSV = &ReadCSVSpec{}
			}
			if err := m.ReadCSV.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SSTWriter", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SSTWriter == nil {
				m.SSTWriter = &SSTWriterSpec{}
			}
			if err := m.SSTWriter.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Sampler", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Sampler == nil {
				m.Sampler = &SamplerSpec{}
			}
			if err := m.Sampler.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SampleAggregator", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SampleAggregator == nil {
				m.SampleAggregator = &SampleAggregatorSpec{}
			}
			if err := m.SampleAggregator.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InterleavedReaderJoiner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.InterleavedReaderJoiner == nil {
				m.InterleavedReaderJoiner = &InterleavedReaderJoinerSpec{}
			}
			if err := m.InterleavedReaderJoiner.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NoopCoreSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NoopCoreSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NoopCoreSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ValuesCoreSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ValuesCoreSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ValuesCoreSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Columns", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Columns = append(m.Columns, DatumInfo{})
			if err := m.Columns[len(m.Columns)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RawBytes", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RawBytes = append(m.RawBytes, make([]byte, postIndex-iNdEx))
			copy(m.RawBytes[len(m.RawBytes)-1], dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TableReaderSpan) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TableReaderSpan: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TableReaderSpan: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Span", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Span.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TableReaderSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TableReaderSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TableReaderSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Table", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Table.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexIdx", wireType)
			}
			m.IndexIdx = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexIdx |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Reverse", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Reverse = bool(v != 0)
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, TableReaderSpan{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field LimitHint", wireType)
			}
			m.LimitHint = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.LimitHint |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IsCheck", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.IsCheck = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *JoinReaderSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: JoinReaderSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: JoinReaderSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Table", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Table.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexIdx", wireType)
			}
			m.IndexIdx = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexIdx |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.LookupColumns = append(m.LookupColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.LookupColumns = append(m.LookupColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field LookupColumns", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SorterSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SorterSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SorterSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputOrdering", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.OutputOrdering.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OrderingMatchLen", wireType)
			}
			m.OrderingMatchLen = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OrderingMatchLen |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *DistinctSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DistinctSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DistinctSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.OrderedColumns = append(m.OrderedColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.OrderedColumns = append(m.OrderedColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field OrderedColumns", wireType)
			}
		case 2:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DistinctColumns = append(m.DistinctColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DistinctColumns = append(m.DistinctColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DistinctColumns", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MergeJoinerSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MergeJoinerSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MergeJoinerSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LeftOrdering", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.LeftOrdering.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RightOrdering", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.RightOrdering.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OnExpr", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.OnExpr.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (JoinType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NullEquality", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.NullEquality = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *HashJoinerSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: HashJoinerSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: HashJoinerSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.LeftEqColumns = append(m.LeftEqColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.LeftEqColumns = append(m.LeftEqColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field LeftEqColumns", wireType)
			}
		case 2:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.RightEqColumns = append(m.RightEqColumns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.RightEqColumns = append(m.RightEqColumns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field RightEqColumns", wireType)
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OnExpr", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.OnExpr.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (JoinType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MergedColumns", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.MergedColumns = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AggregatorSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AggregatorSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AggregatorSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 2:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.GroupCols = append(m.GroupCols, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.GroupCols = append(m.GroupCols, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field GroupCols", wireType)
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Aggregations", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Aggregations = append(m.Aggregations, AggregatorSpec_Aggregation{})
			if err := m.Aggregations[len(m.Aggregations)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AggregatorSpec_Aggregation) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Aggregation: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Aggregation: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Func", wireType)
			}
			m.Func = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Func |= (AggregatorSpec_Func(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Distinct", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Distinct = bool(v != 0)
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field FilterColIdx", wireType)
			}
			var v uint32
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.FilterColIdx = &v
		case 5:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ColIdx = append(m.ColIdx, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ColIdx = append(m.ColIdx, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ColIdx", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackfillerSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackfillerSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackfillerSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (BackfillerSpec_Type(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Table", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Table.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, TableReaderSpan{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Duration", wireType)
			}
			m.Duration = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Duration |= (time.Duration(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ChunkSize", wireType)
			}
			m.ChunkSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ChunkSize |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OtherTables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OtherTables = append(m.OtherTables, cockroach_sql_sqlbase1.TableDescriptor{})
			if err := m.OtherTables[len(m.OtherTables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReadAsOf", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReadAsOf.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *FlowSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: FlowSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: FlowSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FlowID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.FlowID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Processors", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Processors = append(m.Processors, ProcessorSpec{})
			if err := m.Processors[len(m.Processors)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Gateway", wireType)
			}
			m.Gateway = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Gateway |= (github_com_cockroachdb_cockroach_pkg_roachpb.NodeID(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AlgebraicSetOpSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AlgebraicSetOpSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AlgebraicSetOpSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Ordering", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Ordering.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OpType", wireType)
			}
			m.OpType = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OpType |= (AlgebraicSetOpSpec_SetOpType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *JobProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: JobProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: JobProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field JobID", wireType)
			}
			m.JobID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.JobID |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Contribution", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			v = uint32(binary.LittleEndian.Uint32(dAtA[iNdEx:]))
			iNdEx += 4
			m.Contribution = float32(math.Float32frombits(v))
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Slot", wireType)
			}
			m.Slot = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Slot |= (int32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ReadCSVSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ReadCSVSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ReadCSVSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Options", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Options.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SampleSize", wireType)
			}
			m.SampleSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SampleSize |= (int32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableDesc", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.TableDesc.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Progress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Progress.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Uri", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Uri == nil {
				m.Uri = make(map[int32]string)
			}
			var mapkey int32
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= (int32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthProcessors
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipProcessors(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if skippy < 0 {
						return ErrInvalidLengthProcessors
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Uri[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SSTWriterSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SSTWriterSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SSTWriterSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Destination", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Destination = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field WalltimeNanos", wireType)
			}
			m.WalltimeNanos = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.WalltimeNanos |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, SSTWriterSpec_SpanName{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Progress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Progress.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SSTWriterSpec_SpanName) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SpanName: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SpanName: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field End", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.End = append(m.End[:0], dAtA[iNdEx:postIndex]...)
			if m.End == nil {
				m.End = []byte{}
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SketchSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SketchSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SketchSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SketchType", wireType)
			}
			m.SketchType = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SketchType |= (SketchType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Columns = append(m.Columns, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Columns = append(m.Columns, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Columns", wireType)
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field GenerateHistogram", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.GenerateHistogram = bool(v != 0)
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HistogramMaxBuckets", wireType)
			}
			m.HistogramMaxBuckets = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.HistogramMaxBuckets |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StatName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SamplerSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SamplerSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SamplerSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Sketches", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Sketches = append(m.Sketches, SketchSpec{})
			if err := m.Sketches[len(m.Sketches)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SampleSize", wireType)
			}
			m.SampleSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SampleSize |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SampleAggregatorSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SampleAggregatorSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SampleAggregatorSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Sketches", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Sketches = append(m.Sketches, SketchSpec{})
			if err := m.Sketches[len(m.Sketches)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SampleSize", wireType)
			}
			m.SampleSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SampleSize |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ColumnID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ColumnID(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.SampledColumnIDs = append(m.SampledColumnIDs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthProcessors
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ColumnID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowProcessors
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ColumnID(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.SampledColumnIDs = append(m.SampledColumnIDs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field SampledColumnIDs", wireType)
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= (github_com_cockroachdb_cockroach_pkg_sql_sqlbase.ID(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InterleavedReaderJoinerSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: InterleavedReaderJoinerSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: InterleavedReaderJoinerSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tables = append(m.Tables, InterleavedReaderJoinerSpec_Table{})
			if err := m.Tables[len(m.Tables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Reverse", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Reverse = bool(v != 0)
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field LimitHint", wireType)
			}
			m.LimitHint = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.LimitHint |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OnExpr", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.OnExpr.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (JoinType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InterleavedReaderJoinerSpec_Table) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Table: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Table: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Desc", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Desc.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexIdx", wireType)
			}
			m.IndexIdx = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexIdx |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Post", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Post.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Ordering", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Ordering.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthProcessors
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, TableReaderSpan{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipProcessors(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthProcessors
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipProcessors(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowProcessors
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowProcessors
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			iNdEx += length
			if length < 0 {
				return 0, ErrInvalidLengthProcessors
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowProcessors
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipProcessors(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthProcessors = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowProcessors   = fmt.Errorf("proto: integer overflow")
)

func init() { proto.RegisterFile("sql/distsqlrun/processors.proto", fileDescriptorProcessors) }

var fileDescriptorProcessors = []byte{
	// 2678 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xcc, 0x19, 0x4d, 0x6f, 0x1b, 0xc7,
	0x55, 0x24, 0x97, 0x14, 0xf9, 0xf8, 0xa1, 0xf5, 0xc4, 0x41, 0x58, 0x27, 0x95, 0x1c, 0xc6, 0x49,
	0x6c, 0x35, 0xa5, 0x6a, 0xa7, 0x0d, 0xd2, 0x24, 0x45, 0xc2, 0x2f, 0x59, 0x54, 0x24, 0xd2, 0x59,
	0x52, 0xca, 0xc7, 0xa1, 0x8b, 0xe5, 0xee, 0x88, 0x5c, 0x6b, 0xb9, 0x43, 0xed, 0x2e, 0x2d, 0x29,
	0x28, 0x50, 0xf4, 0x50, 0xf4, 0xd6, 0x16, 0xe8, 0xad, 0xa7, 0xa2, 0x40, 0xcf, 0xbd, 0x15, 0xbd,
	0xb4, 0x67, 0x9f, 0x8a, 0xde, 0x5a, 0xf4, 0xe0, 0xb6, 0x4a, 0x2f, 0xfd, 0x0b, 0x3e, 0x15, 0xf3,
	0x76, 0x66, 0xb9, 0xb4, 0xad, 0x0f, 0xdb, 0x40, 0xd0, 0x0b, 0xb1, 0xf3, 0xbe, 0xe6, 0xcd, 0x9b,
	0x37, 0xef, 0x8b, 0xb0, 0xe2, 0x1f, 0x38, 0x6b, 0x96, 0xed, 0x07, 0xfe, 0x81, 0xe3, 0x4d, 0xdd,
	0xb5, 0x89, 0xc7, 0x4c, 0xea, 0xfb, 0xcc, 0xf3, 0xab, 0x13, 0x8f, 0x05, 0x8c, 0x94, 0x4d, 0x66,
	0xee, 0x7b, 0xcc, 0x30, 0x47, 0x55, 0xff, 0xc0, 0xa9, 0xce, 0x48, 0xaf, 0x5c, 0x42, 0xe8, 0x64,
	0xb0, 0x66, 0x4c, 0xec, 0x90, 0x78, 0x06, 0x32, 0xfd, 0x7b, 0x02, 0x44, 0x24, 0xc8, 0x32, 0x02,
	0x43, 0xc0, 0x2e, 0x4b, 0x18, 0xf5, 0xbc, 0x68, 0xa7, 0x2b, 0xaf, 0x70, 0x55, 0xfc, 0x03, 0x67,
	0x60, 0xf8, 0x74, 0xcd, 0x0f, 0xbc, 0xa9, 0x19, 0x4c, 0x3d, 0x6a, 0x09, 0xec, 0x4a, 0x1c, 0x4b,
	0x5d, 0x93, 0x59, 0xd4, 0xd2, 0x2d, 0x23, 0x98, 0x8e, 0x05, 0xc1, 0x37, 0x1e, 0x39, 0x49, 0x6c,
	0xbf, 0xf2, 0x34, 0xb0, 0x9d, 0xb5, 0x91, 0x63, 0xae, 0x05, 0xf6, 0x98, 0xfa, 0x81, 0x31, 0x9e,
	0x48, 0x4d, 0x86, 0x6c, 0xc8, 0xf0, 0x73, 0x8d, 0x7f, 0x85, 0xd0, 0xca, 0xdf, 0x92, 0x50, 0xbc,
	0x23, 0x0d, 0xd1, 0x9b, 0x50, 0x93, 0x34, 0x20, 0x6d, 0xbb, 0x93, 0x69, 0x50, 0x4e, 0x5c, 0x4d,
	0x5d, 0xcf, 0xdf, 0x7a, 0xb3, 0x7a, 0x9a, 0x55, 0xaa, 0x6d, 0x4e, 0xd6, 0x3b, 0x76, 0x4d, 0xce,
	0x57, 0x57, 0xee, 0x3f, 0x58, 0x59, 0xd0, 0x42, 0x5e, 0xb2, 0x0e, 0x8a, 0xc9, 0x3c, 0x5a, 0x4e,
	0x5e, 0x4d, 0x5c, 0xcf, 0xdf, 0x7a, 0xeb, 0x74, 0x19, 0xd1, 0xde, 0x0d, 0xe6, 0xd1, 0x1d, 0xd7,
	0x66, 0xae, 0x10, 0x84, 0xfc, 0x64, 0x03, 0x32, 0x6c, 0x1a, 0x70, 0x6d, 0x52, 0xa8, 0xcd, 0xea,
	0xe9, 0x92, 0xba, 0x48, 0xa7, 0xb1, 0x69, 0x40, 0xbd, 0x98, 0x42, 0x82, 0x9f, 0x34, 0x40, 0x99,
	0x30, 0x3f, 0x28, 0x2b, 0xa8, 0xd1, 0x8d, 0x33, 0x34, 0x62, 0x7e, 0x20, 0xb4, 0x8a, 0x89, 0x41,
	0x66, 0xb2, 0x0a, 0x59, 0x3f, 0x30, 0x86, 0x54, 0xb7, 0xad, 0x72, 0xfa, 0x6a, 0xe2, 0x7a, 0xba,
	0xbe, 0xc4, 0xb1, 0x27, 0x0f, 0x56, 0x16, 0x7b, 0x1c, 0xde, 0x6e, 0x6a, 0x8b, 0x48, 0xd0, 0xb6,
	0x2a, 0xbf, 0x4f, 0xc2, 0xd2, 0x23, 0xb2, 0x48, 0x1d, 0x32, 0x7b, 0xb6, 0x13, 0x50, 0xaf, 0x9c,
	0x40, 0x35, 0xae, 0x9d, 0xae, 0x46, 0xeb, 0x68, 0xe2, 0x51, 0xdf, 0x9f, 0x19, 0x44, 0x70, 0x92,
	0x6b, 0x00, 0x13, 0x8f, 0xdd, 0xa5, 0x66, 0x60, 0x33, 0x17, 0x0d, 0x9c, 0x15, 0x14, 0x31, 0x38,
	0xb9, 0x01, 0xa5, 0xf0, 0xe0, 0xba, 0xc9, 0x9c, 0xe9, 0xd8, 0xf5, 0xd1, 0x80, 0xc5, 0x7a, 0x52,
	0x4d, 0x68, 0xc5, 0x10, 0xd3, 0x08, 0x11, 0x64, 0x1b, 0x0a, 0x1e, 0x75, 0x2d, 0xea, 0xe9, 0xf4,
	0x68, 0xe2, 0xf9, 0x65, 0x05, 0x2d, 0xfd, 0x34, 0xaa, 0xe5, 0x43, 0x7e, 0x0e, 0xf7, 0xc9, 0x2b,
	0x90, 0x61, 0x7b, 0x7b, 0x3e, 0x0d, 0xd0, 0x42, 0x4a, 0x74, 0x0d, 0x08, 0x23, 0x57, 0x20, 0xed,
	0xd8, 0x63, 0x3b, 0x28, 0x67, 0x62, 0xc8, 0x10, 0x54, 0xf9, 0x43, 0x0e, 0xc8, 0xe3, 0xfe, 0x40,
	0xde, 0x03, 0xc5, 0x65, 0x6c, 0x22, 0x4c, 0xf6, 0xc6, 0xe9, 0x7a, 0x75, 0x18, 0x9b, 0x70, 0x36,
	0x6e, 0x6a, 0x0d, 0x79, 0xc8, 0xc7, 0x90, 0x0f, 0x8c, 0x81, 0x43, 0x35, 0x6a, 0x58, 0xd4, 0x13,
	0xee, 0x78, 0xc6, 0xe5, 0xf7, 0x67, 0xc4, 0x28, 0x25, 0xce, 0x4d, 0x36, 0x00, 0xee, 0x32, 0xdb,
	0x15, 0xb2, 0x52, 0x28, 0xeb, 0xfa, 0xe9, 0xb2, 0x36, 0x23, 0x5a, 0x14, 0x15, 0xe3, 0x25, 0x1f,
	0x40, 0xc6, 0x67, 0x1e, 0xf7, 0x03, 0xe5, 0x3c, 0x3f, 0xe8, 0x21, 0x1d, 0x4a, 0x10, 0x3c, 0x5c,
	0x0f, 0x63, 0x38, 0xf4, 0xe8, 0xd0, 0x08, 0x98, 0x87, 0x56, 0x3e, 0x53, 0x8f, 0x5a, 0x44, 0x1b,
	0xea, 0x31, 0xe3, 0x25, 0x75, 0xc8, 0x72, 0x42, 0xdb, 0x35, 0x83, 0xf2, 0xe2, 0x79, 0xe6, 0x6d,
	0x0a, 0x4a, 0x94, 0x12, 0xf1, 0x71, 0x13, 0x8f, 0xa9, 0x37, 0xa4, 0xfc, 0xb8, 0xd4, 0x2b, 0x67,
	0xcf, 0x33, 0xf1, 0xf6, 0x8c, 0x38, 0x34, 0x71, 0x8c, 0x9b, 0x1f, 0x6d, 0x64, 0xf8, 0x23, 0x21,
	0x2b, 0x77, 0xde, 0xd1, 0x36, 0x22, 0xda, 0xf0, 0x68, 0x33, 0x5e, 0xf2, 0x11, 0x64, 0xee, 0x19,
	0xce, 0x94, 0xfa, 0x65, 0x38, 0x4f, 0xca, 0x2e, 0xd2, 0x45, 0x9e, 0x23, 0xf8, 0xb8, 0x2e, 0x03,
	0xc3, 0xdc, 0xdf, 0xb3, 0x1d, 0x87, 0x7a, 0xe5, 0xfc, 0x79, 0x52, 0xea, 0x11, 0x6d, 0xa8, 0xcb,
	0x8c, 0x97, 0xd4, 0x21, 0xed, 0xd3, 0xa0, 0x3b, 0x29, 0x17, 0xce, 0x0b, 0x87, 0x35, 0x67, 0x48,
	0x07, 0x9e, 0x61, 0x9b, 0x3d, 0x4e, 0x8f, 0x82, 0x42, 0x56, 0xf2, 0x21, 0x2c, 0x7a, 0xd4, 0xb0,
	0x1a, 0xbd, 0xdd, 0x72, 0x11, 0xa5, 0xbc, 0x7e, 0xba, 0x14, 0x2d, 0x24, 0x44, 0x76, 0xc9, 0x45,
	0x5a, 0x90, 0xeb, 0xf5, 0xfa, 0x9f, 0x7a, 0x36, 0x77, 0xbb, 0x12, 0x8a, 0x38, 0x23, 0xb6, 0x47,
	0xa4, 0x28, 0x64, 0xc6, 0xc9, 0xf5, 0xe8, 0x19, 0xe3, 0x09, 0x37, 0xc9, 0xd2, 0x79, 0x7a, 0x08,
	0xc2, 0x50, 0x0f, 0xb1, 0x20, 0x5f, 0x80, 0x1a, 0x7e, 0xce, 0xfc, 0xb2, 0xac, 0xa2, 0xa4, 0xea,
	0x79, 0x92, 0x1e, 0xf1, 0xe4, 0xc7, 0xe4, 0x10, 0x06, 0x2f, 0xd9, 0x6e, 0x40, 0x3d, 0x87, 0x1a,
	0xf7, 0xa8, 0x15, 0x3e, 0x36, 0xe1, 0x4b, 0x97, 0x70, 0x8b, 0xef, 0x9d, 0x95, 0xcd, 0x9e, 0xc8,
	0x88, 0x3b, 0x9d, 0x26, 0xf5, 0x3d, 0xe5, 0xfe, 0x6f, 0x56, 0x12, 0x95, 0x12, 0x14, 0xe2, 0xb1,
	0xa7, 0xe2, 0x41, 0x69, 0xde, 0xa7, 0x48, 0x03, 0x16, 0x65, 0x1c, 0x0e, 0xd3, 0xea, 0x6b, 0x67,
	0xbc, 0x33, 0x9e, 0xe9, 0xdb, 0xee, 0x1e, 0x13, 0xd1, 0x51, 0x72, 0x92, 0x97, 0x21, 0xe7, 0x19,
	0x87, 0xfa, 0xe0, 0x38, 0xa0, 0x7e, 0x39, 0x79, 0x35, 0x75, 0xbd, 0xa0, 0x65, 0x3d, 0xe3, 0xb0,
	0xce, 0xd7, 0x95, 0x26, 0x2c, 0xcd, 0x05, 0x2f, 0xc3, 0x25, 0x37, 0x41, 0xf1, 0x27, 0x86, 0x2b,
	0x02, 0xe7, 0x4b, 0xb1, 0x1d, 0x45, 0x51, 0x52, 0xe5, 0x64, 0x32, 0xc1, 0x71, 0xd2, 0xca, 0xef,
	0x92, 0x8f, 0x88, 0xc1, 0xa4, 0x95, 0xc6, 0x28, 0x78, 0x4a, 0x00, 0x16, 0x85, 0x4a, 0x18, 0x3a,
	0x9b, 0xd4, 0x37, 0x3d, 0x7b, 0x12, 0x30, 0x4f, 0x86, 0x76, 0x64, 0x25, 0xaf, 0x42, 0xce, 0x76,
	0x2d, 0x7a, 0xa4, 0xdb, 0xd6, 0x11, 0x46, 0xe1, 0xa2, 0xc0, 0x67, 0x11, 0xdc, 0xb6, 0x8e, 0xc8,
	0x32, 0x77, 0xf0, 0x7b, 0xd4, 0xf3, 0x29, 0x86, 0x56, 0x99, 0xd4, 0x24, 0x90, 0xb4, 0x20, 0xcd,
	0x55, 0x94, 0xf9, 0xe9, 0xa2, 0x41, 0x3c, 0x3a, 0x60, 0xc8, 0x4d, 0x5e, 0x03, 0xc0, 0x6c, 0xa3,
	0x8f, 0x6c, 0x37, 0x4c, 0x51, 0x29, 0x41, 0x90, 0x43, 0xf8, 0x86, 0xed, 0x06, 0x64, 0x05, 0xb2,
	0xb6, 0xaf, 0x9b, 0x23, 0x6a, 0xee, 0x63, 0xa2, 0x8a, 0x94, 0xb1, 0xfd, 0x06, 0x07, 0x56, 0x7e,
	0x9b, 0x80, 0xd2, 0x7c, 0x7c, 0xff, 0xba, 0xcc, 0x74, 0x03, 0x4a, 0x0e, 0x63, 0xfb, 0xd3, 0xc9,
	0x93, 0x12, 0x7b, 0x88, 0x11, 0x89, 0xbd, 0xf2, 0xab, 0x04, 0xc0, 0x2c, 0x7d, 0x90, 0x4f, 0x60,
	0x49, 0x94, 0x04, 0xcc, 0xb3, 0xa8, 0x67, 0xbb, 0x43, 0xa1, 0x6a, 0xe5, 0x8c, 0xa2, 0x4a, 0x50,
	0x0a, 0x35, 0x44, 0x4d, 0x21, 0xa1, 0xe4, 0x16, 0x10, 0x29, 0x4b, 0x1f, 0x1b, 0x81, 0x39, 0xd2,
	0x1d, 0xea, 0xce, 0x29, 0xae, 0x4a, 0xfc, 0x36, 0x47, 0x6f, 0x51, 0xb7, 0x32, 0x80, 0x42, 0x3c,
	0x93, 0x90, 0x37, 0x61, 0x09, 0x69, 0xa8, 0xa5, 0xc7, 0x9f, 0x48, 0x51, 0x2b, 0x09, 0xb0, 0xac,
	0x53, 0x6e, 0x80, 0x2a, 0x93, 0x4e, 0x44, 0x99, 0x44, 0xca, 0x25, 0x09, 0x97, 0x27, 0xff, 0x67,
	0x12, 0x96, 0x1e, 0xc9, 0x33, 0x64, 0x1b, 0x8a, 0x0e, 0xdd, 0x7b, 0x8e, 0xc3, 0x17, 0x38, 0x7b,
	0x74, 0xf4, 0x2e, 0x94, 0x3c, 0x7b, 0x38, 0x8a, 0xc9, 0x4b, 0x3e, 0xa5, 0xbc, 0x22, 0xf2, 0x47,
	0x02, 0x1b, 0xb0, 0xc8, 0x5c, 0x2c, 0xc1, 0x44, 0x4a, 0x7f, 0xaa, 0xe2, 0x90, 0xb9, 0x1c, 0x46,
	0x3e, 0x00, 0x25, 0x38, 0x9e, 0x50, 0x74, 0xda, 0xd2, 0x59, 0xba, 0x70, 0xc3, 0xf4, 0x8f, 0x27,
	0x54, 0xbe, 0x7e, 0xce, 0x45, 0x6e, 0x40, 0xd1, 0x9d, 0x3a, 0x8e, 0x4e, 0x0f, 0xa6, 0x86, 0x63,
	0x07, 0xc7, 0x58, 0x13, 0x48, 0xdf, 0x2f, 0x70, 0x54, 0x4b, 0x60, 0x2a, 0xbf, 0x4e, 0x42, 0x69,
	0x3e, 0xfb, 0x92, 0x55, 0x58, 0x42, 0x03, 0xd3, 0x83, 0xf9, 0x8b, 0x14, 0xae, 0x49, 0xf7, 0x82,
	0xd6, 0x81, 0xbc, 0xcb, 0xb7, 0x40, 0x0d, 0xad, 0x17, 0x23, 0x4e, 0x46, 0xc4, 0xa1, 0x65, 0x67,
	0xd4, 0xff, 0x07, 0xa6, 0xf9, 0x16, 0x94, 0xb0, 0x4e, 0x99, 0x39, 0x69, 0xdc, 0x36, 0xc5, 0x10,
	0x27, 0xdd, 0xef, 0x3f, 0x0a, 0x94, 0xe6, 0x73, 0x15, 0x79, 0x15, 0x60, 0xe8, 0xb1, 0xf0, 0xd5,
	0xc6, 0x8f, 0x9a, 0x43, 0x68, 0x83, 0x39, 0x3e, 0xf9, 0x21, 0x14, 0x64, 0x69, 0x66, 0x33, 0xf1,
	0xae, 0xf3, 0xb7, 0xbe, 0x7b, 0xd1, 0xc2, 0x2e, 0x5a, 0xce, 0x8e, 0x3e, 0x27, 0xef, 0xca, 0x9f,
	0x12, 0x90, 0x8f, 0xd1, 0x90, 0xdb, 0xa0, 0xec, 0x4d, 0x5d, 0x13, 0xdf, 0x41, 0xe9, 0xd6, 0xb7,
	0x2f, 0xbc, 0xcf, 0xfa, 0xd4, 0x8d, 0xba, 0x22, 0x2e, 0x80, 0x5c, 0x8d, 0x55, 0x91, 0xf1, 0x7e,
	0x64, 0x56, 0x23, 0x5e, 0x83, 0x52, 0xd8, 0xbd, 0xf0, 0xe3, 0x63, 0x70, 0xe3, 0x75, 0x6f, 0x51,
	0x2b, 0x84, 0xd0, 0x06, 0x73, 0x78, 0x68, 0x7b, 0x09, 0x93, 0x24, 0xa2, 0xd3, 0xf8, 0xae, 0x33,
	0x26, 0x22, 0x36, 0x95, 0x6c, 0x4a, 0x55, 0x2a, 0x3f, 0x4f, 0x82, 0xc2, 0xf7, 0x26, 0x39, 0x48,
	0xb7, 0x9b, 0xad, 0x4e, 0x5f, 0x5d, 0x20, 0x8b, 0x90, 0xaa, 0xed, 0xde, 0x56, 0x13, 0xa4, 0x00,
	0xd9, 0x7a, 0xb7, 0xbb, 0xa5, 0xd7, 0x3a, 0x4d, 0x35, 0x49, 0xf2, 0xb0, 0x88, 0xab, 0xae, 0xa6,
	0xa6, 0x48, 0x09, 0xa0, 0xd1, 0xed, 0x34, 0x6a, 0x7d, 0xbd, 0x76, 0xfb, 0xb6, 0xaa, 0x70, 0xf6,
	0x46, 0x77, 0xa7, 0xd3, 0x57, 0xd3, 0x9c, 0x7d, 0xbb, 0xf6, 0x99, 0xba, 0x88, 0x1f, 0xed, 0x8e,
	0x9a, 0x25, 0x00, 0x99, 0x5e, 0xbf, 0xd9, 0x6c, 0xed, 0xaa, 0x39, 0x0e, 0xec, 0xed, 0x6c, 0xab,
	0xc0, 0xc5, 0xf5, 0x76, 0xb6, 0xf5, 0x76, 0xa7, 0xaf, 0xe6, 0xf9, 0x4e, 0xbb, 0x35, 0xad, 0x5d,
	0xeb, 0x34, 0x5a, 0x6a, 0x81, 0xa3, 0x3e, 0xeb, 0x6a, 0x28, 0xb9, 0x18, 0xee, 0xb4, 0xd3, 0xe9,
	0xeb, 0x5a, 0xf7, 0xd3, 0x9e, 0x5a, 0x42, 0xbe, 0x4f, 0xb4, 0x66, 0x7b, 0x7d, 0x5d, 0x5d, 0x22,
	0x04, 0x4a, 0xeb, 0xed, 0x4e, 0x6d, 0x4b, 0x8f, 0xb8, 0x55, 0xa2, 0x42, 0x21, 0x84, 0x89, 0x3d,
	0x2f, 0x91, 0x22, 0xe4, 0x6a, 0x9a, 0x56, 0xfb, 0x1c, 0x25, 0x12, 0xbe, 0xd9, 0x66, 0xaf, 0xdb,
	0xc1, 0xd5, 0x0b, 0x1c, 0xc9, 0x57, 0x75, 0x5c, 0x5e, 0xae, 0x3c, 0x4c, 0x41, 0x69, 0xbe, 0xea,
	0xe4, 0x77, 0x8a, 0x4e, 0x7e, 0xee, 0x9d, 0xce, 0xf3, 0x55, 0x1f, 0xf3, 0xf7, 0x28, 0x9b, 0x25,
	0x9f, 0x3d, 0x9b, 0x45, 0x19, 0x3b, 0xf5, 0x5c, 0x19, 0xfb, 0x26, 0x64, 0xad, 0xa9, 0x87, 0x3e,
	0x8b, 0x6e, 0x93, 0xaa, 0xbf, 0xc8, 0xd1, 0x0f, 0x1f, 0xac, 0x14, 0x03, 0x7b, 0x4c, 0xab, 0x4d,
	0x81, 0xd4, 0x22, 0x32, 0x9e, 0xe4, 0xcd, 0xd1, 0xd4, 0xdd, 0xd7, 0x7d, 0xfb, 0x4b, 0x3a, 0x9f,
	0xe4, 0x11, 0xde, 0xb3, 0xbf, 0xa4, 0xa4, 0x0b, 0x05, 0x16, 0x8c, 0xa8, 0xa7, 0xa3, 0xb6, 0x7e,
	0x39, 0x83, 0x5a, 0x3e, 0xdd, 0x49, 0xf3, 0x28, 0x01, 0x71, 0x3e, 0xf9, 0x10, 0xb2, 0xbc, 0xd8,
	0xae, 0xf9, 0xdd, 0x3d, 0xd1, 0x4d, 0x7d, 0x33, 0x26, 0x6c, 0x1a, 0xd8, 0x4e, 0x75, 0xe4, 0x98,
	0xd5, 0xbe, 0x1c, 0xcc, 0xc8, 0x67, 0x22, 0x99, 0x2a, 0xab, 0xa0, 0xf0, 0x8b, 0xe0, 0x7e, 0xd3,
	0x76, 0xef, 0x19, 0x8e, 0x6d, 0xa9, 0x0b, 0xdc, 0x23, 0xc3, 0xb8, 0xa2, 0x26, 0xd0, 0xf3, 0x79,
	0x21, 0xa0, 0x26, 0x2b, 0x5f, 0x25, 0x20, 0xbb, 0xee, 0xb0, 0x43, 0xbc, 0xf6, 0x9b, 0xb0, 0xb8,
	0xe7, 0xb0, 0x43, 0xdd, 0xb6, 0xf0, 0xe6, 0x0b, 0xf5, 0x32, 0x97, 0xfc, 0x8f, 0x07, 0x2b, 0x19,
	0x4e, 0xd2, 0x6e, 0x9e, 0x44, 0x5f, 0x5a, 0x86, 0x13, 0xb6, 0x2d, 0xb2, 0x8d, 0x63, 0x04, 0x31,
	0x00, 0xc3, 0x80, 0x74, 0x66, 0x3f, 0x30, 0x37, 0x23, 0x8a, 0xcd, 0x1b, 0x84, 0x00, 0xb2, 0x03,
	0x8b, 0x43, 0x23, 0xa0, 0x87, 0xc6, 0x31, 0x56, 0x6f, 0xe9, 0xfa, 0xfb, 0xe2, 0x8e, 0xde, 0x1e,
	0xda, 0xc1, 0x68, 0x3a, 0xa8, 0x9a, 0x6c, 0xbc, 0x16, 0x49, 0xb7, 0x06, 0xb3, 0xef, 0xb5, 0xc9,
	0xfe, 0x70, 0x4d, 0x16, 0xa4, 0x1d, 0x66, 0xe1, 0x10, 0x45, 0xc8, 0xaa, 0xfc, 0x25, 0x01, 0xe4,
	0xf1, 0x9e, 0x88, 0x34, 0x21, 0xfb, 0xcc, 0x69, 0x3c, 0xe2, 0xe4, 0x3a, 0xb3, 0x89, 0x8e, 0xef,
	0x25, 0x89, 0xef, 0xe5, 0x9d, 0xa7, 0x69, 0xcc, 0xaa, 0xf8, 0x15, 0x7b, 0x38, 0x19, 0x86, 0xab,
	0xca, 0xcb, 0x90, 0x8b, 0x50, 0x3c, 0x24, 0xb4, 0x8e, 0x4c, 0x3a, 0x09, 0x74, 0xc3, 0x71, 0xd4,
	0x85, 0xca, 0x21, 0xe4, 0x37, 0xd9, 0xe0, 0x8e, 0xc7, 0x86, 0x3c, 0x4b, 0x91, 0x6b, 0x90, 0xb9,
	0xcb, 0x06, 0xf2, 0xde, 0x52, 0xf5, 0xa2, 0x18, 0x27, 0xa5, 0x37, 0xd9, 0xa0, 0xdd, 0xd4, 0xd2,
	0x77, 0xd9, 0xa0, 0x6d, 0x91, 0xeb, 0x50, 0x30, 0x99, 0x1b, 0x78, 0xf6, 0x60, 0x1a, 0x0d, 0x7d,
	0x92, 0x32, 0xc6, 0xc7, 0x31, 0xa4, 0x0c, 0x8a, 0xef, 0xb0, 0x40, 0xdc, 0x81, 0xac, 0xec, 0x1d,
	0x16, 0x54, 0x7e, 0x91, 0x82, 0x7c, 0xac, 0x2f, 0x24, 0x3f, 0xe0, 0x87, 0x0f, 0x13, 0x4d, 0xe2,
	0x31, 0x5f, 0x95, 0xd7, 0xd1, 0xe8, 0xed, 0x76, 0x43, 0x22, 0x59, 0x00, 0x0b, 0x1e, 0xf2, 0x3a,
	0xe4, 0x7d, 0xec, 0xbe, 0xc2, 0x27, 0x96, 0x8c, 0xed, 0x07, 0x21, 0x02, 0xdf, 0xd8, 0xc7, 0x00,
	0xf8, 0xba, 0x74, 0x8b, 0xfa, 0xa6, 0x18, 0x99, 0x3c, 0xdd, 0x0b, 0xcb, 0x05, 0x12, 0x4c, 0x6e,
	0x43, 0x76, 0x22, 0x0c, 0x87, 0x59, 0xfc, 0xcc, 0xde, 0x33, 0x66, 0x65, 0x79, 0xf1, 0x92, 0x99,
	0x7c, 0x04, 0xa9, 0xa9, 0x67, 0x97, 0x17, 0xd1, 0xe9, 0xab, 0x17, 0xea, 0xa3, 0xab, 0x3b, 0x9e,
	0xdd, 0x72, 0x03, 0xef, 0x58, 0xe3, 0xac, 0x57, 0xde, 0x81, 0xac, 0x04, 0x10, 0x15, 0x52, 0xfb,
	0xf4, 0x18, 0xad, 0x98, 0xd6, 0xf8, 0x27, 0xb9, 0x0c, 0x69, 0x9c, 0x21, 0xa0, 0x59, 0x72, 0x5a,
	0xb8, 0x78, 0x2f, 0xf9, 0x6e, 0x62, 0x53, 0xc9, 0x2a, 0x6a, 0x7a, 0x53, 0xc9, 0xa6, 0xd5, 0x4c,
	0xe5, 0x8f, 0x49, 0x28, 0xce, 0xb5, 0xd9, 0xe4, 0x0d, 0xc8, 0x5b, 0x94, 0xa7, 0xcc, 0x30, 0xd8,
	0x71, 0x89, 0x39, 0x19, 0x68, 0x62, 0x08, 0xb2, 0x0a, 0xc5, 0x43, 0xc3, 0x71, 0x78, 0xf4, 0xeb,
	0x18, 0x2e, 0xf3, 0xd1, 0xb0, 0x32, 0xc2, 0xcd, 0xa3, 0xc8, 0xd6, 0x7c, 0xdb, 0xf4, 0x9d, 0x0b,
	0xb6, 0xfc, 0xd8, 0x1a, 0x76, 0x8c, 0x31, 0x9d, 0x8f, 0xc5, 0xf1, 0x2b, 0x48, 0x3f, 0xc7, 0x15,
	0x70, 0x03, 0xca, 0x1d, 0xb8, 0xd3, 0xba, 0xc6, 0x98, 0xce, 0x9d, 0x17, 0x21, 0xdc, 0xb4, 0xd4,
	0xb5, 0xd0, 0x8c, 0x05, 0x8d, 0x7f, 0x6e, 0x2a, 0xd9, 0xa4, 0x9a, 0xaa, 0xfc, 0x34, 0x09, 0xd0,
	0xdb, 0xa7, 0x81, 0x39, 0x42, 0xbb, 0x7d, 0x0c, 0x79, 0x1f, 0x57, 0x7a, 0x2c, 0xf9, 0x9d, 0x35,
	0x53, 0x43, 0xe2, 0xd8, 0xd3, 0x05, 0x3f, 0x82, 0x90, 0xf2, 0xac, 0x55, 0x0f, 0xbb, 0x8b, 0xa8,
	0xff, 0x7e, 0x1b, 0xc8, 0x90, 0xba, 0xd4, 0x33, 0x02, 0xaa, 0x8f, 0x6c, 0x3f, 0x60, 0x43, 0xcf,
	0x18, 0xcf, 0x35, 0xab, 0x97, 0x24, 0x7e, 0x43, 0xa2, 0xc9, 0xbb, 0xf0, 0x62, 0x44, 0xab, 0x8f,
	0x8d, 0x23, 0x7d, 0x30, 0x35, 0xf7, 0x69, 0xe0, 0x87, 0x15, 0x90, 0xe0, 0x7b, 0x21, 0x22, 0xd9,
	0x36, 0x8e, 0xea, 0x21, 0x01, 0x6f, 0x06, 0xfd, 0xc0, 0x08, 0x74, 0xb4, 0x4d, 0x3a, 0x66, 0x9b,
	0x2c, 0x07, 0x73, 0xcb, 0x55, 0x7e, 0x04, 0xf9, 0xd8, 0x8c, 0x85, 0xac, 0x43, 0x36, 0x3c, 0x08,
	0x95, 0x63, 0x86, 0x73, 0x8d, 0x10, 0x0b, 0xe7, 0x11, 0xef, 0x93, 0x1e, 0x77, 0xf1, 0xf1, 0xc7,
	0x5d, 0xf9, 0x6f, 0x12, 0x2e, 0x3f, 0x69, 0x30, 0xf3, 0x35, 0xeb, 0x41, 0x7e, 0x0c, 0x24, 0x5c,
	0xc9, 0xe2, 0x5c, 0xb7, 0x2d, 0xd9, 0x16, 0x7f, 0x72, 0xf2, 0x60, 0x45, 0xcc, 0x89, 0x44, 0x79,
	0xde, 0x6e, 0xfa, 0x0f, 0x1f, 0xac, 0x7c, 0xff, 0x42, 0x69, 0x29, 0xf6, 0x47, 0x4c, 0x55, 0x72,
	0x6b, 0xaa, 0x3f, 0x27, 0xce, 0xf2, 0x89, 0x01, 0xd9, 0x30, 0xca, 0xd9, 0x96, 0xb8, 0xd6, 0x75,
	0xf9, 0xb7, 0x00, 0x06, 0xb5, 0x76, 0xf3, 0xc2, 0x89, 0x30, 0xbe, 0x23, 0x4f, 0x84, 0x28, 0xb7,
	0x6d, 0x55, 0x7e, 0x92, 0x86, 0x97, 0xcf, 0x98, 0x50, 0x91, 0xcf, 0x21, 0x23, 0xca, 0x98, 0xd0,
	0xe0, 0xef, 0x3f, 0xd3, 0xa0, 0x2b, 0x8c, 0xc1, 0x32, 0x9f, 0x85, 0x02, 0xe3, 0x83, 0x99, 0xe4,
	0x93, 0x06, 0x33, 0xf3, 0x13, 0x95, 0xd4, 0x93, 0x27, 0x2a, 0xb1, 0x16, 0x4e, 0x79, 0xee, 0x16,
	0x2e, 0xfd, 0x2c, 0x2d, 0xdc, 0x95, 0x3f, 0x27, 0x21, 0x8d, 0xe7, 0x23, 0x1f, 0x81, 0x82, 0xf9,
	0xe8, 0x59, 0x26, 0x35, 0xc8, 0x79, 0x91, 0x41, 0x8d, 0xfc, 0xc3, 0x29, 0xf5, 0x3c, 0x7f, 0x38,
	0xc5, 0x0b, 0x1d, 0xe5, 0x99, 0x0b, 0x9d, 0xa8, 0x10, 0x4f, 0x3f, 0x4f, 0x21, 0xbe, 0xfa, 0xb3,
	0x04, 0x64, 0xa5, 0x65, 0xb1, 0x14, 0xed, 0x74, 0x5a, 0x9a, 0xba, 0xc0, 0x6b, 0x9c, 0xad, 0xd6,
	0x7a, 0x5f, 0xef, 0xee, 0xf4, 0x5b, 0x9a, 0x9a, 0x20, 0x4b, 0x90, 0xd7, 0xda, 0xb7, 0x37, 0x24,
	0x20, 0xc9, 0x09, 0xd6, 0x77, 0xb6, 0xb6, 0xc4, 0x3a, 0xc5, 0xfb, 0x18, 0x64, 0xe8, 0xb5, 0xb6,
	0xdb, 0xaa, 0x12, 0x2d, 0x6b, 0x9d, 0x7e, 0x5b, 0x4d, 0x93, 0x4b, 0x50, 0x6c, 0x77, 0xfa, 0x2d,
	0xad, 0xd7, 0x6a, 0xf4, 0xf5, 0xda, 0xd6, 0x96, 0x9a, 0xc1, 0x2a, 0xea, 0xb3, 0x46, 0xeb, 0x4e,
	0xb8, 0x5e, 0x5c, 0xad, 0xc8, 0xf0, 0x8f, 0xaa, 0x5c, 0x06, 0x75, 0x63, 0x6b, 0x4b, 0xbf, 0xb3,
	0xb5, 0xd3, 0x0b, 0x7f, 0x76, 0x6f, 0xaa, 0x0b, 0xf5, 0x6b, 0xf7, 0xff, 0xbd, 0xbc, 0x70, 0xff,
	0x64, 0x39, 0xf1, 0xd7, 0x93, 0xe5, 0xc4, 0xdf, 0x4f, 0x96, 0x13, 0xff, 0x3a, 0x59, 0x4e, 0xfc,
	0xf2, 0xab, 0xe5, 0x85, 0x2f, 0x60, 0x76, 0xe0, 0xff, 0x05, 0x00, 0x00, 0xff, 0xff, 0x6e, 0x9f,
	0x45, 0x53, 0x15, 0x1e, 0x00, 0x00,
}
