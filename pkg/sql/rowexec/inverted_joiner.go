// Copyright 2020 The Cockroach Authors.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package rowexec

import (
	"context"
	"fmt"
	"sort"

	"github.com/cockroachdb/cockroach/pkg/roachpb"
	"github.com/cockroachdb/cockroach/pkg/sql/execinfra"
	"github.com/cockroachdb/cockroach/pkg/sql/execinfrapb"
	"github.com/cockroachdb/cockroach/pkg/sql/row"
	"github.com/cockroachdb/cockroach/pkg/sql/rowcontainer"
	"github.com/cockroachdb/cockroach/pkg/sql/scrub"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/span"
	"github.com/cockroachdb/cockroach/pkg/sql/sqlbase"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/cockroach/pkg/util"
	"github.com/cockroachdb/cockroach/pkg/util/log"
	"github.com/cockroachdb/cockroach/pkg/util/mon"
	"github.com/cockroachdb/cockroach/pkg/util/tracing"
	"github.com/opentracing/opentracing-go"
)

const invertedJoinerBatchSize = 10

type invertedJoinerState int

const (
	ijStateUnknown invertedJoinerState = iota
	// ijReadingInput means that a batch of rows is being read from the input.
	ijReadingInput
	// ijPerformingIndexLookup means it is performing an inverted index lookup
	// for the current input row batch.
	ijPerformingLookup
	// ijEmittingRows means it is emitting the results of the join.
	ijEmittingRows
)

// TODO(sumeer): In some special cases, the InvertedJoinerSpec.OnExpr could be
// used to further narrow the rows scanned from the index.

// RowToInvertedIndexExpr is generated by the caller using the
// InvertedJoinerSpec.inverted_expr -- the invertedJoiner computes the
// returned expression. For geospatial, the implementation of
// RowToInvertedIndexExpr will use a GeographyIndex or GeometryIndex
// constructed using the IndexDescriptor.
type RowToInvertedIndexExpr interface {
	// Convert uses the row to construct an inverted index expression.
	//
	// TODO(sumeer): only pass the EncDatum of the column being joined.
	Convert(sqlbase.EncDatumRow) (RPInvertedIndexExpr, error)
}

type invertedJoiner struct {
	execinfra.ProcessorBase

	runningState invertedJoinerState
	diskMonitor  *mon.BytesMonitor
	desc         sqlbase.TableDescriptor
	// The map from ColumnIDs in the table to the column position.
	colIdxMap map[sqlbase.ColumnID]int
	index     *sqlbase.IndexDescriptor
	// The ColumnID of the inverted column. Confusingly, this is also the id of
	// the table column that was indexed.
	invertedColId sqlbase.ColumnID

	// TODO(sumeer): onExpr could benefit from vectorized execution -- the rest
	// of the code here doesn't seem amenable to column-by-column processing
	// since it needs to process set operators on rows.
	onExpr       execinfrapb.Expression
	onExprHelper execinfra.ExprHelper
	combinedRow  sqlbase.EncDatumRow

	joinType sqlbase.JoinType

	// fetcher wraps the row.Fetcher used to perform lookups. This enables the
	// joinReader to wrap the fetcher with a stat collector when necessary.
	fetcher  rowFetcher
	alloc    sqlbase.DatumAlloc
	rowAlloc sqlbase.EncDatumRowAlloc
	// The row retrieved from the index represents the columns of the table
	// with the datums corresponding to the columns in the index populated.
	// The inverted column is in the position colIdxMap[invertedColId] and
	// the []byte stored there is relevant to the batchedExprEvaluator.
	// The remaining index columns, typically the primary key of the table,
	// are placed in keyRow and given to lookedUpRows which will dedup
	// them and assign a RowIndex.
	keyRow         sqlbase.EncDatumRow
	keyTypes       []types.T
	rowToKeyRowMap map[int]int
	// The reverse transformation, from a key row to a table row, is done
	// before evaluating the onExpr.
	tableRow       sqlbase.EncDatumRow
	keyRowToRowMap []int

	// The input being joined using the index.
	input                  execinfra.RowSource
	inputTypes             []types.T
	lookupColumnIdx        uint32
	rowToInvertedIndexExpr RowToInvertedIndexExpr
	// Batch size for fetches. Not a constant so we can lower for testing.
	batchSize int

	// State variables for each batch of input rows.
	inputRows       sqlbase.EncDatumRows
	batchedExprEval batchedInvertedExprEvaluator
	// The row indexes that are the result of the inverted_expr evaluation
	// of the join. These can be further filtered using the onExpr.
	joinedRowIdx [][]RowIndex

	// The container for the "key rows" retrieved from the index. For evaluating
	// the set expression represented by RPInvertedIndexExpr, it is necessary to
	// dedup the rows retrieved from the inverted index (minus the value in the
	// inverted column). Instead of doing such deduping for each expression
	// evaluated by batchedExprEval, it is done once when adding to lookedUpRows
	// -- this is more efficient since multiple expressions may be using the
	// same spans from the index. Additionally, it reduces memory usage by not
	// duplicating inside lookedUpRows.
	//
	// TODO(sumeer): if there is nothing in onExpr, the in-memory implementation of
	// InvertedIndexRowContainer could optimize by only having a map[string]int
	// for deduping, and not store the decoded rows in a MemRowContainer. The
	// disk-backed implementation will always need to store the encoded key => int
	// in the temp engine, so there isn't a similar optimization there.
	lookedUpRows rowcontainer.InvertedIndexRowContainer

	// emitCursor contains information about where the next row to emit is within
	// joinedRowIdx
	emitCursor struct {
		// inputRowIdx corresponds to joinedRowIdx[inputRowIdx]
		inputRowIdx int
		// outputRowIdx corresponds to joinedRowIdx[inputRowIdx][outputRowIdx]
		outputRowIdx int
		// seenMatch is true if there was a match at the current inputRowIdx.
		seenMatch bool
	}

	spanBuilder *span.Builder
	// A row with one element, corresponding to an encoded inverted column
	// value. Used to construct the span of the index for that value.
	invertedColRow sqlbase.EncDatumRow
}

var _ execinfra.Processor = &invertedJoiner{}
var _ execinfra.RowSource = &invertedJoiner{}
var _ execinfrapb.MetadataSource = &invertedJoiner{}
var _ execinfra.OpNode = &invertedJoiner{}

const invertedJoinerProcName = "inverted joiner"

func newInvertedJoiner(
	flowCtx *execinfra.FlowCtx,
	processorID int32,
	spec *execinfrapb.InvertedJoinerSpec,
	rowToInvertedIndexExpr RowToInvertedIndexExpr,
	input execinfra.RowSource,
	post *execinfrapb.PostProcessSpec,
	output execinfra.RowReceiver,
) (execinfra.RowSourcedProcessor, error) {
	ij := &invertedJoiner{
		desc:                   spec.Table,
		colIdxMap:              spec.Table.ColumnIdxMap(),
		input:                  input,
		inputTypes:             input.OutputTypes(),
		lookupColumnIdx:        spec.LookupColumn,
		rowToInvertedIndexExpr: rowToInvertedIndexExpr,
		onExpr:                 spec.OnExpr,
		joinType:               spec.Type,
		batchSize:              invertedJoinerBatchSize,
	}

	var err error
	ij.index, _, err = ij.desc.FindIndexByIndexIdx(int(spec.IndexIdx))
	if err != nil {
		return nil, err
	}
	ij.invertedColId = ij.index.ColumnIDs[0]

	indexColumnIDs, _ := ij.index.FullColumnIDs()
	// TODO: should this be visible columns or something else?
	tableColumns := ij.desc.VisibleColumns()
	ij.keyRow = make(sqlbase.EncDatumRow, len(indexColumnIDs)-1)
	ij.keyTypes = make([]types.T, len(ij.keyRow))
	ij.tableRow = make(sqlbase.EncDatumRow, 0, len(tableColumns))
	ij.keyRowToRowMap = make([]int, len(indexColumnIDs)-1)
	for i := 1; i < len(indexColumnIDs); i++ {
		keyRowIdx := i - 1
		rowIdx := ij.colIdxMap[indexColumnIDs[i]]
		ij.rowToKeyRowMap[rowIdx] = keyRowIdx
		ij.keyRowToRowMap[keyRowIdx] = rowIdx
		ij.keyTypes[keyRowIdx] = ij.desc.Columns[rowIdx].Type
	}

	outputColNums := len(ij.inputTypes)
	// TODO: I am assuming the length of the following is the same as
	// VisibleColumns().
	rightColTypes := ij.desc.ColumnTypes()
	var includeRightCols bool
	if ij.joinType == sqlbase.InnerJoin || ij.joinType == sqlbase.LeftOuterJoin {
		outputColNums += len(rightColTypes)
		includeRightCols = true
	}
	outputColTypes := make([]types.T, 0, outputColNums)
	outputColTypes = append(outputColTypes, ij.inputTypes...)
	if includeRightCols {
		outputColTypes = append(outputColTypes, rightColTypes...)
	}
	if err := ij.ProcessorBase.Init(
		ij, post, outputColTypes, flowCtx, processorID, output, nil, /* memMonitor */
		execinfra.ProcStateOpts{
			InputsToDrain: []execinfra.RowSource{ij.input},
			TrailingMetaCallback: func(ctx context.Context) []execinfrapb.ProducerMetadata {
				ij.close()
				return ij.generateMeta(ctx)
			},
		},
	); err != nil {
		return nil, err
	}

	onExprColTypes := make([]types.T, 0, len(input.OutputTypes())+len(rightColTypes))
	onExprColTypes = append(onExprColTypes, ij.inputTypes...)
	onExprColTypes = append(onExprColTypes, rightColTypes...)
	ij.onExprHelper.Init(ij.onExpr, onExprColTypes, ij.EvalCtx)
	ij.combinedRow = make(sqlbase.EncDatumRow, 0, len(onExprColTypes))

	var fetcher row.Fetcher
	// In general we need all the columns in the index to compute the set
	// expression. There may be InvertedJoinerSpec.InvertedExpr that are
	// known to generate only set union expressions, which together with
	// LEFT_SEMI and LEFT_ANTI, and knowledge of the columns needed by
	// InvertedJoinerSpec.OnExpr, could be used to prune the columns
	// needed here. For now, we do the simple thing.
	allIndexCols := util.MakeFastIntSet()
	for _, colId := range indexColumnIDs {
		allIndexCols.Add(ij.colIdxMap[colId])
	}
	_, _, err = initRowFetcher(
		&fetcher, &ij.desc, int(spec.IndexIdx), ij.colIdxMap, false, /* reverse */
		allIndexCols, false /* isCheck */, &ij.alloc, execinfrapb.ScanVisibility_PUBLIC,
		sqlbase.ScanLockingStrength_FOR_NONE,
	)
	if err != nil {
		return nil, err
	}

	collectingStats := false
	if sp := opentracing.SpanFromContext(flowCtx.EvalCtx.Ctx()); sp != nil && tracing.IsRecording(sp) {
		collectingStats = true
	}
	if collectingStats {
		ij.input = newInputStatCollector(ij.input)
		ij.fetcher = newRowFetcherStatCollector(&fetcher)
		ij.FinishTrace = ij.outputStatsToTrace
	} else {
		ij.fetcher = &fetcher
	}

	ij.spanBuilder = span.MakeBuilder(&ij.desc, ij.index)
	ij.spanBuilder.SetNeededColumns(allIndexCols)

	// Initialize memory monitors and row container for looked up rows.
	ctx := flowCtx.EvalCtx.Ctx()
	// TODO(sumeer): remove the false after implementing
	// DiskBackedInvertedIndexRowContainer.
	if false {
		// Limit the memory use by creating a child monitor with a hard limit.
		// invertedJoiner will overflow to disk if this limit is not enough.
		limit := execinfra.GetWorkMemLimit(flowCtx.Cfg)
		if flowCtx.Cfg.TestingKnobs.ForceDiskSpill {
			limit = 1
		}
		ij.MemMonitor = execinfra.NewLimitedMonitor(ctx, flowCtx.EvalCtx.Mon, flowCtx.Cfg, "joiner-limited")
		ij.diskMonitor = execinfra.NewMonitor(ctx, flowCtx.Cfg.DiskMonitor, "invertedjoiner-disk")
		drc := rowcontainer.NewDiskBackedInvertedIndexRowContainer(
			ij.keyTypes,
			ij.EvalCtx,
			ij.FlowCtx.Cfg.TempStorage,
			ij.MemMonitor,
			ij.diskMonitor,
		)
		if limit < mon.DefaultPoolAllocationSize {
			// The memory limit is too low for caching, most likely to force disk
			// spilling for testing.
			// drc.DisableCache = true
		}
		ij.lookedUpRows = drc
	} else {
		ij.MemMonitor = execinfra.NewMonitor(ctx, flowCtx.EvalCtx.Mon, "invertedjoiner-mem")
		ij.lookedUpRows =
			rowcontainer.NewMemInvertedIndexRowContainer(ij.keyTypes, ij.EvalCtx, ij.MemMonitor)
	}

	return ij, nil
}

// SetBatchSize sets the desired batch size. It should only be used in tests.
func (ij *invertedJoiner) SetBatchSize(batchSize int) {
	ij.batchSize = batchSize
}

// Spilled returns whether the joinReader spilled to disk.
func (ij *invertedJoiner) Spilled() bool {
	return ij.lookedUpRows.(*rowcontainer.DiskBackedInvertedIndexRowContainer).Spilled()
}

func (ij *invertedJoiner) generateSpan(enc encInvertedVal) (roachpb.Span, error) {
	// TODO: this may not work for JSON since it seems to use its own special
	// encoding that maybe can't pretend to be an EncDatum

	// Pretend that the encoded inverted val is an EncDatum
	encDatum := sqlbase.EncDatumFromEncoded(sqlbase.DatumEncoding_ASCENDING_KEY, enc)
	ij.invertedColRow = append(ij.invertedColRow[:0], encDatum)
	span, _, err := ij.spanBuilder.SpanFromEncDatums(ij.invertedColRow, 1)
	return span, err
}

func (ij *invertedJoiner) generateSpans(
	invertedValSpans []encInvertedValSpan,
) (roachpb.Spans, error) {
	var spans []roachpb.Span
	for _, span := range invertedValSpans {
		startSpan, err := ij.generateSpan(span.start)
		if err != nil {
			return nil, err
		}
		if span.end != nil {
			endSpan, err := ij.generateSpan(span.end)
			if err != nil {
				return nil, err
			}
			startSpan.EndKey = endSpan.EndKey
		}
		spans = append(spans, startSpan)
	}
	return spans, nil
}

// Next is part of the RowSource interface.
func (ij *invertedJoiner) Next() (sqlbase.EncDatumRow, *execinfrapb.ProducerMetadata) {
	// The join is implemented as follows:
	// - Read the input rows in batches.
	// - For each batch, map the rows to RPInvertedIndexExprs and initialize
	//   a batchedInvertedExprEvaluator. Use that evaluator to generate spans
	//   to read in the index.
	// - Retrieve the index lookup results and place these rows in the
	//   InvertedIndexRowContainer that dedups and pass the deduped number assigned
	//   to the row to the batch evaluator.
	// - Retrieve the results from the batch evaluator and buffer in joinedRowIdx,
	//   and use the emitCursor to emit rows.
	for ij.State == execinfra.StateRunning {
		var row sqlbase.EncDatumRow
		var meta *execinfrapb.ProducerMetadata
		switch ij.runningState {
		case ijReadingInput:
			ij.runningState, meta = ij.readInput()
		case ijPerformingLookup:
			ij.runningState, meta = ij.performLookup()
		case ijEmittingRows:
			ij.runningState, row, meta = ij.emitRow()
		default:
			log.Fatalf(ij.Ctx, "unsupported state: %d", ij.runningState)
		}
		if row == nil && meta == nil {
			continue
		}
		if meta != nil {
			return nil, meta
		}
		if outRow := ij.ProcessRowHelper(row); outRow != nil {
			return outRow, nil
		}
	}
	return nil, ij.DrainHelper()
}

// readInput reads the next batch of input rows and starts an index scan.
func (ij *invertedJoiner) readInput() (invertedJoinerState, *execinfrapb.ProducerMetadata) {
	// Read the next batch of input rows.
	for len(ij.inputRows) < ij.batchSize {
		row, meta := ij.input.Next()
		if meta != nil {
			if meta.Err != nil {
				ij.MoveToDraining(nil /* err */)
				return ijStateUnknown, meta
			}
			return ijReadingInput, meta
		}
		if row == nil {
			break
		}
		ij.inputRows = append(ij.inputRows, ij.rowAlloc.CopyRow(row))
		if row[ij.lookupColumnIdx].IsNull() {
			ij.batchedExprEval.exprs = append(ij.batchedExprEval.exprs, nil)
		} else {
			expr, err := ij.rowToInvertedIndexExpr.Convert(row)
			if err != nil {
				ij.MoveToDraining(err)
				return ijStateUnknown, ij.DrainHelper()
			}
			ij.batchedExprEval.exprs = append(ij.batchedExprEval.exprs, expr)
		}
	}

	if len(ij.inputRows) == 0 {
		log.VEventf(ij.Ctx, 1, "no more input rows")
		// We're done.
		ij.MoveToDraining(nil)
		return ijStateUnknown, ij.DrainHelper()
	}
	log.VEventf(ij.Ctx, 1, "read %d input rows", len(ij.inputRows))

	spans := ij.batchedExprEval.getSpans()
	if len(spans) == 0 {
		// All of the input rows were filtered out. Skip the index lookup. For
		// each input row, place a nil slice in the joined rows, for emitRow() to
		// process.
		ij.joinedRowIdx = ij.joinedRowIdx[:0]
		for range ij.inputRows {
			ij.joinedRowIdx = append(ij.joinedRowIdx, nil)
		}
		return ijEmittingRows, nil
	}
	indexSpans, err := ij.generateSpans(spans)
	if err != nil {
		ij.MoveToDraining(err)
		return ijStateUnknown, ij.DrainHelper()
	}

	// Sort the spans for locality of reads.
	sort.Sort(indexSpans)
	log.VEventf(ij.Ctx, 1, "scanning %d spans", len(indexSpans))
	err = ij.fetcher.StartScan(
		ij.Ctx, ij.FlowCtx.Txn, indexSpans, false /* limitBatches */, 0, /* limitHint */
		ij.FlowCtx.TraceKV)
	if err != nil {
		ij.MoveToDraining(err)
		return ijStateUnknown, ij.DrainHelper()
	}

	return ijPerformingLookup, nil
}

func (ij *invertedJoiner) performLookup() (invertedJoinerState, *execinfrapb.ProducerMetadata) {
	log.VEventf(ij.Ctx, 1, "joining rows")
	// Read the entire set of rows looked up for the last input batch.
	lookedUpRowIdx := 0
	for ; ; lookedUpRowIdx++ {
		// Fetch the next row and copy it into the row container.
		lookedUpRow, _, _, err := ij.fetcher.NextRow(ij.Ctx)
		if err != nil {
			ij.MoveToDraining(scrub.UnwrapScrubError(err))
			return ijStateUnknown, ij.DrainHelper()
		}
		if lookedUpRow == nil {
			// Done with this input batch.
			break
		}
		// TODO(sumeer): eliminate this copy.
		encInvertedVal := encInvertedVal(lookedUpRow[ij.colIdxMap[ij.invertedColId]].EncodedString())
		ij.transformToKeyRow(lookedUpRow)
		rowIdx, err := ij.lookedUpRows.AddRowAndDedup(ij.Ctx, ij.keyRow)
		if err != nil {
			ij.MoveToDraining(err)
			return ijStateUnknown, ij.DrainHelper()
		}
		ij.batchedExprEval.addIndexRow(encInvertedVal, rowIdx)
	}
	ij.joinedRowIdx = ij.batchedExprEval.evaluate()
	log.VEventf(ij.Ctx, 1, "done joining rows (%d loop iterations)", lookedUpRowIdx)

	return ijEmittingRows, nil
}

// emitRow returns the next row from ij.emitCursor, if present. Otherwise it
// prepares for another input batch.
func (ij *invertedJoiner) emitRow() (
	invertedJoinerState,
	sqlbase.EncDatumRow,
	*execinfrapb.ProducerMetadata,
) {
	// Finished processing the batch.
	if ij.emitCursor.inputRowIdx >= len(ij.joinedRowIdx) {
		log.VEventf(ij.Ctx, 1, "done emitting rows")
		// Ready for another input batch. Reset state.
		ij.inputRows = ij.inputRows[:0]
		ij.batchedExprEval.reset()
		ij.joinedRowIdx = ij.joinedRowIdx[:0]
		ij.emitCursor.outputRowIdx = 0
		ij.emitCursor.inputRowIdx = 0
		ij.emitCursor.seenMatch = false
		if err := ij.lookedUpRows.UnsafeReset(ij.Ctx); err != nil {
			ij.MoveToDraining(err)
			return ijStateUnknown, nil, ij.DrainHelper()
		}
		return ijReadingInput, nil, nil
	}

	// Reached the end of the matches for an input row. May need to emit for
	// LeftOuterJoin and LeftAntiJoin.
	if ij.emitCursor.inputRowIdx < len(ij.joinedRowIdx) &&
		ij.emitCursor.outputRowIdx >= len(ij.joinedRowIdx[ij.emitCursor.inputRowIdx]) {
		inputRowIdx := ij.emitCursor.inputRowIdx
		seenMatch := ij.emitCursor.seenMatch
		ij.emitCursor.inputRowIdx++
		ij.emitCursor.outputRowIdx = 0
		ij.emitCursor.seenMatch = false

		if !seenMatch {
			switch ij.joinType {
			case sqlbase.LeftOuterJoin:
				return ijEmittingRows, ij.renderUnmatchedRow(ij.inputRows[inputRowIdx]), nil
			case sqlbase.LeftAntiJoin:
				return ijEmittingRows, ij.inputRows[inputRowIdx], nil
			}
		}
		return ijEmittingRows, nil, nil
	}

	inputRow := ij.inputRows[ij.emitCursor.inputRowIdx]
	joinedRowIdx := ij.joinedRowIdx[ij.emitCursor.inputRowIdx][ij.emitCursor.outputRowIdx]
	indexedRow, err := ij.lookedUpRows.GetRow(ij.Ctx, joinedRowIdx)
	if err != nil {
		ij.MoveToDraining(err)
		return ijStateUnknown, nil, ij.DrainHelper()
	}
	matchedRow := indexedRow.(rowcontainer.IndexedRow).Row
	ij.emitCursor.outputRowIdx++
	ij.transformToTableRow(matchedRow)
	renderedRow, err := ij.render(inputRow, ij.tableRow)
	if err != nil {
		ij.MoveToDraining(err)
		return ijStateUnknown, nil, ij.DrainHelper()
	}
	if renderedRow != nil {
		ij.emitCursor.seenMatch = true
		switch ij.joinType {
		case sqlbase.InnerJoin, sqlbase.LeftOuterJoin:
			return ijEmittingRows, renderedRow, nil
		case sqlbase.LeftSemiJoin:
			// Skip the rest of the joined rows.
			ij.emitCursor.outputRowIdx = len(ij.joinedRowIdx[ij.emitCursor.inputRowIdx])
			return ijEmittingRows, inputRow, nil
		case sqlbase.LeftAntiJoin:
			// Skip the rest of the joined rows.
			ij.emitCursor.outputRowIdx = len(ij.joinedRowIdx[ij.emitCursor.inputRowIdx])
		}
	}
	return ijEmittingRows, nil, nil
}

// render constructs a row with columns from both sides. The ON condition is
// evaluated; if it fails, returns nil.
func (ij *invertedJoiner) render(lrow, rrow sqlbase.EncDatumRow) (sqlbase.EncDatumRow, error) {
	ij.combinedRow = append(ij.combinedRow[:0], lrow...)
	ij.combinedRow = append(ij.combinedRow, rrow...)
	if ij.onExprHelper.Expr != nil {
		res, err := ij.onExprHelper.EvalFilter(ij.combinedRow)
		if !res || err != nil {
			return nil, err
		}
	}
	return ij.combinedRow, nil
}

// renderUnmatchedRow creates a result row given an unmatched row.
func (ij *invertedJoiner) renderUnmatchedRow(row sqlbase.EncDatumRow) sqlbase.EncDatumRow {
	ij.combinedRow = append(ij.combinedRow[:0], row...)
	ij.combinedRow = ij.combinedRow[:cap(ij.combinedRow)]
	for i := len(row); i < len(ij.combinedRow); i++ {
		ij.combinedRow[i].Datum = tree.DNull
	}
	return ij.combinedRow
}

func (ij *invertedJoiner) transformToKeyRow(row sqlbase.EncDatumRow) {
	for i, rowIdx := range ij.keyRowToRowMap {
		ij.keyRow[i] = row[rowIdx]
	}
}

func (ij *invertedJoiner) transformToTableRow(keyRow sqlbase.EncDatumRow) {
	for r, k := range ij.rowToKeyRowMap {
		ij.tableRow[r] = keyRow[k]
	}
}

// Start is part of the RowSource interface.
func (ij *invertedJoiner) Start(ctx context.Context) context.Context {
	ij.input.Start(ctx)
	ctx = ij.StartInternal(ctx, invertedJoinerProcName)
	ij.runningState = ijReadingInput
	return ctx
}

// ConsumerClosed is part of the RowSource interface.
func (ij *invertedJoiner) ConsumerClosed() {
	// The consumer is done, Next() will not be called again.
	ij.close()
}

func (ij *invertedJoiner) close() {
	if ij.InternalClose() {
		if ij.lookedUpRows != nil {
			ij.lookedUpRows.Close(ij.Ctx)
		}
		ij.MemMonitor.Stop(ij.Ctx)
		if ij.diskMonitor != nil {
			ij.diskMonitor.Stop(ij.Ctx)
		}
	}
}

// TODO(sumeer): refactor to properly reuse JoinReaderStats.Stats() and
// StatsForQueryPlan() that are defined in joinreader.go.
//
// outputStatsToTrace outputs the collected stats to the trace. Will
// fail silently if the invertedJoiner is not collecting stats.
func (ij *invertedJoiner) outputStatsToTrace() {
	is, ok := getInputStats(ij.FlowCtx, ij.input)
	if !ok {
		return
	}
	ils, ok := getFetcherInputStats(ij.FlowCtx, ij.fetcher)
	if !ok {
		return
	}

	jrs := &JoinReaderStats{
		InputStats:       is,
		IndexLookupStats: ils,
	}
	if sp := opentracing.SpanFromContext(ij.Ctx); sp != nil {
		tracing.SetSpanStats(sp, jrs)
	}
}

func (ij *invertedJoiner) generateMeta(ctx context.Context) []execinfrapb.ProducerMetadata {
	if tfs := execinfra.GetLeafTxnFinalState(ctx, ij.FlowCtx.Txn); tfs != nil {
		return []execinfrapb.ProducerMetadata{{LeafTxnFinalState: tfs}}
	}
	return nil
}

// DrainMeta is part of the MetadataSource interface.
func (ij *invertedJoiner) DrainMeta(ctx context.Context) []execinfrapb.ProducerMetadata {
	return ij.generateMeta(ctx)
}

// ChildCount is part of the execinfra.OpNode interface.
func (ij *invertedJoiner) ChildCount(verbose bool) int {
	if _, ok := ij.input.(execinfra.OpNode); ok {
		return 1
	}
	return 0
}

// Child is part of the execinfra.OpNode interface.
func (ij *invertedJoiner) Child(nth int, verbose bool) execinfra.OpNode {
	if nth == 0 {
		if n, ok := ij.input.(execinfra.OpNode); ok {
			return n
		}
		panic("input to invertedJoiner is not an execinfra.OpNode")
	}
	panic(fmt.Sprintf("invalid index %d", nth))
}
