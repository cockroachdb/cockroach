# ----------------------------------------------------------------------
# Load 1000 512-dimension OpenAI embeddings and search them. Use small
# partition size to ensure a deeper tree.
# ----------------------------------------------------------------------
new-index dataset=images-512d-10k.gob dataset-count=1000 min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 512 dimensions.
3 levels, 207 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Search with small beam size.
search max-results=1 use-dataset=5000 beam-size=1
----
vec302: 0.6601
12 leaf vectors, 33 vectors, 11 full vectors, 3 partitions

# Search for additional results.
search max-results=6 use-dataset=5000 beam-size=1
----
vec302: 0.6601
vec95: 0.7008
vec633: 0.7513
vec423: 0.7956
vec220: 0.7957
vec848: 0.7958
12 leaf vectors, 33 vectors, 11 full vectors, 3 partitions

# Use a larger beam size.
search max-results=6 use-dataset=5000 beam-size=4
----
vec356: 0.5976
vec302: 0.6601
vec95: 0.7008
vec386: 0.7301
vec633: 0.7513
vec25: 0.761
44 leaf vectors, 75 vectors, 25 full vectors, 7 partitions

# Turn off re-ranking, which results in increased inaccuracy.
search max-results=6 use-dataset=5000 beam-size=4 skip-rerank
----
vec356: 0.607 ± 0.03
vec302: 0.6669 ± 0.03
vec633: 0.6868 ± 0.03
vec386: 0.715 ± 0.04
vec95: 0.7241 ± 0.04
vec872: 0.7576 ± 0.04
44 leaf vectors, 75 vectors, 0 full vectors, 7 partitions

# Return top 25 results with large beam size.
search max-results=25 use-dataset=5000 beam-size=16
----
vec771: 0.5624
vec356: 0.5976
vec640: 0.6525
vec302: 0.6601
vec329: 0.6871
vec95: 0.7008
vec386: 0.7301
vec309: 0.7311
vec633: 0.7513
vec117: 0.7576
vec25: 0.761
vec872: 0.7707
vec240: 0.7723
vec347: 0.7745
vec11: 0.777
vec340: 0.7858
vec423: 0.7956
vec220: 0.7957
vec848: 0.7958
vec387: 0.8038
vec410: 0.8062
vec979: 0.8066
vec457: 0.8084
vec590: 0.8131
vec184: 0.8139
180 leaf vectors, 271 vectors, 71 full vectors, 25 partitions

# Search for an "easy" result, where adaptive search inspects less partitions.
recall topk=20 use-dataset=8601 beam-size=8
----
80.00% recall@20
88 leaf vectors, 130 vectors, 32 full vectors, 13 partitions

# Search for a "hard" result, where adaptive search inspects more partitions.
recall topk=20 use-dataset=2717 beam-size=8
----
40.00% recall@20
90 leaf vectors, 143 vectors, 42 full vectors, 13 partitions

# Show the nearest partitions to the "easy" vector, ordered by estimated
# distance to their centroids. Notice that there are several partitions that are
# very near, and yet the "spread" between centroids is fairly large, which makes
# finding results easier.
best-centroids topk=10 use-dataset=8601
----
151: 0.1696 ± 0.0098 (exact=0.1569)
113: 0.2114 ± 0.0091 (exact=0.2164)
150: 0.2365 ± 0.0089 (exact=0.2380)
155: 0.2836 ± 0.0091 (exact=0.2778)
154: 0.2943 ± 0.0108 (exact=0.2954)
68: 0.2953 ± 0.0146 (exact=0.3056)
97: 0.2988 ± 0.0097 (exact=0.3037)
147: 0.2994 ± 0.0156 (exact=0.2853)
159: 0.3001 ± 0.0120 (exact=0.2995)
139: 0.3274 ± 0.0133 (exact=0.3368)

# Show the nearest partitions to the "hard" vector, ordered by estimated
# distance to their centroids. Notice that the partitions are relatively far
# away and are bunched together, with low "spread". This makes finding results
# more difficult.
best-centroids topk=10 use-dataset=2717
----
197: 0.5183 ± 0.0161 (exact=0.5179)
166: 0.5361 ± 0.0223 (exact=0.5644)
170: 0.5403 ± 0.0156 (exact=0.5453)
30: 0.5524 ± 0.0197 (exact=0.5515)
196: 0.5546 ± 0.0206 (exact=0.5621)
187: 0.5646 ± 0.0171 (exact=0.5625)
135: 0.5674 ± 0.0234 (exact=0.6034)
177: 0.5708 ± 0.0254 (exact=0.5674)
61: 0.5755 ± 0.0211 (exact=0.5581)
183: 0.5777 ± 0.0159 (exact=0.5915)

# Test recall at different beam sizes.
recall topk=10 beam-size=2 samples=64
----
29.84% recall@10
21 leaf vectors, 42 vectors, 15 full vectors, 4 partitions

recall topk=10 beam-size=4 samples=64
----
47.97% recall@10
42 leaf vectors, 74 vectors, 19 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=64
----
69.06% recall@10
85 leaf vectors, 138 vectors, 24 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=64
----
87.66% recall@10
168 leaf vectors, 263 vectors, 27 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=64
----
95.62% recall@10
336 leaf vectors, 442 vectors, 30 full vectors, 42 partitions

# ----------------------------------------------------------------------
# Compare orderings of same dataset with different distance metrics.
# ----------------------------------------------------------------------
# L2Squared.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=L2Squared min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 199 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
search max-results=10 use-dataset=999 beam-size=256
----
vec999: 0
vec409: 3008262
vec984: 3107759
vec968: 3186131
vec161: 3206090
vec130: 3392299
vec610: 3558417
vec152: 3574788
vec611: 3682006
vec420: 3781823
1000 leaf vectors, 1102 vectors, 20 full vectors, 103 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec999: 0
vec409: 3008262
vec984: 3107759
vec968: 3186131
vec161: 3206090
vec130: 3392299
vec610: 3558417
vec152: 3574788
vec611: 3682006
vec420: 3781823
97 leaf vectors, 146 vectors, 20 full vectors, 13 partitions

# Cosine.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=Cosine min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 211 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
search max-results=10 use-dataset=999 beam-size=256
----
vec999: 0
vec984: 0.0923
vec968: 0.1013
vec610: 0.1045
vec811: 0.1123
vec660: 0.1129
vec409: 0.1185
vec144: 0.1197
vec476: 0.124
vec109: 0.1273
1000 leaf vectors, 1109 vectors, 16 full vectors, 110 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec999: 0
vec984: 0.0923
vec968: 0.1013
vec610: 0.1045
vec811: 0.1123
vec660: 0.1129
vec409: 0.1185
vec144: 0.1197
vec476: 0.124
vec109: 0.1273
78 leaf vectors, 136 vectors, 16 full vectors, 13 partitions

# InnerProduct.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=InnerProduct min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 209 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
# NOTE: With InnerProduct "distance", a vector can be "closer" to another vector
# than it is to itself! This is why vector 999 is not the top result, as with
# L2Squared and Cosine distances.
search max-results=10 use-dataset=999 beam-size=256
----
vec773: -14979871
vec7: -14608286
vec109: -14526173
vec289: -14343052
vec811: -14265605
vec216: -14251070
vec312: -14063724
vec197: -14040257
vec476: -13816669
vec311: -13589641
1000 leaf vectors, 1107 vectors, 15 full vectors, 108 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec773: -14979871
vec7: -14608286
vec109: -14526173
vec289: -14343052
vec811: -14265605
vec216: -14251070
vec312: -14063724
vec197: -14040257
vec476: -13816669
vec265: -13573769
84 leaf vectors, 137 vectors, 16 full vectors, 13 partitions

# ----------------------------------------------------------------------
# Load 950 1536-dimension image embeddings and search them using Cosine
# distance.
# ----------------------------------------------------------------------

new-index dataset=dbpedia-1536d-1k.gob dataset-count=950 distance-metric=Cosine min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 950 vectors with 1536 dimensions.
3 levels, 189 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
61.20% recall@10
42 leaf vectors, 72 vectors, 20 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
79.80% recall@10
83 leaf vectors, 133 vectors, 21 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
91.00% recall@10
165 leaf vectors, 256 vectors, 24 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
97.20% recall@10
329 leaf vectors, 431 vectors, 26 full vectors, 42 partitions

# ----------------------------------------------------------------------
# Load 950 768-dimension image embeddings and search them using
# InnerProduct distance.
# ----------------------------------------------------------------------

new-index dataset=laion-768d-1k.gob dataset-count=950 distance-metric=InnerProduct min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 950 vectors with 768 dimensions.
3 levels, 189 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
48.60% recall@10
44 leaf vectors, 76 vectors, 20 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
69.00% recall@10
88 leaf vectors, 144 vectors, 25 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
85.00% recall@10
173 leaf vectors, 272 vectors, 30 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
95.20% recall@10
342 leaf vectors, 441 vectors, 33 full vectors, 41 partitions
