# ----------------------------------------------------------------------
# Load 1000 512-dimension OpenAI embeddings and search them. Use small
# partition size to ensure a deeper tree.
# ----------------------------------------------------------------------
new-index dataset=images-512d-10k.gob dataset-count=1000 min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 512 dimensions.
3 levels, 209 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Search with small beam size.
search max-results=1 use-dataset=5000 beam-size=1
----
vec309: 0.7311
9 leaf vectors, 29 vectors, 2 full vectors, 3 partitions

# Search for additional results.
search max-results=6 use-dataset=5000 beam-size=1
----
vec309: 0.7311
vec879: 0.8291
vec50: 0.8542
vec282: 0.8908
vec359: 0.8978
vec208: 0.9026
9 leaf vectors, 29 vectors, 8 full vectors, 3 partitions

# Use a larger beam size.
search max-results=6 use-dataset=5000 beam-size=4
----
vec640: 0.6525
vec329: 0.6871
vec309: 0.7311
vec25: 0.761
vec240: 0.7723
vec347: 0.7745
49 leaf vectors, 76 vectors, 12 full vectors, 7 partitions

# Turn off re-ranking, which results in increased inaccuracy.
search max-results=6 use-dataset=5000 beam-size=4 skip-rerank
----
vec329: 0.655 ± 0.04
vec640: 0.6854 ± 0.04
vec309: 0.7225 ± 0.04
vec240: 0.7637 ± 0.04
vec704: 0.7669 ± 0.04
vec25: 0.7694 ± 0.04
49 leaf vectors, 76 vectors, 0 full vectors, 7 partitions

# Return top 25 results with large beam size.
search max-results=25 use-dataset=5000 beam-size=16
----
vec771: 0.5624
vec640: 0.6525
vec302: 0.6601
vec329: 0.6871
vec386: 0.7301
vec309: 0.7311
vec633: 0.7513
vec117: 0.7576
vec25: 0.761
vec240: 0.7723
vec347: 0.7745
vec11: 0.777
vec340: 0.7858
vec239: 0.7878
vec704: 0.7916
vec848: 0.7958
vec637: 0.8039
vec410: 0.8062
vec457: 0.8084
vec590: 0.8131
vec493: 0.8184
vec525: 0.8184
vec37: 0.8214
vec202: 0.8218
vec706: 0.8238
161 leaf vectors, 255 vectors, 51 full vectors, 25 partitions

# Search for an "easy" result, where adaptive search inspects less partitions.
recall topk=20 use-dataset=8601 beam-size=8
----
75.00% recall@20
75 leaf vectors, 126 vectors, 31 full vectors, 13 partitions

# Search for a "hard" result, where adaptive search inspects more partitions.
recall topk=20 use-dataset=2717 beam-size=8
----
35.00% recall@20
89 leaf vectors, 145 vectors, 39 full vectors, 13 partitions

# Show the nearest partitions to the "easy" vector, ordered by estimated
# distance to their centroids. Notice that there are several partitions that are
# very near, and yet the "spread" between centroids is fairly large, which makes
# finding results easier.
best-centroids topk=10 use-dataset=8601
----
149: 0.1720 ± 0.0150 (exact=0.1766)
211: 0.2046 ± 0.0148 (exact=0.1888)
206: 0.2525 ± 0.0135 (exact=0.2491)
210: 0.2686 ± 0.0140 (exact=0.2516)
177: 0.2908 ± 0.0204 (exact=0.2788)
205: 0.2932 ± 0.0160 (exact=0.2839)
78: 0.2993 ± 0.0114 (exact=0.3013)
176: 0.3442 ± 0.0145 (exact=0.3378)
148: 0.3447 ± 0.0136 (exact=0.3536)
197: 0.3454 ± 0.0113 (exact=0.3456)

# Show the nearest partitions to the "hard" vector, ordered by estimated
# distance to their centroids. Notice that the partitions are relatively far
# away and are bunched together, with low "spread". This makes finding results
# more difficult.
best-centroids topk=10 use-dataset=2717
----
102: 0.5314 ± 0.0174 (exact=0.5311)
201: 0.5355 ± 0.0220 (exact=0.5554)
129: 0.5391 ± 0.0191 (exact=0.5444)
158: 0.5487 ± 0.0173 (exact=0.5536)
43: 0.5508 ± 0.0220 (exact=0.5358)
64: 0.5747 ± 0.0215 (exact=0.5869)
117: 0.5759 ± 0.0210 (exact=0.5823)
192: 0.5792 ± 0.0180 (exact=0.5793)
54: 0.5863 ± 0.0177 (exact=0.5906)
153: 0.5928 ± 0.0233 (exact=0.5855)

# Test recall at different beam sizes.
recall topk=10 beam-size=2 samples=64
----
25.78% recall@10
22 leaf vectors, 42 vectors, 14 full vectors, 4 partitions

recall topk=10 beam-size=4 samples=64
----
47.81% recall@10
43 leaf vectors, 75 vectors, 17 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=64
----
71.09% recall@10
83 leaf vectors, 138 vectors, 20 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=64
----
86.56% recall@10
165 leaf vectors, 261 vectors, 24 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=64
----
95.94% recall@10
328 leaf vectors, 435 vectors, 26 full vectors, 42 partitions

# ----------------------------------------------------------------------
# Compare orderings of same dataset with different distance metrics.
# ----------------------------------------------------------------------
# L2Squared.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=L2Squared min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 201 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
search max-results=10 use-dataset=999 beam-size=256
----
vec999: 0
vec409: 3008262
vec984: 3107759
vec968: 3186131
vec161: 3206090
vec130: 3392299
vec610: 3558417
vec152: 3574788
vec611: 3682006
vec420: 3781823
1000 leaf vectors, 1104 vectors, 15 full vectors, 105 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec999: 0
vec409: 3008262
vec984: 3107759
vec968: 3186131
vec161: 3206090
vec130: 3392299
vec610: 3558417
vec152: 3574788
vec611: 3682006
vec420: 3781823
80 leaf vectors, 124 vectors, 15 full vectors, 13 partitions

# Cosine.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=Cosine min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 209 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
search max-results=10 use-dataset=999 beam-size=256
----
vec999: 0
vec984: 0.0923
vec968: 0.1013
vec610: 0.1045
vec811: 0.1123
vec660: 0.1129
vec409: 0.1185
vec144: 0.1197
vec476: 0.124
vec109: 0.1273
1000 leaf vectors, 1108 vectors, 11 full vectors, 109 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec999: 0
vec984: 0.0923
vec968: 0.1013
vec610: 0.1045
vec811: 0.1123
vec660: 0.1129
vec409: 0.1185
vec144: 0.1197
vec476: 0.124
vec109: 0.1273
84 leaf vectors, 135 vectors, 11 full vectors, 13 partitions

# InnerProduct.
new-index dataset=fashion-784d-1k.gob dataset-count=1000 distance-metric=InnerProduct min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 784 dimensions.
3 levels, 239 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

# Brute force the search to get perfect matches to compare against.
# NOTE: With InnerProduct "distance", a vector can be "closer" to another vector
# than it is to itself! This is why vector 999 is not the top result, as with
# L2Squared and Cosine distances.
search max-results=10 use-dataset=999 beam-size=256
----
vec773: -14979871
vec7: -14608286
vec109: -14526173
vec289: -14343052
vec811: -14265605
vec216: -14251070
vec312: -14063724
vec197: -14040257
vec476: -13816669
vec311: -13589641
1000 leaf vectors, 1123 vectors, 18 full vectors, 124 partitions

# Now use lower beam size.
search max-results=10 use-dataset=999 beam-size=8
----
vec811: -14265605
vec312: -14063724
vec311: -13589641
vec265: -13573769
vec984: -13534513
vec610: -13491291
vec220: -13433810
vec968: -13060514
vec999: -12779612
vec735: -12533078
71 leaf vectors, 131 vectors, 12 full vectors, 13 partitions

# ----------------------------------------------------------------------
# Load 950 1536-dimension image embeddings and search them using Cosine
# distance.
# ----------------------------------------------------------------------

new-index dataset=dbpedia-1536d-1k.gob dataset-count=950 distance-metric=Cosine min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 950 vectors with 1536 dimensions.
3 levels, 183 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
55.40% recall@10
41 leaf vectors, 74 vectors, 17 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
78.00% recall@10
81 leaf vectors, 138 vectors, 18 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
87.60% recall@10
162 leaf vectors, 266 vectors, 21 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
96.40% recall@10
320 leaf vectors, 424 vectors, 21 full vectors, 41 partitions

# ----------------------------------------------------------------------
# Load 950 768-dimension image embeddings and search them using
# InnerProduct distance.
# ----------------------------------------------------------------------

new-index dataset=laion-768d-1k.gob dataset-count=950 distance-metric=InnerProduct min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 950 vectors with 768 dimensions.
3 levels, 189 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
50.60% recall@10
44 leaf vectors, 74 vectors, 18 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
69.80% recall@10
86 leaf vectors, 136 vectors, 21 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
85.20% recall@10
175 leaf vectors, 266 vectors, 25 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
96.00% recall@10
349 leaf vectors, 450 vectors, 28 full vectors, 42 partitions

# ----------------------------------------------------------------------
# Load 1000 512-dimension image embeddings generated with a multi-modal
# model and search them using text embeddings generated with the same
# model. This will result in low accuracy due to the modality gap.
# ----------------------------------------------------------------------

new-index dataset=clip-512d-1050.gob dataset-count=1000 distance-metric=InnerProduct min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 1000 vectors with 512 dimensions.
3 levels, 207 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
20.60% recall@10
40 leaf vectors, 71 vectors, 36 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
33.80% recall@10
78 leaf vectors, 129 vectors, 59 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
52.40% recall@10
158 leaf vectors, 247 vectors, 91 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
67.40% recall@10
327 leaf vectors, 435 vectors, 108 full vectors, 43 partitions

# Do not fetch extra results for reranking. Expect recall to drop significantly.
recall topk=10 beam-size=32 samples=50 rerank-multiplier=0
----
27.00% recall@12
327 leaf vectors, 435 vectors, 12 full vectors, 43 partitions

# ----------------------------------------------------------------------
# Search 950 100-dimension word embeddings generated by the GloVe model.
# This model is older; it's challenging to get good search accuracies.
# ----------------------------------------------------------------------

new-index dataset=glove-100d-1k.gob dataset-count=950 distance-metric=Cosine min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4 hide-tree
----
Created index with 950 vectors with 100 dimensions.
3 levels, 183 partitions.
CV stats:
  level 2 - mean: 0.0000, stdev: 0.0000
  level 3 - mean: 0.0000, stdev: 0.0000

recall topk=10 beam-size=4 samples=50
----
20.80% recall@10
45 leaf vectors, 74 vectors, 31 full vectors, 7 partitions

recall topk=10 beam-size=8 samples=50
----
28.40% recall@10
88 leaf vectors, 139 vectors, 47 full vectors, 13 partitions

recall topk=10 beam-size=16 samples=50
----
34.60% recall@10
175 leaf vectors, 265 vectors, 66 full vectors, 25 partitions

recall topk=10 beam-size=32 samples=50
----
38.60% recall@10
348 leaf vectors, 447 vectors, 89 full vectors, 42 partitions
