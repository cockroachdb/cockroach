# ----------------------------------------------------------------------
# Load 1000 512-dimension OpenAI embeddings and search them. Use small
# partition size to ensure a deeper tree.
# ----------------------------------------------------------------------
new-index dataset=images-512d-10k.gob train-count=1000 min-partition-size=4 max-partition-size=16 quality-samples=8 beam-size=4
----
Created index with 1000 vectors with 512 dimensions.

recall topk=10 beam-size=1 samples=20
----
24.00% recall@10

recall topk=10 beam-size=2 samples=20
----
33.50% recall@10

recall topk=10 beam-size=4 samples=20
----
59.00% recall@10

recall topk=10 beam-size=8 samples=20
----
75.00% recall@10

recall topk=10 beam-size=16 samples=20
----
91.00% recall@10

recall topk=10 beam-size=32 samples=20
----
99.00% recall@10

recall topk=10 beam-size=64 samples=20
----
100.00% recall@10
