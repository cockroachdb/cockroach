# LogicTest: local

statement ok
CREATE TABLE a (a INT, b INT, c INT4, PRIMARY KEY (a, b))

statement ok
CREATE TABLE c (a INT, b INT, c INT, d INT, PRIMARY KEY (a, c), INDEX sec (b))

statement ok
CREATE TABLE d (a INT, b INT, PRIMARY KEY (b, a))

statement ok
INSERT INTO a SELECT g//2, g, g FROM generate_series(0,2000) g(g)

statement ok
INSERT INTO c VALUES (1, 1, 1, 0), (2, 1, 2, 0)

statement ok
ALTER TABLE c INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 1,
    "distinct_count": 1
  }
]'

statement ok
INSERT INTO d VALUES (1, 1), (1, 2)

# Test that vectorized stats are collected correctly.
statement ok
SET vectorize = on

statement ok
SET distsql = on

query T
EXPLAIN ANALYZE (DISTSQL) SELECT a FROM a
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows read from KV: 2,001 (16 KiB)
maximum memory usage: <hidden>
network usage: <hidden>
·
• scan
  cluster nodes: <hidden>
  actual row count: 2,001
  KV rows read: 2,001
  KV bytes read: 16 KiB
  missing stats
  table: a@primary
  spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJyMkMFKKzEUhvf3KcK_zuXO3IWLrIpSoVSttMWNzCKdHGpgmsScM2Ap81i-gE8mM6mCiODy__6Z7-ScE_i5g8FmfjO_2iqrrterW2WhEaKjO3sghnlEjUYj5dgSc8wjOk0fLNwLTKXhQ-plxI1GGzPBnCBeOoLB1u46WpN1lP9V0HAk1neT1s5S9gebj9DYJBvYqL_QWPVi1KyGxvJBiT-QUdXbK5fcxiAUxMfwrZI-dcQqk3VG_ddVdVbsjvKJ6wu19JfQ2Flpn4hV7CWN88annQUfqCiaQaOQ84Isdk8w9aB_f4Q1cYqB6cv-P5mrodEgt6dyaI59buk-x3YaU-Jq-m8CjlhKW5ewCKUamuHPewAAAP__3R6a_g==

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c JOIN d ON d.b = c.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows read from KV: 3 (24 B)
maximum memory usage: <hidden>
network usage: <hidden>
·
• lookup join
│ cluster nodes: <hidden>
│ actual row count: 2
│ KV rows read: 1
│ KV bytes read: 8 B
│ table: d@primary
│ equality: (b) = (b)
│
└── • scan
      cluster nodes: <hidden>
      actual row count: 2
      KV rows read: 2
      KV bytes read: 16 B
      estimated row count: 1 (100% of the table; stats collected <hidden> ago)
      table: c@sec
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJykklGLEzEUhd_9FZfzHGvTB5GAUJQVuq4d6S6-yDxkkssanSYxycAupT_LP-Avk5mMYi2Kuo_n3Dm593zMAflzD4Xri6uLlzdkFppe7Zo3ZOiy2WzJUrMlu-joOZlFBwEfLG_1njPUe0i0AjEFwzmHNFqH6YONvYNaCjgfhzLarYAJiaEOKK70DIUb3fW8Y205PVlCwHLRrp-eNevMBgLXUfus6DEEmqEoWkuxXkHg9Tsqbs-Kll-_5KpN8IV9ccGfjcoQe86UWFtFc7y7Lz8s-ZReQKDTxXzgTGEocVw23jRHv1srtEeBquZWuehbhpJH8ffNL4Pzc3F5WtyuY3J7ne4hcBXCpyHSx-A8Ba9oaj5jwLxg7lZrVScX3ffnDP4TlzzH9WyixXdshvP8gyCu_gXijnMMPvMJwN-9vDy2Amxvuf6iOQzJ8NsUzLSmymbKTYblXOpUVrHxdTQe-HNY_jG8-iXcHh99CwAA__-Hph2I

query T
EXPLAIN (OPT, VERBOSE) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
project
 ├── columns: a:1
 ├── stats: [rows=10]
 ├── cost: 1100.77
 ├── prune: (1)
 └── inner-join (merge)
      ├── columns: c.a:1 d.b:8
      ├── flags: force merge join
      ├── left ordering: +1
      ├── right ordering: +8
      ├── stats: [rows=10, distinct(1)=1, null(1)=0, distinct(8)=1, null(8)=0]
      ├── cost: 1100.66
      ├── fd: (1)==(8), (8)==(1)
      ├── sort
      │    ├── columns: c.a:1
      │    ├── stats: [rows=1, distinct(1)=1, null(1)=0]
      │    ├── cost: 15.93
      │    ├── ordering: +1
      │    ├── prune: (1)
      │    ├── interesting orderings: (+1)
      │    ├── unfiltered-cols: (1-6)
      │    └── scan c@sec
      │         ├── columns: c.a:1
      │         ├── stats: [rows=1, distinct(1)=1, null(1)=0]
      │         ├── cost: 15.89
      │         ├── prune: (1)
      │         ├── interesting orderings: (+1)
      │         └── unfiltered-cols: (1-6)
      ├── scan d
      │    ├── columns: d.b:8
      │    ├── stats: [rows=1000, distinct(8)=100, null(8)=0]
      │    ├── cost: 1074.61
      │    ├── ordering: +8
      │    ├── prune: (8)
      │    ├── interesting orderings: (+8)
      │    └── unfiltered-cols: (7-10)
      └── filters (true)

query T
EXPLAIN ANALYZE (DISTSQL) SELECT c.a FROM c INNER MERGE JOIN d ON c.a = d.b
----
planning time: 10µs
execution time: 100µs
distribution: <hidden>
vectorized: <hidden>
rows read from KV: 4 (32 B)
maximum memory usage: <hidden>
network usage: <hidden>
·
• merge join
│ cluster nodes: <hidden>
│ actual row count: 2
│ equality: (a) = (b)
│
├── • sort
│   │ cluster nodes: <hidden>
│   │ actual row count: 2
│   │ estimated row count: 1
│   │ order: +a
│   │
│   └── • scan
│         cluster nodes: <hidden>
│         actual row count: 2
│         KV rows read: 2
│         KV bytes read: 16 B
│         estimated row count: 1 (100% of the table; stats collected <hidden> ago)
│         table: c@sec
│         spans: FULL SCAN
│
└── • scan
      cluster nodes: <hidden>
      actual row count: 2
      KV rows read: 2
      KV bytes read: 16 B
      missing stats
      table: d@primary
      spans: FULL SCAN
·
Diagram: https://cockroachdb.github.io/distsqlplan/decode.html#eJzMk8GO0zwQx-_fU4zm9KE12zpdcbC0UgQKqAtNULrignJw7aEbkdjBdqRWVR-LF-DJUJIFNm1ZqLjsLfOf-dvzm3F26L9UKHCZvEte3YK6lPA6zxagYJ6mSQ6LJH-TwE02T0FDlvYF16AvV8jQWE2prMmj-IgcC4aNs4q8t66Tdn3BXG9QTBmWpmlDJxcMlXWEYoehDBWhwFu5qignqclNpshQU5Bl1R-rYk8KGS4babyA58gwa4OAmCPDtx8glDUJmH776odYWRPIhNKao1Rom4o8OJJaQDRoq234KfEX8BIZrmRQd-TBtqHpbuoaurf-kCIs9gyH6B7JB7kmFHzP_h57aV0gN-Fj4phfIEPakGqPMWq5gZpq67Ygq8oqGUgLmPaNdzmvXNc-6NJ_Pq74J7ToHLSHG43GfDpuXFlLtz211ehJbnX2W_RfxK2xTpMjPaItOuefSk7Mb0FuTTe2NOQms_H8KvoU_o_5xbNrV67vhs_RX_H0ns7VOU8nJ99Y4-lwjidPnnbDI72mYRnetk7Re2dVf80QZr2vFzT5MGT5EMzNkOoafGjmj5pnIzM_NEdnmKND8-xR89VB28X-v-8BAAD__8iO4Q8=

statement ok
RESET vectorize; RESET distsql

statement ok
SET tracing=off

# Making sure that colBatchScan operator can parallelize scans.
# This test is similar to that in testplannerlogic/select
statement ok
CREATE TABLE tpar (
    a INT PRIMARY KEY, item STRING, price FLOAT, FAMILY (a, item, price),
    UNIQUE INDEX item (item), UNIQUE INDEX p (price)
)

statement ok
ALTER TABLE tpar SPLIT AT VALUES(5)

# Run a select to prime the range cache to simplify the trace below.
statement ok
SELECT * FROM tpar

# Make sure that the scan actually gets parallelized.
statement ok
SET tracing = on; SELECT * FROM tpar WHERE a = 0 OR a = 10; SET tracing = off

# The span "sending partial batch" means that the scan was parallelized.
# Note that table ID here is hardcoded, so if a new table is created before
# tpar, this query will need an adjustment.
query T
SELECT message FROM [SHOW TRACE FOR SESSION] WHERE message IN
    ('querying next range at /Table/56/1/0',
     'querying next range at /Table/56/1/10')
----
querying next range at /Table/56/1/0
querying next range at /Table/56/1/10

# Regression test for #46123 (rowexec.TableReader not implementing
# execinfra.OpNode interface).
statement ok
CREATE TABLE t46123(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev(0) FROM t46123 WHERE ('' COLLATE en)::BOOL
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colexecbase.distinctChainOps
      └ *colexecbase.constInt64Op
        └ *rowexec.filtererProcessor
          └ *colfetcher.ColBatchScan

# Regression test for #46122.
statement ok
CREATE TABLE t46122_0(c0 STRING); CREATE TABLE t46122_1(c0 STRING)

query T
EXPLAIN (VEC) SELECT t46122_0.c0 FROM t46122_0, t46122_1
----
│
└ Node 1
  └ *colexecjoin.crossJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE t46404_0(c0 INT); CREATE TABLE t46404_1(c0 INT)

query T
EXPLAIN (VEC) SELECT stddev((t46404_1.c0 > ANY (0, 0))::INT) FROM t46404_0, t46404_1 GROUP BY t46404_0.rowid
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colexecbase.castBoolInt64Op
      └ *colexecproj.defaultCmpRConstProjOp
        └ *colexecjoin.crossJoiner
          ├ *colfetcher.ColBatchScan
          └ *colfetcher.ColBatchScan

statement ok
CREATE TABLE xyz (
  x INT,
  y INT,
  z TEXT
)

# Check that we fallback gracefully to row-by-row engine on a join type with
# ON expression that we don't support.
query T
EXPLAIN (VEC) SELECT * FROM xyz AS t1 FULL OUTER JOIN xyz AS t2 ON t1.x = t2.x AND t1.x + t2.x = 0
----
│
└ Node 1
  └ *rowexec.hashJoiner
    ├ *colfetcher.ColBatchScan
    └ *colfetcher.ColBatchScan

# Verify that the vectorized engine is used (there is a mismatch between
# argument type width and the result).
query T
EXPLAIN (VEC) SELECT max(c) FROM a
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colexecbase.distinctChainOps
      └ *colfetcher.ColBatchScan

# Verify that binary operations on integers of any width return INT8.
statement ok
CREATE TABLE ints (_int2 INT2, _int4 INT4, _int8 INT8);
INSERT INTO ints VALUES (1, 1, 1), (2, 2, 2)

query T
SELECT pg_typeof(_int2 - _int2) FROM ints LIMIT 1
----
bigint

query T
EXPLAIN (VEC) SELECT _int2 * _int2 FROM ints WHERE _int4 + _int4 = _int8 + 2
----
│
└ Node 1
  └ *colexecproj.projMultInt64Int64Op
    └ *colexecbase.castInt16Int64Op
      └ *colexecbase.castInt16Int64Op
        └ *colexecsel.selEQInt64Int64Op
          └ *colexecproj.projPlusInt64Int64ConstOp
            └ *colexecproj.projPlusInt64Int64Op
              └ *colexecbase.castInt32Int64Op
                └ *colexecbase.castInt32Int64Op
                  └ *colfetcher.ColBatchScan

query I
SELECT _int2 * _int2 FROM ints WHERE _int4 + _int4 = _int8 + 2
----
4

# Check that joinReader core is wrapped into the plan when vectorize is set to
# `experimental_always` - that core is the only exception to disabling of
# wrapping.

query T
EXPLAIN (VEC) SELECT c.a FROM c JOIN d ON d.b = c.b
----
│
└ Node 1
  └ *rowexec.joinReader
    └ *colfetcher.ColBatchScan

statement ok
SET vectorize = experimental_always

statement ok
SELECT c.a FROM c JOIN d ON d.b = c.b

statement ok
RESET vectorize

statement ok
CREATE TABLE bytes_string(_group INT, _bytes BYTES, _string STRING)

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string GROUP BY _group
----
│
└ Node 1
  └ *colexec.hashAggregator
    └ *colfetcher.ColBatchScan

query T
EXPLAIN (VEC) SELECT concat_agg(_bytes), concat_agg(_string) FROM bytes_string
----
│
└ Node 1
  └ *colexec.orderedAggregator
    └ *colexecbase.distinctChainOps
      └ *colfetcher.ColBatchScan
