# LogicTest: 5node

# Disable automatic stats.
statement ok
SET CLUSTER SETTING sql.stats.automatic_collection.enabled = false

# Check that vectorize row count threshold is respected.

statement ok
CREATE TABLE small (a INT PRIMARY KEY)

statement ok
SET vectorize_row_count_threshold = 1000

# There are no stats available, so this should run through the row execution
# engine.
query T
EXPLAIN SELECT count(*) from small
----
distribution: full
vectorized: false
·
• group (scalar)
│
└── • scan
      missing stats
      table: small@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 0

# This should run through the vectorized execution engine because we disabled
# the threshold.
query T
EXPLAIN SELECT count(*) from small
----
distribution: full
vectorized: true
·
• group (scalar)
│
└── • scan
      missing stats
      table: small@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 1000

statement ok
ALTER TABLE small INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100,
    "distinct_count": 100
  }
]'

# This should run through the row execution engine.
query T
EXPLAIN SELECT count(*) from small
----
distribution: full
vectorized: false
·
• group (scalar)
│ estimated row count: 1
│
└── • scan
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: small@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 1

# This should run through the vectorized execution engine because we lowered
# the threshold.
query T
EXPLAIN SELECT count(*) from small
----
distribution: full
vectorized: true
·
• group (scalar)
│ estimated row count: 1
│
└── • scan
      estimated row count: 100 (100% of the table; stats collected <hidden> ago)
      table: small@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 1000

statement ok
CREATE TABLE large (a INT PRIMARY KEY)

statement ok
ALTER TABLE large INJECT STATISTICS '[
  {
    "columns": ["a"],
    "created_at": "2018-01-01 1:00:00.00000+00:00",
    "row_count": 100000,
    "distinct_count": 100000
  }
]'

# This should run through the vectorized execution engine.
query T
EXPLAIN SELECT count(*) from large
----
distribution: full
vectorized: true
·
• group (scalar)
│ estimated row count: 1
│
└── • scan
      estimated row count: 100,000 (100% of the table; stats collected <hidden> ago)
      table: large@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 1000000

# This should run through the row execution engine because we increased the
# threshold.
query T
EXPLAIN SELECT count(*) from large
----
distribution: full
vectorized: false
·
• group (scalar)
│ estimated row count: 1
│
└── • scan
      estimated row count: 100,000 (100% of the table; stats collected <hidden> ago)
      table: large@primary
      spans: FULL SCAN

statement ok
SET vectorize_row_count_threshold = 1000

# Check that we estimate the row count correctly when multiple tables are
# scanned.
query T
EXPLAIN SELECT * FROM small INNER MERGE JOIN large ON small.a = large.a
----
distribution: full
vectorized: true
·
• merge join
│ estimated row count: 100
│ equality: (a) = (a)
│ left cols are key
│ right cols are key
│
├── • scan
│     estimated row count: 100 (100% of the table; stats collected <hidden> ago)
│     table: small@primary
│     spans: FULL SCAN
│
└── • scan
      estimated row count: 100,000 (100% of the table; stats collected <hidden> ago)
      table: large@primary
      spans: FULL SCAN
