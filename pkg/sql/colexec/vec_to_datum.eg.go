// Code generated by execgen; DO NOT EDIT.
// Copyright 2020 The Cockroach Authors.
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package colexec

import (
	"math/big"

	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/coldataext"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecbase/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/sqlbase"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/cockroach/pkg/util/timeutil/pgdate"
	"github.com/cockroachdb/cockroach/pkg/util/uuid"
	"github.com/lib/pq/oid"
)

// vecToDatumConverter is a helper struct that converts vectors from batches to
// their datum representations.
// TODO(yuzefovich): the result of converting the vectors to datums is usually
// put into sqlbase.EncDatumRow, so it might make sense to look into creating
// a converter that would store EncDatumRows directly. I prototyped such
// converter, but it showed worse performance both in the microbenchmarks and
// some of the TPCH queries. I think the main reason for the slowdown is that
// the amount of memory allocated increases just because EncDatums take more
// space than Datums. Another thing is that allocating whole W vectors, one
// vector at a time, in vecToDatumConverter is noticeably faster that
// allocating N rows of W length, one row at a time (meaning that
// O(batch width) vs O(batch length) comparison). We could probably play around
// with allocating a big flat []EncDatum slice in which datums from the same
// column are contiguous and then populate the output row in the materializer
// by choosing appropriate elements, but I'm not sure whether it would be more
// performant.
type vecToDatumConverter struct {
	convertedVecs    []tree.Datums
	vecIdxsToConvert []int
	// TODO(yuzefovich): consider customizing the allocation size of DatumAlloc
	// for vectorized purposes.
	da sqlbase.DatumAlloc
}

// newVecToDatumConverter creates a new vecToDatumConverter.
// - batchWidth determines the width of the batches that it will be converting.
// - vecIdxsToConvert determines which vectors need to be converted. It can be
// nil indicating that all vectors need to be converted.
func newVecToDatumConverter(batchWidth int, vecIdxsToConvert []int) *vecToDatumConverter {
	if vecIdxsToConvert == nil {
		vecIdxsToConvert = make([]int, batchWidth)
		for i := range vecIdxsToConvert {
			vecIdxsToConvert[i] = i
		}
	}
	return &vecToDatumConverter{
		convertedVecs:    make([]tree.Datums, batchWidth),
		vecIdxsToConvert: vecIdxsToConvert,
	}
}

// convertBatch converts the selected vectors from the batch.
func (c *vecToDatumConverter) convertBatch(batch coldata.Batch) {
	if len(c.vecIdxsToConvert) == 0 {
		// No vectors were selected for conversion, so there is nothing to do.
		return
	}
	batchLength := batch.Length()
	// Ensure that convertedVecs are of sufficient length.
	if cap(c.convertedVecs[c.vecIdxsToConvert[0]]) < batchLength {
		for _, vecIdx := range c.vecIdxsToConvert {
			c.convertedVecs[vecIdx] = make([]tree.Datum, batchLength)
		}
	} else {
		for _, vecIdx := range c.vecIdxsToConvert {
			c.convertedVecs[vecIdx] = c.convertedVecs[vecIdx][:batchLength]
		}
	}
	sel := batch.Selection()
	vecs := batch.ColVecs()
	for _, vecIdx := range c.vecIdxsToConvert {
		PhysicalTypeColVecToDatum(
			c.convertedVecs[vecIdx], vecs[vecIdx], batchLength, sel, &c.da,
		)
	}
}

// getDatumColumn returns the converted column of tree.Datum of the vector on
// position colIdx from the last converted batch.
// NOTE: this column is "dense" in regards to the selection vector - if there
// was a selection vector on the batch, only elements that were selected are
// converted, so in order to access the tuple at position tupleIdx, use
// getDatumColumn(colIdx)[tupleIdx] and *NOT*
// getDatumColumn(colIdx)[sel[tupleIdx]].
func (c *vecToDatumConverter) getDatumColumn(colIdx int) tree.Datums {
	return c.convertedVecs[colIdx]
}

func PhysicalTypeColVecToDatum(
	converted []tree.Datum, col coldata.Vec, length int, sel []int, da *sqlbase.DatumAlloc,
) {
	if col.MaybeHasNulls() {
		nulls := col.Nulls()
		if sel != nil {
			sel = sel[:length]
			var idx, tupleIdx int
			switch ct := col.Type(); ct.Family() {
			case types.StringFamily:
				// Note that there is no need for a copy since casting to a string will
				// do that.
				bytes := col.Bytes()
				if ct.Oid() == oid.T_name {
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDName(tree.DString(bytes.Get(tupleIdx)))
					}
					return
				}
				for idx = 0; idx < length; idx++ {
					tupleIdx = sel[idx]
					if nulls.NullAt(tupleIdx) {
						converted[idx] = tree.DNull
						continue
					}
					converted[idx] = da.NewDString(tree.DString(bytes.Get(tupleIdx)))
				}
			case types.BoolFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bool()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = tree.MakeDBool(tree.DBool(typedCol[tupleIdx]))
					}
				}
			case types.IntFamily:
				switch ct.Width() {
				case 16:
					typedCol := col.Int16()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case 32:
					typedCol := col.Int32()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				}
			case types.FloatFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Float64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDFloat(tree.DFloat(typedCol[tupleIdx]))
					}
				}
			case types.DecimalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Decimal()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						d := da.NewDDecimal(tree.DDecimal{Decimal: typedCol[tupleIdx]})
						// Clear the Coeff so that the Set below allocates a new slice for the
						// Coeff.abs field.
						d.Coeff = big.Int{}
						d.Coeff.Set(&typedCol[tupleIdx].Coeff)
						converted[idx] = d
					}
				}
			case types.DateFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDDate(tree.DDate{Date: pgdate.MakeCompatibleDateFromDisk(typedCol[tupleIdx])})
					}
				}
			case types.BytesFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						// Note that there is no need for a copy since DBytes uses a string
						// as underlying storage, which will perform the copy for us.
						converted[idx] = da.NewDBytes(tree.DBytes(typedCol.Get(tupleIdx)))
					}
				}
			case types.OidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDOid(tree.MakeDOid(tree.DInt(typedCol[tupleIdx])))
					}
				}
			case types.UuidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						// Note that there is no need for a copy because uuid.FromBytes
						// will perform a copy.
						id, err := uuid.FromBytes(typedCol.Get(tupleIdx))
						if err != nil {
							colexecerror.InternalError(err)
						}
						converted[idx] = da.NewDUuid(tree.DUuid{UUID: id})
					}
				}
			case types.TimestampFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDTimestamp(tree.DTimestamp{Time: typedCol[tupleIdx]})
					}
				}
			case types.TimestampTZFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDTimestampTZ(tree.DTimestampTZ{Time: typedCol[tupleIdx]})
					}
				}
			case types.IntervalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Interval()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInterval(tree.DInterval{Duration: typedCol[tupleIdx]})
					}
				}
			case typeconv.DatumVecCanonicalTypeFamily:
			default:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Datum()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = typedCol.Get(tupleIdx).(*coldataext.Datum).Datum
					}
				}
			}
		} else {
			var idx, tupleIdx int
			switch ct := col.Type(); ct.Family() {
			case types.StringFamily:
				// Note that there is no need for a copy since casting to a string will
				// do that.
				bytes := col.Bytes()
				if ct.Oid() == oid.T_name {
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDName(tree.DString(bytes.Get(tupleIdx)))
					}
					return
				}
				for idx = 0; idx < length; idx++ {
					tupleIdx = idx
					if nulls.NullAt(tupleIdx) {
						converted[idx] = tree.DNull
						continue
					}
					converted[idx] = da.NewDString(tree.DString(bytes.Get(tupleIdx)))
				}
			case types.BoolFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bool()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = tree.MakeDBool(tree.DBool(typedCol[tupleIdx]))
					}
				}
			case types.IntFamily:
				switch ct.Width() {
				case 16:
					typedCol := col.Int16()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case 32:
					typedCol := col.Int32()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				}
			case types.FloatFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Float64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDFloat(tree.DFloat(typedCol[tupleIdx]))
					}
				}
			case types.DecimalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Decimal()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						d := da.NewDDecimal(tree.DDecimal{Decimal: typedCol[tupleIdx]})
						// Clear the Coeff so that the Set below allocates a new slice for the
						// Coeff.abs field.
						d.Coeff = big.Int{}
						d.Coeff.Set(&typedCol[tupleIdx].Coeff)
						converted[idx] = d
					}
				}
			case types.DateFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDDate(tree.DDate{Date: pgdate.MakeCompatibleDateFromDisk(typedCol[tupleIdx])})
					}
				}
			case types.BytesFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						// Note that there is no need for a copy since DBytes uses a string
						// as underlying storage, which will perform the copy for us.
						converted[idx] = da.NewDBytes(tree.DBytes(typedCol.Get(tupleIdx)))
					}
				}
			case types.OidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDOid(tree.MakeDOid(tree.DInt(typedCol[tupleIdx])))
					}
				}
			case types.UuidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						// Note that there is no need for a copy because uuid.FromBytes
						// will perform a copy.
						id, err := uuid.FromBytes(typedCol.Get(tupleIdx))
						if err != nil {
							colexecerror.InternalError(err)
						}
						converted[idx] = da.NewDUuid(tree.DUuid{UUID: id})
					}
				}
			case types.TimestampFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDTimestamp(tree.DTimestamp{Time: typedCol[tupleIdx]})
					}
				}
			case types.TimestampTZFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDTimestampTZ(tree.DTimestampTZ{Time: typedCol[tupleIdx]})
					}
				}
			case types.IntervalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Interval()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = da.NewDInterval(tree.DInterval{Duration: typedCol[tupleIdx]})
					}
				}
			case typeconv.DatumVecCanonicalTypeFamily:
			default:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Datum()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						if nulls.NullAt(tupleIdx) {
							converted[idx] = tree.DNull
							continue
						}
						converted[idx] = typedCol.Get(tupleIdx).(*coldataext.Datum).Datum
					}
				}
			}
		}
	} else {
		if sel != nil {
			sel = sel[:length]
			var idx, tupleIdx int
			switch ct := col.Type(); ct.Family() {
			case types.StringFamily:
				// Note that there is no need for a copy since casting to a string will
				// do that.
				bytes := col.Bytes()
				if ct.Oid() == oid.T_name {
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDName(tree.DString(bytes.Get(tupleIdx)))
					}
					return
				}
				for idx = 0; idx < length; idx++ {
					tupleIdx = sel[idx]
					converted[idx] = da.NewDString(tree.DString(bytes.Get(tupleIdx)))
				}
			case types.BoolFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bool()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = tree.MakeDBool(tree.DBool(typedCol[tupleIdx]))
					}
				}
			case types.IntFamily:
				switch ct.Width() {
				case 16:
					typedCol := col.Int16()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case 32:
					typedCol := col.Int32()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				}
			case types.FloatFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Float64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDFloat(tree.DFloat(typedCol[tupleIdx]))
					}
				}
			case types.DecimalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Decimal()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						d := da.NewDDecimal(tree.DDecimal{Decimal: typedCol[tupleIdx]})
						// Clear the Coeff so that the Set below allocates a new slice for the
						// Coeff.abs field.
						d.Coeff = big.Int{}
						d.Coeff.Set(&typedCol[tupleIdx].Coeff)
						converted[idx] = d
					}
				}
			case types.DateFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDDate(tree.DDate{Date: pgdate.MakeCompatibleDateFromDisk(typedCol[tupleIdx])})
					}
				}
			case types.BytesFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						// Note that there is no need for a copy since DBytes uses a string
						// as underlying storage, which will perform the copy for us.
						converted[idx] = da.NewDBytes(tree.DBytes(typedCol.Get(tupleIdx)))
					}
				}
			case types.OidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDOid(tree.MakeDOid(tree.DInt(typedCol[tupleIdx])))
					}
				}
			case types.UuidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						// Note that there is no need for a copy because uuid.FromBytes
						// will perform a copy.
						id, err := uuid.FromBytes(typedCol.Get(tupleIdx))
						if err != nil {
							colexecerror.InternalError(err)
						}
						converted[idx] = da.NewDUuid(tree.DUuid{UUID: id})
					}
				}
			case types.TimestampFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDTimestamp(tree.DTimestamp{Time: typedCol[tupleIdx]})
					}
				}
			case types.TimestampTZFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDTimestampTZ(tree.DTimestampTZ{Time: typedCol[tupleIdx]})
					}
				}
			case types.IntervalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Interval()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = da.NewDInterval(tree.DInterval{Duration: typedCol[tupleIdx]})
					}
				}
			case typeconv.DatumVecCanonicalTypeFamily:
			default:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Datum()
					for idx = 0; idx < length; idx++ {
						tupleIdx = sel[idx]
						converted[idx] = typedCol.Get(tupleIdx).(*coldataext.Datum).Datum
					}
				}
			}
		} else {
			var idx, tupleIdx int
			switch ct := col.Type(); ct.Family() {
			case types.StringFamily:
				// Note that there is no need for a copy since casting to a string will
				// do that.
				bytes := col.Bytes()
				if ct.Oid() == oid.T_name {
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDName(tree.DString(bytes.Get(tupleIdx)))
					}
					return
				}
				for idx = 0; idx < length; idx++ {
					tupleIdx = idx
					converted[idx] = da.NewDString(tree.DString(bytes.Get(tupleIdx)))
				}
			case types.BoolFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bool()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = tree.MakeDBool(tree.DBool(typedCol[tupleIdx]))
					}
				}
			case types.IntFamily:
				switch ct.Width() {
				case 16:
					typedCol := col.Int16()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case 32:
					typedCol := col.Int32()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDInt(tree.DInt(typedCol[tupleIdx]))
					}
				}
			case types.FloatFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Float64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDFloat(tree.DFloat(typedCol[tupleIdx]))
					}
				}
			case types.DecimalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Decimal()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						d := da.NewDDecimal(tree.DDecimal{Decimal: typedCol[tupleIdx]})
						// Clear the Coeff so that the Set below allocates a new slice for the
						// Coeff.abs field.
						d.Coeff = big.Int{}
						d.Coeff.Set(&typedCol[tupleIdx].Coeff)
						converted[idx] = d
					}
				}
			case types.DateFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDDate(tree.DDate{Date: pgdate.MakeCompatibleDateFromDisk(typedCol[tupleIdx])})
					}
				}
			case types.BytesFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						// Note that there is no need for a copy since DBytes uses a string
						// as underlying storage, which will perform the copy for us.
						converted[idx] = da.NewDBytes(tree.DBytes(typedCol.Get(tupleIdx)))
					}
				}
			case types.OidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Int64()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDOid(tree.MakeDOid(tree.DInt(typedCol[tupleIdx])))
					}
				}
			case types.UuidFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Bytes()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						// Note that there is no need for a copy because uuid.FromBytes
						// will perform a copy.
						id, err := uuid.FromBytes(typedCol.Get(tupleIdx))
						if err != nil {
							colexecerror.InternalError(err)
						}
						converted[idx] = da.NewDUuid(tree.DUuid{UUID: id})
					}
				}
			case types.TimestampFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDTimestamp(tree.DTimestamp{Time: typedCol[tupleIdx]})
					}
				}
			case types.TimestampTZFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Timestamp()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDTimestampTZ(tree.DTimestampTZ{Time: typedCol[tupleIdx]})
					}
				}
			case types.IntervalFamily:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Interval()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = da.NewDInterval(tree.DInterval{Duration: typedCol[tupleIdx]})
					}
				}
			case typeconv.DatumVecCanonicalTypeFamily:
			default:
				switch ct.Width() {
				case -1:
				default:
					typedCol := col.Datum()
					for idx = 0; idx < length; idx++ {
						tupleIdx = idx
						converted[idx] = typedCol.Get(tupleIdx).(*coldataext.Datum).Datum
					}
				}
			}
		}
	}
}
