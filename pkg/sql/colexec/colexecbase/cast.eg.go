// Code generated by execgen; DO NOT EDIT.
// Copyright 2019 The Cockroach Authors.
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package colexecbase

import (
	"context"
	"fmt"
	"math"

	"github.com/cockroachdb/apd/v2"
	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/coldataext"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexec/colexecutils"
	"github.com/cockroachdb/cockroach/pkg/sql/colexec/execgen"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecop"
	"github.com/cockroachdb/cockroach/pkg/sql/colmem"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/errors"
)

// Workaround for bazel auto-generated code. goimports does not automatically
// pick up the right packages when run within the bazel sandbox.
var _ coldataext.Datum

func GetCastOperator(
	allocator *colmem.Allocator,
	input colexecop.Operator,
	colIdx int,
	resultIdx int,
	fromType *types.T,
	toType *types.T,
) (colexecop.Operator, error) {
	input = colexecutils.NewVectorTypeEnforcer(allocator, input, toType, resultIdx)
	base := castOpBase{
		OneInputInitCloserHelper: colexecop.MakeOneInputInitCloserHelper(input),
		allocator:                allocator,
		colIdx:                   colIdx,
		outputIdx:                resultIdx,
	}
	if fromType.Family() == types.UnknownFamily {
		return &castOpNullAny{castOpBase: base}, nil
	}
	if toType.Identical(fromType) || (fromType.Family() == types.FloatFamily && toType.Family() == types.FloatFamily) {
		// We either have an identity cast or we have a cast between floats (and
		// all floats are represented by float64 physically, so they are
		// essentially identical too), so we use a custom identity cast
		// operator.
		return &castIdentityOp{castOpBase: base}, nil
	}
	isFromDatum := typeconv.TypeFamilyToCanonicalTypeFamily(fromType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	isToDatum := typeconv.TypeFamilyToCanonicalTypeFamily(toType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	if isFromDatum {
		if isToDatum {
			return &castDatumDatumOp{castOpBase: base}, nil
		}
		switch toType.Family() {
		case types.BoolFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumBoolOp{castOpBase: base}, nil
			}
		}
	} else {
		if !isToDatum {
			switch fromType.Family() {
			case types.BoolFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castBoolFloatOp{castOpBase: base}, nil
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castBoolInt2Op{castOpBase: base}, nil
						case 32:
							return &castBoolInt4Op{castOpBase: base}, nil
						case -1:
						default:
							return &castBoolIntOp{castOpBase: base}, nil
						}
					}
				}
			case types.DecimalFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castDecimalBoolOp{castOpBase: base}, nil
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castDecimalInt2Op{castOpBase: base}, nil
						case 32:
							return &castDecimalInt4Op{castOpBase: base}, nil
						case -1:
						default:
							return &castDecimalIntOp{castOpBase: base}, nil
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castDecimalFloatOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castDecimalDecimalOp{castOpBase: base}, nil
						}
					}
				}
			case types.IntFamily:
				switch fromType.Width() {
				case 16:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 32:
							return &castInt2Int4Op{castOpBase: base}, nil
						case -1:
						default:
							return &castInt2IntOp{castOpBase: base}, nil
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt2BoolOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt2DecimalOp{castOpBase: base}, nil
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt2FloatOp{castOpBase: base}, nil
						}
					}
				case 32:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castInt4Int2Op{castOpBase: base}, nil
						case -1:
						default:
							return &castInt4IntOp{castOpBase: base}, nil
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt4BoolOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt4DecimalOp{castOpBase: base}, nil
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castInt4FloatOp{castOpBase: base}, nil
						}
					}
				case -1:
				default:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castIntInt2Op{castOpBase: base}, nil
						case 32:
							return &castIntInt4Op{castOpBase: base}, nil
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castIntBoolOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castIntDecimalOp{castOpBase: base}, nil
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castIntFloatOp{castOpBase: base}, nil
						}
					}
				}
			case types.FloatFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castFloatBoolOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castFloatDecimalOp{castOpBase: base}, nil
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castFloatInt2Op{castOpBase: base}, nil
						case 32:
							return &castFloatInt4Op{castOpBase: base}, nil
						case -1:
						default:
							return &castFloatIntOp{castOpBase: base}, nil
						}
					}
				}
			case types.DateFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return &castDateInt2Op{castOpBase: base}, nil
						case 32:
							return &castDateInt4Op{castOpBase: base}, nil
						case -1:
						default:
							return &castDateIntOp{castOpBase: base}, nil
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castDateFloatOp{castOpBase: base}, nil
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return &castDateDecimalOp{castOpBase: base}, nil
						}
					}
				}
			}
		}
	}
	return nil, errors.Errorf("unhandled cast %s -> %s", fromType, toType)
}

func IsCastSupported(fromType, toType *types.T) bool {
	if fromType.Family() == types.UnknownFamily {
		return true
	}
	if toType.Identical(fromType) || (fromType.Family() == types.FloatFamily && toType.Family() == types.FloatFamily) {
		return true
	}
	isFromDatum := typeconv.TypeFamilyToCanonicalTypeFamily(fromType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	isToDatum := typeconv.TypeFamilyToCanonicalTypeFamily(toType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	if isFromDatum {
		if isToDatum {
			return true
		}
		switch toType.Family() {
		case types.BoolFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		}
	} else {
		if isToDatum {
			// TODO(yuzefovich): support this case.
			return false
		} else {
			switch fromType.Family() {
			case types.BoolFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case 32:
							return true
						case -1:
						default:
							return true
						}
					}
				}
			case types.DecimalFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case 32:
							return true
						case -1:
						default:
							return true
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					}
				}
			case types.IntFamily:
				switch fromType.Width() {
				case 16:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 32:
							return true
						case -1:
						default:
							return true
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					}
				case 32:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case -1:
						default:
							return true
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					}
				case -1:
				default:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case 32:
							return true
						}
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					}
				}
			case types.FloatFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.BoolFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case 32:
							return true
						case -1:
						default:
							return true
						}
					}
				}
			case types.DateFamily:
				switch fromType.Width() {
				case -1:
				default:
					switch toType.Family() {
					case types.IntFamily:
						switch toType.Width() {
						case 16:
							return true
						case 32:
							return true
						case -1:
						default:
							return true
						}
					case types.FloatFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					case types.DecimalFamily:
						switch toType.Width() {
						case -1:
						default:
							return true
						}
					}
				}
			}
		}
	}
	return false
}

type castOpBase struct {
	colexecop.OneInputInitCloserHelper

	allocator *colmem.Allocator
	colIdx    int
	outputIdx int
}

func (c *castOpBase) Reset(ctx context.Context) {
	if r, ok := c.Input.(colexecop.Resetter); ok {
		r.Reset(ctx)
	}
}

type castOpNullAny struct {
	castOpBase
}

var _ colexecop.ClosableOperator = &castOpNullAny{}

func (c *castOpNullAny) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	vec := batch.ColVec(c.colIdx)
	projVec := batch.ColVec(c.outputIdx)
	vecNulls := vec.Nulls()
	projNulls := projVec.Nulls()
	if projVec.MaybeHasNulls() {
		// We need to make sure that there are no left over nulls values in the
		// output vector.
		projNulls.UnsetNulls()
	}
	if sel := batch.Selection(); sel != nil {
		sel = sel[:n]
		for _, i := range sel {
			if vecNulls.NullAt(i) {
				projNulls.SetNull(i)
			} else {
				colexecerror.InternalError(errors.Errorf("unexpected non-null at index %d", i))
			}
		}
	} else {
		for i := 0; i < n; i++ {
			if vecNulls.NullAt(i) {
				projNulls.SetNull(i)
			} else {
				colexecerror.InternalError(fmt.Errorf("unexpected non-null at index %d", i))
			}
		}
	}
	return batch
}

// castIdentityOp is a special cast operator for the case when "from" and "to"
// types are identical. The job of this operator is to simply copy the input
// column into the output column, without performing the deselection step. Not
// performing the deselection is justified by the following:
// 1. to be in line with other cast operators
// 2. AND/OR projection operators cannot handle when a different batch is
//    returned than the one they fed into the projection chain (which might
//    contain casts)
// 3. performing the deselection would require copying over all vectors, not
//    just the output one.
// This operator should be planned rarely enough (if ever) to not be very
// important.
type castIdentityOp struct {
	castOpBase
}

var _ colexecop.ClosableOperator = &castIdentityOp{}

func (c *castIdentityOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	projVec := batch.ColVec(c.outputIdx)
	c.allocator.PerformOperation([]coldata.Vec{projVec}, func() {
		maxIdx := n
		if sel := batch.Selection(); sel != nil {
			// We don't want to perform the deselection during copying, so we
			// will copy everything up to (and including) the last selected
			// element, without the selection vector.
			maxIdx = sel[n-1] + 1
		}
		projVec.Copy(coldata.SliceArgs{
			Src:       batch.ColVec(c.colIdx),
			SrcEndIdx: maxIdx,
		})
	})
	return batch
}

type castBoolFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolFloatOp{}
var _ colexecop.ClosableOperator = &castBoolFloatOp{}

func (c *castBoolFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolInt2Op{}
var _ colexecop.ClosableOperator = &castBoolInt2Op{}

func (c *castBoolInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolInt4Op{}
var _ colexecop.ClosableOperator = &castBoolInt4Op{}

func (c *castBoolInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolIntOp{}
var _ colexecop.ClosableOperator = &castBoolIntOp{}

func (c *castBoolIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64

						r = 0
						if v {
							r = 1
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						r = 0
						if v {
							r = 1
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalBoolOp{}
var _ colexecop.ClosableOperator = &castDecimalBoolOp{}

func (c *castDecimalBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool
						r = v.Sign() != 0
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool
						r = v.Sign() != 0
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool
						r = v.Sign() != 0
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool
						r = v.Sign() != 0
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalInt2Op struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalInt2Op{}
var _ colexecop.ClosableOperator = &castDecimalInt2Op{}

func (c *castDecimalInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}

							shifted := _i >> uint(15)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(_i)

						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}

							shifted := _i >> uint(15)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(_i)

						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}

							shifted := _i >> uint(15)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(_i)

						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}

							shifted := _i >> uint(15)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(_i)

						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalInt4Op struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalInt4Op{}
var _ colexecop.ClosableOperator = &castDecimalInt4Op{}

func (c *castDecimalInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}

							shifted := _i >> uint(31)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(_i)

						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}

							shifted := _i >> uint(31)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(_i)

						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}

							shifted := _i >> uint(31)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(_i)

						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}

							shifted := _i >> uint(31)
							if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(_i)

						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalIntOp struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalIntOp{}
var _ colexecop.ClosableOperator = &castDecimalIntOp{}

func (c *castDecimalIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(_i)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(_i)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(_i)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						{
							tmpDec := &_overloadHelper.TmpDec1
							_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							_i, err := tmpDec.Int64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(_i)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalFloatOp{}
var _ colexecop.ClosableOperator = &castDecimalFloatOp{}

func (c *castDecimalFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						{
							f, err := v.Float64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
							}
							r = f
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						{
							f, err := v.Float64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
							}
							r = f
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						{
							f, err := v.Float64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
							}
							r = f
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						{
							f, err := v.Float64()
							if err != nil {
								colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
							}
							r = f
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalDecimalOp{}
var _ colexecop.ClosableOperator = &castDecimalDecimalOp{}

func (c *castDecimalDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.Set(&v)
						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.Set(&v)
						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.Set(&v)
						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.Set(&v)
						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2Int4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2Int4Op{}
var _ colexecop.ClosableOperator = &castInt2Int4Op{}

func (c *castInt2Int4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32
						r = int32(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32
						r = int32(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32
						r = int32(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32
						r = int32(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2IntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2IntOp{}
var _ colexecop.ClosableOperator = &castInt2IntOp{}

func (c *castInt2IntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2BoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2BoolOp{}
var _ colexecop.ClosableOperator = &castInt2BoolOp{}

func (c *castInt2BoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2DecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2DecimalOp{}
var _ colexecop.ClosableOperator = &castInt2DecimalOp{}

func (c *castInt2DecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2FloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2FloatOp{}
var _ colexecop.ClosableOperator = &castInt2FloatOp{}

func (c *castInt2FloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4Int2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4Int2Op{}
var _ colexecop.ClosableOperator = &castInt4Int2Op{}

func (c *castInt4Int2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4IntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4IntOp{}
var _ colexecop.ClosableOperator = &castInt4IntOp{}

func (c *castInt4IntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4BoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4BoolOp{}
var _ colexecop.ClosableOperator = &castInt4BoolOp{}

func (c *castInt4BoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4DecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4DecimalOp{}
var _ colexecop.ClosableOperator = &castInt4DecimalOp{}

func (c *castInt4DecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4FloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4FloatOp{}
var _ colexecop.ClosableOperator = &castInt4FloatOp{}

func (c *castInt4FloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntInt2Op{}
var _ colexecop.ClosableOperator = &castIntInt2Op{}

func (c *castIntInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntInt4Op{}
var _ colexecop.ClosableOperator = &castIntInt4Op{}

func (c *castIntInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntBoolOp{}
var _ colexecop.ClosableOperator = &castIntBoolOp{}

func (c *castIntBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntDecimalOp{}
var _ colexecop.ClosableOperator = &castIntDecimalOp{}

func (c *castIntDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntFloatOp{}
var _ colexecop.ClosableOperator = &castIntFloatOp{}

func (c *castIntFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatBoolOp{}
var _ colexecop.ClosableOperator = &castFloatBoolOp{}

func (c *castFloatBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						r = v != 0

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatDecimalOp{}
var _ colexecop.ClosableOperator = &castFloatDecimalOp{}

func (c *castFloatDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						if _, err := r.SetFloat64(float64(v)); err != nil {
							colexecerror.ExpectedError(err)
						}

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						if _, err := r.SetFloat64(float64(v)); err != nil {
							colexecerror.ExpectedError(err)
						}

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						if _, err := r.SetFloat64(float64(v)); err != nil {
							colexecerror.ExpectedError(err)
						}

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						if _, err := r.SetFloat64(float64(v)); err != nil {
							colexecerror.ExpectedError(err)
						}

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatInt2Op{}
var _ colexecop.ClosableOperator = &castFloatInt2Op{}

func (c *castFloatInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatInt4Op{}
var _ colexecop.ClosableOperator = &castFloatInt4Op{}

func (c *castFloatInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatIntOp{}
var _ colexecop.ClosableOperator = &castFloatIntOp{}

func (c *castFloatIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64

						if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
							colexecerror.ExpectedError(tree.ErrIntOutOfRange)
						}
						r = int64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateInt2Op{}
var _ colexecop.ClosableOperator = &castDateInt2Op{}

func (c *castDateInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int16

						shifted := v >> uint(15)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
						}
						r = int16(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateInt4Op{}
var _ colexecop.ClosableOperator = &castDateInt4Op{}

func (c *castDateInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int32

						shifted := v >> uint(31)
						if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
							colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
						}
						r = int32(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateIntOp{}
var _ colexecop.ClosableOperator = &castDateIntOp{}

func (c *castDateIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r int64
						r = int64(v)
						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateFloatOp{}
var _ colexecop.ClosableOperator = &castDateFloatOp{}

func (c *castDateFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r float64

						r = float64(v)

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateDecimalOp{}
var _ colexecop.ClosableOperator = &castDateDecimalOp{}

func (c *castDateDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r apd.Decimal

						r.SetInt64(int64(v))

						if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
							colexecerror.ExpectedError(err)
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumBoolOp{}
var _ colexecop.ClosableOperator = &castDatumBoolOp{}

func (c *castDatumBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r bool

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, types.Bool)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum == tree.DBoolTrue
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, types.Bool)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum == tree.DBoolTrue
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r bool

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, types.Bool)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum == tree.DBoolTrue
						}

						outputCol.Set(tupleIdx, r)
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r bool

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, types.Bool)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum == tree.DBoolTrue
						}

						//gcassert:bce
						outputCol.Set(tupleIdx, r)
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumDatumOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumDatumOp{}
var _ colexecop.ClosableOperator = &castDatumDatumOp{}

func (c *castDatumDatumOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			outputCol := outputVec.Datum()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				inputNulls := inputVec.Nulls()
				outputNulls.Copy(inputNulls)
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						v := inputCol.Get(tupleIdx)
						var r interface{}

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, toType)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum
						}

						outputCol.Set(tupleIdx, r)
						// Casting to datum-backed vector might produce a null value on
						// non-null tuple, so we need to check that case after the cast was
						// performed.
						if r == tree.DNull {
							outputNulls.SetNull(tupleIdx)
						}
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						if inputNulls.NullAt(tupleIdx) {
							continue
						}
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r interface{}

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, toType)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum
						}

						outputCol.Set(tupleIdx, r)
						// Casting to datum-backed vector might produce a null value on
						// non-null tuple, so we need to check that case after the cast was
						// performed.
						if r == tree.DNull {
							outputNulls.SetNull(tupleIdx)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					sel = sel[:n]
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = sel[i]
						v := inputCol.Get(tupleIdx)
						var r interface{}

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, toType)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum
						}

						outputCol.Set(tupleIdx, r)
						// Casting to datum-backed vector might produce a null value on
						// non-null tuple, so we need to check that case after the cast was
						// performed.
						if r == tree.DNull {
							outputNulls.SetNull(tupleIdx)
						}
					}
				} else {
					// Remove bounds checks for inputCol[i] and outputCol[i].
					_ = inputCol.Get(n - 1)
					_ = outputCol.Get(n - 1)
					var tupleIdx int
					for i := 0; i < n; i++ {
						tupleIdx = i
						//gcassert:bce
						v := inputCol.Get(tupleIdx)
						var r interface{}

						{
							_castedDatum, err := v.(*coldataext.Datum).Cast(inputCol, toType)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _castedDatum
						}

						outputCol.Set(tupleIdx, r)
						// Casting to datum-backed vector might produce a null value on
						// non-null tuple, so we need to check that case after the cast was
						// performed.
						if r == tree.DNull {
							outputNulls.SetNull(tupleIdx)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}
