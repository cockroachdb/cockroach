// Code generated by execgen; DO NOT EDIT.
// Copyright 2019 The Cockroach Authors.
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package colexecbase

import (
	"bytes"
	"context"
	"fmt"
	"math"
	"strings"
	"time"

	"github.com/cockroachdb/apd/v2"
	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexec/colexecutils"
	"github.com/cockroachdb/cockroach/pkg/sql/colexec/execgen"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecop"
	"github.com/cockroachdb/cockroach/pkg/sql/colmem"
	"github.com/cockroachdb/cockroach/pkg/sql/lex"
	"github.com/cockroachdb/cockroach/pkg/sql/rowenc"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/cockroach/pkg/util"
	"github.com/cockroachdb/cockroach/pkg/util/duration"
	"github.com/cockroachdb/cockroach/pkg/util/json"
	"github.com/cockroachdb/cockroach/pkg/util/uuid"
	"github.com/cockroachdb/errors"
	"github.com/lib/pq/oid"
)

// Workaround for bazel auto-generated code. goimports does not automatically
// pick up the right packages when run within the bazel sandbox.
var (
	_ duration.Duration
	_ json.JSON
	_ = lex.DecodeRawBytesToByteArrayAuto
	_ = uuid.FromBytes
	_ = oid.T_name
	_ = util.TruncateString
)

func isIdentityCast(fromType, toType *types.T) bool {
	if fromType.Identical(toType) {
		return true
	}
	if fromType.Family() == types.FloatFamily && toType.Family() == types.FloatFamily {
		// Casts between floats are identical because all floats are represented
		// by float64 physically.
		return true
	}
	if fromType.Family() == types.UuidFamily && toType.Family() == types.BytesFamily {
		// The cast from UUID to Bytes is an identity because we don't need to
		// perform any conversion since both are represented in the same way.
		return true
	}
	return false
}

func GetCastOperator(
	allocator *colmem.Allocator,
	input colexecop.Operator,
	colIdx int,
	resultIdx int,
	fromType *types.T,
	toType *types.T,
	evalCtx *tree.EvalContext,
) (colexecop.Operator, error) {
	input = colexecutils.NewVectorTypeEnforcer(allocator, input, toType, resultIdx)
	base := castOpBase{
		OneInputInitCloserHelper: colexecop.MakeOneInputInitCloserHelper(input),
		allocator:                allocator,
		colIdx:                   colIdx,
		outputIdx:                resultIdx,
		evalCtx:                  evalCtx,
	}
	if fromType.Family() == types.UnknownFamily {
		return &castOpNullAny{castOpBase: base}, nil
	}
	if isIdentityCast(fromType, toType) {
		return &castIdentityOp{castOpBase: base}, nil
	}
	isFromDatum := typeconv.TypeFamilyToCanonicalTypeFamily(fromType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	isToDatum := typeconv.TypeFamilyToCanonicalTypeFamily(toType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	if isFromDatum {
		if isToDatum {
			return &castDatumDatumOp{castOpBase: base}, nil
		}
		switch toType.Family() {
		case types.BoolFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumBoolOp{castOpBase: base}, nil
			}
		case types.IntFamily:
			switch toType.Width() {
			case 16:
				return &castDatumInt2Op{castOpBase: base}, nil
			case 32:
				return &castDatumInt4Op{castOpBase: base}, nil
			case -1:
			default:
				return &castDatumIntOp{castOpBase: base}, nil
			}
		case types.FloatFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumFloatOp{castOpBase: base}, nil
			}
		case types.DecimalFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumDecimalOp{castOpBase: base}, nil
			}
		case types.DateFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumDateOp{castOpBase: base}, nil
			}
		case types.TimestampFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumTimestampOp{castOpBase: base}, nil
			}
		case types.IntervalFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumIntervalOp{castOpBase: base}, nil
			}
		case types.StringFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumStringOp{castOpBase: base}, nil
			}
		case types.BytesFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumBytesOp{castOpBase: base}, nil
			}
		case types.TimestampTZFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumTimestamptzOp{castOpBase: base}, nil
			}
		case types.UuidFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumUuidOp{castOpBase: base}, nil
			}
		case types.JsonFamily:
			switch toType.Width() {
			case -1:
			default:
				return &castDatumJsonbOp{castOpBase: base}, nil
			}
		}
	} else {
		if isToDatum {
			return &castNativeToDatumOp{castOpBase: base}, nil
		}
		switch fromType.Family() {
		case types.BoolFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castBoolFloatOp{castOpBase: base}, nil
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castBoolInt2Op{castOpBase: base}, nil
					case 32:
						return &castBoolInt4Op{castOpBase: base}, nil
					case -1:
					default:
						return &castBoolIntOp{castOpBase: base}, nil
					}
				}
			}
		case types.DecimalFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castDecimalBoolOp{castOpBase: base}, nil
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castDecimalInt2Op{castOpBase: base}, nil
					case 32:
						return &castDecimalInt4Op{castOpBase: base}, nil
					case -1:
					default:
						return &castDecimalIntOp{castOpBase: base}, nil
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castDecimalFloatOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castDecimalDecimalOp{castOpBase: base}, nil
					}
				}
			}
		case types.IntFamily:
			switch fromType.Width() {
			case 16:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 32:
						return &castInt2Int4Op{castOpBase: base}, nil
					case -1:
					default:
						return &castInt2IntOp{castOpBase: base}, nil
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt2BoolOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt2DecimalOp{castOpBase: base}, nil
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt2FloatOp{castOpBase: base}, nil
					}
				}
			case 32:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castInt4Int2Op{castOpBase: base}, nil
					case -1:
					default:
						return &castInt4IntOp{castOpBase: base}, nil
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt4BoolOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt4DecimalOp{castOpBase: base}, nil
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castInt4FloatOp{castOpBase: base}, nil
					}
				}
			case -1:
			default:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castIntInt2Op{castOpBase: base}, nil
					case 32:
						return &castIntInt4Op{castOpBase: base}, nil
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castIntBoolOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castIntDecimalOp{castOpBase: base}, nil
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castIntFloatOp{castOpBase: base}, nil
					}
				}
			}
		case types.FloatFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castFloatBoolOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castFloatDecimalOp{castOpBase: base}, nil
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castFloatInt2Op{castOpBase: base}, nil
					case 32:
						return &castFloatInt4Op{castOpBase: base}, nil
					case -1:
					default:
						return &castFloatIntOp{castOpBase: base}, nil
					}
				}
			}
		case types.DateFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return &castDateInt2Op{castOpBase: base}, nil
					case 32:
						return &castDateInt4Op{castOpBase: base}, nil
					case -1:
					default:
						return &castDateIntOp{castOpBase: base}, nil
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castDateFloatOp{castOpBase: base}, nil
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castDateDecimalOp{castOpBase: base}, nil
					}
				}
			}
		case types.BytesFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.UuidFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castBytesUuidOp{castOpBase: base}, nil
					}
				}
			}
		case types.StringFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castStringBoolOp{castOpBase: base}, nil
					}
				case types.BytesFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castStringBytesOp{castOpBase: base}, nil
					}
				case types.StringFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castStringStringOp{castOpBase: base}, nil
					}
				case types.UuidFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castStringUuidOp{castOpBase: base}, nil
					}
				}
			}
		case types.JsonFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.StringFamily:
					switch toType.Width() {
					case -1:
					default:
						return &castJsonbStringOp{castOpBase: base}, nil
					}
				}
			}
		}
	}
	return nil, errors.Errorf("unhandled cast %s -> %s", fromType.SQLString(), toType.SQLString())
}

func IsCastSupported(fromType, toType *types.T) bool {
	if fromType.Family() == types.UnknownFamily {
		return true
	}
	if isIdentityCast(fromType, toType) {
		return true
	}
	isFromDatum := typeconv.TypeFamilyToCanonicalTypeFamily(fromType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	isToDatum := typeconv.TypeFamilyToCanonicalTypeFamily(toType.Family()) == typeconv.DatumVecCanonicalTypeFamily
	if isFromDatum {
		if isToDatum {
			return true
		}
		switch toType.Family() {
		case types.BoolFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.IntFamily:
			switch toType.Width() {
			case 16:
				return true
			case 32:
				return true
			case -1:
			default:
				return true
			}
		case types.FloatFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.DecimalFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.DateFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.TimestampFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.IntervalFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.StringFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.BytesFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.TimestampTZFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.UuidFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		case types.JsonFamily:
			switch toType.Width() {
			case -1:
			default:
				return true
			}
		}
	} else {
		if isToDatum {
			return true
		}
		switch fromType.Family() {
		case types.BoolFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case 32:
						return true
					case -1:
					default:
						return true
					}
				}
			}
		case types.DecimalFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case 32:
						return true
					case -1:
					default:
						return true
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		case types.IntFamily:
			switch fromType.Width() {
			case 16:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 32:
						return true
					case -1:
					default:
						return true
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			case 32:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case -1:
					default:
						return true
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			case -1:
			default:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case 32:
						return true
					}
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		case types.FloatFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case 32:
						return true
					case -1:
					default:
						return true
					}
				}
			}
		case types.DateFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.IntFamily:
					switch toType.Width() {
					case 16:
						return true
					case 32:
						return true
					case -1:
					default:
						return true
					}
				case types.FloatFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.DecimalFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		case types.BytesFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.UuidFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		case types.StringFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.BoolFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.BytesFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.StringFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				case types.UuidFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		case types.JsonFamily:
			switch fromType.Width() {
			case -1:
			default:
				switch toType.Family() {
				case types.StringFamily:
					switch toType.Width() {
					case -1:
					default:
						return true
					}
				}
			}
		}
	}
	return false
}

type castOpBase struct {
	colexecop.OneInputInitCloserHelper

	allocator *colmem.Allocator
	colIdx    int
	outputIdx int
	evalCtx   *tree.EvalContext
}

func (c *castOpBase) Reset(ctx context.Context) {
	if r, ok := c.Input.(colexecop.Resetter); ok {
		r.Reset(ctx)
	}
}

type castOpNullAny struct {
	castOpBase
}

var _ colexecop.ClosableOperator = &castOpNullAny{}

func (c *castOpNullAny) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	vec := batch.ColVec(c.colIdx)
	projVec := batch.ColVec(c.outputIdx)
	vecNulls := vec.Nulls()
	projNulls := projVec.Nulls()
	if projVec.MaybeHasNulls() {
		// We need to make sure that there are no left over nulls values in the
		// output vector.
		projNulls.UnsetNulls()
	}
	if sel := batch.Selection(); sel != nil {
		sel = sel[:n]
		for _, i := range sel {
			if vecNulls.NullAt(i) {
				projNulls.SetNull(i)
			} else {
				colexecerror.InternalError(errors.Errorf("unexpected non-null at index %d", i))
			}
		}
	} else {
		for i := 0; i < n; i++ {
			if vecNulls.NullAt(i) {
				projNulls.SetNull(i)
			} else {
				colexecerror.InternalError(fmt.Errorf("unexpected non-null at index %d", i))
			}
		}
	}
	return batch
}

// castIdentityOp is a special cast operator for the case when "from" and "to"
// types are identical. The job of this operator is to simply copy the input
// column into the output column, without performing the deselection step. Not
// performing the deselection is justified by the following:
// 1. to be in line with other cast operators
// 2. AND/OR projection operators cannot handle when a different batch is
//    returned than the one they fed into the projection chain (which might
//    contain casts)
// 3. performing the deselection would require copying over all vectors, not
//    just the output one.
// This operator should be planned rarely enough (if ever) to not be very
// important.
type castIdentityOp struct {
	castOpBase
}

var _ colexecop.ClosableOperator = &castIdentityOp{}

func (c *castIdentityOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	projVec := batch.ColVec(c.outputIdx)
	c.allocator.PerformOperation([]coldata.Vec{projVec}, func() {
		maxIdx := n
		if sel := batch.Selection(); sel != nil {
			// We don't want to perform the deselection during copying, so we
			// will copy everything up to (and including) the last selected
			// element, without the selection vector.
			maxIdx = sel[n-1] + 1
		}
		projVec.Copy(coldata.SliceArgs{
			Src:       batch.ColVec(c.colIdx),
			SrcEndIdx: maxIdx,
		})
	})
	return batch
}

type castNativeToDatumOp struct {
	castOpBase

	scratch []tree.Datum
	da      rowenc.DatumAlloc
}

var _ colexecop.ClosableOperator = &castNativeToDatumOp{}

func (c *castNativeToDatumOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	outputCol := outputVec.Datum()
	outputNulls := outputVec.Nulls()
	toType := outputVec.Type()
	c.allocator.PerformOperation([]coldata.Vec{outputVec}, func() {
		if n > c.da.AllocSize {
			c.da.AllocSize = n
		}
		if cap(c.scratch) < n {
			c.scratch = make([]tree.Datum, n)
		} else {
			c.scratch = c.scratch[:n]
		}
		scratch := c.scratch
		sel := batch.Selection()
		colconv.ColVecToDatumAndDeselect(scratch, inputVec, n, sel, &c.da)
		if sel != nil {
			if inputVec.Nulls().MaybeHasNulls() {
				for scratchIdx, outputIdx := range sel[:n] {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						converted := scratch[scratchIdx]
						if true && converted == tree.DNull {
							outputNulls.SetNull(outputIdx)
							continue
						}
						res, err := tree.PerformCast(evalCtx, converted, toType)
						if err != nil {
							colexecerror.ExpectedError(err)
						}
						outputCol.Set(outputIdx, res)
					}
				}
			} else {
				for scratchIdx, outputIdx := range sel[:n] {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						converted := scratch[scratchIdx]
						if false && converted == tree.DNull {
							outputNulls.SetNull(outputIdx)
							continue
						}
						res, err := tree.PerformCast(evalCtx, converted, toType)
						if err != nil {
							colexecerror.ExpectedError(err)
						}
						outputCol.Set(outputIdx, res)
					}
				}
			}
		} else {
			_ = scratch[n-1]
			if inputVec.Nulls().MaybeHasNulls() {
				for idx := 0; idx < n; idx++ {
					{
						var (
							scratchIdx int               = idx
							outputIdx  int               = idx
							evalCtx    *tree.EvalContext = c.evalCtx
						)
						//gcassert:bce
						converted := scratch[scratchIdx]
						if true && converted == tree.DNull {
							outputNulls.SetNull(outputIdx)
							continue
						}
						res, err := tree.PerformCast(evalCtx, converted, toType)
						if err != nil {
							colexecerror.ExpectedError(err)
						}
						outputCol.Set(outputIdx, res)
					}
				}
			} else {
				for idx := 0; idx < n; idx++ {
					{
						var (
							scratchIdx int               = idx
							outputIdx  int               = idx
							evalCtx    *tree.EvalContext = c.evalCtx
						)
						//gcassert:bce
						converted := scratch[scratchIdx]
						if false && converted == tree.DNull {
							outputNulls.SetNull(outputIdx)
							continue
						}
						res, err := tree.PerformCast(evalCtx, converted, toType)
						if err != nil {
							colexecerror.ExpectedError(err)
						}
						outputCol.Set(outputIdx, res)
					}
				}
			}
		}
	})
	return batch
}

// setNativeToDatumCast performs the cast of the converted datum in
// scratch[scratchIdx] to toType and sets the result into position outputIdx of
// outputCol (or into the output nulls bitmap).
// execgen:inline
const _ = "template_setNativeToDatumCast"

type castBoolFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolFloatOp{}
var _ colexecop.ClosableOperator = &castBoolFloatOp{}

func (c *castBoolFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolInt2Op{}
var _ colexecop.ClosableOperator = &castBoolInt2Op{}

func (c *castBoolInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolInt4Op{}
var _ colexecop.ClosableOperator = &castBoolInt4Op{}

func (c *castBoolInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBoolIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBoolIntOp{}
var _ colexecop.ClosableOperator = &castBoolIntOp{}

func (c *castBoolIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bool()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							r = 0
							if v {
								r = 1
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							r = 0
							if v {
								r = 1
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalBoolOp{}
var _ colexecop.ClosableOperator = &castDecimalBoolOp{}

func (c *castDecimalBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool
							r = v.Sign() != 0
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool
							r = v.Sign() != 0
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool
							r = v.Sign() != 0
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool
							r = v.Sign() != 0
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalInt2Op struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalInt2Op{}
var _ colexecop.ClosableOperator = &castDecimalInt2Op{}

func (c *castDecimalInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}

								shifted := _i >> uint(15)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}
								r = int16(_i)

							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}

								shifted := _i >> uint(15)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}
								r = int16(_i)

							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}

								shifted := _i >> uint(15)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}
								r = int16(_i)

							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}

								shifted := _i >> uint(15)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
								}
								r = int16(_i)

							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalInt4Op struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalInt4Op{}
var _ colexecop.ClosableOperator = &castDecimalInt4Op{}

func (c *castDecimalInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}

								shifted := _i >> uint(31)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}
								r = int32(_i)

							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}

								shifted := _i >> uint(31)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}
								r = int32(_i)

							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}

								shifted := _i >> uint(31)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}
								r = int32(_i)

							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}

								shifted := _i >> uint(31)
								if (_i >= 0 && shifted > 0) || (_i < 0 && shifted < -1) {
									colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
								}
								r = int32(_i)

							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalIntOp struct {
	castOpBase

	overloadHelper execgen.OverloadHelper
}

var _ colexecop.ResettableOperator = &castDecimalIntOp{}
var _ colexecop.ClosableOperator = &castDecimalIntOp{}

func (c *castDecimalIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	// In order to inline the templated code of overloads, we need to have a
	// "_overloadHelper" local variable of type "execgen.OverloadHelper".
	_overloadHelper := c.overloadHelper
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrIntOutOfRange)
								}
								r = int64(_i)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrIntOutOfRange)
								}
								r = int64(_i)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrIntOutOfRange)
								}
								r = int64(_i)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								tmpDec := &_overloadHelper.TmpDec1
								_, err := tree.DecimalCtx.RoundToIntegralValue(tmpDec, &v)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								_i, err := tmpDec.Int64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrIntOutOfRange)
								}
								r = int64(_i)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalFloatOp{}
var _ colexecop.ClosableOperator = &castDecimalFloatOp{}

func (c *castDecimalFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								f, err := v.Float64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
								}
								r = f
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								f, err := v.Float64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
								}
								r = f
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								f, err := v.Float64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
								}
								r = f
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								f, err := v.Float64()
								if err != nil {
									colexecerror.ExpectedError(tree.ErrFloatOutOfRange)
								}
								r = f
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDecimalDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDecimalDecimalOp{}
var _ colexecop.ClosableOperator = &castDecimalDecimalOp{}

func (c *castDecimalDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Decimal()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.Set(&v)
							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.Set(&v)
							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.Set(&v)
							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.Set(&v)
							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2Int4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2Int4Op{}
var _ colexecop.ClosableOperator = &castInt2Int4Op{}

func (c *castInt2Int4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32
							r = int32(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32
							r = int32(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32
							r = int32(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32
							r = int32(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2IntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2IntOp{}
var _ colexecop.ClosableOperator = &castInt2IntOp{}

func (c *castInt2IntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2BoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2BoolOp{}
var _ colexecop.ClosableOperator = &castInt2BoolOp{}

func (c *castInt2BoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2DecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2DecimalOp{}
var _ colexecop.ClosableOperator = &castInt2DecimalOp{}

func (c *castInt2DecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt2FloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt2FloatOp{}
var _ colexecop.ClosableOperator = &castInt2FloatOp{}

func (c *castInt2FloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int16()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4Int2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4Int2Op{}
var _ colexecop.ClosableOperator = &castInt4Int2Op{}

func (c *castInt4Int2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4IntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4IntOp{}
var _ colexecop.ClosableOperator = &castInt4IntOp{}

func (c *castInt4IntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4BoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4BoolOp{}
var _ colexecop.ClosableOperator = &castInt4BoolOp{}

func (c *castInt4BoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4DecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4DecimalOp{}
var _ colexecop.ClosableOperator = &castInt4DecimalOp{}

func (c *castInt4DecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castInt4FloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castInt4FloatOp{}
var _ colexecop.ClosableOperator = &castInt4FloatOp{}

func (c *castInt4FloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int32()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntInt2Op{}
var _ colexecop.ClosableOperator = &castIntInt2Op{}

func (c *castIntInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntInt4Op{}
var _ colexecop.ClosableOperator = &castIntInt4Op{}

func (c *castIntInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntBoolOp{}
var _ colexecop.ClosableOperator = &castIntBoolOp{}

func (c *castIntBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntDecimalOp{}
var _ colexecop.ClosableOperator = &castIntDecimalOp{}

func (c *castIntDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castIntFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castIntFloatOp{}
var _ colexecop.ClosableOperator = &castIntFloatOp{}

func (c *castIntFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatBoolOp{}
var _ colexecop.ClosableOperator = &castFloatBoolOp{}

func (c *castFloatBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r bool

							r = v != 0

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatDecimalOp{}
var _ colexecop.ClosableOperator = &castFloatDecimalOp{}

func (c *castFloatDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							if _, err := r.SetFloat64(float64(v)); err != nil {
								colexecerror.ExpectedError(err)
							}

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							if _, err := r.SetFloat64(float64(v)); err != nil {
								colexecerror.ExpectedError(err)
							}

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							if _, err := r.SetFloat64(float64(v)); err != nil {
								colexecerror.ExpectedError(err)
							}

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							if _, err := r.SetFloat64(float64(v)); err != nil {
								colexecerror.ExpectedError(err)
							}

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatInt2Op{}
var _ colexecop.ClosableOperator = &castFloatInt2Op{}

func (c *castFloatInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt16) || v >= float64(math.MaxInt16) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatInt4Op{}
var _ colexecop.ClosableOperator = &castFloatInt4Op{}

func (c *castFloatInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt32) || v >= float64(math.MaxInt32) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castFloatIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castFloatIntOp{}
var _ colexecop.ClosableOperator = &castFloatIntOp{}

func (c *castFloatIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Float64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64

							if math.IsNaN(float64(v)) || v <= float64(math.MinInt64) || v >= float64(math.MaxInt64) {
								colexecerror.ExpectedError(tree.ErrIntOutOfRange)
							}
							r = int64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateInt2Op{}
var _ colexecop.ClosableOperator = &castDateInt2Op{}

func (c *castDateInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int16

							shifted := v >> uint(15)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt2OutOfRange)
							}
							r = int16(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateInt4Op{}
var _ colexecop.ClosableOperator = &castDateInt4Op{}

func (c *castDateInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int32

							shifted := v >> uint(31)
							if (v >= 0 && shifted > 0) || (v < 0 && shifted < -1) {
								colexecerror.ExpectedError(tree.ErrInt4OutOfRange)
							}
							r = int32(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateIntOp{}
var _ colexecop.ClosableOperator = &castDateIntOp{}

func (c *castDateIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r int64
							r = int64(v)
							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateFloatOp{}
var _ colexecop.ClosableOperator = &castDateFloatOp{}

func (c *castDateFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r float64

							r = float64(v)

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDateDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDateDecimalOp{}
var _ colexecop.ClosableOperator = &castDateDecimalOp{}

func (c *castDateDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Int64()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = inputCol.Get(n - 1)
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							//gcassert:bce
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							r.SetInt64(int64(v))

							if err := tree.LimitDecimalWidth(&r, int(toType.Precision()), int(toType.Scale())); err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castBytesUuidOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castBytesUuidOp{}
var _ colexecop.ClosableOperator = &castBytesUuidOp{}

func (c *castBytesUuidOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bytes()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromBytes(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromBytes(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromBytes(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromBytes(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castStringBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castStringBoolOp{}
var _ colexecop.ClosableOperator = &castStringBoolOp{}

func (c *castStringBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bytes()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							var err error
							r, err = tree.ParseBool(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							var err error
							r, err = tree.ParseBool(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							var err error
							r, err = tree.ParseBool(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							var err error
							r, err = tree.ParseBool(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castStringBytesOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castStringBytesOp{}
var _ colexecop.ClosableOperator = &castStringBytesOp{}

func (c *castStringBytesOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bytes()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							var err error
							r, err = lex.DecodeRawBytesToByteArrayAuto(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							var err error
							r, err = lex.DecodeRawBytesToByteArrayAuto(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							var err error
							r, err = lex.DecodeRawBytesToByteArrayAuto(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							var err error
							r, err = lex.DecodeRawBytesToByteArrayAuto(v)
							if err != nil {
								colexecerror.ExpectedError(err)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castStringStringOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castStringStringOp{}
var _ colexecop.ClosableOperator = &castStringStringOp{}

func (c *castStringStringOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bytes()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							if toType.Oid() == oid.T_name {
								// For Names we don't perform the truncation, and there is no need
								// to do anything about the Oids since those are stored in the type.
								r = v
							} else {
								// bpchar types truncate trailing whitespace.
								if toType.Oid() == oid.T_bpchar {
									v = bytes.TrimRight(v, " ")
								}
								// If the string type specifies a limit we truncate to that limit:
								//   'hello'::CHAR(2) -> 'he'
								// This is true of all the string type variants.
								if toType.Width() > 0 {
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), int(toType.Width())))
								}
								if toType.Oid() == oid.T_char {
									// "char" is supposed to truncate long values.
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), 1))
								}
								r = v
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							if toType.Oid() == oid.T_name {
								// For Names we don't perform the truncation, and there is no need
								// to do anything about the Oids since those are stored in the type.
								r = v
							} else {
								// bpchar types truncate trailing whitespace.
								if toType.Oid() == oid.T_bpchar {
									v = bytes.TrimRight(v, " ")
								}
								// If the string type specifies a limit we truncate to that limit:
								//   'hello'::CHAR(2) -> 'he'
								// This is true of all the string type variants.
								if toType.Width() > 0 {
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), int(toType.Width())))
								}
								if toType.Oid() == oid.T_char {
									// "char" is supposed to truncate long values.
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), 1))
								}
								r = v
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							if toType.Oid() == oid.T_name {
								// For Names we don't perform the truncation, and there is no need
								// to do anything about the Oids since those are stored in the type.
								r = v
							} else {
								// bpchar types truncate trailing whitespace.
								if toType.Oid() == oid.T_bpchar {
									v = bytes.TrimRight(v, " ")
								}
								// If the string type specifies a limit we truncate to that limit:
								//   'hello'::CHAR(2) -> 'he'
								// This is true of all the string type variants.
								if toType.Width() > 0 {
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), int(toType.Width())))
								}
								if toType.Oid() == oid.T_char {
									// "char" is supposed to truncate long values.
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), 1))
								}
								r = v
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							if toType.Oid() == oid.T_name {
								// For Names we don't perform the truncation, and there is no need
								// to do anything about the Oids since those are stored in the type.
								r = v
							} else {
								// bpchar types truncate trailing whitespace.
								if toType.Oid() == oid.T_bpchar {
									v = bytes.TrimRight(v, " ")
								}
								// If the string type specifies a limit we truncate to that limit:
								//   'hello'::CHAR(2) -> 'he'
								// This is true of all the string type variants.
								if toType.Width() > 0 {
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), int(toType.Width())))
								}
								if toType.Oid() == oid.T_char {
									// "char" is supposed to truncate long values.
									// TODO(yuzefovich): figure out whether we can avoid converting
									// to a string.
									v = []byte(util.TruncateString(string(v), 1))
								}
								r = v
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castStringUuidOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castStringUuidOp{}
var _ colexecop.ClosableOperator = &castStringUuidOp{}

func (c *castStringUuidOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Bytes()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromString(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromString(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromString(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_uuid, err := uuid.FromString(string(v))
							if err != nil {
								colexecerror.ExpectedError(err)
							}
							r = _uuid.GetBytes()

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castJsonbStringOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castJsonbStringOp{}
var _ colexecop.ClosableOperator = &castJsonbStringOp{}

func (c *castJsonbStringOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.JSON()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_string := v.String()
							switch toType.Oid() {
							case oid.T_char:
								// "char" is supposed to truncate long values.
								_string = util.TruncateString(_string, 1)
							case oid.T_bpchar:
								// bpchar types truncate trailing whitespace.
								_string = strings.TrimRight(_string, " ")
							}
							r = []byte(_string)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_string := v.String()
							switch toType.Oid() {
							case oid.T_char:
								// "char" is supposed to truncate long values.
								_string = util.TruncateString(_string, 1)
							case oid.T_bpchar:
								// bpchar types truncate trailing whitespace.
								_string = strings.TrimRight(_string, " ")
							}
							r = []byte(_string)

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_string := v.String()
							switch toType.Oid() {
							case oid.T_char:
								// "char" is supposed to truncate long values.
								_string = util.TruncateString(_string, 1)
							case oid.T_bpchar:
								// bpchar types truncate trailing whitespace.
								_string = strings.TrimRight(_string, " ")
							}
							r = []byte(_string)

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							_string := v.String()
							switch toType.Oid() {
							case oid.T_char:
								// "char" is supposed to truncate long values.
								_string = util.TruncateString(_string, 1)
							case oid.T_bpchar:
								// bpchar types truncate trailing whitespace.
								_string = strings.TrimRight(_string, " ")
							}
							r = []byte(_string)

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumBoolOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumBoolOp{}
var _ colexecop.ClosableOperator = &castDatumBoolOp{}

func (c *castDatumBoolOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bool()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(bool)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(bool)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(bool)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r bool

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(bool)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumInt2Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumInt2Op{}
var _ colexecop.ClosableOperator = &castDatumInt2Op{}

func (c *castDatumInt2Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int16()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int16)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int16)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int16)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int16

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int16)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumInt4Op struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumInt4Op{}
var _ colexecop.ClosableOperator = &castDatumInt4Op{}

func (c *castDatumInt4Op) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int32()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int32)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int32)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int32)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int32

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int32)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumIntOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumIntOp{}
var _ colexecop.ClosableOperator = &castDatumIntOp{}

func (c *castDatumIntOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumFloatOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumFloatOp{}
var _ colexecop.ClosableOperator = &castDatumFloatOp{}

func (c *castDatumFloatOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Float64()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(float64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(float64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(float64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r float64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(float64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumDecimalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumDecimalOp{}
var _ colexecop.ClosableOperator = &castDatumDecimalOp{}

func (c *castDatumDecimalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Decimal()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(apd.Decimal)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(apd.Decimal)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(apd.Decimal)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r apd.Decimal

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(apd.Decimal)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumDateOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumDateOp{}
var _ colexecop.ClosableOperator = &castDatumDateOp{}

func (c *castDatumDateOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Int64()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r int64

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(int64)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumTimestampOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumTimestampOp{}
var _ colexecop.ClosableOperator = &castDatumTimestampOp{}

func (c *castDatumTimestampOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Timestamp()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumIntervalOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumIntervalOp{}
var _ colexecop.ClosableOperator = &castDatumIntervalOp{}

func (c *castDatumIntervalOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Interval()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r duration.Duration

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(duration.Duration)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r duration.Duration

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(duration.Duration)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r duration.Duration

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(duration.Duration)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r duration.Duration

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(duration.Duration)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumStringOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumStringOp{}
var _ colexecop.ClosableOperator = &castDatumStringOp{}

func (c *castDatumStringOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumBytesOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumBytesOp{}
var _ colexecop.ClosableOperator = &castDatumBytesOp{}

func (c *castDatumBytesOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumTimestamptzOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumTimestamptzOp{}
var _ colexecop.ClosableOperator = &castDatumTimestamptzOp{}

func (c *castDatumTimestamptzOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Timestamp()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						_ = outputCol.Get(n - 1)
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r time.Time

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(time.Time)
							}

							//gcassert:bce
							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumUuidOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumUuidOp{}
var _ colexecop.ClosableOperator = &castDatumUuidOp{}

func (c *castDatumUuidOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Bytes()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r []byte

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).([]byte)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumJsonbOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumJsonbOp{}
var _ colexecop.ClosableOperator = &castDatumJsonbOp{}

func (c *castDatumJsonbOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.JSON()
			outputNulls := outputVec.Nulls()
			converter := colconv.GetDatumToPhysicalFn(toType)
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r json.JSON

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(json.JSON)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r json.JSON

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(json.JSON)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r json.JSON

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(json.JSON)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r json.JSON

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = converter(_castedDatum).(json.JSON)
							}

							outputCol.Set(tupleIdx, r)
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

type castDatumDatumOp struct {
	castOpBase
}

var _ colexecop.ResettableOperator = &castDatumDatumOp{}
var _ colexecop.ClosableOperator = &castDatumDatumOp{}

func (c *castDatumDatumOp) Next() coldata.Batch {
	batch := c.Input.Next()
	n := batch.Length()
	if n == 0 {
		return coldata.ZeroBatch
	}
	sel := batch.Selection()
	inputVec := batch.ColVec(c.colIdx)
	outputVec := batch.ColVec(c.outputIdx)
	toType := outputVec.Type()
	// Remove unused warnings.
	_ = toType
	c.allocator.PerformOperation(
		[]coldata.Vec{outputVec}, func() {
			inputCol := inputVec.Datum()
			inputNulls := inputVec.Nulls()
			outputCol := outputVec.Datum()
			outputNulls := outputVec.Nulls()
			if inputVec.MaybeHasNulls() {
				outputNulls.Copy(inputNulls)
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r interface{}

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = _castedDatum
							}

							outputCol.Set(tupleIdx, r)
							// Casting to datum-backed vector might produce a null value on
							// non-null tuple, so we need to check that case after the cast was
							// performed.
							if r == tree.DNull {
								outputNulls.SetNull(tupleIdx)
							}
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if true && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r interface{}

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = _castedDatum
							}

							outputCol.Set(tupleIdx, r)
							// Casting to datum-backed vector might produce a null value on
							// non-null tuple, so we need to check that case after the cast was
							// performed.
							if r == tree.DNull {
								outputNulls.SetNull(tupleIdx)
							}
						}
					}
				}
			} else {
				// We need to make sure that there are no left over null values
				// in the output vector.
				outputNulls.UnsetNulls()
				if sel != nil {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = sel[i]
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r interface{}

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = _castedDatum
							}

							outputCol.Set(tupleIdx, r)
							// Casting to datum-backed vector might produce a null value on
							// non-null tuple, so we need to check that case after the cast was
							// performed.
							if r == tree.DNull {
								outputNulls.SetNull(tupleIdx)
							}
						}
					}
				} else {
					{
						var evalCtx *tree.EvalContext = c.evalCtx
						// Silence unused warning.
						_ = evalCtx
						var tupleIdx int
						for i := 0; i < n; i++ {
							tupleIdx = i
							if false && inputNulls.NullAt(tupleIdx) {
								continue
							}
							v := inputCol.Get(tupleIdx)
							var r interface{}

							{
								_castedDatum, err := tree.PerformCast(evalCtx, v.(tree.Datum), toType)
								if err != nil {
									colexecerror.ExpectedError(err)
								}
								r = _castedDatum
							}

							outputCol.Set(tupleIdx, r)
							// Casting to datum-backed vector might produce a null value on
							// non-null tuple, so we need to check that case after the cast was
							// performed.
							if r == tree.DNull {
								outputNulls.SetNull(tupleIdx)
							}
						}
					}
				}
			}
			batch.SetLength(n)
		},
	)
	return batch
}

// castTuples casts all non-null tuples from the vector named 'inputCol' to the
// vector named 'outputCol'.
// execgen:inline
const _ = "template_castTuples"

// setNativeToDatumCast performs the cast of the converted datum in
// scratch[scratchIdx] to toType and sets the result into position outputIdx of
// outputCol (or into the output nulls bitmap).
// execgen:inline
const _ = "inlined_setNativeToDatumCast_true_false"

// setNativeToDatumCast performs the cast of the converted datum in
// scratch[scratchIdx] to toType and sets the result into position outputIdx of
// outputCol (or into the output nulls bitmap).
// execgen:inline
const _ = "inlined_setNativeToDatumCast_false_false"

// setNativeToDatumCast performs the cast of the converted datum in
// scratch[scratchIdx] to toType and sets the result into position outputIdx of
// outputCol (or into the output nulls bitmap).
// execgen:inline
const _ = "inlined_setNativeToDatumCast_true_true"

// setNativeToDatumCast performs the cast of the converted datum in
// scratch[scratchIdx] to toType and sets the result into position outputIdx of
// outputCol (or into the output nulls bitmap).
// execgen:inline
const _ = "inlined_setNativeToDatumCast_false_true"

// castTuples casts all non-null tuples from the vector named 'inputCol' to the
// vector named 'outputCol'.
// execgen:inline
const _ = "inlined_castTuples_true_true"

// castTuples casts all non-null tuples from the vector named 'inputCol' to the
// vector named 'outputCol'.
// execgen:inline
const _ = "inlined_castTuples_true_false"

// castTuples casts all non-null tuples from the vector named 'inputCol' to the
// vector named 'outputCol'.
// execgen:inline
const _ = "inlined_castTuples_false_true"

// castTuples casts all non-null tuples from the vector named 'inputCol' to the
// vector named 'outputCol'.
// execgen:inline
const _ = "inlined_castTuples_false_false"
