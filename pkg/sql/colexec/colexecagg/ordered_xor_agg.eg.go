// Code generated by execgen; DO NOT EDIT.
// Copyright 2026 The Cockroach Authors.
//
// Use of this software is governed by the CockroachDB Software License
// included in the /LICENSE file.

package colexecagg

import (
	"unsafe"

	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/colmem"
	"github.com/cockroachdb/cockroach/pkg/sql/pgwire/pgcode"
	"github.com/cockroachdb/cockroach/pkg/sql/pgwire/pgerror"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/errors"
)

// Workaround for bazel auto-generated code. goimports does not automatically
// pick up the right packages when run within the bazel sandbox.
var (
	_ = typeconv.TypeFamilyToCanonicalTypeFamily
	_ pgcode.Code
	_ pgerror.Error
)

const xorNumOverloads = 4

func init() {
	// Sanity check the hard-coded number of overloads.
	var numOverloads int
	numOverloads++
	numOverloads++
	numOverloads++
	numOverloads++
	if numOverloads != xorNumOverloads {
		colexecerror.InternalError(errors.AssertionFailedf(
			"xorNumOverloads should be updated: expected %d, found %d", numOverloads, xorNumOverloads,
		))
	}
}

// xorOverloadOffset returns the offset for this particular type overload
// within contiguous slice of allocators for this aggregate function.
func xorOverloadOffset(t *types.T) int {
	var offset int
	canonicalTypeFamily := typeconv.TypeFamilyToCanonicalTypeFamily(t.Family())
	if canonicalTypeFamily == types.IntFamily {
		if t.Width() == 16 {
			return offset
		}
		offset++
		if t.Width() == 32 {
			return offset
		}
		offset++
		return offset
	}
	offset += 3
	if canonicalTypeFamily == types.BytesFamily {
		return offset
	}
	offset += 1
	colexecerror.InternalError(errors.AssertionFailedf("didn't find overload offset for %s", t.SQLStringForError()))
	return 0
}

func newXorOrderedAggAlloc(
	allocator *colmem.Allocator, t *types.T, allocSize int64,
) (aggregateFuncAlloc, error) {
	allocBase := aggAllocBase{allocator: allocator, allocSize: allocSize}
	switch t.Family() {
	case types.IntFamily:
		switch t.Width() {
		case 16:
			return &xorInt16OrderedAggAlloc{aggAllocBase: allocBase}, nil
		case 32:
			return &xorInt32OrderedAggAlloc{aggAllocBase: allocBase}, nil
		case -1:
		default:
			return &xorInt64OrderedAggAlloc{aggAllocBase: allocBase}, nil
		}
	case types.BytesFamily:
		switch t.Width() {
		case -1:
		default:
			return &xorBytesOrderedAggAlloc{aggAllocBase: allocBase}, nil
		}
	}
	return nil, errors.AssertionFailedf("unsupported xor agg type %s", t.Name())
}

type xorInt16OrderedAgg struct {
	orderedAggregateFuncBase
	// col points to the output vector we are updating.
	col coldata.Int64s
	// curAgg holds the running XOR result, so we can index into the slice once per
	// group, instead of on each iteration.
	curAgg int64
	// numNonNull tracks the number of non-null values we have seen for the group
	// that is currently being aggregated.
	numNonNull uint64
}

var _ AggregateFunc = &xorInt16OrderedAgg{}

func (a *xorInt16OrderedAgg) SetOutput(vec *coldata.Vec) {
	a.orderedAggregateFuncBase.SetOutput(vec)
	a.col = vec.Int64()
}

func (a *xorInt16OrderedAgg) Compute(
	vecs []*coldata.Vec, inputIdxs []uint32, startIdx, endIdx int, sel []int,
) {
	var oldCurAggSize uintptr
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int16(), vec.Nulls()
	a.allocator.PerformOperation([]*coldata.Vec{a.vec}, func() {
		// Capture groups and col to force bounds check to work. See
		// https://github.com/golang/go/issues/39756
		groups := a.groups
		col := col
		if sel == nil {
			_, _ = groups[endIdx-1], groups[startIdx]
			_, _ = col.Get(endIdx-1), col.Get(startIdx)
			if nulls.MaybeHasNulls() {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		} else {
			sel = sel[startIdx:endIdx]
			if nulls.MaybeHasNulls() {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		}
	},
	)
	var newCurAggSize uintptr
	if newCurAggSize != oldCurAggSize {
		a.allocator.AdjustMemoryUsageAfterAllocation(int64(newCurAggSize - oldCurAggSize))
	}
}

func (a *xorInt16OrderedAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should be
	// null.
	// Go around "argument overwritten before first use" linter error.
	_ = outputIdx
	outputIdx = a.curIdx
	a.curIdx++
	col := a.col
	if a.numNonNull == 0 {
		a.nulls.SetNull(outputIdx)
	} else {
		col.Set(outputIdx, a.curAgg)
	}
}

func (a *xorInt16OrderedAgg) Reset() {
	a.orderedAggregateFuncBase.Reset()
	a.curAgg = zeroInt64Value
	a.numNonNull = 0
}

type xorInt16OrderedAggAlloc struct {
	aggAllocBase
	aggFuncs []xorInt16OrderedAgg
}

var _ aggregateFuncAlloc = &xorInt16OrderedAggAlloc{}

const sizeOfXorInt16OrderedAgg = int64(unsafe.Sizeof(xorInt16OrderedAgg{}))
const xorInt16OrderedAggSliceOverhead = int64(unsafe.Sizeof([]xorInt16OrderedAgg{}))

func (a *xorInt16OrderedAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(xorInt16OrderedAggSliceOverhead + sizeOfXorInt16OrderedAgg*a.allocSize)
		a.aggFuncs = make([]xorInt16OrderedAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type xorInt32OrderedAgg struct {
	orderedAggregateFuncBase
	// col points to the output vector we are updating.
	col coldata.Int64s
	// curAgg holds the running XOR result, so we can index into the slice once per
	// group, instead of on each iteration.
	curAgg int64
	// numNonNull tracks the number of non-null values we have seen for the group
	// that is currently being aggregated.
	numNonNull uint64
}

var _ AggregateFunc = &xorInt32OrderedAgg{}

func (a *xorInt32OrderedAgg) SetOutput(vec *coldata.Vec) {
	a.orderedAggregateFuncBase.SetOutput(vec)
	a.col = vec.Int64()
}

func (a *xorInt32OrderedAgg) Compute(
	vecs []*coldata.Vec, inputIdxs []uint32, startIdx, endIdx int, sel []int,
) {
	var oldCurAggSize uintptr
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int32(), vec.Nulls()
	a.allocator.PerformOperation([]*coldata.Vec{a.vec}, func() {
		// Capture groups and col to force bounds check to work. See
		// https://github.com/golang/go/issues/39756
		groups := a.groups
		col := col
		if sel == nil {
			_, _ = groups[endIdx-1], groups[startIdx]
			_, _ = col.Get(endIdx-1), col.Get(startIdx)
			if nulls.MaybeHasNulls() {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		} else {
			sel = sel[startIdx:endIdx]
			if nulls.MaybeHasNulls() {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		}
	},
	)
	var newCurAggSize uintptr
	if newCurAggSize != oldCurAggSize {
		a.allocator.AdjustMemoryUsageAfterAllocation(int64(newCurAggSize - oldCurAggSize))
	}
}

func (a *xorInt32OrderedAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should be
	// null.
	// Go around "argument overwritten before first use" linter error.
	_ = outputIdx
	outputIdx = a.curIdx
	a.curIdx++
	col := a.col
	if a.numNonNull == 0 {
		a.nulls.SetNull(outputIdx)
	} else {
		col.Set(outputIdx, a.curAgg)
	}
}

func (a *xorInt32OrderedAgg) Reset() {
	a.orderedAggregateFuncBase.Reset()
	a.curAgg = zeroInt64Value
	a.numNonNull = 0
}

type xorInt32OrderedAggAlloc struct {
	aggAllocBase
	aggFuncs []xorInt32OrderedAgg
}

var _ aggregateFuncAlloc = &xorInt32OrderedAggAlloc{}

const sizeOfXorInt32OrderedAgg = int64(unsafe.Sizeof(xorInt32OrderedAgg{}))
const xorInt32OrderedAggSliceOverhead = int64(unsafe.Sizeof([]xorInt32OrderedAgg{}))

func (a *xorInt32OrderedAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(xorInt32OrderedAggSliceOverhead + sizeOfXorInt32OrderedAgg*a.allocSize)
		a.aggFuncs = make([]xorInt32OrderedAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type xorInt64OrderedAgg struct {
	orderedAggregateFuncBase
	// col points to the output vector we are updating.
	col coldata.Int64s
	// curAgg holds the running XOR result, so we can index into the slice once per
	// group, instead of on each iteration.
	curAgg int64
	// numNonNull tracks the number of non-null values we have seen for the group
	// that is currently being aggregated.
	numNonNull uint64
}

var _ AggregateFunc = &xorInt64OrderedAgg{}

func (a *xorInt64OrderedAgg) SetOutput(vec *coldata.Vec) {
	a.orderedAggregateFuncBase.SetOutput(vec)
	a.col = vec.Int64()
}

func (a *xorInt64OrderedAgg) Compute(
	vecs []*coldata.Vec, inputIdxs []uint32, startIdx, endIdx int, sel []int,
) {
	var oldCurAggSize uintptr
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int64(), vec.Nulls()
	a.allocator.PerformOperation([]*coldata.Vec{a.vec}, func() {
		// Capture groups and col to force bounds check to work. See
		// https://github.com/golang/go/issues/39756
		groups := a.groups
		col := col
		if sel == nil {
			_, _ = groups[endIdx-1], groups[startIdx]
			_, _ = col.Get(endIdx-1), col.Get(startIdx)
			if nulls.MaybeHasNulls() {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		} else {
			sel = sel[startIdx:endIdx]
			if nulls.MaybeHasNulls() {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			} else {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroInt64Value

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						v := col.Get(i)

						a.curAgg = int64(a.curAgg) ^ int64(v)

						a.numNonNull++
					}
				}
			}
		}
	},
	)
	var newCurAggSize uintptr
	if newCurAggSize != oldCurAggSize {
		a.allocator.AdjustMemoryUsageAfterAllocation(int64(newCurAggSize - oldCurAggSize))
	}
}

func (a *xorInt64OrderedAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should be
	// null.
	// Go around "argument overwritten before first use" linter error.
	_ = outputIdx
	outputIdx = a.curIdx
	a.curIdx++
	col := a.col
	if a.numNonNull == 0 {
		a.nulls.SetNull(outputIdx)
	} else {
		col.Set(outputIdx, a.curAgg)
	}
}

func (a *xorInt64OrderedAgg) Reset() {
	a.orderedAggregateFuncBase.Reset()
	a.curAgg = zeroInt64Value
	a.numNonNull = 0
}

type xorInt64OrderedAggAlloc struct {
	aggAllocBase
	aggFuncs []xorInt64OrderedAgg
}

var _ aggregateFuncAlloc = &xorInt64OrderedAggAlloc{}

const sizeOfXorInt64OrderedAgg = int64(unsafe.Sizeof(xorInt64OrderedAgg{}))
const xorInt64OrderedAggSliceOverhead = int64(unsafe.Sizeof([]xorInt64OrderedAgg{}))

func (a *xorInt64OrderedAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(xorInt64OrderedAggSliceOverhead + sizeOfXorInt64OrderedAgg*a.allocSize)
		a.aggFuncs = make([]xorInt64OrderedAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type xorBytesOrderedAgg struct {
	orderedAggregateFuncBase
	// col points to the output vector we are updating.
	col *coldata.Bytes
	// curAgg holds the running XOR result, so we can index into the slice once per
	// group, instead of on each iteration.
	curAgg []byte
	// numNonNull tracks the number of non-null values we have seen for the group
	// that is currently being aggregated.
	numNonNull uint64
}

var _ AggregateFunc = &xorBytesOrderedAgg{}

func (a *xorBytesOrderedAgg) SetOutput(vec *coldata.Vec) {
	a.orderedAggregateFuncBase.SetOutput(vec)
	a.col = vec.Bytes()
}

func (a *xorBytesOrderedAgg) Compute(
	vecs []*coldata.Vec, inputIdxs []uint32, startIdx, endIdx int, sel []int,
) {
	oldCurAggSize := len(a.curAgg)
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Bytes(), vec.Nulls()
	a.allocator.PerformOperation([]*coldata.Vec{a.vec}, func() {
		// Capture groups and col to force bounds check to work. See
		// https://github.com/golang/go/issues/39756
		groups := a.groups
		col := col
		if sel == nil {
			_, _ = groups[endIdx-1], groups[startIdx]
			_, _ = col.Get(endIdx-1), col.Get(startIdx)
			if nulls.MaybeHasNulls() {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroBytesValue

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						{
							if a.numNonNull == 0 {
								a.curAgg = make([]byte, len(v))
								copy(a.curAgg, v)
							} else {
								if len(a.curAgg) != len(v) {
									colexecerror.ExpectedError(pgerror.Newf(pgcode.InvalidParameterValue,
										"arguments to xor must all be the same length %d vs %d", len(a.curAgg), len(v),
									))
								}
								for j := range a.curAgg {
									a.curAgg[j] = a.curAgg[j] ^ v[j]
								}
							}
						}
						a.numNonNull++
					}
				}
			} else {
				for i := startIdx; i < endIdx; i++ {

					//gcassert:bce
					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroBytesValue

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						//gcassert:bce
						v := col.Get(i)

						{
							if a.numNonNull == 0 {
								a.curAgg = make([]byte, len(v))
								copy(a.curAgg, v)
							} else {
								if len(a.curAgg) != len(v) {
									colexecerror.ExpectedError(pgerror.Newf(pgcode.InvalidParameterValue,
										"arguments to xor must all be the same length %d vs %d", len(a.curAgg), len(v),
									))
								}
								for j := range a.curAgg {
									a.curAgg[j] = a.curAgg[j] ^ v[j]
								}
							}
						}
						a.numNonNull++
					}
				}
			}
		} else {
			sel = sel[startIdx:endIdx]
			if nulls.MaybeHasNulls() {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroBytesValue

							a.numNonNull = 0
						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = nulls.NullAt(i)
					if !isNull {
						v := col.Get(i)

						{
							if a.numNonNull == 0 {
								a.curAgg = make([]byte, len(v))
								copy(a.curAgg, v)
							} else {
								if len(a.curAgg) != len(v) {
									colexecerror.ExpectedError(pgerror.Newf(pgcode.InvalidParameterValue,
										"arguments to xor must all be the same length %d vs %d", len(a.curAgg), len(v),
									))
								}
								for j := range a.curAgg {
									a.curAgg[j] = a.curAgg[j] ^ v[j]
								}
							}
						}
						a.numNonNull++
					}
				}
			} else {
				for _, i := range sel {

					if groups[i] {
						if !a.isFirstGroup {
							// If we encounter a new group, and we haven't found any non-nulls for the
							// current group, the output for this group should be null.
							if a.numNonNull == 0 {
								a.nulls.SetNull(a.curIdx)
							} else {
								a.col.Set(a.curIdx, a.curAgg)
							}
							a.curIdx++
							a.curAgg = zeroBytesValue

						}
						a.isFirstGroup = false
					}

					var isNull bool
					isNull = false
					if !isNull {
						v := col.Get(i)

						{
							if a.numNonNull == 0 {
								a.curAgg = make([]byte, len(v))
								copy(a.curAgg, v)
							} else {
								if len(a.curAgg) != len(v) {
									colexecerror.ExpectedError(pgerror.Newf(pgcode.InvalidParameterValue,
										"arguments to xor must all be the same length %d vs %d", len(a.curAgg), len(v),
									))
								}
								for j := range a.curAgg {
									a.curAgg[j] = a.curAgg[j] ^ v[j]
								}
							}
						}
						a.numNonNull++
					}
				}
			}
		}
	},
	)
	newCurAggSize := len(a.curAgg)
	if newCurAggSize != oldCurAggSize {
		a.allocator.AdjustMemoryUsageAfterAllocation(int64(newCurAggSize - oldCurAggSize))
	}
}

func (a *xorBytesOrderedAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should be
	// null.
	// Go around "argument overwritten before first use" linter error.
	_ = outputIdx
	outputIdx = a.curIdx
	a.curIdx++
	col := a.col
	if a.numNonNull == 0 {
		a.nulls.SetNull(outputIdx)
	} else {
		col.Set(outputIdx, a.curAgg)
	}
}

func (a *xorBytesOrderedAgg) Reset() {
	a.orderedAggregateFuncBase.Reset()
	a.curAgg = zeroBytesValue
	a.numNonNull = 0
}

type xorBytesOrderedAggAlloc struct {
	aggAllocBase
	aggFuncs []xorBytesOrderedAgg
}

var _ aggregateFuncAlloc = &xorBytesOrderedAggAlloc{}

const sizeOfXorBytesOrderedAgg = int64(unsafe.Sizeof(xorBytesOrderedAgg{}))
const xorBytesOrderedAggSliceOverhead = int64(unsafe.Sizeof([]xorBytesOrderedAgg{}))

func (a *xorBytesOrderedAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(xorBytesOrderedAggSliceOverhead + sizeOfXorBytesOrderedAgg*a.allocSize)
		a.aggFuncs = make([]xorBytesOrderedAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}
