// Code generated by execgen; DO NOT EDIT.
// Copyright 2019 The Cockroach Authors.
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package colexecagg

import (
	"bytes"
	"math"
	"time"
	"unsafe"

	"github.com/cockroachdb/apd/v2"
	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/coldataext"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecbase/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/colmem"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/cockroach/pkg/util/duration"
)

// Remove unused warning.
var _ = colexecerror.InternalError

func newMinHashAggAlloc(
	allocator *colmem.Allocator, t *types.T, allocSize int64,
) aggregateFuncAlloc {
	allocBase := aggAllocBase{allocator: allocator, allocSize: allocSize}
	switch typeconv.TypeFamilyToCanonicalTypeFamily(t.Family()) {
	case types.BoolFamily:
		return &minBoolHashAggAlloc{aggAllocBase: allocBase}
	case types.BytesFamily:
		return &minBytesHashAggAlloc{aggAllocBase: allocBase}
	case types.DecimalFamily:
		return &minDecimalHashAggAlloc{aggAllocBase: allocBase}
	case types.IntFamily:
		switch t.Width() {
		case 16:
			return &minInt16HashAggAlloc{aggAllocBase: allocBase}
		case 32:
			return &minInt32HashAggAlloc{aggAllocBase: allocBase}
		default:
			return &minInt64HashAggAlloc{aggAllocBase: allocBase}
		}
	case types.FloatFamily:
		return &minFloat64HashAggAlloc{aggAllocBase: allocBase}
	case types.TimestampTZFamily:
		return &minTimestampHashAggAlloc{aggAllocBase: allocBase}
	case types.IntervalFamily:
		return &minIntervalHashAggAlloc{aggAllocBase: allocBase}
	default:
		return &minDatumHashAggAlloc{aggAllocBase: allocBase}
	}
}

func newMaxHashAggAlloc(
	allocator *colmem.Allocator, t *types.T, allocSize int64,
) aggregateFuncAlloc {
	allocBase := aggAllocBase{allocator: allocator, allocSize: allocSize}
	switch typeconv.TypeFamilyToCanonicalTypeFamily(t.Family()) {
	case types.BoolFamily:
		return &maxBoolHashAggAlloc{aggAllocBase: allocBase}
	case types.BytesFamily:
		return &maxBytesHashAggAlloc{aggAllocBase: allocBase}
	case types.DecimalFamily:
		return &maxDecimalHashAggAlloc{aggAllocBase: allocBase}
	case types.IntFamily:
		switch t.Width() {
		case 16:
			return &maxInt16HashAggAlloc{aggAllocBase: allocBase}
		case 32:
			return &maxInt32HashAggAlloc{aggAllocBase: allocBase}
		default:
			return &maxInt64HashAggAlloc{aggAllocBase: allocBase}
		}
	case types.FloatFamily:
		return &maxFloat64HashAggAlloc{aggAllocBase: allocBase}
	case types.TimestampTZFamily:
		return &maxTimestampHashAggAlloc{aggAllocBase: allocBase}
	case types.IntervalFamily:
		return &maxIntervalHashAggAlloc{aggAllocBase: allocBase}
	default:
		return &maxDatumHashAggAlloc{aggAllocBase: allocBase}
	}
}

type minBoolHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg bool
	// col points to the output vector we are updating.
	col coldata.Bools
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minBoolHashAgg{}

func (a *minBoolHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Bool()
	a.Reset()
}

func (a *minBoolHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minBoolHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Bool(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minBoolHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minBoolHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minBoolHashAgg
}

var _ aggregateFuncAlloc = &minBoolHashAggAlloc{}

const sizeOfminBoolHashAgg = int64(unsafe.Sizeof(minBoolHashAgg{}))
const minBoolHashAggSliceOverhead = int64(unsafe.Sizeof([]minBoolHashAgg{}))

func (a *minBoolHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minBoolHashAggSliceOverhead + sizeOfminBoolHashAgg*a.allocSize)
		a.aggFuncs = make([]minBoolHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minBytesHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg []byte
	// col points to the output vector we are updating.
	col *coldata.Bytes
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minBytesHashAgg{}

func (a *minBytesHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Bytes()
	a.Reset()
}

func (a *minBytesHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minBytesHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	oldCurAggSize := len(a.curAgg)
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Bytes(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			}
		},
	)
	newCurAggSize := len(a.curAgg)
	a.allocator.AdjustMemoryUsage(int64(newCurAggSize - oldCurAggSize))
}

func (a *minBytesHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col.Set(outputIdx, a.curAgg)
	}
	// Release the reference to curAgg eagerly.
	a.allocator.AdjustMemoryUsage(-int64(len(a.curAgg)))
	a.curAgg = nil
}

type minBytesHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minBytesHashAgg
}

var _ aggregateFuncAlloc = &minBytesHashAggAlloc{}

const sizeOfminBytesHashAgg = int64(unsafe.Sizeof(minBytesHashAgg{}))
const minBytesHashAggSliceOverhead = int64(unsafe.Sizeof([]minBytesHashAgg{}))

func (a *minBytesHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minBytesHashAggSliceOverhead + sizeOfminBytesHashAgg*a.allocSize)
		a.aggFuncs = make([]minBytesHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minDecimalHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg apd.Decimal
	// col points to the output vector we are updating.
	col coldata.Decimals
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minDecimalHashAgg{}

func (a *minDecimalHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Decimal()
	a.Reset()
}

func (a *minDecimalHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minDecimalHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Decimal(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minDecimalHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx].Set(&a.curAgg)
	}
}

type minDecimalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minDecimalHashAgg
}

var _ aggregateFuncAlloc = &minDecimalHashAggAlloc{}

const sizeOfminDecimalHashAgg = int64(unsafe.Sizeof(minDecimalHashAgg{}))
const minDecimalHashAggSliceOverhead = int64(unsafe.Sizeof([]minDecimalHashAgg{}))

func (a *minDecimalHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minDecimalHashAggSliceOverhead + sizeOfminDecimalHashAgg*a.allocSize)
		a.aggFuncs = make([]minDecimalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt16HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int16
	// col points to the output vector we are updating.
	col coldata.Int16s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minInt16HashAgg{}

func (a *minInt16HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int16()
	a.Reset()
}

func (a *minInt16HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minInt16HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int16(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt16HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minInt16HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt16HashAgg
}

var _ aggregateFuncAlloc = &minInt16HashAggAlloc{}

const sizeOfminInt16HashAgg = int64(unsafe.Sizeof(minInt16HashAgg{}))
const minInt16HashAggSliceOverhead = int64(unsafe.Sizeof([]minInt16HashAgg{}))

func (a *minInt16HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minInt16HashAggSliceOverhead + sizeOfminInt16HashAgg*a.allocSize)
		a.aggFuncs = make([]minInt16HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt32HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int32
	// col points to the output vector we are updating.
	col coldata.Int32s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minInt32HashAgg{}

func (a *minInt32HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int32()
	a.Reset()
}

func (a *minInt32HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minInt32HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int32(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt32HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minInt32HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt32HashAgg
}

var _ aggregateFuncAlloc = &minInt32HashAggAlloc{}

const sizeOfminInt32HashAgg = int64(unsafe.Sizeof(minInt32HashAgg{}))
const minInt32HashAggSliceOverhead = int64(unsafe.Sizeof([]minInt32HashAgg{}))

func (a *minInt32HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minInt32HashAggSliceOverhead + sizeOfminInt32HashAgg*a.allocSize)
		a.aggFuncs = make([]minInt32HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt64HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minInt64HashAgg{}

func (a *minInt64HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int64()
	a.Reset()
}

func (a *minInt64HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minInt64HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt64HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minInt64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt64HashAgg
}

var _ aggregateFuncAlloc = &minInt64HashAggAlloc{}

const sizeOfminInt64HashAgg = int64(unsafe.Sizeof(minInt64HashAgg{}))
const minInt64HashAggSliceOverhead = int64(unsafe.Sizeof([]minInt64HashAgg{}))

func (a *minInt64HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minInt64HashAggSliceOverhead + sizeOfminInt64HashAgg*a.allocSize)
		a.aggFuncs = make([]minInt64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minFloat64HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg float64
	// col points to the output vector we are updating.
	col coldata.Float64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minFloat64HashAgg{}

func (a *minFloat64HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Float64()
	a.Reset()
}

func (a *minFloat64HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minFloat64HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Float64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minFloat64HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minFloat64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minFloat64HashAgg
}

var _ aggregateFuncAlloc = &minFloat64HashAggAlloc{}

const sizeOfminFloat64HashAgg = int64(unsafe.Sizeof(minFloat64HashAgg{}))
const minFloat64HashAggSliceOverhead = int64(unsafe.Sizeof([]minFloat64HashAgg{}))

func (a *minFloat64HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minFloat64HashAggSliceOverhead + sizeOfminFloat64HashAgg*a.allocSize)
		a.aggFuncs = make([]minFloat64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minTimestampHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg time.Time
	// col points to the output vector we are updating.
	col coldata.Times
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minTimestampHashAgg{}

func (a *minTimestampHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Timestamp()
	a.Reset()
}

func (a *minTimestampHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minTimestampHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Timestamp(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minTimestampHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minTimestampHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minTimestampHashAgg
}

var _ aggregateFuncAlloc = &minTimestampHashAggAlloc{}

const sizeOfminTimestampHashAgg = int64(unsafe.Sizeof(minTimestampHashAgg{}))
const minTimestampHashAggSliceOverhead = int64(unsafe.Sizeof([]minTimestampHashAgg{}))

func (a *minTimestampHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minTimestampHashAggSliceOverhead + sizeOfminTimestampHashAgg*a.allocSize)
		a.aggFuncs = make([]minTimestampHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minIntervalHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg duration.Duration
	// col points to the output vector we are updating.
	col coldata.Durations
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minIntervalHashAgg{}

func (a *minIntervalHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Interval()
	a.Reset()
}

func (a *minIntervalHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minIntervalHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Interval(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minIntervalHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type minIntervalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minIntervalHashAgg
}

var _ aggregateFuncAlloc = &minIntervalHashAggAlloc{}

const sizeOfminIntervalHashAgg = int64(unsafe.Sizeof(minIntervalHashAgg{}))
const minIntervalHashAggSliceOverhead = int64(unsafe.Sizeof([]minIntervalHashAgg{}))

func (a *minIntervalHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minIntervalHashAggSliceOverhead + sizeOfminIntervalHashAgg*a.allocSize)
		a.aggFuncs = make([]minIntervalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minDatumHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg interface{}
	// col points to the output vector we are updating.
	col coldata.DatumVec
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &minDatumHashAgg{}

func (a *minDatumHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Datum()
	a.Reset()
}

func (a *minDatumHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *minDatumHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	var oldCurAggSize uintptr
	if a.curAgg != nil {
		oldCurAggSize = a.curAgg.(*coldataext.Datum).Size()
	}
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Datum(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
	var newCurAggSize uintptr
	if a.curAgg != nil {
		newCurAggSize = a.curAgg.(*coldataext.Datum).Size()
	}
	a.allocator.AdjustMemoryUsage(int64(newCurAggSize - oldCurAggSize))
}

func (a *minDatumHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col.Set(outputIdx, a.curAgg)
	}
	// Release the reference to curAgg eagerly.
	if d, ok := a.curAgg.(*coldataext.Datum); ok {
		a.allocator.AdjustMemoryUsage(-int64(d.Size()))
	}
	a.curAgg = nil
}

type minDatumHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minDatumHashAgg
}

var _ aggregateFuncAlloc = &minDatumHashAggAlloc{}

const sizeOfminDatumHashAgg = int64(unsafe.Sizeof(minDatumHashAgg{}))
const minDatumHashAggSliceOverhead = int64(unsafe.Sizeof([]minDatumHashAgg{}))

func (a *minDatumHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(minDatumHashAggSliceOverhead + sizeOfminDatumHashAgg*a.allocSize)
		a.aggFuncs = make([]minDatumHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxBoolHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg bool
	// col points to the output vector we are updating.
	col coldata.Bools
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxBoolHashAgg{}

func (a *maxBoolHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Bool()
	a.Reset()
}

func (a *maxBoolHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxBoolHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Bool(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxBoolHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxBoolHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxBoolHashAgg
}

var _ aggregateFuncAlloc = &maxBoolHashAggAlloc{}

const sizeOfmaxBoolHashAgg = int64(unsafe.Sizeof(maxBoolHashAgg{}))
const maxBoolHashAggSliceOverhead = int64(unsafe.Sizeof([]maxBoolHashAgg{}))

func (a *maxBoolHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxBoolHashAggSliceOverhead + sizeOfmaxBoolHashAgg*a.allocSize)
		a.aggFuncs = make([]maxBoolHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxBytesHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg []byte
	// col points to the output vector we are updating.
	col *coldata.Bytes
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxBytesHashAgg{}

func (a *maxBytesHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Bytes()
	a.Reset()
}

func (a *maxBytesHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxBytesHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	oldCurAggSize := len(a.curAgg)
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Bytes(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			}
		},
	)
	newCurAggSize := len(a.curAgg)
	a.allocator.AdjustMemoryUsage(int64(newCurAggSize - oldCurAggSize))
}

func (a *maxBytesHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col.Set(outputIdx, a.curAgg)
	}
	// Release the reference to curAgg eagerly.
	a.allocator.AdjustMemoryUsage(-int64(len(a.curAgg)))
	a.curAgg = nil
}

type maxBytesHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxBytesHashAgg
}

var _ aggregateFuncAlloc = &maxBytesHashAggAlloc{}

const sizeOfmaxBytesHashAgg = int64(unsafe.Sizeof(maxBytesHashAgg{}))
const maxBytesHashAggSliceOverhead = int64(unsafe.Sizeof([]maxBytesHashAgg{}))

func (a *maxBytesHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxBytesHashAggSliceOverhead + sizeOfmaxBytesHashAgg*a.allocSize)
		a.aggFuncs = make([]maxBytesHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxDecimalHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg apd.Decimal
	// col points to the output vector we are updating.
	col coldata.Decimals
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxDecimalHashAgg{}

func (a *maxDecimalHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Decimal()
	a.Reset()
}

func (a *maxDecimalHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxDecimalHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Decimal(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxDecimalHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx].Set(&a.curAgg)
	}
}

type maxDecimalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxDecimalHashAgg
}

var _ aggregateFuncAlloc = &maxDecimalHashAggAlloc{}

const sizeOfmaxDecimalHashAgg = int64(unsafe.Sizeof(maxDecimalHashAgg{}))
const maxDecimalHashAggSliceOverhead = int64(unsafe.Sizeof([]maxDecimalHashAgg{}))

func (a *maxDecimalHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxDecimalHashAggSliceOverhead + sizeOfmaxDecimalHashAgg*a.allocSize)
		a.aggFuncs = make([]maxDecimalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt16HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int16
	// col points to the output vector we are updating.
	col coldata.Int16s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxInt16HashAgg{}

func (a *maxInt16HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int16()
	a.Reset()
}

func (a *maxInt16HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxInt16HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int16(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt16HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxInt16HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt16HashAgg
}

var _ aggregateFuncAlloc = &maxInt16HashAggAlloc{}

const sizeOfmaxInt16HashAgg = int64(unsafe.Sizeof(maxInt16HashAgg{}))
const maxInt16HashAggSliceOverhead = int64(unsafe.Sizeof([]maxInt16HashAgg{}))

func (a *maxInt16HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxInt16HashAggSliceOverhead + sizeOfmaxInt16HashAgg*a.allocSize)
		a.aggFuncs = make([]maxInt16HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt32HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int32
	// col points to the output vector we are updating.
	col coldata.Int32s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxInt32HashAgg{}

func (a *maxInt32HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int32()
	a.Reset()
}

func (a *maxInt32HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxInt32HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int32(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt32HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxInt32HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt32HashAgg
}

var _ aggregateFuncAlloc = &maxInt32HashAggAlloc{}

const sizeOfmaxInt32HashAgg = int64(unsafe.Sizeof(maxInt32HashAgg{}))
const maxInt32HashAggSliceOverhead = int64(unsafe.Sizeof([]maxInt32HashAgg{}))

func (a *maxInt32HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxInt32HashAggSliceOverhead + sizeOfmaxInt32HashAgg*a.allocSize)
		a.aggFuncs = make([]maxInt32HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt64HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxInt64HashAgg{}

func (a *maxInt64HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Int64()
	a.Reset()
}

func (a *maxInt64HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxInt64HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Int64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt64HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxInt64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt64HashAgg
}

var _ aggregateFuncAlloc = &maxInt64HashAggAlloc{}

const sizeOfmaxInt64HashAgg = int64(unsafe.Sizeof(maxInt64HashAgg{}))
const maxInt64HashAggSliceOverhead = int64(unsafe.Sizeof([]maxInt64HashAgg{}))

func (a *maxInt64HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxInt64HashAggSliceOverhead + sizeOfmaxInt64HashAgg*a.allocSize)
		a.aggFuncs = make([]maxInt64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxFloat64HashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg float64
	// col points to the output vector we are updating.
	col coldata.Float64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxFloat64HashAgg{}

func (a *maxFloat64HashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Float64()
	a.Reset()
}

func (a *maxFloat64HashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxFloat64HashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Float64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxFloat64HashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxFloat64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxFloat64HashAgg
}

var _ aggregateFuncAlloc = &maxFloat64HashAggAlloc{}

const sizeOfmaxFloat64HashAgg = int64(unsafe.Sizeof(maxFloat64HashAgg{}))
const maxFloat64HashAggSliceOverhead = int64(unsafe.Sizeof([]maxFloat64HashAgg{}))

func (a *maxFloat64HashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxFloat64HashAggSliceOverhead + sizeOfmaxFloat64HashAgg*a.allocSize)
		a.aggFuncs = make([]maxFloat64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxTimestampHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg time.Time
	// col points to the output vector we are updating.
	col coldata.Times
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxTimestampHashAgg{}

func (a *maxTimestampHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Timestamp()
	a.Reset()
}

func (a *maxTimestampHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxTimestampHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Timestamp(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxTimestampHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxTimestampHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxTimestampHashAgg
}

var _ aggregateFuncAlloc = &maxTimestampHashAggAlloc{}

const sizeOfmaxTimestampHashAgg = int64(unsafe.Sizeof(maxTimestampHashAgg{}))
const maxTimestampHashAggSliceOverhead = int64(unsafe.Sizeof([]maxTimestampHashAgg{}))

func (a *maxTimestampHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxTimestampHashAggSliceOverhead + sizeOfmaxTimestampHashAgg*a.allocSize)
		a.aggFuncs = make([]maxTimestampHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxIntervalHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg duration.Duration
	// col points to the output vector we are updating.
	col coldata.Durations
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxIntervalHashAgg{}

func (a *maxIntervalHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Interval()
	a.Reset()
}

func (a *maxIntervalHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxIntervalHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Interval(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxIntervalHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col[outputIdx] = a.curAgg
	}
}

type maxIntervalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxIntervalHashAgg
}

var _ aggregateFuncAlloc = &maxIntervalHashAggAlloc{}

const sizeOfmaxIntervalHashAgg = int64(unsafe.Sizeof(maxIntervalHashAgg{}))
const maxIntervalHashAggSliceOverhead = int64(unsafe.Sizeof([]maxIntervalHashAgg{}))

func (a *maxIntervalHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxIntervalHashAggSliceOverhead + sizeOfmaxIntervalHashAgg*a.allocSize)
		a.aggFuncs = make([]maxIntervalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxDatumHashAgg struct {
	hashAggregateFuncBase
	allocator *colmem.Allocator
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg interface{}
	// col points to the output vector we are updating.
	col coldata.DatumVec
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ AggregateFunc = &maxDatumHashAgg{}

func (a *maxDatumHashAgg) Init(groups []bool, vec coldata.Vec) {
	a.hashAggregateFuncBase.Init(groups, vec)
	a.vec = vec
	a.col = vec.Datum()
	a.Reset()
}

func (a *maxDatumHashAgg) Reset() {
	a.hashAggregateFuncBase.Reset()
	a.foundNonNullForCurrentGroup = false
}

func (a *maxDatumHashAgg) Compute(
	vecs []coldata.Vec, inputIdxs []uint32, inputLen int, sel []int,
) {
	var oldCurAggSize uintptr
	if a.curAgg != nil {
		oldCurAggSize = a.curAgg.(*coldataext.Datum).Size()
	}
	vec := vecs[inputIdxs[0]]
	col, nulls := vec.Datum(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			{
				sel = sel[:inputLen]
				if nulls.MaybeHasNulls() {
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
	var newCurAggSize uintptr
	if a.curAgg != nil {
		newCurAggSize = a.curAgg.(*coldataext.Datum).Size()
	}
	a.allocator.AdjustMemoryUsage(int64(newCurAggSize - oldCurAggSize))
}

func (a *maxDatumHashAgg) Flush(outputIdx int) {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(outputIdx)
	} else {
		a.col.Set(outputIdx, a.curAgg)
	}
	// Release the reference to curAgg eagerly.
	if d, ok := a.curAgg.(*coldataext.Datum); ok {
		a.allocator.AdjustMemoryUsage(-int64(d.Size()))
	}
	a.curAgg = nil
}

type maxDatumHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxDatumHashAgg
}

var _ aggregateFuncAlloc = &maxDatumHashAggAlloc{}

const sizeOfmaxDatumHashAgg = int64(unsafe.Sizeof(maxDatumHashAgg{}))
const maxDatumHashAggSliceOverhead = int64(unsafe.Sizeof([]maxDatumHashAgg{}))

func (a *maxDatumHashAggAlloc) newAggFunc() AggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(maxDatumHashAggSliceOverhead + sizeOfmaxDatumHashAgg*a.allocSize)
		a.aggFuncs = make([]maxDatumHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}
