// Code generated by execgen; DO NOT EDIT.
// Copyright 2019 The Cockroach Authors.
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package colexec

import (
	"bytes"
	"math"
	"time"
	"unsafe"

	"github.com/cockroachdb/apd/v2"
	"github.com/cockroachdb/cockroach/pkg/col/coldata"
	"github.com/cockroachdb/cockroach/pkg/col/coldataext"
	"github.com/cockroachdb/cockroach/pkg/col/typeconv"
	"github.com/cockroachdb/cockroach/pkg/sql/colexecbase/colexecerror"
	"github.com/cockroachdb/cockroach/pkg/sql/colmem"
	"github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	"github.com/cockroachdb/cockroach/pkg/sql/types"
	"github.com/cockroachdb/cockroach/pkg/util/duration"
)

// Remove unused warning.
var _ = colexecerror.InternalError

func newMinHashAggAlloc(
	allocator *colmem.Allocator, t *types.T, allocSize int64,
) aggregateFuncAlloc {
	allocBase := aggAllocBase{allocator: allocator, allocSize: allocSize}
	switch typeconv.TypeFamilyToCanonicalTypeFamily(t.Family()) {
	case types.BoolFamily:
		return &minBoolHashAggAlloc{aggAllocBase: allocBase}
	case types.BytesFamily:
		return &minBytesHashAggAlloc{aggAllocBase: allocBase}
	case types.DecimalFamily:
		return &minDecimalHashAggAlloc{aggAllocBase: allocBase}
	case types.IntFamily:
		switch t.Width() {
		case 16:
			return &minInt16HashAggAlloc{aggAllocBase: allocBase}
		case 32:
			return &minInt32HashAggAlloc{aggAllocBase: allocBase}
		default:
			return &minInt64HashAggAlloc{aggAllocBase: allocBase}
		}
	case types.FloatFamily:
		return &minFloat64HashAggAlloc{aggAllocBase: allocBase}
	case types.TimestampTZFamily:
		return &minTimestampHashAggAlloc{aggAllocBase: allocBase}
	case types.IntervalFamily:
		return &minIntervalHashAggAlloc{aggAllocBase: allocBase}
	default:
		return &minDatumHashAggAlloc{aggAllocBase: allocBase}
	}
}

func newMaxHashAggAlloc(
	allocator *colmem.Allocator, t *types.T, allocSize int64,
) aggregateFuncAlloc {
	allocBase := aggAllocBase{allocator: allocator, allocSize: allocSize}
	switch typeconv.TypeFamilyToCanonicalTypeFamily(t.Family()) {
	case types.BoolFamily:
		return &maxBoolHashAggAlloc{aggAllocBase: allocBase}
	case types.BytesFamily:
		return &maxBytesHashAggAlloc{aggAllocBase: allocBase}
	case types.DecimalFamily:
		return &maxDecimalHashAggAlloc{aggAllocBase: allocBase}
	case types.IntFamily:
		switch t.Width() {
		case 16:
			return &maxInt16HashAggAlloc{aggAllocBase: allocBase}
		case 32:
			return &maxInt32HashAggAlloc{aggAllocBase: allocBase}
		default:
			return &maxInt64HashAggAlloc{aggAllocBase: allocBase}
		}
	case types.FloatFamily:
		return &maxFloat64HashAggAlloc{aggAllocBase: allocBase}
	case types.TimestampTZFamily:
		return &maxTimestampHashAggAlloc{aggAllocBase: allocBase}
	case types.IntervalFamily:
		return &maxIntervalHashAggAlloc{aggAllocBase: allocBase}
	default:
		return &maxDatumHashAggAlloc{aggAllocBase: allocBase}
	}
}

type minBoolHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg bool
	// col points to the output vector we are updating.
	col coldata.Bools
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minBoolHashAgg{}

const sizeOfminBoolHashAgg = int64(unsafe.Sizeof(minBoolHashAgg{}))

func (a *minBoolHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Bool()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minBoolHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minBoolHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minBoolHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minBoolHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Bool(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minBoolHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minBoolHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minBoolHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minBoolHashAgg
}

var _ aggregateFuncAlloc = &minBoolHashAggAlloc{}

func (a *minBoolHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminBoolHashAgg * a.allocSize)
		a.aggFuncs = make([]minBoolHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minBytesHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg []byte
	// col points to the output vector we are updating.
	col *coldata.Bytes
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minBytesHashAgg{}

const sizeOfminBytesHashAgg = int64(unsafe.Sizeof(minBytesHashAgg{}))

func (a *minBytesHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Bytes()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minBytesHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minBytesHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minBytesHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minBytesHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Bytes(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					col = col
					_ = 0
					_ = inputLen
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					col = col
					_ = 0
					_ = inputLen
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minBytesHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col.Set(a.curIdx, a.curAgg)
	}
	a.curIdx++
}

func (a *minBytesHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minBytesHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minBytesHashAgg
}

var _ aggregateFuncAlloc = &minBytesHashAggAlloc{}

func (a *minBytesHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminBytesHashAgg * a.allocSize)
		a.aggFuncs = make([]minBytesHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minDecimalHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg apd.Decimal
	// col points to the output vector we are updating.
	col coldata.Decimals
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minDecimalHashAgg{}

const sizeOfminDecimalHashAgg = int64(unsafe.Sizeof(minDecimalHashAgg{}))

func (a *minDecimalHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Decimal()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minDecimalHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minDecimalHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minDecimalHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minDecimalHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Decimal(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minDecimalHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx].Set(&a.curAgg)
	}
	a.curIdx++
}

func (a *minDecimalHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minDecimalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minDecimalHashAgg
}

var _ aggregateFuncAlloc = &minDecimalHashAggAlloc{}

func (a *minDecimalHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminDecimalHashAgg * a.allocSize)
		a.aggFuncs = make([]minDecimalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt16HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minInt16HashAgg{}

const sizeOfminInt16HashAgg = int64(unsafe.Sizeof(minInt16HashAgg{}))

func (a *minInt16HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minInt16HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minInt16HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minInt16HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minInt16HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int16(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt16HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minInt16HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minInt16HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt16HashAgg
}

var _ aggregateFuncAlloc = &minInt16HashAggAlloc{}

func (a *minInt16HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminInt16HashAgg * a.allocSize)
		a.aggFuncs = make([]minInt16HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt32HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minInt32HashAgg{}

const sizeOfminInt32HashAgg = int64(unsafe.Sizeof(minInt32HashAgg{}))

func (a *minInt32HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minInt32HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minInt32HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minInt32HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minInt32HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int32(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt32HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minInt32HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minInt32HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt32HashAgg
}

var _ aggregateFuncAlloc = &minInt32HashAggAlloc{}

func (a *minInt32HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminInt32HashAgg * a.allocSize)
		a.aggFuncs = make([]minInt32HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minInt64HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minInt64HashAgg{}

const sizeOfminInt64HashAgg = int64(unsafe.Sizeof(minInt64HashAgg{}))

func (a *minInt64HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minInt64HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minInt64HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minInt64HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minInt64HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minInt64HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minInt64HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minInt64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minInt64HashAgg
}

var _ aggregateFuncAlloc = &minInt64HashAggAlloc{}

func (a *minInt64HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminInt64HashAgg * a.allocSize)
		a.aggFuncs = make([]minInt64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minFloat64HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg float64
	// col points to the output vector we are updating.
	col coldata.Float64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minFloat64HashAgg{}

const sizeOfminFloat64HashAgg = int64(unsafe.Sizeof(minFloat64HashAgg{}))

func (a *minFloat64HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Float64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minFloat64HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minFloat64HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minFloat64HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minFloat64HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Float64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minFloat64HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minFloat64HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minFloat64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []minFloat64HashAgg
}

var _ aggregateFuncAlloc = &minFloat64HashAggAlloc{}

func (a *minFloat64HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminFloat64HashAgg * a.allocSize)
		a.aggFuncs = make([]minFloat64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minTimestampHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg time.Time
	// col points to the output vector we are updating.
	col coldata.Times
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minTimestampHashAgg{}

const sizeOfminTimestampHashAgg = int64(unsafe.Sizeof(minTimestampHashAgg{}))

func (a *minTimestampHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Timestamp()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minTimestampHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minTimestampHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minTimestampHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minTimestampHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Timestamp(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minTimestampHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minTimestampHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minTimestampHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minTimestampHashAgg
}

var _ aggregateFuncAlloc = &minTimestampHashAggAlloc{}

func (a *minTimestampHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminTimestampHashAgg * a.allocSize)
		a.aggFuncs = make([]minTimestampHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minIntervalHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg duration.Duration
	// col points to the output vector we are updating.
	col coldata.Durations
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minIntervalHashAgg{}

const sizeOfminIntervalHashAgg = int64(unsafe.Sizeof(minIntervalHashAgg{}))

func (a *minIntervalHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Interval()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minIntervalHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minIntervalHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minIntervalHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minIntervalHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Interval(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minIntervalHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *minIntervalHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minIntervalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minIntervalHashAgg
}

var _ aggregateFuncAlloc = &minIntervalHashAggAlloc{}

func (a *minIntervalHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminIntervalHashAgg * a.allocSize)
		a.aggFuncs = make([]minIntervalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type minDatumHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg interface{}
	// col points to the output vector we are updating.
	col coldata.DatumVec
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &minDatumHashAgg{}

const sizeOfminDatumHashAgg = int64(unsafe.Sizeof(minDatumHashAgg{}))

func (a *minDatumHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Datum()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *minDatumHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *minDatumHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *minDatumHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *minDatumHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Datum(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col.Slice(0, inputLen)
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col.Slice(0, inputLen)
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult < 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *minDatumHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col.Set(a.curIdx, a.curAgg)
	}
	a.curIdx++
}

func (a *minDatumHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type minDatumHashAggAlloc struct {
	aggAllocBase
	aggFuncs []minDatumHashAgg
}

var _ aggregateFuncAlloc = &minDatumHashAggAlloc{}

func (a *minDatumHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfminDatumHashAgg * a.allocSize)
		a.aggFuncs = make([]minDatumHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxBoolHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg bool
	// col points to the output vector we are updating.
	col coldata.Bools
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxBoolHashAgg{}

const sizeOfmaxBoolHashAgg = int64(unsafe.Sizeof(maxBoolHashAgg{}))

func (a *maxBoolHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Bool()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxBoolHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxBoolHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxBoolHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxBoolHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Bool(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if !candidate && a.curAgg {
										cmpResult = -1
									} else if candidate && !a.curAgg {
										cmpResult = 1
									} else {
										cmpResult = 0
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxBoolHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxBoolHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxBoolHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxBoolHashAgg
}

var _ aggregateFuncAlloc = &maxBoolHashAggAlloc{}

func (a *maxBoolHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxBoolHashAgg * a.allocSize)
		a.aggFuncs = make([]maxBoolHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxBytesHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg []byte
	// col points to the output vector we are updating.
	col *coldata.Bytes
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxBytesHashAgg{}

const sizeOfmaxBytesHashAgg = int64(unsafe.Sizeof(maxBytesHashAgg{}))

func (a *maxBytesHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Bytes()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxBytesHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxBytesHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxBytesHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxBytesHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Bytes(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					col = col
					_ = 0
					_ = inputLen
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				} else {
					col = col
					_ = 0
					_ = inputLen
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = append(a.curAgg[:0], val...)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = bytes.Compare(candidate, a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = append(a.curAgg[:0], candidate...)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxBytesHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col.Set(a.curIdx, a.curAgg)
	}
	a.curIdx++
}

func (a *maxBytesHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxBytesHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxBytesHashAgg
}

var _ aggregateFuncAlloc = &maxBytesHashAggAlloc{}

func (a *maxBytesHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxBytesHashAgg * a.allocSize)
		a.aggFuncs = make([]maxBytesHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxDecimalHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg apd.Decimal
	// col points to the output vector we are updating.
	col coldata.Decimals
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxDecimalHashAgg{}

const sizeOfmaxDecimalHashAgg = int64(unsafe.Sizeof(maxDecimalHashAgg{}))

func (a *maxDecimalHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Decimal()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxDecimalHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxDecimalHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxDecimalHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxDecimalHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Decimal(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg.Set(&val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = tree.CompareDecimals(&candidate, &a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg.Set(&candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxDecimalHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx].Set(&a.curAgg)
	}
	a.curIdx++
}

func (a *maxDecimalHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxDecimalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxDecimalHashAgg
}

var _ aggregateFuncAlloc = &maxDecimalHashAggAlloc{}

func (a *maxDecimalHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxDecimalHashAgg * a.allocSize)
		a.aggFuncs = make([]maxDecimalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt16HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxInt16HashAgg{}

const sizeOfmaxInt16HashAgg = int64(unsafe.Sizeof(maxInt16HashAgg{}))

func (a *maxInt16HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxInt16HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxInt16HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxInt16HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxInt16HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int16(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt16HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxInt16HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxInt16HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt16HashAgg
}

var _ aggregateFuncAlloc = &maxInt16HashAggAlloc{}

func (a *maxInt16HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxInt16HashAgg * a.allocSize)
		a.aggFuncs = make([]maxInt16HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt32HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxInt32HashAgg{}

const sizeOfmaxInt32HashAgg = int64(unsafe.Sizeof(maxInt32HashAgg{}))

func (a *maxInt32HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxInt32HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxInt32HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxInt32HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxInt32HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int32(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt32HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxInt32HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxInt32HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt32HashAgg
}

var _ aggregateFuncAlloc = &maxInt32HashAggAlloc{}

func (a *maxInt32HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxInt32HashAgg * a.allocSize)
		a.aggFuncs = make([]maxInt32HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxInt64HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg int64
	// col points to the output vector we are updating.
	col coldata.Int64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxInt64HashAgg{}

const sizeOfmaxInt64HashAgg = int64(unsafe.Sizeof(maxInt64HashAgg{}))

func (a *maxInt64HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Int64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxInt64HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxInt64HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxInt64HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxInt64HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Int64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = int64(val)
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := int64(candidate), int64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else {
											cmpResult = 0
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = int64(candidate)
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxInt64HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxInt64HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxInt64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxInt64HashAgg
}

var _ aggregateFuncAlloc = &maxInt64HashAggAlloc{}

func (a *maxInt64HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxInt64HashAgg * a.allocSize)
		a.aggFuncs = make([]maxInt64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxFloat64HashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg float64
	// col points to the output vector we are updating.
	col coldata.Float64s
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxFloat64HashAgg{}

const sizeOfmaxFloat64HashAgg = int64(unsafe.Sizeof(maxFloat64HashAgg{}))

func (a *maxFloat64HashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Float64()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxFloat64HashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxFloat64HashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxFloat64HashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxFloat64HashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Float64(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									{
										a, b := float64(candidate), float64(a.curAgg)
										if a < b {
											cmpResult = -1
										} else if a > b {
											cmpResult = 1
										} else if a == b {
											cmpResult = 0
										} else if math.IsNaN(a) {
											if math.IsNaN(b) {
												cmpResult = 0
											} else {
												cmpResult = -1
											}
										} else {
											cmpResult = 1
										}
									}

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxFloat64HashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxFloat64HashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxFloat64HashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxFloat64HashAgg
}

var _ aggregateFuncAlloc = &maxFloat64HashAggAlloc{}

func (a *maxFloat64HashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxFloat64HashAgg * a.allocSize)
		a.aggFuncs = make([]maxFloat64HashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxTimestampHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg time.Time
	// col points to the output vector we are updating.
	col coldata.Times
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxTimestampHashAgg{}

const sizeOfmaxTimestampHashAgg = int64(unsafe.Sizeof(maxTimestampHashAgg{}))

func (a *maxTimestampHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Timestamp()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxTimestampHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxTimestampHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxTimestampHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxTimestampHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Timestamp(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int

									if candidate.Before(a.curAgg) {
										cmpResult = -1
									} else if a.curAgg.Before(candidate) {
										cmpResult = 1
									} else {
										cmpResult = 0
									}
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxTimestampHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxTimestampHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxTimestampHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxTimestampHashAgg
}

var _ aggregateFuncAlloc = &maxTimestampHashAggAlloc{}

func (a *maxTimestampHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxTimestampHashAgg * a.allocSize)
		a.aggFuncs = make([]maxTimestampHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxIntervalHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg duration.Duration
	// col points to the output vector we are updating.
	col coldata.Durations
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxIntervalHashAgg{}

const sizeOfmaxIntervalHashAgg = int64(unsafe.Sizeof(maxIntervalHashAgg{}))

func (a *maxIntervalHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Interval()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxIntervalHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxIntervalHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxIntervalHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxIntervalHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Interval(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col[0:inputLen]
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i) //gcassert:inline
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i) //gcassert:inline

								{
									var cmpResult int
									cmpResult = candidate.Compare(a.curAgg)
									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxIntervalHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col[a.curIdx] = a.curAgg
	}
	a.curIdx++
}

func (a *maxIntervalHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxIntervalHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxIntervalHashAgg
}

var _ aggregateFuncAlloc = &maxIntervalHashAggAlloc{}

func (a *maxIntervalHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxIntervalHashAgg * a.allocSize)
		a.aggFuncs = make([]maxIntervalHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}

type maxDatumHashAgg struct {
	allocator *colmem.Allocator
	curIdx    int
	// curAgg holds the running min/max, so we can index into the slice once per
	// group, instead of on each iteration.
	// NOTE: if foundNonNullForCurrentGroup is false, curAgg is undefined.
	curAgg interface{}
	// col points to the output vector we are updating.
	col coldata.DatumVec
	// vec is the same as col before conversion from coldata.Vec.
	vec coldata.Vec
	// nulls points to the output null vector that we are updating.
	nulls *coldata.Nulls
	// foundNonNullForCurrentGroup tracks if we have seen any non-null values
	// for the group that is currently being aggregated.
	foundNonNullForCurrentGroup bool
}

var _ aggregateFunc = &maxDatumHashAgg{}

const sizeOfmaxDatumHashAgg = int64(unsafe.Sizeof(maxDatumHashAgg{}))

func (a *maxDatumHashAgg) Init(groups []bool, v coldata.Vec) {
	a.vec = v
	a.col = v.Datum()
	a.nulls = v.Nulls()
	a.Reset()
}

func (a *maxDatumHashAgg) Reset() {
	a.curIdx = 0
	a.foundNonNullForCurrentGroup = false
	a.nulls.UnsetNulls()
}

func (a *maxDatumHashAgg) CurrentOutputIndex() int {
	return a.curIdx
}

func (a *maxDatumHashAgg) SetOutputIndex(idx int) {
	a.curIdx = idx
}

func (a *maxDatumHashAgg) Compute(b coldata.Batch, inputIdxs []uint32) {
	inputLen := b.Length()
	vec, sel := b.ColVec(int(inputIdxs[0])), b.Selection()
	col, nulls := vec.Datum(), vec.Nulls()
	a.allocator.PerformOperation(
		[]coldata.Vec{a.vec},
		func() {
			if nulls.MaybeHasNulls() {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col.Slice(0, inputLen)
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = nulls.NullAt(i)
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			} else {
				if sel != nil {
					sel = sel[:inputLen]
					for _, i := range sel {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				} else {
					col = col.Slice(0, inputLen)
					for i := 0; i < inputLen; i++ {

						var isNull bool
						isNull = false
						if !isNull {
							if !a.foundNonNullForCurrentGroup {
								val := col.Get(i)
								a.curAgg = val
								a.foundNonNullForCurrentGroup = true
							} else {
								var cmp bool
								candidate := col.Get(i)

								{
									var cmpResult int

									cmpResult = candidate.(*coldataext.Datum).CompareDatum(col, a.curAgg)

									cmp = cmpResult > 0
								}

								if cmp {
									a.curAgg = candidate
								}
							}
						}
					}
				}
			}
		},
	)
}

func (a *maxDatumHashAgg) Flush() {
	// The aggregation is finished. Flush the last value. If we haven't found
	// any non-nulls for this group so far, the output for this group should
	// be null.
	if !a.foundNonNullForCurrentGroup {
		a.nulls.SetNull(a.curIdx)
	} else {
		a.col.Set(a.curIdx, a.curAgg)
	}
	a.curIdx++
}

func (a *maxDatumHashAgg) HandleEmptyInputScalar() {
	a.nulls.SetNull(0)
}

type maxDatumHashAggAlloc struct {
	aggAllocBase
	aggFuncs []maxDatumHashAgg
}

var _ aggregateFuncAlloc = &maxDatumHashAggAlloc{}

func (a *maxDatumHashAggAlloc) newAggFunc() aggregateFunc {
	if len(a.aggFuncs) == 0 {
		a.allocator.AdjustMemoryUsage(sizeOfmaxDatumHashAgg * a.allocSize)
		a.aggFuncs = make([]maxDatumHashAgg, a.allocSize)
	}
	f := &a.aggFuncs[0]
	f.allocator = a.allocator
	a.aggFuncs = a.aggFuncs[1:]
	return f
}
