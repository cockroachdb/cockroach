// Copyright 2021 The Cockroach Authors.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.


syntax = "proto3";
package cockroach.repstream.streampb;
option go_package = "github.com/cockroachdb/cockroach/pkg/repstream/streampb";


import "kv/kvpb/api.proto";
import "roachpb/data.proto";
import "jobs/jobspb/jobs.proto";
import "roachpb/metadata.proto";
import "util/hlc/timestamp.proto";
import "util/unresolved_addr.proto";
import "gogoproto/gogo.proto";
import "google/protobuf/duration.proto";

// ReplicationProducerSpec is the specification returned by the replication
// producer job when it is created.
message ReplicationProducerSpec {
  int64 stream_id = 1 [(gogoproto.customname) = "StreamID", (gogoproto.casttype) = "StreamID"];

  // ReplicationStartTime is the initial timestamp from which the replication
  // producer job will begin streaming MVCC revisions. This timestamp is picked
  // once when the replication producer job is created, and is never updated
  // through the lifetime of a replication stream. This will be the timestamp as
  // of which each partition will perform its initial rangefeed scan.
  util.hlc.Timestamp replication_start_time = 2 [(gogoproto.nullable) = false];
}

// StreamPartitionSpec is the stream partition specification.
message StreamPartitionSpec {
  // PreviousReplicatedTimestamp specifies the timestamp from which spans will
  // start ingesting data in the replication job. This timestamp is empty unless
  // the replication job resumes after a progress checkpoint has been recorded.
  // While it is empty we use the InitialScanTimestamp described below.
  util.hlc.Timestamp previous_replicated_timestamp = 1 [(gogoproto.nullable) = false];

  // InitialScanTimestamp is the timestamp at which the partition will run the
  // initial rangefeed scan before replicating further changes to the target
  // spans. This timestamp is always non-empty, but a partition will only run an
  // initial scan if no progress has been recorded prior to the current
  // resumption of the replication job. Otherwise, all spans will start
  // ingesting data from the PreviousReplicatedTimestamp described above.
  util.hlc.Timestamp initial_scan_timestamp = 4 [(gogoproto.nullable) = false];

  // List of spans to stream.
  repeated roachpb.Span spans = 2 [(gogoproto.nullable) = false];

  // ExecutionConfig describes various knobs to control execution behavior
  // of the stream.  If unspecified, reasonable defaults will be set.
  message ExecutionConfig {
    // Controls the number of concurrent scan requests issued during initial scan.
    int32 initial_scan_parallelism = 1;

    // Controls how often checkpoint records are published.
    google.protobuf.Duration min_checkpoint_frequency = 2
       [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];

    // Controls batch size in bytes.
    int64 batch_byte_size = 3;
  }

  ExecutionConfig config = 3 [(gogoproto.nullable) = false];
}

message ReplicationStreamSpec {
  message Partition {
    // ID of the node this partition resides
    int32 node_id = 1 [(gogoproto.customname) = "NodeID",
      (gogoproto.casttype) = "github.com/cockroachdb/cockroach/pkg/roachpb.NodeID"];

    // The SQL address of the node.
    util.UnresolvedAddr sql_address = 2 [(gogoproto.nullable) = false,
      (gogoproto.customname) = "SQLAddress"];

    // Locality of the node
    roachpb.Locality locality = 3 [(gogoproto.nullable) = false];

    // The spec of the processor responsible for streaming this partition
    StreamPartitionSpec partition_spec = 4 [(gogoproto.customname) = "PartitionSpec"];
  }

  repeated Partition partitions = 1 [(gogoproto.nullable) = false];

  roachpb.TenantID source_tenant_id = 2 [(gogoproto.nullable) = false, (gogoproto.customname) = "SourceTenantID"];
}

// StreamEvent describes a replication stream event
message StreamEvent {
  message Batch {
    repeated roachpb.KeyValue key_values = 1 [(gogoproto.nullable) = false];
    repeated roachpb.RangeFeedSSTable ssts = 2 [(gogoproto.nullable) = false];
    repeated roachpb.RangeFeedDeleteRange del_ranges = 3 [(gogoproto.nullable) = false];
  }

  // Checkpoint represents stream checkpoint.
  message StreamCheckpoint {
    reserved 1;
    repeated cockroach.sql.jobs.jobspb.ResolvedSpan resolved_spans = 2  [(gogoproto.nullable) = false];
  }

  // Only 1 field ought to be set.
  Batch batch = 1;
  StreamCheckpoint checkpoint = 2;
}

message StreamReplicationStatus {
  enum StreamStatus {
    // Stream is running. Consumers should continue to heartbeat.
    STREAM_ACTIVE = 0;
    // Stream stopped running. Consumers should stop heartbeating and
    // optionally start a new replication stream.
    STREAM_INACTIVE = 1;
    // Stream replication is paused. Consumers can resume the job and start heartbeating.
    STREAM_PAUSED = 2;
    // Stream status is unknown. Consumers should retry heartbeating.
    UNKNOWN_STREAM_STATUS_RETRY = 4;
  }

  StreamStatus stream_status = 1;

  // Current protected timestamp for spans being replicated. It is absent
  // when the replication stream is 'STOPPED'.
  util.hlc.Timestamp protected_timestamp = 2;
}

message StreamIngestionStats {
  // The status of current stream producer job.
  StreamReplicationStatus producer_status = 1;

  // The error when trying to reach the current stream producer job.
  string producer_error = 2;

  // Stream ingestion details.
  cockroach.sql.jobs.jobspb.StreamIngestionDetails ingestion_details = 3;

  // Stream ingestion progress, including each partition ingestion progress.
  cockroach.sql.jobs.jobspb.StreamIngestionProgress ingestion_progress = 4;

  message ReplicationLagInfo {
    // The timestamp at which we have confirmed all partitions have ingested to.
    // The cutover can only happen when this timestamp is not less than the
    // above cutover timestamp, i.e., this is max timestamp we can cut over.
    util.hlc.Timestamp min_ingested_timestamp = 1 [(gogoproto.nullable) = false];

    // The difference between destination cluster's current time and
    // the ingestion high watermark.
    google.protobuf.Duration replication_lag = 2
    [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];

    util.hlc.Timestamp latest_checkpointed_timestamp = 3 [(gogoproto.nullable) = false];
    util.hlc.Timestamp earliest_checkpointed_timestamp = 4 [(gogoproto.nullable) = false];
    reserved 5;
    reserved 6;

    // Lag between the slowest ingested timestamp to the fastest ingested timestamp
    // among all partitions.
    google.protobuf.Duration slowest_fastest_ingestion_lag = 7
    [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];
  }

  // Current replication lag information. It is absent if no ingestion progress
  // has been recorded yet.
  ReplicationLagInfo replication_lag_info = 5;
}
