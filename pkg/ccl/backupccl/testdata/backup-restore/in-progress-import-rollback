# Ensure clear range induces full reintroduction of spans and that restore properly elides
# clear ranged data from initial backup
# - begin import jobs and pause it
# - run inc backup - verify inc has captured the data
# - roll it back it back non-mvcc
# - run an inc backup and ensure we reintroduce the table spans

new-server name=s1
----

exec-sql
CREATE DATABASE d;
USE d;
CREATE TABLE foo (i INT PRIMARY KEY, s STRING);
CREATE INDEX foo_idx ON foo (s);
CREATE INDEX foo_to_drop_idx ON foo (s);
CREATE TABLE foofoo (i INT PRIMARY KEY, s STRING);
INSERT INTO foofoo VALUES (10, 'x0');
CREATE TABLE baz (i INT PRIMARY KEY, s STRING);
INSERT INTO baz VALUES (1, 'x'),(2,'y'),(3,'z');
----

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'import.after_ingest';
----

exec-sql
SET CLUSTER SETTING kv.bulkio.write_metadata_sst.enabled = false;
----


exec-sql
EXPORT INTO CSV 'nodelocal://0/export1/' FROM SELECT * FROM baz;
----


# Pause the import job, in order to back up the importing data.
import expect-pausepoint tag=a
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----
job paused at pausepoint


import expect-pausepoint tag=aa
IMPORT INTO foofoo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----
job paused at pausepoint


# Ensure table, database, and cluster full backups capture importing rows.
exec-sql
BACKUP INTO 'nodelocal://0/cluster/' with revision_history;
----


exec-sql
BACKUP DATABASE d INTO 'nodelocal://0/database/' with revision_history;
----

exec-sql
BACKUP TABLE d.* INTO 'nodelocal://0/table/' with revision_history;
----


exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = '';
----


# Resume the job so the next set of incremental backups observes that tables are back online
job cancel=a
----

job cancel=aa
----

job tag=a wait-for-state=cancelled
----


job tag=aa wait-for-state=cancelled
----

# Verify proper rollback
query-sql
SELECT count(*) FROM d.foo;
----
0


query-sql
SELECT count(*) FROM d.foofoo;
----
1


# Even though the full table will get backed up from ts=0 during the next round of incremental
# backups, only active indexes (foo_idx and foo_new_idx) should appear in the restored cluster.
exec-sql
DROP INDEX foo_to_drop_idx;
----
NOTICE: the data for dropped indexes is reclaimed asynchronously
HINT: The reclamation delay can be customized in the zone configuration for the table.

exec-sql
CREATE INDEX foo_new_idx ON foo (s);
----


# Ensure incremental backups backup the newly online spans from ts=0, as the
# import was rolled back via non-mvcc clear range. So, backup 0 rows from foo
# (it was empty pre-import), and 1 row from foo (had 1 row pre-import);
exec-sql
BACKUP INTO LATEST IN 'nodelocal://0/cluster/' with revision_history;
----

exec-sql
BACKUP DATABASE d INTO LATEST IN 'nodelocal://0/database/' with revision_history;
----


exec-sql
BACKUP TABLE d.* INTO LATEST IN 'nodelocal://0/table/' with revision_history;
----


# Note that the cluster level SHOW BACKUP includes foo and foofoo in the full
# backup while the the table and database ones do not. This is because CLUSTER
# backup manifests includes these in the Descriptors field (i.e. cluster backups
# explicitly backup offline tables, see #88043), while table and database
# backups only include these descriptors in manifest.DescriptorChanges (see
# #88042).

query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/cluster/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 3 full
d foofoo table 4 full
d foo table 0 incremental
d foofoo table 1 incremental

query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/database/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 0 incremental
d foofoo table 1 incremental


query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/table/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 0 incremental
d foofoo table 1 incremental


# To verify the incremental backed up the pre-import state table, restore d and ensure all tables
# are in their pre-import state.

new-server name=s2 share-io-dir=s1
----

exec-sql
RESTORE FROM LATEST IN 'nodelocal://0/cluster/';
----


query-sql
SELECT count(*) FROM d.foo;
----
0


query-sql
SELECT count(*) FROM d.foofoo;
----
1


query-sql
select DISTINCT index_name FROM [SHOW INDEXES FROM d.foo];
----
foo_pkey
foo_idx
foo_new_idx


exec-sql
RESTORE DATABASE d FROM LATEST IN 'nodelocal://0/database/' with new_db_name=d2;
----

query-sql
SELECT count(*) FROM d2.foo;
----
0


query-sql
SELECT count(*) FROM d2.foofoo;
----
1

query-sql
select DISTINCT index_name FROM [SHOW INDEXES FROM d2.foo];
----
foo_pkey
foo_idx
foo_new_idx

exec-sql
CREATE DATABASE d3;
----

exec-sql
RESTORE TABLE d.* FROM LATEST IN 'nodelocal://0/database/' with into_db=d3;
----

query-sql
SELECT count(*) FROM d3.foo;
----
0


query-sql
SELECT count(*) FROM d3.foofoo;
----
1

query-sql
select DISTINCT index_name FROM [SHOW INDEXES FROM d3.foo];
----
foo_pkey
foo_idx
foo_new_idx
