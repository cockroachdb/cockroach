# Test that Import INTO properly increments the importEpoch descriptor field only when the user runs
# an IMPORT INTO on a non-empty table.

new-server name=s1
----

exec-sql
CREATE DATABASE d;
USE d;
CREATE TABLE foo (i INT PRIMARY KEY, s STRING);
CREATE TABLE baz (i INT PRIMARY KEY, s STRING);
INSERT INTO baz VALUES (1, 'x'),(2,'y'),(3,'z');
----

exec-sql
CREATE VIEW import_epoch (epoch, type)
AS WITH tbls AS (
   	SELECT id, crdb_internal.pb_to_json('cockroach.sql.sqlbase.Descriptor', descriptor) AS orig FROM system.descriptor
   )
   SELECT orig->'table'->'importEpoch', orig->'table'->'importTypeInProgress' FROM tbls WHERE id = '109';
----

exec-sql
EXPORT INTO CSV 'nodelocal://0/export1/' FROM SELECT * FROM baz WHERE i = 1;
----

exec-sql
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----

query-sql
SELECT name, id FROM system.namespace WHERE name = 'foo';
----
foo 109

query-sql
SELECT * FROM import_epoch
----
1 <nil>

exec-sql
EXPORT INTO CSV 'nodelocal://0/export2/' FROM SELECT * FROM baz WHERE i = 2;
----

exec-sql
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export2/export*-n*.0.csv')
----

query-sql
SELECT * FROM import_epoch
----
2 <nil>

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'import.after_ingest';
----

exec-sql
EXPORT INTO CSV 'nodelocal://0/export3/' FROM SELECT * FROM baz WHERE i = 3;
----

# ensure the ImportEpoch increments before planning and does not rollback after the IMPORT INTO
# job gets cancelled
import expect-pausepoint tag=a
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export3/export*-n*.0.csv')
----
job paused at pausepoint

query-sql
SELECT * FROM import_epoch
----
3 "IMPORT_INTO_NON_EMPTY"

# Cancel the job so that the cleanup hook runs.
job cancel=a
----

query-sql
SELECT * FROM import_epoch
----
3 <nil>
