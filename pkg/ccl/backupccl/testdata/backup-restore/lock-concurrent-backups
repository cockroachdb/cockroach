new-server name=s1
----

# Test that a backup job does not read its own lock file on resumption,
# effectively locking itself out. We pause the job at a point such that on
# resumption we re-check for `BACKUP-LOCK` files written by other jobs but not
# our own.
subtest backup-does-not-read-its-own-lock

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'backup.before.details_has_locked';
----

backup expect-pausepoint tag=a
BACKUP INTO 'userfile://defaultdb.public.foo/foo';
----
job paused at pausepoint

# The job should have written a `BACKUP-LOCK` file suffixed with a job ID and a
# timestamp.
query-sql
SELECT regexp_replace(filename, '.*BACKUP-LOCK-[0-9]+.+', 'BACKUP-LOCK') FROM defaultdb.public.foo_upload_files;
----
BACKUP-LOCK

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = '';
----

# Resume the job and expect it to succeed.
job resume=a
----

job tag=a wait-for-state=succeeded
----

subtest end


# Test that a backup job on resume writes a versioned `BACKUP-LOCK` file
# maintaining write-once semantics.
subtest backup-lock-is-versioned

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'backup.before.details_has_locked';
----

backup expect-pausepoint tag=b
BACKUP INTO 'userfile://defaultdb.public.bar/bar';
----
job paused at pausepoint

# The job should have written a `BACKUP-LOCK` file suffixed with a job ID and a
# timestamp.
query-sql
SELECT regexp_replace(filename, '.*BACKUP-LOCK-[0-9]+.+', 'BACKUP-LOCK') FROM defaultdb.public.bar_upload_files;
----
BACKUP-LOCK

# Resume the job and expect it to pause again after writing `BACKUP-LOCK` again.
job resume=b
----

job tag=b wait-for-state=paused
----

# We expect to see two lock files since they are versioned.
query-sql
SELECT regexp_replace(filename, '.*BACKUP-LOCK-[0-9]+.+', 'BACKUP-LOCK') FROM defaultdb.public.bar_upload_files;
----
BACKUP-LOCK
BACKUP-LOCK

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = '';
----

# Resume the job and expect it to succeed.
job resume=b
----

job tag=b wait-for-state=succeeded
----

subtest end

# Note, `BACKUP TO` is going away, and `BACKUP INTO` picks a timestamped
# directory making it *impossible* for two backups to write to the same
# directory in the future.
#
# Backup should fail if it sees a BACKUP_LOCK in the bucket.
subtest backup-lock-file-prevents-concurrent-backups

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'backup.before.flow';
----

backup expect-pausepoint
BACKUP TO 'userfile://defaultdb.public.baz/baz';
----
job paused at pausepoint

exec-sql expect-error-regex='userfile://defaultdb.public.baz/baz already contains a `BACKUP-LOCK`'
BACKUP TO 'userfile://defaultdb.public.baz/baz';
----
regex matches error

subtest end

# For mixed version compatability the backup job also checks for a
# `BACKUP-CHECKPOINT` file when ensuring that there are no concurrent backups
# writing to the same bucket.
#
# This test ensures that a backup job does not check for a `BACKUP-CHECKPOINT`
# lock file after writing its own `BACKUP-CHECKPOINT`. See
# `BackupDetails.HasLockedLocation` for more information.
subtest backup-does-not-read-its-own-checkpoint

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'backup.after.write_first_checkpoint';
----

backup expect-pausepoint tag=d
BACKUP TO 'userfile://defaultdb.public.bat/bat';
----
job paused at pausepoint

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = '';
----

# Resume the job and expect it to succeed.
job resume=d
----

job tag=d wait-for-state=succeeded
----

subtest end
