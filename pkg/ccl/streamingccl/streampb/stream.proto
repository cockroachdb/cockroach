// Copyright 2021 The Cockroach Authors.
//
// Licensed as a CockroachDB Enterprise file under the Cockroach Community
// License (the "License"); you may not use this file except in compliance with
// the License. You may obtain a copy of the License at
//
//     https://github.com/cockroachdb/cockroach/blob/master/licenses/CCL.txt


syntax = "proto3";
package cockroach.ccl.streamingccl;
option go_package = "streampb";


import "roachpb/api.proto";
import "roachpb/data.proto";
import "jobs/jobspb/jobs.proto";
import "roachpb/metadata.proto";
import "util/hlc/timestamp.proto";
import "util/unresolved_addr.proto";
import "gogoproto/gogo.proto";
import "google/protobuf/duration.proto";

// StreamPartitionSpec is the stream partition specification.
message StreamPartitionSpec {
  // start_from specifies the starting point for all spans.  If its empty,
  // an initial scan is performed.
  util.hlc.Timestamp start_from = 1 [(gogoproto.nullable) = false];
  // List of spans to stream.
  repeated roachpb.Span spans = 2 [(gogoproto.nullable) = false];

  // ExecutionConfig describes various knobs to control execution behavior
  // of the stream.  If unspecified, reasonable defaults will be set.
  message ExecutionConfig {
    // Controls the number of concurrent scan requests issued during initial scan.
    int32 initial_scan_parallelism = 1;

    // Controls how often checkpoint records are published.
    google.protobuf.Duration min_checkpoint_frequency = 2
       [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];

    // Controls batch size in bytes.
    int64 batch_byte_size = 3;
  }

  ExecutionConfig config = 3 [(gogoproto.nullable) = false];
}

message ReplicationStreamSpec {
  message Partition {
    // ID of the node this partition resides
    int32 node_id = 1 [(gogoproto.customname) = "NodeID",
      (gogoproto.casttype) = "github.com/cockroachdb/cockroach/pkg/roachpb.NodeID"];

    // The SQL address of the node.
    util.UnresolvedAddr sql_address = 2 [(gogoproto.nullable) = false,
      (gogoproto.customname) = "SQLAddress"];

    // Locality of the node
    roachpb.Locality locality = 3 [(gogoproto.nullable) = false];

    // The spec of the processor responsible for streaming this partition
    StreamPartitionSpec partition_spec = 4 [(gogoproto.customname) = "PartitionSpec"];
  }

  repeated Partition partitions = 1 [(gogoproto.nullable) = false];
}

// StreamEvent describes a replication stream event
message StreamEvent {
  message Batch {
    repeated roachpb.KeyValue key_values = 1 [(gogoproto.nullable) = false];
    repeated roachpb.RangeFeedSSTable ssts = 2 [(gogoproto.nullable) = false];
    repeated roachpb.RangeFeedDeleteRange del_ranges = 3 [(gogoproto.nullable) = false];
  }

  // Checkpoint represents stream checkpoint.
  message StreamCheckpoint {
    reserved 1;
    repeated cockroach.sql.jobs.jobspb.ResolvedSpan resolved_spans = 2  [(gogoproto.nullable) = false];
  }

  // Only 1 field ought to be set.
  Batch batch = 1;
  StreamCheckpoint checkpoint = 2;
}

message StreamReplicationStatus {
  enum StreamStatus {
    // Stream is running. Consumers should continue to heartbeat.
    STREAM_ACTIVE = 0;
    // Stream stopped running. Consumers should stop heartbeating and
    // optionally start a new replication stream.
    STREAM_INACTIVE = 1;
    // Stream replication is paused. Consumers can resume the job and start heartbeating.
    STREAM_PAUSED = 2;
    // Stream status is unknown. Consumers should retry heartbeating.
    UNKNOWN_STREAM_STATUS_RETRY = 4;
  }

  StreamStatus stream_status = 1;

  // Current protected timestamp for spans being replicated. It is absent
  // when the replication stream is 'STOPPED'.
  util.hlc.Timestamp protected_timestamp = 2;
}

message StreamIngestionStats {
  // The status of current stream producer job.
  StreamReplicationStatus producer_status = 1;

  // The error when trying to reach the current stream producer job.
  string producer_error = 2;

  // Stream ingestion details.
  cockroach.sql.jobs.jobspb.StreamIngestionDetails ingestion_details = 3;

  // Stream ingestion progress, including each partition ingestion progress.
  cockroach.sql.jobs.jobspb.StreamIngestionProgress ingestion_progress = 4;

  message ReplicationLagInfo {
    // The timestamp at which we have confirmed all partitions have ingested to.
    // The cutover can only happen when this timestamp is not less than the
    // above cutover timestamp, i.e., this is max timestamp we can cut over.
    util.hlc.Timestamp min_ingested_timestamp = 1 [(gogoproto.nullable) = false];

    // The difference between destination cluster's current time and
    // the ingestion high watermark.
    google.protobuf.Duration replication_lag = 2
    [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];

    util.hlc.Timestamp latest_checkpointed_timestamp = 3 [(gogoproto.nullable) = false];
    util.hlc.Timestamp earliest_checkpointed_timestamp = 4 [(gogoproto.nullable) = false];
    reserved 5;
    reserved 6;

    // Lag between the slowest ingested timestamp to the fastest ingested timestamp
    // among all partitions.
    google.protobuf.Duration slowest_fastest_ingestion_lag = 7
    [(gogoproto.nullable) = false, (gogoproto.stdduration) = true];
  }

  // Current replication lag information. It is absent if no ingestion progress
  // has been recorded yet.
  ReplicationLagInfo replication_lag_info = 5;
}
