new-cluster localities=us-east-1,us-east-1,us-east-1,us-central-1,us-central-1,us-central-1,us-west-1,us-west-1,us-west-1,eu-central-1,eu-west-1
----

exec-sql idx=0
CREATE DATABASE db PRIMARY REGION "us-east-1" REGIONS  "us-west-1", "us-central-1", "eu-central-1";
----

exec-sql idx=0
CREATE TABLE db.rbr(k INT PRIMARY KEY, v INT) LOCALITY REGIONAL BY ROW;
----

exec-sql idx=0
INSERT INTO db.rbr (k, v, crdb_region) VALUES (1, 1, 'us-east-1'), (2, 2, 'us-central-1'), (3, 3, 'us-west-1'), (4, 4, 'eu-central-1')
----

# We can't constrain non-voters to specific replicas other than 9 because we
# have 7 candidates for non-voters, but only one per region will be allocated (3
# total).
wait-for-zone-config-changes db-name=db table-name=rbr partition-name=us-east-1 num-voters=3 num-non-voters=3 leaseholder=0 voter=1,2 non-voter=9 not-present=10
----

wait-for-zone-config-changes db-name=db table-name=rbr partition-name=us-central-1 num-voters=3 num-non-voters=3 leaseholder=3 voter=4,5 non-voter=9 not-present=10
----

wait-for-zone-config-changes db-name=db table-name=rbr partition-name=us-west-1 num-voters=3 num-non-voters=3 leaseholder=6 voter=7,8 non-voter=9 not-present=10
----

# For eu-central-1, we do not have enough nodes in eu-central-1 to fill all 3
# voters slots, so we cannot assert anything about replica placement other than
# the leaseholder location.
wait-for-zone-config-changes db-name=db table-name=rbr partition-name=eu-central-1 num-voters=3 num-non-voters=3 leaseholder=9
----

# We'll attempt to perform follower reads to us-central-1 and validate the
# following behavior:
# 1. Leaseholder (3) can serve follower reads
# 2. Voters (4) can serve follower reads
# 3. Non-voters (9) can serve follower reads
# 4. Nodes without a replica (10) cannot serve follower reads.

# Sleep to ensure we can get follower reads.
sleep-for-follower-read
----

refresh-range-descriptor-cache db-name=db idx=3 table-name=rbr partition-name=us-central-1
SELECT * FROM db.rbr WHERE k = 2
----
LAG_BY_CLUSTER_SETTING

# Note that because this node is a leaseholder, it can still serve historical
# reads, but these reads don't count as "follower reads" since the leaseholder
# owns the data.
trace-sql idx=3 trace-analysis=rbr
SELECT * FROM db.rbr AS OF SYSTEM TIME follower_read_timestamp() WHERE k = 2
----
served local region search on current node: true
served local region search via follower read: false
found in local region: true

refresh-range-descriptor-cache db-name=db idx=4 table-name=rbr partition-name=us-central-1
SELECT * FROM db.rbr WHERE k = 2
----
LAG_BY_CLUSTER_SETTING

# This is a voter, so scenario 2.
trace-sql idx=4 trace-analysis=rbr
SELECT * FROM db.rbr AS OF SYSTEM TIME follower_read_timestamp() WHERE k = 2
----
served local region search on current node: true
served local region search via follower read: true
found in local region: true

refresh-range-descriptor-cache db-name=db idx=9 table-name=rbr partition-name=us-central-1
SELECT * FROM db.rbr WHERE k = 2
----
LAG_BY_CLUSTER_SETTING

# This is a non-voter, so scenario 3.
trace-sql idx=9 trace-analysis=rbr
SELECT * FROM db.rbr AS OF SYSTEM TIME follower_read_timestamp() WHERE k = 2
----
served local region search on current node: true
served local region search via follower read: false
found in local region: false
served remote region read via follower read: true

refresh-range-descriptor-cache db-name=db idx=10 table-name=rbr partition-name=us-central-1
SELECT * FROM db.rbr WHERE k = 2
----
LAG_BY_CLUSTER_SETTING

# Note that in this case, the eu-west-1 region is not in the database, so it
# won't attempt local region search. Therefore, there will be only one
# request, and we will use simple trace analysis.
trace-sql idx=10 trace-analysis=simple
SELECT * FROM db.rbr AS OF SYSTEM TIME follower_read_timestamp() WHERE k = 2
----
served locally: false
