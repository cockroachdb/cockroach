# Test that estimated CPU metrics and tokens are recorded and reported.

# Switch to use the estimated CPU model rather than the RU model.
estimated-nodes count=3
----

# When throttle = -1, the provider will refuse to grant any tokens, either
# directly or via a trickle.
configure
throttle: -1
----

token-bucket
----
5000.00 tokens filling @ 0.00 tokens/s

# Ensure that estimated CPU metrics change, but not RU metrics.
write repeat=100 count=6 bytes=2048 networkCost=1
----

# Expect ~269 tokens to be consumed.
token-bucket
----
4731.05 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 100
tenant.sql_usage.write_requests: 600
tenant.sql_usage.write_bytes: 204800
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.27
tenant.sql_usage.estimated_cpu_seconds: 0.27

# Wait for the token bucket response triggered by low tokens. Not doing this
# causes a race condition, since in some cases this response arrives after the
# configure command below, and the write batch rate is not set correctly.
wait-for-event
token-bucket-response
----

# Wait until the next tick, at which point background CPU usage will be added.
advance wait=true
1s
----
00:00:01.000

# ~29 tokens removed from bucket to account for background CPU.
token-bucket
----
4701.92 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 100
tenant.sql_usage.write_requests: 600
tenant.sql_usage.write_bytes: 204800
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.27
tenant.sql_usage.estimated_cpu_seconds: 0.30

# Do same writes, but with a different write batch rate. This time, the
# estimated CPU consumption should be less.

configure
write_batch_rate: 1000
throttle: -1
----

advance
40s
----
00:00:41.000

# Wait for the token bucket request to ensure that new batch rate is known by
# the client.
wait-for-event
token-bucket-response
----

write repeat=100 count=6 bytes=2048 networkCost=1
----

# Wait until the next tick, at which point background CPU usage will be added.
advance wait=true
1s
----
00:00:42.000

# Expect ~241 tokens to be removed, as compared to ~298 above (269 + 29).
token-bucket
----
4460.51 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 200
tenant.sql_usage.write_requests: 1200
tenant.sql_usage.write_bytes: 409600
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.49
tenant.sql_usage.estimated_cpu_seconds: 0.54

# Advance time to next period and do same writes, with the same write batch
# rate, but with a global estimated CPU rate. The estimated CPU rate should not
# change, since this SQL node will only subtract its own portion of the global
# background CPU usage.

configure
write_batch_rate: 1000
estimated_cpu_rate: 6
throttle: -1
----

advance
10s
----
00:00:52.000

wait-for-event
token-bucket-response
----

write repeat=100 count=6 bytes=2048 networkCost=1
----

advance wait=true
1s
----
00:00:53.000

# Expect ~241 tokens to be consumed, like above.
token-bucket
----
4219.10 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 300
tenant.sql_usage.write_requests: 1800
tenant.sql_usage.write_bytes: 614400
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.70
tenant.sql_usage.estimated_cpu_seconds: 0.78

# Now perform some read operations.

read repeat=1000 count=20 bytes=10000
----

advance wait=true
1s
----
00:00:54.000

token-bucket
----
2827.49 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 300
tenant.sql_usage.write_requests: 1800
tenant.sql_usage.write_bytes: 614400
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 1.96
tenant.sql_usage.estimated_cpu_seconds: 2.17

# KV CPU seconds should not change, only total CPU seconds. Background CPU usage
# should be accounted for.
cpu
1s
----

advance wait=true
1s
----
00:00:55.000

token-bucket
----
1730.24 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 300
tenant.sql_usage.write_requests: 1800
tenant.sql_usage.write_bytes: 614400
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 1.96
tenant.sql_usage.estimated_cpu_seconds: 3.27

# External I/O should not block or consume tokens.
external-egress bytes=1024000
----

external-ingress bytes=1024000
----

advance wait=true
1s
----
00:00:56.000

token-bucket
----
1730.24 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 300
tenant.sql_usage.write_requests: 1800
tenant.sql_usage.write_bytes: 614400
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 1024000
tenant.sql_usage.external_io_egress_bytes: 1024000
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 1.96
tenant.sql_usage.estimated_cpu_seconds: 3.27

# PGWire egress should not block or consume tokens.
pgwire-egress
12345
----

advance wait=true
1s
----
00:00:57.000

token-bucket
----
1730.24 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 300
tenant.sql_usage.write_requests: 1800
tenant.sql_usage.write_bytes: 614400
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 12345
tenant.sql_usage.external_io_ingress_bytes: 1024000
tenant.sql_usage.external_io_egress_bytes: 1024000
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 1.96
tenant.sql_usage.estimated_cpu_seconds: 3.27

# Ensure that token bucket request is made after 10 seconds (though it returns
# no tokens).
advance
10s
----
00:01:07.000

wait-for-event
token-bucket-response
----

token-bucket
----
1730.24 tokens filling @ 0.00 tokens/s

# Allow the provider to grant tokens again.
configure
throttle: 0
----

# Advance another 10 seconds, but this time expect no token bucket request,
# since there's been no consumption.
advance wait=true
10s
----
00:01:17.000

token-bucket
----
1730.24 tokens filling @ 0.00 tokens/s
