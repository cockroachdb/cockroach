# Test that estimated CPU metrics and tokens are recorded and reported.

# Switch to use the estimated CPU model rather than the RU model.
estimated-nodes count=3
----

# When throttle = -1, the provider will refuse to grant any tokens, either
# directly or via a trickle.
configure
throttle: -1
----

token-bucket
----
5000.00 tokens filling @ 0.00 tokens/s

# Ensure that estimated CPU metrics change, but not RU metrics.
write repeat=35 count=6 bytes=2048 localities=same-zone
----

# Expect ~283 tokens to be consumed.
token-bucket
----
4717.33 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 105
tenant.sql_usage.write_requests: 630
tenant.sql_usage.write_bytes: 218190
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.28
tenant.sql_usage.estimated_cpu_seconds: 0.28
tenant.sql_usage.estimated_replication_bytes: 145460
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 145460

# Wait for the token bucket response triggered by low tokens. Not doing this
# causes a race condition, since in some cases this response arrives after the
# configure command below, and the write batch rate is not set correctly.
wait-for-event
token-bucket-response
----

# Wait until the next tick, at which point background CPU usage will be added.
advance wait=true
1s
----
00:00:01.000

# ~31 tokens removed from bucket to account for background CPU.
token-bucket
----
4686.71 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 105
tenant.sql_usage.write_requests: 630
tenant.sql_usage.write_bytes: 218190
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.28
tenant.sql_usage.estimated_cpu_seconds: 0.31
tenant.sql_usage.estimated_replication_bytes: 145460
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 145460

# Do same writes, but with a different write batch rate. This time, the
# estimated CPU consumption should be less.

configure
write_batch_rate: 1000
throttle: -1
----

advance
40s
----
00:00:41.000

# Wait for the token bucket request to ensure that new batch rate is known by
# the client.
wait-for-event
token-bucket-response
----

write repeat=35 count=6 bytes=2048 localities=cross-zone
----

# Wait until the next tick, at which point background CPU usage will be added.
advance wait=true
1s
----
00:00:42.000

# Expect ~254 tokens to be removed, as compared to ~314 above (283 + 31).
token-bucket
----
4432.93 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 210
tenant.sql_usage.write_requests: 1260
tenant.sql_usage.write_bytes: 436380
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.51
tenant.sql_usage.estimated_cpu_seconds: 0.57
tenant.sql_usage.estimated_replication_bytes: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 218190
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 72730

# Advance time to next period and do same writes, with the same write batch
# rate, but with a global estimated CPU rate. The estimated CPU rate should not
# change, since this SQL node will only subtract its own portion of the global
# background CPU usage.

configure
write_batch_rate: 1000
estimated_cpu_rate: 6
throttle: -1
----

advance
10s
----
00:00:52.000

wait-for-event
token-bucket-response
----

write repeat=35 count=6 bytes=2048 localities=cross-zone
----

advance wait=true
1s
----
00:00:53.000

# Expect ~254 tokens to be consumed, like above.
token-bucket
----
4179.15 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 0
tenant.sql_usage.read_requests: 0
tenant.sql_usage.read_bytes: 0
tenant.sql_usage.write_batches: 315
tenant.sql_usage.write_requests: 1890
tenant.sql_usage.write_bytes: 654570
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 0.74
tenant.sql_usage.estimated_cpu_seconds: 0.82
tenant.sql_usage.estimated_replication_bytes: 436380
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 145460

# Now perform some read operations.

read repeat=1000 count=20 bytes=10000 localities=cross-zone
----

advance wait=true
1s
----
00:00:54.000

token-bucket
----
2787.54 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 315
tenant.sql_usage.write_requests: 1890
tenant.sql_usage.write_bytes: 654570
tenant.sql_usage.sql_pods_cpu_seconds: 0.00
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 2.00
tenant.sql_usage.estimated_cpu_seconds: 2.21
tenant.sql_usage.estimated_replication_bytes: 436380
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 145460

# KV CPU seconds should not change, only total CPU seconds. Background CPU usage
# should be accounted for.
cpu
1s
----

advance wait=true
1s
----
00:00:55.000

token-bucket
----
1690.29 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 315
tenant.sql_usage.write_requests: 1890
tenant.sql_usage.write_bytes: 654570
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 0
tenant.sql_usage.external_io_egress_bytes: 0
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 2.00
tenant.sql_usage.estimated_cpu_seconds: 3.31
tenant.sql_usage.estimated_replication_bytes: 436380
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 145460

# External I/O should not block or consume tokens.
external-egress bytes=1024000
----

external-ingress bytes=1024000
----

advance wait=true
1s
----
00:00:56.000

token-bucket
----
1690.29 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 315
tenant.sql_usage.write_requests: 1890
tenant.sql_usage.write_bytes: 654570
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 0
tenant.sql_usage.external_io_ingress_bytes: 1024000
tenant.sql_usage.external_io_egress_bytes: 1024000
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 2.00
tenant.sql_usage.estimated_cpu_seconds: 3.31
tenant.sql_usage.estimated_replication_bytes: 436380
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 145460

# PGWire egress should not block or consume tokens.
pgwire-egress
12345
----

advance wait=true
1s
----
00:00:57.000

token-bucket
----
1690.29 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 315
tenant.sql_usage.write_requests: 1890
tenant.sql_usage.write_bytes: 654570
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 12345
tenant.sql_usage.external_io_ingress_bytes: 1024000
tenant.sql_usage.external_io_egress_bytes: 1024000
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 2.00
tenant.sql_usage.estimated_cpu_seconds: 3.31
tenant.sql_usage.estimated_replication_bytes: 436380
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 290920
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 145460

# Ensure that token bucket request is made after 10 seconds (though it returns
# no tokens).
advance
10s
----
00:01:07.000

wait-for-event
token-bucket-response
----

token-bucket
----
1690.29 tokens filling @ 0.00 tokens/s

# Perform cross-region write request.
write count=100 bytes=1000 localities=cross-region
----

# Wait until the next tick, at which point background CPU usage will be added.
advance wait=true
1s
----
00:01:08.000

token-bucket
----
1652.30 tokens filling @ 0.00 tokens/s

metrics
----
tenant.sql_usage.request_units: 0.00
tenant.sql_usage.kv_request_units: 0.00
tenant.sql_usage.read_batches: 1000
tenant.sql_usage.read_requests: 20000
tenant.sql_usage.read_bytes: 10000000
tenant.sql_usage.write_batches: 320
tenant.sql_usage.write_requests: 2390
tenant.sql_usage.write_bytes: 661570
tenant.sql_usage.sql_pods_cpu_seconds: 0.99
tenant.sql_usage.pgwire_egress_bytes: 12345
tenant.sql_usage.external_io_ingress_bytes: 1024000
tenant.sql_usage.external_io_egress_bytes: 1024000
tenant.sql_usage.cross_region_network_ru: 0.00
tenant.sql_usage.estimated_kv_cpu_seconds: 2.03
tenant.sql_usage.estimated_cpu_seconds: 3.35
tenant.sql_usage.estimated_replication_bytes: 441980
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="",to_region="europe-west1",to_zone=""}: 2800
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az1"}: 292320
tenant.sql_usage.estimated_replication_bytes{from_region="us-central1",from_zone="az1",to_region="us-central1",to_zone="az2"}: 146860

# Allow the provider to grant tokens again.
configure
throttle: 0
----

# Advance another 10 seconds, but this time expect no token bucket request,
# since there's been no consumption.
advance wait=true
10s
----
00:01:18.000

token-bucket
----
1652.30 tokens filling @ 0.00 tokens/s
