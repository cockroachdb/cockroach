go list -tags '' -f \
'go test -v -race -tags '\'''\'' -ldflags '\'''\'' -i -c {{.ImportPath}} -o {{.Dir}}/stress.test && (cd {{.Dir}} && if [ -f stress.test ]; then stress -maxtime 15m -maxfails 1 -stderr ./stress.test -test.run '\''.'\'' -test.timeout 0 -test.v; fi)' github.com/cockroachdb/cockroach/pkg/storage | \
/bin/bash
github.com/cockroachdb/cockroach/pkg/cli/cliflags
github.com/gogo/protobuf/proto
golang.org/x/net/context
github.com/cockroachdb/cockroach/pkg/util/log/logflags
github.com/cockroachdb/cockroach/pkg/util/humanizeutil
github.com/cockroachdb/cockroach/pkg/util/uuid
github.com/cockroachdb/cockroach/pkg/util/duration
github.com/cockroachdb/cockroach/pkg/util/decimal
github.com/golang/protobuf/proto
github.com/cockroachdb/cockroach/pkg/util/syncutil
github.com/opentracing/opentracing-go
golang.org/x/net/trace
golang.org/x/net/http2
github.com/cockroachdb/cockroach/pkg/util/caller
google.golang.org/grpc/credentials
google.golang.org/grpc/metadata
github.com/opentracing/opentracing-go/ext
github.com/cockroachdb/cockroach/pkg/util/retry
github.com/cockroachdb/cockroach/pkg/util/encoding
github.com/spf13/pflag
github.com/montanaflynn/stats
google.golang.org/grpc/peer
github.com/cockroachdb/cockroach/pkg/util/interval
github.com/cockroachdb/cockroach/pkg/util/shuffle
github.com/cockroachdb/cockroach/pkg/sql/privilege
golang.org/x/text/internal/tag
golang.org/x/text/unicode/norm
github.com/cockroachdb/cockroach/pkg/sql/pgwire/pgerror
golang.org/x/text/language
github.com/cockroachdb/c-protobuf
github.com/cockroachdb/cockroach/pkg/util/bufalloc
github.com/lib/pq
github.com/cockroachdb/cockroach/pkg/ui
github.com/golang/protobuf/jsonpb
github.com/grpc-ecosystem/grpc-gateway/runtime/internal
github.com/golang/protobuf/ptypes/timestamp
github.com/prometheus/client_model/go
github.com/matttproud/golang_protobuf_extensions/pbutil
github.com/golang/protobuf/protoc-gen-go/descriptor
github.com/coreos/etcd/raft/raftpb
golang.org/x/text/internal/colltab
github.com/prometheus/common/expfmt
github.com/cockroachdb/cockroach/pkg/build
github.com/gogo/protobuf/types
github.com/opentracing/basictracer-go/wire
github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis/google/api
golang.org/x/text/collate
github.com/coreos/etcd/raft
github.com/opentracing/basictracer-go
github.com/cockroachdb/cockroach/pkg/util/log
google.golang.org/grpc/transport
github.com/cockroachdb/cmux
github.com/lightstep/lightstep-tracer-go/thrift_rpc
github.com/cockroachdb/cockroach/pkg/util/sdnotify
github.com/cockroachdb/cockroach/pkg/util/envutil
github.com/cockroachdb/cockroach/pkg/util/cache
github.com/cockroachdb/cockroach/pkg/util/timeutil
github.com/cockroachdb/cockroach/pkg/util/randutil
github.com/cockroachdb/cockroach/pkg/util/hlc
github.com/cockroachdb/cockroach/pkg/security
github.com/cockroachdb/cockroach/pkg/util
github.com/gogo/protobuf/jsonpb
google.golang.org/grpc
github.com/cockroachdb/cockroach/pkg/util/metric
github.com/cockroachdb/cockroach/pkg/storage/engine/enginepb
github.com/cockroachdb/cockroach/pkg/util/leaktest
github.com/cockroachdb/cockroach/pkg/security/securitytest
github.com/cockroachdb/cockroach/pkg/sql/mon
github.com/grpc-ecosystem/grpc-gateway/runtime
github.com/lightstep/lightstep-tracer-go/collectorpb
github.com/lightstep/lightstep-tracer-go
github.com/cockroachdb/cockroach/pkg/util/httputil
github.com/cockroachdb/cockroach/pkg/util/protoutil
github.com/cockroachdb/cockroach/pkg/util/tracing
github.com/cockroachdb/cockroach/pkg/roachpb
github.com/cockroachdb/cockroach/pkg/util/stop
github.com/cockroachdb/cockroach/pkg/keys
github.com/cockroachdb/cockroach/pkg/ts/tspb
github.com/cockroachdb/cockroach/pkg/storage/storagebase
github.com/cockroachdb/cockroach/pkg/sql/parser
github.com/cockroachdb/cockroach/pkg/base
github.com/cockroachdb/cockroach/pkg/util/netutil
github.com/cockroachdb/cockroach/pkg/config
github.com/cockroachdb/cockroach/pkg/server/status
github.com/cockroachdb/cockroach/pkg/util/grpcutil
github.com/cockroachdb/cockroach/pkg/gossip/resolver
github.com/cockroachdb/cockroach/pkg/internal/client
github.com/cockroachdb/cockroach/pkg/testutils
github.com/cockroachdb/cockroach/pkg/rpc
github.com/cockroachdb/cockroach/pkg/gossip
github.com/cockroachdb/cockroach/pkg/sql/sqlutil
github.com/cockroachdb/cockroach/pkg/kv
github.com/cockroachdb/cockroach/pkg/server/serverpb
github.com/cockroachdb/cockroach/pkg/testutils/gossiputil
github.com/cockroachdb/cockroach/pkg/sql/sqlbase
github.com/cockroachdb/cockroach/pkg/testutils/sqlutils
github.com/cockroachdb/cockroach/pkg/testutils/serverutils
github.com/cockroachdb/cockroach/pkg/sql/distsqlrun
github.com/cockroachdb/cockroach/pkg/storage/engine/rocksdb
github.com/cockroachdb/cockroach/pkg/storage/engine
github.com/cockroachdb/cockroach/pkg/storage
github.com/cockroachdb/cockroach/pkg/sql
github.com/cockroachdb/cockroach/pkg/ts
github.com/cockroachdb/cockroach/pkg/sql/pgwire
github.com/cockroachdb/cockroach/pkg/server
github.com/cockroachdb/cockroach/pkg/testutils/testcluster
github.com/cockroachdb/cockroach/pkg/cli/cliflags
golang.org/x/net/context
github.com/cockroachdb/cockroach/pkg/util/log/logflags
github.com/montanaflynn/stats
github.com/cockroachdb/c-protobuf
github.com/cockroachdb/cockroach/pkg/util/bufalloc
github.com/cockroachdb/cockroach/pkg/util/shuffle
golang.org/x/text/internal/tag
github.com/gogo/protobuf/proto
github.com/cockroachdb/cockroach/pkg/util/humanizeutil
github.com/cockroachdb/cockroach/pkg/util/syncutil
github.com/opentracing/opentracing-go
golang.org/x/net/trace
github.com/cockroachdb/cockroach/pkg/util/uuid
github.com/cockroachdb/cockroach/pkg/util/duration
github.com/cockroachdb/cockroach/pkg/util/caller
github.com/cockroachdb/cockroach/pkg/util/decimal
github.com/golang/protobuf/proto
golang.org/x/net/http2
google.golang.org/grpc/credentials
google.golang.org/grpc/metadata
github.com/opentracing/opentracing-go/ext
google.golang.org/grpc/peer
github.com/cockroachdb/cockroach/pkg/util/retry
github.com/cockroachdb/cockroach/pkg/util/encoding
github.com/spf13/pflag
github.com/cockroachdb/cockroach/pkg/util/interval
github.com/cockroachdb/cockroach/pkg/sql/privilege
golang.org/x/text/language
golang.org/x/text/unicode/norm
github.com/cockroachdb/cockroach/pkg/sql/pgwire/pgerror
github.com/lib/pq
github.com/cockroachdb/cockroach/pkg/ui
github.com/cockroachdb/cockroach/pkg/util/sdnotify
golang.org/x/text/internal/colltab
github.com/golang/protobuf/jsonpb
github.com/grpc-ecosystem/grpc-gateway/runtime/internal
github.com/golang/protobuf/ptypes/timestamp
github.com/prometheus/client_model/go
github.com/matttproud/golang_protobuf_extensions/pbutil
github.com/cockroachdb/cockroach/pkg/build
github.com/gogo/protobuf/types
github.com/opentracing/basictracer-go/wire
github.com/coreos/etcd/raft/raftpb
github.com/prometheus/common/expfmt
github.com/opentracing/basictracer-go
github.com/golang/protobuf/protoc-gen-go/descriptor
google.golang.org/grpc/transport
github.com/cockroachdb/cmux
github.com/cockroachdb/cockroach/pkg/util/log
github.com/lightstep/lightstep-tracer-go/thrift_rpc
github.com/coreos/etcd/raft
github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis/google/api
golang.org/x/text/collate
github.com/gogo/protobuf/jsonpb
github.com/cockroachdb/cockroach/pkg/util/envutil
github.com/cockroachdb/cockroach/pkg/util/cache
google.golang.org/grpc
github.com/cockroachdb/cockroach/pkg/util/timeutil
github.com/cockroachdb/cockroach/pkg/util/randutil
github.com/cockroachdb/cockroach/pkg/util/hlc
github.com/cockroachdb/cockroach/pkg/util
github.com/cockroachdb/cockroach/pkg/security
github.com/cockroachdb/cockroach/pkg/util/metric
github.com/cockroachdb/cockroach/pkg/util/leaktest
github.com/cockroachdb/cockroach/pkg/storage/engine/enginepb
github.com/cockroachdb/cockroach/pkg/security/securitytest
github.com/cockroachdb/cockroach/pkg/sql/mon
github.com/grpc-ecosystem/grpc-gateway/runtime
github.com/lightstep/lightstep-tracer-go/collectorpb
github.com/lightstep/lightstep-tracer-go
github.com/cockroachdb/cockroach/pkg/util/httputil
github.com/cockroachdb/cockroach/pkg/util/protoutil
github.com/cockroachdb/cockroach/pkg/util/tracing
github.com/cockroachdb/cockroach/pkg/roachpb
github.com/cockroachdb/cockroach/pkg/util/stop
github.com/cockroachdb/cockroach/pkg/keys
github.com/cockroachdb/cockroach/pkg/storage/storagebase
github.com/cockroachdb/cockroach/pkg/ts/tspb
github.com/cockroachdb/cockroach/pkg/sql/parser
github.com/cockroachdb/cockroach/pkg/base
github.com/cockroachdb/cockroach/pkg/util/netutil
github.com/cockroachdb/cockroach/pkg/config
github.com/cockroachdb/cockroach/pkg/util/grpcutil
github.com/cockroachdb/cockroach/pkg/server/status
github.com/cockroachdb/cockroach/pkg/gossip/resolver
github.com/cockroachdb/cockroach/pkg/rpc
github.com/cockroachdb/cockroach/pkg/internal/client
github.com/cockroachdb/cockroach/pkg/testutils
github.com/cockroachdb/cockroach/pkg/gossip
github.com/cockroachdb/cockroach/pkg/sql/sqlutil
github.com/cockroachdb/cockroach/pkg/testutils/gossiputil
github.com/cockroachdb/cockroach/pkg/kv
github.com/cockroachdb/cockroach/pkg/server/serverpb
github.com/cockroachdb/cockroach/pkg/sql/sqlbase
github.com/cockroachdb/cockroach/pkg/testutils/sqlutils
github.com/cockroachdb/cockroach/pkg/testutils/serverutils
github.com/cockroachdb/cockroach/pkg/sql/distsqlrun
github.com/cockroachdb/cockroach/pkg/storage/engine/rocksdb
github.com/cockroachdb/cockroach/pkg/storage/engine
github.com/cockroachdb/cockroach/pkg/storage
github.com/cockroachdb/cockroach/pkg/storage
github.com/cockroachdb/cockroach/pkg/sql
github.com/cockroachdb/cockroach/pkg/ts
github.com/cockroachdb/cockroach/pkg/sql/pgwire
github.com/cockroachdb/cockroach/pkg/server
github.com/cockroachdb/cockroach/pkg/testutils/testcluster
github.com/cockroachdb/cockroach/pkg/storage_test
testmain
0 runs so far, 0 failures, over 5s
0 runs so far, 0 failures, over 10s
0 runs so far, 0 failures, over 15s
0 runs so far, 0 failures, over 20s
0 runs so far, 0 failures, over 25s
0 runs so far, 0 failures, over 30s
0 runs so far, 0 failures, over 35s
0 runs so far, 0 failures, over 40s
0 runs so far, 0 failures, over 45s
0 runs so far, 0 failures, over 50s
0 runs so far, 0 failures, over 55s
0 runs so far, 0 failures, over 1m0s
0 runs so far, 0 failures, over 1m5s
0 runs so far, 0 failures, over 1m10s
0 runs so far, 0 failures, over 1m15s
1 runs so far, 0 failures, over 1m20s
3 runs so far, 0 failures, over 1m25s
6 runs so far, 0 failures, over 1m30s
6 runs so far, 0 failures, over 1m35s
6 runs so far, 0 failures, over 1m40s
6 runs so far, 0 failures, over 1m45s
6 runs so far, 0 failures, over 1m50s
6 runs so far, 0 failures, over 1m55s
6 runs so far, 0 failures, over 2m0s

E161116 07:20:23.435209 1 util/envutil/env.go:169  error parsing COCKROACH_PROPOSER_EVALUATED_KV: strconv.ParseBool: parsing "": invalid syntax
I161116 07:20:23.441067 1 rand.go:76  Random seed: -8301062165662417020
=== RUN   TestAbortCachePutGetClearData
I161116 07:20:23.457071 38 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.459188 38 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAbortCachePutGetClearData (0.02s)
=== RUN   TestAbortCacheEmptyParams
I161116 07:20:23.470231 4 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.471116 4 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAbortCacheEmptyParams (0.02s)
=== RUN   TestAbortCacheCopyInto
I161116 07:20:23.484397 6 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.485193 6 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.486210 6 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAbortCacheCopyInto (0.02s)
=== RUN   TestAbortCacheCopyFrom
I161116 07:20:23.501492 50 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.502488 50 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.503475 50 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAbortCacheCopyFrom (0.01s)
=== RUN   TestUpdateRangeAddressing
I161116 07:20:23.517362 53 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.517510 53 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.517704 53 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.518046 53 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:23.530438 59 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:23.553552 53 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestUpdateRangeAddressing (0.05s)
=== RUN   TestUpdateRangeAddressingSplitMeta1
--- PASS: TestUpdateRangeAddressingSplitMeta1 (0.02s)
=== RUN   TestAllocatorSimpleRetrieval
=== RUN   TestAllocatorSimpleRetrieval/without_rule_solver
I161116 07:20:23.589723 12 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.589823 12 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.589998 12 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.594658 12 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorSimpleRetrieval/with_rule_solver
I161116 07:20:23.596997 14 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.597108 14 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.597257 14 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.598321 14 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorSimpleRetrieval (0.02s)
    --- PASS: TestAllocatorSimpleRetrieval/without_rule_solver (0.01s)
    --- PASS: TestAllocatorSimpleRetrieval/with_rule_solver (0.00s)
=== RUN   TestAllocatorCorruptReplica
=== RUN   TestAllocatorCorruptReplica/without_rule_solver
I161116 07:20:23.608605 91 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.608690 91 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.608823 91 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.610653 91 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorCorruptReplica/with_rule_solver
I161116 07:20:23.611162 115 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.611252 115 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.611378 115 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.612804 115 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorCorruptReplica (0.02s)
    --- PASS: TestAllocatorCorruptReplica/without_rule_solver (0.00s)
    --- PASS: TestAllocatorCorruptReplica/with_rule_solver (0.00s)
=== RUN   TestAllocatorNoAvailableDisks
=== RUN   TestAllocatorNoAvailableDisks/without_rule_solver
I161116 07:20:23.628456 124 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.628555 124 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.628775 124 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.629130 124 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorNoAvailableDisks/with_rule_solver
I161116 07:20:23.631330 49 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.631434 49 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.631612 49 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.631960 49 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorNoAvailableDisks (0.02s)
    --- PASS: TestAllocatorNoAvailableDisks/without_rule_solver (0.01s)
    --- PASS: TestAllocatorNoAvailableDisks/with_rule_solver (0.00s)
=== RUN   TestAllocatorTwoDatacenters
=== RUN   TestAllocatorTwoDatacenters/without_rule_solver
I161116 07:20:23.647366 99 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.647455 99 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.647637 99 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.648835 99 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.648990 99 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
=== RUN   TestAllocatorTwoDatacenters/with_rule_solver
I161116 07:20:23.649490 104 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.649568 104 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.649733 104 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.650837 104 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorTwoDatacenters (0.04s)
    --- PASS: TestAllocatorTwoDatacenters/without_rule_solver (0.00s)
    --- PASS: TestAllocatorTwoDatacenters/with_rule_solver (0.00s)
=== RUN   TestAllocatorExistingReplica
=== RUN   TestAllocatorExistingReplica/without_rule_solver
I161116 07:20:23.676645 127 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.676747 127 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.677242 127 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.679047 127 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.679132 127 util/stop/stopper.go:468  quiescing; tasks left:
4      gossip/infostore.go:301
I161116 07:20:23.679263 127 util/stop/stopper.go:468  quiescing; tasks left:
3      gossip/infostore.go:301
I161116 07:20:23.679393 127 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:23.679469 127 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
=== RUN   TestAllocatorExistingReplica/with_rule_solver
I161116 07:20:23.681818 128 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.681924 128 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.685733 128 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.715346 128 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorExistingReplica (0.05s)
    --- PASS: TestAllocatorExistingReplica/without_rule_solver (0.00s)
    --- PASS: TestAllocatorExistingReplica/with_rule_solver (0.04s)
=== RUN   TestAllocatorRelaxConstraints
=== RUN   TestAllocatorRelaxConstraints/without_rule_solver
I161116 07:20:23.725998 164 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.726104 164 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.726250 164 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.728128 164 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver
I161116 07:20:23.728696 169 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.728773 169 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.728925 169 base/node_id.go:62  NodeID set to 1
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1)_with_existing_replica_(store_1)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1)_with_two_existing_replicas
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_two_existing_replicas
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(matching_store_1)_with_existing_replica_(store_1)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(matching_store_2)_with_exiting_replica_(store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_existing_replica_(store_1)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_existing_replica_(store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2)_with_existing_replica_(store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(half_matching_store_2)_with_existing_replica_(store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2)_with_two_existing_replica
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(2/3_matching_store_2)
=== RUN   TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(1/3_matching_store_2)
I161116 07:20:23.736951 169 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorRelaxConstraints (0.03s)
    --- PASS: TestAllocatorRelaxConstraints/without_rule_solver (0.00s)
    --- PASS: TestAllocatorRelaxConstraints/with_rule_solver (0.01s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1)_with_existing_replica_(store_1) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_1)_with_two_existing_replicas (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_two_existing_replicas (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(matching_store_1)_with_existing_replica_(store_1) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(matching_store_2)_with_exiting_replica_(store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_existing_replica_(store_1) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(matching_store_2)_with_existing_replica_(store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2)_with_existing_replica_(store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/required_constraints_(half_matching_store_2)_with_existing_replica_(store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(half_matching_store_2)_with_two_existing_replica (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(2/3_matching_store_2) (0.00s)
        --- PASS: TestAllocatorRelaxConstraints/with_rule_solver/positive_constraints_(1/3_matching_store_2) (0.00s)
=== RUN   TestAllocatorRebalance
=== RUN   TestAllocatorRebalance/without_rule_solver
I161116 07:20:23.756069 154 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.756153 154 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.756278 154 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.765396 154 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorRebalance/with_rule_solver
I161116 07:20:23.766083 132 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.766167 132 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.766301 132 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.768465 132 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorRebalance (0.02s)
    --- PASS: TestAllocatorRebalance/without_rule_solver (0.01s)
    --- PASS: TestAllocatorRebalance/with_rule_solver (0.00s)
=== RUN   TestAllocatorRebalanceThrashing
=== RUN   TestAllocatorRebalanceThrashing/without_rule_solver
I161116 07:20:23.783192 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.783276 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.783399 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.785079 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.785159 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.785279 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.788833 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.788949 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.789195 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.790993 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.791073 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.791220 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.793176 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.793286 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.793428 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.795824 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.795926 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.796050 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.805974 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.806494 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.806784 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.816435 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.816520 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.816642 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.818923 141 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.819004 141 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.819195 141 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.821919 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822043 141 util/stop/stopper.go:468  quiescing; tasks left:
7      gossip/infostore.go:301
I161116 07:20:23.822115 141 util/stop/stopper.go:468  quiescing; tasks left:
6      gossip/infostore.go:301
I161116 07:20:23.822201 141 util/stop/stopper.go:468  quiescing; tasks left:
5      gossip/infostore.go:301
I161116 07:20:23.822259 141 util/stop/stopper.go:468  quiescing; tasks left:
4      gossip/infostore.go:301
I161116 07:20:23.822422 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822510 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822602 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822685 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822775 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822860 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.822958 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.823040 141 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorRebalanceThrashing/with_rule_solver
I161116 07:20:23.823727 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.823806 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.823943 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.826063 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.826186 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.826314 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.829266 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.829382 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.829542 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.833413 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.833498 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.833618 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.835489 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.835590 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.835706 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.842931 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.843031 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.843174 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.845274 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.845357 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.845476 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.847558 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.847638 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.847755 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.849701 237 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.849780 237 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.849908 237 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.854401 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.854514 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.854682 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.854970 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.855150 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.855328 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.855529 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.855839 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:23.856056 237 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorRebalanceThrashing (0.11s)
    --- PASS: TestAllocatorRebalanceThrashing/without_rule_solver (0.04s)
    	allocator_test.go:812: test case 0: [{5 false} {5 false} {5 false} {5 false}]
    	allocator_test.go:812: test case 1: [{5 false} {5 false} {5 false} {6 false}]
    	allocator_test.go:812: test case 2: [{100 true} {100 true} {100 true} {0 false}]
    	allocator_test.go:812: test case 3: [{98 false} {99 false} {101 false} {102 false}]
    	allocator_test.go:812: test case 4: [{106 true} {98 false} {98 false} {98 false} {98 false}]
    	allocator_test.go:812: test case 5: [{1051 true} {987 false} {987 false} {987 false} {987 false}]
    	allocator_test.go:812: test case 6: [{10501 true} {9874 false} {9874 false} {9874 false} {9874 false}]
    	allocator_test.go:812: test case 7: [{949 false} {1013 true} {1013 true} {1013 true} {1013 true}]
    	allocator_test.go:812: test case 8: [{949 false} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true}]
    --- PASS: TestAllocatorRebalanceThrashing/with_rule_solver (0.03s)
    	allocator_test.go:812: test case 0: [{5 false} {5 false} {5 false} {5 false}]
    	allocator_test.go:812: test case 1: [{5 false} {5 false} {5 false} {6 false}]
    	allocator_test.go:812: test case 2: [{100 true} {100 true} {100 true} {0 false}]
    	allocator_test.go:812: test case 3: [{98 false} {99 false} {101 false} {102 false}]
    	allocator_test.go:812: test case 4: [{106 true} {98 false} {98 false} {98 false} {98 false}]
    	allocator_test.go:812: test case 5: [{1051 true} {987 false} {987 false} {987 false} {987 false}]
    	allocator_test.go:812: test case 6: [{10501 true} {9874 false} {9874 false} {9874 false} {9874 false}]
    	allocator_test.go:812: test case 7: [{949 false} {1013 true} {1013 true} {1013 true} {1013 true}]
    	allocator_test.go:812: test case 8: [{949 false} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true} {1006 true}]
=== RUN   TestAllocatorRebalanceByCount
=== RUN   TestAllocatorRebalanceByCount/without_rule_solver
I161116 07:20:23.879827 316 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.879943 316 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.880087 316 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.882004 316 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorRebalanceByCount/with_rule_solver
I161116 07:20:23.882667 197 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.882756 197 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.882885 197 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.884654 197 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorRebalanceByCount (0.02s)
    --- PASS: TestAllocatorRebalanceByCount/without_rule_solver (0.00s)
    --- PASS: TestAllocatorRebalanceByCount/with_rule_solver (0.00s)
=== RUN   TestAllocatorTransferLeaseTarget
I161116 07:20:23.903832 370 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.903979 370 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.904126 370 base/node_id.go:62  NodeID set to 1
=== RUN   TestAllocatorTransferLeaseTarget/0
=== RUN   TestAllocatorTransferLeaseTarget/1
=== RUN   TestAllocatorTransferLeaseTarget/2
=== RUN   TestAllocatorTransferLeaseTarget/3
=== RUN   TestAllocatorTransferLeaseTarget/4
=== RUN   TestAllocatorTransferLeaseTarget/5
=== RUN   TestAllocatorTransferLeaseTarget/6
I161116 07:20:23.907810 370 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorTransferLeaseTarget (0.03s)
    --- PASS: TestAllocatorTransferLeaseTarget/0 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/1 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/2 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/3 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/4 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/5 (0.00s)
    --- PASS: TestAllocatorTransferLeaseTarget/6 (0.00s)
=== RUN   TestAllocatorShouldTransferLease
I161116 07:20:23.930947 205 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.931071 205 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.931235 205 base/node_id.go:62  NodeID set to 1
=== RUN   TestAllocatorShouldTransferLease/0
=== RUN   TestAllocatorShouldTransferLease/1
=== RUN   TestAllocatorShouldTransferLease/2
I161116 07:20:23.933755 205 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorShouldTransferLease (0.01s)
    --- PASS: TestAllocatorShouldTransferLease/0 (0.00s)
    --- PASS: TestAllocatorShouldTransferLease/1 (0.00s)
    --- PASS: TestAllocatorShouldTransferLease/2 (0.00s)
=== RUN   TestAllocatorRemoveTarget
=== RUN   TestAllocatorRemoveTarget/without_rule_solver
I161116 07:20:23.957785 391 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.957884 391 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.958028 391 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.962374 391 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorRemoveTarget/with_rule_solver
I161116 07:20:23.963049 346 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.963132 346 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.963258 346 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.964745 346 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorRemoveTarget (0.03s)
    --- PASS: TestAllocatorRemoveTarget/without_rule_solver (0.01s)
    --- PASS: TestAllocatorRemoveTarget/with_rule_solver (0.00s)
=== RUN   TestAllocatorComputeAction
=== RUN   TestAllocatorComputeAction/without_rule_solver
I161116 07:20:23.982109 402 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.982193 402 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.982331 402 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.982638 402 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorComputeAction/with_rule_solver
I161116 07:20:23.983349 398 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:23.983432 398 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:23.983563 398 base/node_id.go:62  NodeID set to 1
I161116 07:20:23.983921 398 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorComputeAction (0.02s)
    --- PASS: TestAllocatorComputeAction/without_rule_solver (0.00s)
    --- PASS: TestAllocatorComputeAction/with_rule_solver (0.00s)
=== RUN   TestAllocatorComputeActionNoStorePool
=== RUN   TestAllocatorComputeActionNoStorePool/without_rule_solver
=== RUN   TestAllocatorComputeActionNoStorePool/with_rule_solver
--- PASS: TestAllocatorComputeActionNoStorePool (0.03s)
    --- PASS: TestAllocatorComputeActionNoStorePool/without_rule_solver (0.00s)
    --- PASS: TestAllocatorComputeActionNoStorePool/with_rule_solver (0.00s)
=== RUN   TestAllocatorError
--- PASS: TestAllocatorError (0.02s)
=== RUN   TestAllocatorThrottled
=== RUN   TestAllocatorThrottled/without_rule_solver
I161116 07:20:24.051346 410 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.051438 410 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.051597 410 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.052615 410 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
=== RUN   TestAllocatorThrottled/with_rule_solver
I161116 07:20:24.053140 414 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.053239 414 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.053366 414 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.054155 414 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAllocatorThrottled (0.02s)
    --- PASS: TestAllocatorThrottled/without_rule_solver (0.00s)
    --- PASS: TestAllocatorThrottled/with_rule_solver (0.00s)
=== RUN   TestCommandQueue
--- PASS: TestCommandQueue (0.02s)
=== RUN   TestCommandQueueWriteWaitForNonAdjacentRead
--- PASS: TestCommandQueueWriteWaitForNonAdjacentRead (0.01s)
=== RUN   TestCommandQueueNoWaitOnReadOnly
--- PASS: TestCommandQueueNoWaitOnReadOnly (0.01s)
=== RUN   TestCommandQueueMultipleExecutingCommands
--- PASS: TestCommandQueueMultipleExecutingCommands (0.04s)
=== RUN   TestCommandQueueMultiplePendingCommands
--- PASS: TestCommandQueueMultiplePendingCommands (0.03s)
=== RUN   TestCommandQueueRemove
--- PASS: TestCommandQueueRemove (0.01s)
=== RUN   TestCommandQueueExclusiveEnd
--- PASS: TestCommandQueueExclusiveEnd (0.01s)
=== RUN   TestCommandQueueSelfOverlap
--- PASS: TestCommandQueueSelfOverlap (0.01s)
=== RUN   TestCommandQueueCoveringOptimization
--- PASS: TestCommandQueueCoveringOptimization (0.03s)
=== RUN   TestCommandQueueWithoutCoveringOptimization
--- PASS: TestCommandQueueWithoutCoveringOptimization (0.02s)
=== RUN   TestCommandQueueIssue6495
--- PASS: TestCommandQueueIssue6495 (0.02s)
=== RUN   TestEntryCache
--- PASS: TestEntryCache (0.02s)
=== RUN   TestEntryCacheClearTo
--- PASS: TestEntryCacheClearTo (0.01s)
=== RUN   TestEntryCacheEviction
--- PASS: TestEntryCacheEviction (0.02s)
=== RUN   TestGCQueueShouldQueue
I161116 07:20:24.323789 422 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.323897 422 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.324073 422 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.324149 422 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.334381 426 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.345297 422 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGCQueueShouldQueue (0.04s)
=== RUN   TestGCQueueProcess
I161116 07:20:24.358373 442 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.358459 442 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.358583 442 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.358626 442 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.367041 442 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:24.368997 446 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.419600 442 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGCQueueProcess (0.07s)
=== RUN   TestGCQueueTransactionTable
I161116 07:20:24.433447 514 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.433537 514 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.433671 514 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.433738 514 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.442925 514 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:24.447364 518 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 72h0m0.900000001s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-04 00:00:00 +0000 UTC]
I161116 07:20:24.459417 474 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: boom
W161116 07:20:24.459999 514 storage/gc_queue.go:218  unable to resolve intents of committed txn on gc: boom
I161116 07:20:24.464923 514 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGCQueueTransactionTable (0.04s)
=== RUN   TestGCQueueIntentResolution
I161116 07:20:24.474402 521 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.474489 521 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.474621 521 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.474670 521 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.487766 521 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:24.489156 526 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.526070 521 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGCQueueIntentResolution (0.07s)
=== RUN   TestIDAllocator
I161116 07:20:24.545426 610 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.545527 610 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.545723 610 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.546012 610 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.563622 618 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.581105 610 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestIDAllocator (0.06s)
=== RUN   TestIDAllocatorNegativeValue
I161116 07:20:24.600786 674 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.600870 674 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.601048 674 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.601276 674 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.609898 680 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.761212 674 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:24.761297 674 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/id_alloc.go:108
W161116 07:20:24.761669 671 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command Increment [/System/"range-idgen",/Min)
W161116 07:20:24.761897 671 storage/id_alloc.go:117  unable to allocate 10 ids from /System/"range-idgen": result is ambiguous
W161116 07:20:24.818848 671 storage/id_alloc.go:109  node unavailable; try another peer
--- PASS: TestIDAllocatorNegativeValue (0.23s)
=== RUN   TestNewIDAllocatorInvalidArgs
--- PASS: TestNewIDAllocatorInvalidArgs (0.00s)
=== RUN   TestAllocateErrorAndRecovery
I161116 07:20:24.842424 588 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.842511 588 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.842672 588 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.842908 588 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.852785 722 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
W161116 07:20:24.858136 760 storage/id_alloc.go:117  unable to allocate 10 ids from /Min: attempted access to empty key
I161116 07:20:24.912401 588 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:24.912477 588 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/id_alloc.go:108
W161116 07:20:24.912832 760 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command Increment [/System/"range-idgen",/Min)
W161116 07:20:24.913004 760 storage/id_alloc.go:117  unable to allocate 10 ids from /System/"range-idgen": result is ambiguous
W161116 07:20:24.961665 760 storage/id_alloc.go:109  node unavailable; try another peer
--- PASS: TestAllocateErrorAndRecovery (0.13s)
=== RUN   TestAllocateWithStopper
I161116 07:20:24.976322 774 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:24.976416 774 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:24.976539 774 base/node_id.go:62  NodeID set to 1
I161116 07:20:24.976785 774 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:24.988829 720 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:24.991096 774 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:24.992760 766 storage/id_alloc.go:109  node unavailable; try another peer
--- PASS: TestAllocateWithStopper (0.03s)
=== RUN   TestPushTransactionsWithNonPendingIntent
I161116 07:20:25.008255 767 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.008342 767 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.008516 767 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.008559 767 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.015114 767 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.016840 851 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.020472 767 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:25.020551 767 util/stop/stopper.go:468  quiescing; tasks left:
4      gossip/infostore.go:301
--- PASS: TestPushTransactionsWithNonPendingIntent (0.03s)
=== RUN   TestMigrate7310And6991
I161116 07:20:25.043814 894 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
W161116 07:20:25.045091 894 storage/migration.go:56  migration: synthesized TruncatedState for {RangeID:1 StartKey:/Min EndKey:/Max Replicas:[{NodeID:1 StoreID:1 ReplicaID:1}] NextReplicaID:2}
W161116 07:20:25.045236 894 storage/migration.go:67  migration: synthesized HardState for {RangeID:1 StartKey:/Min EndKey:/Max Replicas:[{NodeID:1 StoreID:1 ReplicaID:1}] NextReplicaID:2}
I161116 07:20:25.045588 894 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestMigrate7310And6991 (0.03s)
=== RUN   TestQueuePriorityQueue
--- PASS: TestQueuePriorityQueue (0.02s)
=== RUN   TestBaseQueueAddUpdateAndRemove
I161116 07:20:25.080780 840 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.080864 840 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.081000 840 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.081059 840 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.086916 840 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.089712 844 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.093896 840 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:25.093970 840 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:25.094094 840 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestBaseQueueAddUpdateAndRemove (0.03s)
=== RUN   TestBaseQueueAdd
I161116 07:20:25.110045 932 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.110131 932 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.110298 932 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.110349 932 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.117672 932 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.124215 936 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.127188 932 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:25.127257 932 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestBaseQueueAdd (0.03s)
=== RUN   TestBaseQueueProcess
I161116 07:20:25.141470 963 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.141563 963 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.141747 963 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.141800 963 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.150206 967 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m26.048129976s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:25.150078143 +0000 UTC]
I161116 07:20:25.155708 963 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBaseQueueProcess (0.08s)
=== RUN   TestBaseQueueAddRemove
I161116 07:20:25.220821 996 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.220906 996 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.221078 996 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.221126 996 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.236828 996 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.238780 1001 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.242164 996 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:25.242241 996 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:25.242547 996 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestBaseQueueAddRemove (0.04s)
=== RUN   TestAcceptsUnsplitRanges
I161116 07:20:25.263723 1058 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.263810 1058 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.263989 1058 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.264239 1058 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.274296 1064 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.278960 1058 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAcceptsUnsplitRanges (0.03s)
=== RUN   TestBaseQueuePurgatory
I161116 07:20:25.291819 1089 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.291905 1089 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.292077 1089 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.292128 1089 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.305002 1018 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m26.203251514s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:25.30488407 +0000 UTC]
E161116 07:20:25.310633 1170 storage/queue.go:586  [s1,test,r1001/1:"1{"-/end"}] purgatory: test error
E161116 07:20:25.311724 1170 storage/queue.go:586  [s1,test,r1002/1:"2{"-/end"}] purgatory: test error
E161116 07:20:25.312624 1170 storage/queue.go:586  [s1,test,r1003/1:"3{"-/end"}] purgatory: test error
E161116 07:20:25.313402 1170 storage/queue.go:586  [s1,test,r1004/1:"4{"-/end"}] purgatory: test error
E161116 07:20:25.314396 1170 storage/queue.go:586  [s1,test,r1005/1:"5{"-/end"}] purgatory: test error
E161116 07:20:25.315344 1170 storage/queue.go:586  [s1,test,r1006/1:"6{"-/end"}] purgatory: test error
E161116 07:20:25.316220 1170 storage/queue.go:586  [s1,test,r1007/1:"7{"-/end"}] purgatory: test error
E161116 07:20:25.317127 1170 storage/queue.go:586  [s1,test,r1008/1:"8{"-/end"}] purgatory: test error
E161116 07:20:25.318151 1170 storage/queue.go:586  [s1,test,r1009/1:"9{"-/end"}] purgatory: test error
E161116 07:20:25.318983 1170 storage/queue.go:586  [s1,test,r1010/1:"10{"-/end"}] purgatory: test error
E161116 07:20:25.321475 1121 storage/queue.go:586  [s1,test,r1006/1:"6{"-/end"}] purgatory: test error
E161116 07:20:25.321704 1121 storage/queue.go:586  [s1,test,r1007/1:"7{"-/end"}] purgatory: test error
E161116 07:20:25.321917 1121 storage/queue.go:586  [s1,test,r1008/1:"8{"-/end"}] purgatory: test error
E161116 07:20:25.322142 1121 storage/queue.go:586  [s1,test,r1010/1:"10{"-/end"}] purgatory: test error
E161116 07:20:25.322346 1121 storage/queue.go:586  [s1,test,r1001/1:"1{"-/end"}] purgatory: test error
E161116 07:20:25.322549 1121 storage/queue.go:586  [s1,test,r1003/1:"3{"-/end"}] purgatory: test error
E161116 07:20:25.322745 1121 storage/queue.go:586  [s1,test,r1005/1:"5{"-/end"}] purgatory: test error
E161116 07:20:25.322949 1121 storage/queue.go:586  [s1,test,r1002/1:"2{"-/end"}] purgatory: test error
E161116 07:20:25.323147 1121 storage/queue.go:586  [s1,test,r1004/1:"4{"-/end"}] purgatory: test error
E161116 07:20:25.323343 1121 storage/queue.go:586  [s1,test,r1009/1:"9{"-/end"}] purgatory: test error
I161116 07:20:25.325393 1121 storage/queue.go:638  [s1,test] purgatory is now empty
I161116 07:20:25.325936 1089 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBaseQueuePurgatory (0.05s)
=== RUN   TestBaseQueueProcessTimeout
I161116 07:20:25.337314 1123 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.337399 1123 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.337573 1123 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.337620 1123 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.345519 1123 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.348171 1132 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
E161116 07:20:25.353151 1201 storage/queue.go:575  [s1,test,r1/1:/M{in-ax}] context deadline exceeded
I161116 07:20:25.353203 1123 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBaseQueueProcessTimeout (0.03s)
=== RUN   TestBaseQueueTimeMetric
I161116 07:20:25.385584 1155 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.385674 1155 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.385849 1155 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.385896 1155 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.395828 1206 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.410546 1155 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBaseQueueTimeMetric (0.08s)
=== RUN   TestGetQuorumIndex
--- PASS: TestGetQuorumIndex (0.01s)
=== RUN   TestComputeTruncatableIndex
--- PASS: TestComputeTruncatableIndex (0.01s)
=== RUN   TestGetTruncatableIndexes
I161116 07:20:25.471835 1266 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.471930 1266 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.472076 1266 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.472311 1266 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.506335 1274 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:25.729716 1266 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGetTruncatableIndexes (0.31s)
=== RUN   TestProactiveRaftLogTruncate
--- SKIP: TestProactiveRaftLogTruncate (0.01s)
	raft_log_queue_test.go:228: #9772
=== RUN   TestReplicaDataIteratorEmptyRange
I161116 07:20:25.795788 1184 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.795872 1184 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.796039 1184 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.796090 1184 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.800945 1184 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.806490 1184 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaDataIteratorEmptyRange (0.03s)
=== RUN   TestReplicaDataIterator
I161116 07:20:25.814730 1342 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.814822 1342 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.814957 1342 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.815009 1342 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.825921 1342 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:25.831790 1342 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaDataIterator (0.09s)
=== RUN   TestReplicaGCShouldQueue
--- PASS: TestReplicaGCShouldQueue (0.01s)
=== RUN   TestSkipLargeReplicaSnapshot
I161116 07:20:25.915859 1362 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:25.915969 1362 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:25.916198 1362 base/node_id.go:62  NodeID set to 1
I161116 07:20:25.916492 1362 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:25.927061 1368 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m26.823830867s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:25.926933375 +0000 UTC]
I161116 07:20:27.507927 1362 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot a5e0497f at index 932
I161116 07:20:31.156200 1362 storage/replica_raftstorage.go:290  [s1,r1/1:/M{in-ax}] [n1,s1,r1/1:/M{in-ax}]: not generating snapshot because replica is too large: 3078608 > 2 * 1048576
I161116 07:20:31.156244 1362 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSkipLargeReplicaSnapshot (5.25s)
=== RUN   TestSynthesizeHardState
I161116 07:20:31.167331 1390 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.168758 1390 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSynthesizeHardState (0.07s)
=== RUN   TestIsOnePhaseCommit
--- PASS: TestIsOnePhaseCommit (0.00s)
=== RUN   TestReplicaContains
--- PASS: TestReplicaContains (0.01s)
=== RUN   TestReplicaReadConsistency
I161116 07:20:31.257608 1261 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.257727 1261 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.257945 1261 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.258017 1261 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.264949 1261 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.268161 1265 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.276952 1427 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.278711 1261 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaReadConsistency (0.03s)
=== RUN   TestBehaviorDuringLeaseTransfer
I161116 07:20:31.288452 1466 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.288540 1466 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.288683 1466 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.288763 1466 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.295497 1466 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.296642 1402 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 1.000000123s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.302732 1404 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: storage/replica_test.go:543: injected transfer error
I161116 07:20:31.306126 1466 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBehaviorDuringLeaseTransfer (0.10s)
=== RUN   TestApplyCmdLeaseError
I161116 07:20:31.388549 1468 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.388663 1468 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.388830 1468 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.388879 1468 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.395783 1468 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.398003 1507 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.402489 1473 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.403182 1468 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestApplyCmdLeaseError (0.09s)
=== RUN   TestReplicaRangeBoundsChecking
I161116 07:20:31.467560 1545 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.467660 1545 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.467832 1545 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.467880 1545 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.477955 1545 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.480094 1555 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.486179 1558 storage/replica_proposal.go:332  [s1,r2/1:{"a"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.487423 1545 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaRangeBoundsChecking (0.06s)
=== RUN   TestReplicaLease
I161116 07:20:31.529909 1585 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.530011 1585 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.530146 1585 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.530199 1585 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.539798 1585 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.539866 1627 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.545194 1623 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.546975 1585 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLease (0.08s)
=== RUN   TestReplicaNotLeaseHolderError
I161116 07:20:31.625423 1491 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.625510 1491 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.625650 1491 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.625696 1491 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.641654 1495 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.647474 1497 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.650024 1491 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNotLeaseHolderError (0.11s)
=== RUN   TestReplicaLeaseCounters
I161116 07:20:31.716355 1163 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.716439 1163 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.716602 1163 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.716662 1163 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.724108 1163 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.727291 1167 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.732613 1163 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLeaseCounters (0.02s)
=== RUN   TestReplicaGossipConfigsOnLease
I161116 07:20:31.753641 1590 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.753778 1590 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.753939 1590 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.753987 1590 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.767744 1596 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.777522 1597 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.778997 1595 storage/replica_proposal.go:332  new range lease replica {1 1 1} 1970-01-01 00:00:00.900000135 +0000 UTC 22ns following replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 11ns [physicalTime=1970-01-01 00:00:00.900000137 +0000 UTC]
I161116 07:20:31.780787 1590 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaGossipConfigsOnLease (0.13s)
=== RUN   TestReplicaTSCacheLowWaterOnLease
I161116 07:20:31.867903 1783 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.867990 1783 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.868116 1783 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.868165 1783 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.874015 1783 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.876971 1777 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.886476 1799 storage/replica_proposal.go:381  range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:20:31.887802 1798 storage/replica_proposal.go:332  new range lease replica {1 1 1} 1970-01-01 00:00:00.900000175 +0000 UTC 20ns following replica {2 2 2} 1970-01-01 00:00:00.900000155 +0000 UTC 20ns [physicalTime=1970-01-01 00:00:00.900000125 +0000 UTC]
I161116 07:20:31.888762 1783 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaTSCacheLowWaterOnLease (0.03s)
=== RUN   TestReplicaLeaseRejectUnknownRaftNodeID
I161116 07:20:31.897866 1785 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.897954 1785 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.898112 1785 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.898158 1785 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.904099 1785 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.907291 1789 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.916756 1785 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLeaseRejectUnknownRaftNodeID (0.04s)
=== RUN   TestReplicaDrainLease
I161116 07:20:31.942889 1877 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.942988 1877 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.943159 1877 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.943211 1877 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.951027 1877 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.951578 1889 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.966471 1877 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:31.966551 1877 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/replica_test.go:1143
--- PASS: TestReplicaDrainLease (0.03s)
=== RUN   TestReplicaGossipFirstRange
I161116 07:20:31.978077 1912 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:31.978175 1912 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:31.978370 1912 base/node_id.go:62  NodeID set to 1
I161116 07:20:31.978424 1912 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:31.985856 1940 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:31.986684 1912 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:31.987873 1912 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:31.987941 1912 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:31.988068 1912 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestReplicaGossipFirstRange (0.08s)
=== RUN   TestReplicaGossipAllConfigs
I161116 07:20:32.052579 1973 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.052678 1973 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.052869 1973 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.052926 1973 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.060929 1977 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.063630 1973 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:32.063717 1973 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestReplicaGossipAllConfigs (0.02s)
=== RUN   TestReplicaNoGossipConfig
I161116 07:20:32.072847 2004 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.072935 2004 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.073062 2004 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.073113 2004 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.078365 2004 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.082004 2009 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.105893 2004 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNoGossipConfig (0.05s)
=== RUN   TestReplicaNoGossipFromNonLeader
I161116 07:20:32.127189 2035 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.127278 2035 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.127401 2035 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.127447 2035 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.145219 2035 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.147839 2080 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.157887 2035 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNoGossipFromNonLeader (0.04s)
=== RUN   TestOptimizePuts
I161116 07:20:32.175916 2046 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.176032 2046 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.176201 2046 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.176253 2046 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.182658 2046 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.184640 2063 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.199438 2046 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestOptimizePuts (0.10s)
=== RUN   TestAcquireLease
I161116 07:20:32.275318 2049 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.275417 2049 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.275569 2049 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.275636 2049 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.281568 2049 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.283698 2165 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.294645 2049 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:32.295765 2049 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.295845 2049 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.295966 2049 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.296000 2049 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.302847 2049 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.304550 2219 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.314684 2049 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAcquireLease (0.07s)
=== RUN   TestLeaseConcurrent
I161116 07:20:32.338100 2186 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.338200 2186 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.338394 2186 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.338443 2186 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.346503 2186 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.350084 2191 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.355214 2186 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:32.356450 2186 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.356536 2186 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.356862 2186 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.356917 2186 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.364813 2186 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.366983 2290 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.372299 2186 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestLeaseConcurrent (0.05s)
=== RUN   TestReplicaUpdateTSCache
I161116 07:20:32.385507 2276 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.385610 2276 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.387144 2276 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.387196 2276 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.402447 2276 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.405642 2280 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.412691 2276 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaUpdateTSCache (0.05s)
=== RUN   TestReplicaCommandQueue
I161116 07:20:32.430413 2364 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.430516 2364 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.430743 2364 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.430797 2364 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.436978 2364 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.439029 2368 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m33.33703938s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:32.438909644 +0000 UTC]
=== RUN   TestReplicaCommandQueue/read-read
=== RUN   TestReplicaCommandQueue/read-read-noop
=== RUN   TestReplicaCommandQueue/read-write
=== RUN   TestReplicaCommandQueue/read-write-noop
=== RUN   TestReplicaCommandQueue/write-read
=== RUN   TestReplicaCommandQueue/write-read-noop
=== RUN   TestReplicaCommandQueue/write-write
=== RUN   TestReplicaCommandQueue/write-write-noop
I161116 07:20:32.462032 2364 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaCommandQueue (0.05s)
    --- PASS: TestReplicaCommandQueue/read-read (0.00s)
    --- PASS: TestReplicaCommandQueue/read-read-noop (0.00s)
    --- PASS: TestReplicaCommandQueue/read-write (0.00s)
    --- PASS: TestReplicaCommandQueue/read-write-noop (0.00s)
    --- PASS: TestReplicaCommandQueue/write-read (0.00s)
    --- PASS: TestReplicaCommandQueue/write-read-noop (0.00s)
    --- PASS: TestReplicaCommandQueue/write-write (0.00s)
    --- PASS: TestReplicaCommandQueue/write-write-noop (0.00s)
=== RUN   TestReplicaCommandQueueInconsistent
I161116 07:20:32.482464 2427 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.482550 2427 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.482719 2427 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.482769 2427 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.488278 2427 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.490480 2494 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m33.38838118s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:32.490354548 +0000 UTC]
I161116 07:20:32.494296 2427 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaCommandQueueInconsistent (0.07s)
=== RUN   TestReplicaCommandQueueCancellation
I161116 07:20:32.559690 2506 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.560076 2506 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.560268 2506 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.560317 2506 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.574644 2506 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.577672 2510 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m33.474768908s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:32.577552604 +0000 UTC]
I161116 07:20:32.581321 2511 storage/replica_test.go:2144  starting to block header:<key:"one" > value:<raw_bytes:"\000\000\000\000\003" timestamp:<wall_time:0 logical:0 > > inline:false blind:false 
W161116 07:20:32.581854 2337 storage/replica.go:1285  [s1,r1/1:/M{in-ax}] context canceled before command queue: Put ["one",/Min), Put ["two",/Min)
W161116 07:20:32.582771 2562 storage/replica.go:1310  [s1,r1/1:/M{in-ax}] context canceled while in command queue: Put ["one",/Min), Put ["two",/Min)
I161116 07:20:32.583599 2506 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:32.583670 2506 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/store.go:1123
--- PASS: TestReplicaCommandQueueCancellation (0.04s)
=== RUN   TestReplicaUseTSCache
I161116 07:20:32.598739 2558 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.598841 2558 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.599012 2558 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.599073 2558 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.608307 2558 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.610888 2587 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.620601 2558 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaUseTSCache (0.05s)
=== RUN   TestReplicaNoTSCacheInconsistent
I161116 07:20:32.647430 2529 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.647537 2529 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.647668 2529 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.647715 2529 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.661433 2529 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.663035 2613 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.668485 2529 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNoTSCacheInconsistent (0.11s)
=== RUN   TestReplicaNoTSCacheUpdateOnFailure
I161116 07:20:32.757656 2662 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.757751 2662 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.757877 2662 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.757918 2662 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.763227 2662 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.765313 2607 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.779168 2662 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNoTSCacheUpdateOnFailure (0.04s)
=== RUN   TestReplicaNoTimestampIncrementWithinTxn
I161116 07:20:32.794269 2648 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.794369 2648 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.794509 2648 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.794562 2648 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.801124 2648 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.802530 2707 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.807977 2648 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaNoTimestampIncrementWithinTxn (0.03s)
=== RUN   TestReplicaAbortCacheReadError
I161116 07:20:32.832213 2348 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.832303 2348 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.832499 2348 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.832548 2348 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.839207 2348 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.841530 2352 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
E161116 07:20:32.845827 2738 storage/replica.go:4086  [s1,r1/1:/M{in-ax}] stalling replica due to: could not read from abort cache: proto: illegal wireType 6
I161116 07:20:32.846472 2348 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaAbortCacheReadError (0.03s)
=== RUN   TestReplicaAbortCacheStoredTxnRetryError
I161116 07:20:32.882008 2791 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.882150 2791 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.882346 2791 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.882445 2791 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.900199 2791 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.901635 2795 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.915683 2791 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaAbortCacheStoredTxnRetryError (0.07s)
=== RUN   TestTransactionRetryLeavesIntents
I161116 07:20:32.933102 2771 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.933193 2771 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.933341 2771 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.933410 2771 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.939141 2771 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:32.941388 2775 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.947423 2771 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestTransactionRetryLeavesIntents (0.03s)
=== RUN   TestReplicaAbortCacheOnlyWithIntent
I161116 07:20:32.969213 2477 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:32.969304 2477 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:32.969488 2477 base/node_id.go:62  NodeID set to 1
I161116 07:20:32.969538 2477 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:32.977702 2481 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:32.983123 2477 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaAbortCacheOnlyWithIntent (0.09s)
=== RUN   TestEndTransactionDeadline
I161116 07:20:33.057196 2869 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.057281 2869 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.057406 2869 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.057458 2869 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.064183 2869 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.067441 2847 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.100788 2869 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionDeadline (0.06s)
=== RUN   TestEndTransactionTxnSpanGCThreshold
I161116 07:20:33.126905 2873 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.127866 2873 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.128013 2873 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.128076 2873 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.141914 2873 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.144061 2972 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.158315 2873 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionTxnSpanGCThreshold (0.05s)
=== RUN   TestEndTransactionDeadline_1PC
I161116 07:20:33.169461 2949 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.169548 2949 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.169675 2949 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.169722 2949 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.175138 2949 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.177354 2953 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.181424 2949 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionDeadline_1PC (0.02s)
=== RUN   TestEndTransactionWithMalformedSplitTrigger
I161116 07:20:33.188125 3013 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.188229 3013 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.188371 3013 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.188417 3013 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.213554 3013 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.216540 3018 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
E161116 07:20:33.221750 3017 storage/replica.go:4086  [s1,r1/1:/M{in-ax}] stalling replica due to: range does not match splits: ("bar"-/Min) + (/Min-/Min) != [n1,s1,r1/1:/M{in-ax}]
I161116 07:20:33.222340 3013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionWithMalformedSplitTrigger (0.04s)
=== RUN   TestEndTransactionBeforeHeartbeat
I161116 07:20:33.231871 3090 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.231956 3090 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.232089 3090 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.232138 3090 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.240116 3094 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.249625 3090 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionBeforeHeartbeat (0.08s)
=== RUN   TestEndTransactionAfterHeartbeat
I161116 07:20:33.311313 3039 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.311404 3039 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.311549 3039 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.311600 3039 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.317639 3039 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.321252 3139 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.330413 3039 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionAfterHeartbeat (0.03s)
=== RUN   TestEndTransactionWithPushedTimestamp
I161116 07:20:33.343156 2312 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.343243 2312 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.343365 2312 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.343407 2312 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.351956 2316 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.375223 2312 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionWithPushedTimestamp (0.05s)
=== RUN   TestEndTransactionWithIncrementedEpoch
I161116 07:20:33.398273 3161 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.398358 3161 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.399311 3161 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.399438 3161 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.409403 3161 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.412220 3165 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.424243 3161 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionWithIncrementedEpoch (0.10s)
=== RUN   TestEndTransactionWithErrors
I161116 07:20:33.499578 3195 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.499705 3195 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.499871 3195 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.499938 3195 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.508499 3195 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.510537 3199 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.527105 3195 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionWithErrors (0.04s)
=== RUN   TestEndTransactionRollbackAbortedTransaction
I161116 07:20:33.539129 3306 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.539218 3306 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.539346 3306 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.539394 3306 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.544702 3306 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.546688 3310 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.552584 3306 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionRollbackAbortedTransaction (0.03s)
=== RUN   TestRaftReplayProtection
I161116 07:20:33.568591 3278 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.568688 3278 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.568842 3278 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.568903 3278 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.596400 3278 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.604761 3378 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.622896 3278 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftReplayProtection (0.07s)
=== RUN   TestRaftReplayProtectionInTxn
I161116 07:20:33.641772 3376 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.641868 3376 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.642006 3376 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.642055 3376 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.647557 3376 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.651192 3412 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.548147334s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:33.651053235 +0000 UTC]
I161116 07:20:33.657081 3376 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftReplayProtectionInTxn (0.02s)
=== RUN   TestReplicaLaziness
I161116 07:20:33.665787 3432 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.665910 3432 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.666121 3432 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.666170 3432 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.673724 3432 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.685127 3456 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.697440 3432 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:33.698463 3432 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.698548 3432 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.698670 3432 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.698710 3432 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.702651 3432 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.706574 3493 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.708467 3432 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:33.709625 3432 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.709737 3432 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.709895 3432 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.709938 3432 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.713996 3432 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.720629 3538 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.722254 3432 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLaziness (0.07s)
=== RUN   TestReplayProtection
I161116 07:20:33.750815 3525 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.750916 3525 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.751042 3525 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.751087 3525 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.762942 3525 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.766176 3567 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.783245 3525 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplayProtection (0.06s)
=== RUN   TestDuplicateBeginTransaction
I161116 07:20:33.794861 1611 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.794962 1611 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.795134 1611 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.795183 1611 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.801787 1611 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.802983 1615 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.807624 1611 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestDuplicateBeginTransaction (0.03s)
=== RUN   TestEndTransactionLocalGC
I161116 07:20:33.816514 3532 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.816597 3532 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.816720 3532 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.816767 3532 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.825560 3532 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.827408 3536 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.725611655s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:33.827294613 +0000 UTC]
I161116 07:20:33.855366 3532 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:33.855490 3532 util/stop/stopper.go:468  quiescing; tasks left:
3      storage/intent_resolver.go:383
1      storage/replica_range_lease.go:159
I161116 07:20:33.856278 3659 storage/replica_proposal.go:332  [s1,r2/1:{"c"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.750667533s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:33.856138524 +0000 UTC]
W161116 07:20:33.856616 3659 gossip/infostore.go:303  [n1] node unavailable; try another peer
W161116 07:20:33.857511 2765 storage/replica.go:1810  [s1,r2/1:{"c"-/Max}] shutdown cancellation of command ResolveIntentRange ["c","c\x00")
W161116 07:20:33.857751 2765 storage/intent_resolver.go:337  [n1,s1,r1/1:{/Min-"c"}]: failed to resolve intents: result is ambiguous
W161116 07:20:33.858196 2767 storage/replica.go:1810  [s1,r2/1:{"c"-/Max}] shutdown cancellation of command ResolveIntentRange ["c","q")
W161116 07:20:33.858387 2767 storage/intent_resolver.go:337  [n1,s1,r1/1:{/Min-"c"}]: failed to resolve intents: result is ambiguous
I161116 07:20:33.860091 3532 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
W161116 07:20:33.860318 2768 storage/replica.go:1810  [s1,r2/1:{"c"-/Max}] shutdown cancellation of command ResolveIntent ["c",/Min)
W161116 07:20:33.863260 2768 storage/intent_resolver.go:337  [n1,s1,r1/1:{/Min-"c"}]: failed to resolve intents: result is ambiguous
--- PASS: TestEndTransactionLocalGC (0.06s)
=== RUN   TestEndTransactionResolveOnlyLocalIntents
I161116 07:20:33.881949 3675 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.882050 3675 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.882180 3675 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.882228 3675 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.887409 3675 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.890389 3486 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.787507624s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:33.89027442 +0000 UTC]
I161116 07:20:33.903352 3489 storage/replica_proposal.go:332  [s1,r2/1:{"a\x00"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.801511515s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:33.903219374 +0000 UTC]
I161116 07:20:33.907960 3700 storage/replica_command.go:87  [s1,r2/1:{"a\x00"-/Max}] test injecting error: boom
W161116 07:20:33.908367 3584 storage/intent_resolver.go:337  [n1,s1,r1/1:{/Min-"a\x00"}]: failed to resolve intents: boom
I161116 07:20:33.909896 3675 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionResolveOnlyLocalIntents (0.04s)
=== RUN   TestEndTransactionDirectGC
I161116 07:20:33.935065 3585 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.935188 3585 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.935393 3585 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.935436 3585 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.941953 3585 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:33.945061 3734 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.960311 3736 storage/replica_proposal.go:332  [s1,r2/1:{"a\x00"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:33.968693 3585 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:33.969939 3585 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:33.970043 3585 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:33.970171 3585 base/node_id.go:62  NodeID set to 1
I161116 07:20:33.970211 3585 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:33.992248 3760 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.001665 3758 storage/replica_proposal.go:332  [s1,r2/1:{"a\x00"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.011113 3585 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:34.012444 3585 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.012527 3585 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.012653 3585 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.012692 3585 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.018229 3585 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.020474 3834 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.028027 3837 storage/replica_proposal.go:332  [s1,r2/1:{"a\x00"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.036554 3585 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionDirectGC (0.14s)
=== RUN   TestEndTransactionDirectGCFailure
I161116 07:20:34.054507 3693 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.054629 3693 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.054985 3693 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.055116 3693 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.075252 3791 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.973419741s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:34.0751363 +0000 UTC]
I161116 07:20:34.076909 3693 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.082562 3792 storage/replica_proposal.go:332  [s1,r2/1:{"a\x00"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m34.980947905s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:34.082445457 +0000 UTC]
I161116 07:20:34.086733 3793 storage/replica_command.go:87  [s1,r2/1:{"a\x00"-/Max}] test injecting error: boom
W161116 07:20:34.087980 3856 storage/intent_resolver.go:337  [n1,s1,r1/1:{/Min-"a\x00"}]: failed to resolve intents: boom
I161116 07:20:34.088933 3693 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionDirectGCFailure (0.06s)
=== RUN   TestEndTransactionDirectGC_1PC
I161116 07:20:34.110765 3807 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.110855 3807 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.111016 3807 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.111070 3807 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.117347 3807 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.120570 3939 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.124730 3807 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:34.127057 3807 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.127145 3807 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.127276 3807 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.127317 3807 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.132963 3807 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.136394 3972 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.142274 3807 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEndTransactionDirectGC_1PC (0.05s)
=== RUN   TestReplicaResolveIntentNoWait
I161116 07:20:34.159378 4018 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.159467 4018 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.159697 4018 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.159775 4018 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.166795 4018 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.168755 4022 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m35.066839816s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:34.168639078 +0000 UTC]
I161116 07:20:34.176230 4026 storage/replica_proposal.go:332  [s1,r2/1:{"aa"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m35.074630189s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:34.17610514 +0000 UTC]
I161116 07:20:34.182462 4018 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaResolveIntentNoWait (0.03s)
=== RUN   TestSequenceCachePoisonOnResolve
I161116 07:20:34.190308 4083 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.190391 4083 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.190557 4083 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.190601 4083 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.204473 4083 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.207628 4089 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.215084 4083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:34.216421 4083 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.216514 4083 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.216652 4083 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.216697 4083 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.222173 4083 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.224520 4064 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.232041 4083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:34.233487 4083 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.233574 4083 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.233706 4083 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.233746 4083 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.239208 4083 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.241784 3245 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.266284 4083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:34.280495 4083 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.280593 4083 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.280730 4083 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.280768 4083 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.286659 4083 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.296501 4127 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.314717 4083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSequenceCachePoisonOnResolve (0.14s)
=== RUN   TestAbortCacheError
I161116 07:20:34.327812 4234 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.327910 4234 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.328036 4234 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.328083 4234 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.341298 4234 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.345673 4238 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.348416 4234 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAbortCacheError (0.04s)
=== RUN   TestPushTxnBadKey
I161116 07:20:34.364746 2769 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.364832 2769 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.364968 2769 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.365016 2769 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.376553 2769 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.378683 4293 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.382008 2769 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnBadKey (0.02s)
=== RUN   TestPushTxnAlreadyCommittedOrAborted
I161116 07:20:34.398117 4014 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.398204 4014 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.398330 4014 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.398378 4014 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.409561 4014 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.413316 4354 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.422770 4014 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnAlreadyCommittedOrAborted (0.10s)
=== RUN   TestPushTxnUpgradeExistingTxn
I161116 07:20:34.490030 4327 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.490118 4327 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.490243 4327 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.490291 4327 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.502976 4327 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.505324 4331 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.515944 4327 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnUpgradeExistingTxn (0.04s)
=== RUN   TestPushTxnHeartbeatTimeout
I161116 07:20:34.528882 4436 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.528987 4436 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.529135 4436 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.529188 4436 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.535709 4436 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.538780 4440 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.621012 4436 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnHeartbeatTimeout (0.11s)
=== RUN   TestResolveIntentPushTxnReplyTxn
I161116 07:20:34.637576 4361 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.637661 4361 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.637780 4361 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.637825 4361 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.674207 4361 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.675429 4430 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.679148 4361 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestResolveIntentPushTxnReplyTxn (0.07s)
=== RUN   TestPushTxnPriorities
I161116 07:20:34.702775 4397 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.702873 4397 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.703040 4397 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.703099 4397 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.708966 4397 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.712869 4562 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.787041 4397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnPriorities (0.11s)
=== RUN   TestPushTxnPushTimestamp
I161116 07:20:34.814677 4549 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.814761 4549 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.814884 4549 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.814943 4549 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.822698 4553 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.827846 4549 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnPushTimestamp (0.02s)
=== RUN   TestPushTxnPushTimestampAlreadyPushed
I161116 07:20:34.849341 4592 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.849430 4592 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.849582 4592 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.849634 4592 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.865854 4592 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.867751 4644 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.872902 4592 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnPushTimestampAlreadyPushed (0.06s)
=== RUN   TestPushTxnSerializableRestart
I161116 07:20:34.916690 4630 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.916807 4630 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.916968 4630 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.917022 4630 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.922394 4630 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.925370 4686 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.933179 4630 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPushTxnSerializableRestart (0.04s)
=== RUN   TestReplicaResolveIntentRange
I161116 07:20:34.939072 4724 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.939176 4724 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.939327 4724 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.939388 4724 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.951574 4724 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.954531 4720 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.960305 4724 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaResolveIntentRange (0.03s)
=== RUN   TestReplicaStatsComputation
I161116 07:20:34.968395 4778 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:34.968478 4778 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:34.968648 4778 base/node_id.go:62  NodeID set to 1
I161116 07:20:34.968697 4778 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:34.974562 4778 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:34.978346 4760 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:34.985974 4778 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaStatsComputation (0.03s)
=== RUN   TestMerge
I161116 07:20:35.000512 4536 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.000606 4536 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.000736 4536 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.000788 4536 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.008002 4536 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.010918 4806 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.021438 4536 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestMerge (0.06s)
=== RUN   TestTruncateLog
I161116 07:20:35.049840 4243 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.049927 4243 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.050061 4243 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.050109 4243 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.062732 4243 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.064444 4780 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.090742 4868 storage/replica_command.go:1565  [s1,r1/1:/M{in-ax}] attempting to truncate raft logs for another range 2. Normally this is due to a merge and can be ignored.
I161116 07:20:35.091328 4243 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestTruncateLog (0.05s)
=== RUN   TestConditionFailedError
I161116 07:20:35.107394 4898 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.107502 4898 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.107646 4898 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.107738 4898 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.114890 4898 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.116958 4839 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.132667 4898 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestConditionFailedError (0.04s)
=== RUN   TestReplicaSetsEqual
--- PASS: TestReplicaSetsEqual (0.01s)
=== RUN   TestAppliedIndex
I161116 07:20:35.150881 4922 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.151010 4922 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.151209 4922 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.151271 4922 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.159222 4922 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.165639 4926 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.199409 4922 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestAppliedIndex (0.06s)
=== RUN   TestReplicaCorruption
I161116 07:20:35.207864 4979 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.207964 4979 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.208120 4979 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.208173 4979 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.223290 4971 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m36.121144073s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:35.223150443 +0000 UTC]
I161116 07:20:35.232651 4973 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: replica corruption (processed=false): boom
E161116 07:20:35.232749 4973 storage/replica.go:4086  [s1,r1/1:/M{in-ax}] stalling replica due to: boom
I161116 07:20:35.233441 4979 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaCorruption (0.04s)
=== RUN   TestChangeReplicasDuplicateError
I161116 07:20:35.243735 5034 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.243822 5034 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.244028 5034 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.244081 5034 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.249729 5034 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.251933 5038 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.254207 5034 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestChangeReplicasDuplicateError (0.02s)
=== RUN   TestReplicaDanglingMetaIntent
I161116 07:20:35.261651 4960 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.261863 4960 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.262067 4960 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.262143 4960 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.270581 4960 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.273828 5076 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.282419 4960 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:35.282491 4960 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/intent_resolver.go:317
I161116 07:20:35.282660 4960 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
W161116 07:20:35.283231 4321 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["a",/Min)
W161116 07:20:35.283432 4321 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
I161116 07:20:35.285254 4960 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.286665 4960 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.286797 4960 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.286846 4960 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.294069 4960 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.296529 5018 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.303016 4960 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:35.303133 4960 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/intent_resolver.go:317
W161116 07:20:35.303953 5163 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["a",/Min)
W161116 07:20:35.304147 5163 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
I161116 07:20:35.305039 4960 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
W161116 07:20:35.305856 5162 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["a",/Min)
W161116 07:20:35.306013 5162 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
--- PASS: TestReplicaDanglingMetaIntent (0.12s)
=== RUN   TestReplicaLookupUseReverseScan
I161116 07:20:35.378431 5164 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.378518 5164 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.378686 5164 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.378737 5164 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.386199 5164 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.387379 5168 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.406657 5164 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:35.406729 5164 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/intent_resolver.go:317
W161116 07:20:35.408069 5195 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn [/Min,/Min)
W161116 07:20:35.408222 5195 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
I161116 07:20:35.408309 5164 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
--- PASS: TestReplicaLookupUseReverseScan (0.06s)
=== RUN   TestRangeLookup
I161116 07:20:35.435851 5146 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.435939 5146 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.436115 5146 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.436163 5146 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.444296 5146 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.444822 5150 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.448675 5146 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeLookup (0.02s)
=== RUN   TestRequestLeaderEncounterGroupDeleteError
I161116 07:20:35.462637 4891 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.462725 4891 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.462890 4891 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.462932 4891 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.472527 4891 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.473738 4895 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.477817 4891 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRequestLeaderEncounterGroupDeleteError (0.08s)
=== RUN   TestIntentIntersect
--- PASS: TestIntentIntersect (0.01s)
=== RUN   TestBatchErrorWithIndex
I161116 07:20:35.560685 5319 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.560796 5319 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.560955 5319 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.561017 5319 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.568320 5319 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.571348 5261 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.577874 5319 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:35.577979 5319 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestBatchErrorWithIndex (0.04s)
=== RUN   TestReplicaLoadSystemConfigSpanIntent
I161116 07:20:35.602988 5245 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.603089 5245 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.603221 5245 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.603267 5245 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.609336 5245 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.612164 5248 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.631707 5245 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLoadSystemConfigSpanIntent (0.05s)
=== RUN   TestReplicaDestroy
I161116 07:20:35.651359 5203 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.651446 5203 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.651632 5203 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.651687 5203 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.657962 5203 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.660980 5373 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.663651 5203 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:35.663722 5203 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestReplicaDestroy (0.10s)
=== RUN   TestEntries
I161116 07:20:35.744542 5353 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.744629 5353 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.744758 5353 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.744807 5353 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.750640 5353 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.753127 5357 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.815378 5353 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEntries (0.09s)
=== RUN   TestTerm
I161116 07:20:35.833061 5467 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.833142 5467 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.833278 5467 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.833320 5467 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.838964 5467 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.843347 5440 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.864773 5467 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestTerm (0.05s)
=== RUN   TestGCIncorrectRange
I161116 07:20:35.886188 5523 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.886321 5523 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.886466 5523 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.886548 5523 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.892502 5523 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.895891 5528 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:35.903054 5539 storage/replica_proposal.go:332  [s1,r2/1:{"c"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
W161116 07:20:35.906079 5536 util/hlc/hlc.go:213  remote wall time is too far ahead (2ns) to be trustworthy - updating anyway
I161116 07:20:35.913667 5523 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestGCIncorrectRange (0.05s)
=== RUN   TestReplicaCancelRaft
--- SKIP: TestReplicaCancelRaft (0.01s)
	replica_test.go:5758: TODO(spencerkimball): https://github.com/cockroachdb/cockroach/issues/10488
=== RUN   TestComputeChecksumVersioning
I161116 07:20:35.934784 5586 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:35.934870 5586 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:35.934996 5586 base/node_id.go:62  NodeID set to 1
I161116 07:20:35.935058 5586 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:35.941235 5586 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:35.943577 5590 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
E161116 07:20:35.945354 5586 storage/replica_command.go:2004  Incompatible versions: e=2, v=3
I161116 07:20:35.945397 5586 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestComputeChecksumVersioning (0.04s)
=== RUN   TestNewReplicaCorruptionError
--- PASS: TestNewReplicaCorruptionError (0.00s)
=== RUN   TestDiffRange
--- PASS: TestDiffRange (0.02s)
=== RUN   TestSyncSnapshot
I161116 07:20:36.006051 5635 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.006151 5635 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.006329 5635 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.006381 5635 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.012707 5635 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.020712 5579 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m36.913151336s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:36.020556195 +0000 UTC]
I161116 07:20:36.023387 5635 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 9b78d037 at index 12
I161116 07:20:36.026170 5635 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSyncSnapshot (0.03s)
=== RUN   TestReplicaIDChangePending
I161116 07:20:36.060380 5636 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.060470 5636 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.060642 5636 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.060687 5636 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.068673 5636 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.070824 5681 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m55.395679993s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:36.070665151 +0000 UTC]
I161116 07:20:36.073216 5636 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:36.073293 5636 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestReplicaIDChangePending (0.10s)
=== RUN   TestReplicaRetryRaftProposal
I161116 07:20:36.136136 5714 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.136229 5714 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.136357 5714 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.136405 5714 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.143714 5714 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.146923 5712 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.150475 5714 storage/replica_test.go:6062  test begins
I161116 07:20:36.153006 5714 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaRetryRaftProposal (0.03s)
=== RUN   TestReplicaCancelRaftCommandProgress
I161116 07:20:36.167146 5637 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.167239 5637 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.167436 5637 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.167489 5637 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.174463 5637 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.178849 5640 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.181881 5637 storage/replica_test.go:6138  abandoning command 1
I161116 07:20:36.182708 5637 storage/replica_test.go:6138  abandoning command 7
I161116 07:20:36.182773 5637 storage/replica_test.go:6138  abandoning command 8
I161116 07:20:36.182829 5637 storage/replica_test.go:6138  abandoning command 9
I161116 07:20:36.185289 5637 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaCancelRaftCommandProgress (0.10s)
=== RUN   TestReplicaBurstPendingCommandsAndRepropose
--- SKIP: TestReplicaBurstPendingCommandsAndRepropose (0.00s)
	replica_test.go:6162: TODO(bdarnell): https://github.com/cockroachdb/cockroach/issues/8422
=== RUN   TestReplicaRefreshPendingCommandsTicks
I161116 07:20:36.276448 5754 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.276534 5754 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.276653 5754 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.276700 5754 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.285440 5721 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m55.61067483s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:36.285317276 +0000 UTC]
I161116 07:20:36.289857 5754 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaRefreshPendingCommandsTicks (0.03s)
=== RUN   TestCommandTimeThreshold
I161116 07:20:36.298475 5806 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.298615 5806 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.298807 5806 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.298877 5806 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.319468 5806 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.321428 5756 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
W161116 07:20:36.327888 5759 util/hlc/hlc.go:213  remote wall time is too far ahead (2ns) to be trustworthy - updating anyway
W161116 07:20:36.329426 5760 util/hlc/hlc.go:213  remote wall time is too far ahead (3ns) to be trustworthy - updating anyway
I161116 07:20:36.329744 5806 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestCommandTimeThreshold (0.04s)
=== RUN   TestDeprecatedRequests
I161116 07:20:36.344416 5873 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.344499 5873 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.344709 5873 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.344762 5873 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.352650 5873 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.353780 5877 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.357031 5873 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestDeprecatedRequests (0.03s)
=== RUN   TestReplicaTimestampCacheBumpNotLost
I161116 07:20:36.368105 5902 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.368195 5902 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.368329 5902 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.368379 5902 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.376934 5902 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.382506 5851 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.389798 5902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:36.389876 5902 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestReplicaTimestampCacheBumpNotLost (0.03s)
=== RUN   TestReplicaEvaluationNotTxnMutation
I161116 07:20:36.398075 5921 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.398174 5921 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.398308 5921 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.398357 5921 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.409647 5921 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.412955 5968 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.415239 5921 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaEvaluationNotTxnMutation (0.02s)
=== RUN   TestBookieReserve
--- PASS: TestBookieReserve (0.01s)
=== RUN   TestBookieReserveMaxRanges
--- PASS: TestBookieReserveMaxRanges (0.01s)
=== RUN   TestBookieReserveMaxBytes
--- PASS: TestBookieReserveMaxBytes (0.01s)
=== RUN   TestRuleSolver
I161116 07:20:36.452876 6003 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.452964 6003 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.453108 6003 base/node_id.go:62  NodeID set to 1
=== RUN   TestRuleSolver/no_constraints_or_rules
=== RUN   TestRuleSolver/white_list_rule
=== RUN   TestRuleSolver/ruleReplicasUniqueNodes_-_2_available_nodes
=== RUN   TestRuleSolver/ruleReplicasUniqueNodes_-_0_available_nodes
=== RUN   TestRuleSolver/ruleConstraints_-_required_constraints
=== RUN   TestRuleSolver/ruleConstraints_-_required_locality_constraints
=== RUN   TestRuleSolver/ruleConstraints_-_prohibited_constraints
=== RUN   TestRuleSolver/ruleConstraints_-_prohibited_locality_constraints
=== RUN   TestRuleSolver/ruleConstraints_-_positive_constraints
=== RUN   TestRuleSolver/ruleConstraints_-_positive_locality_constraints
=== RUN   TestRuleSolver/ruleDiversity_-_no_existing_replicas
=== RUN   TestRuleSolver/ruleDiversity_-_one_existing_replicas
=== RUN   TestRuleSolver/ruleCapacity
I161116 07:20:36.457200 6003 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRuleSolver (0.02s)
    --- PASS: TestRuleSolver/no_constraints_or_rules (0.00s)
    --- PASS: TestRuleSolver/white_list_rule (0.00s)
    --- PASS: TestRuleSolver/ruleReplicasUniqueNodes_-_2_available_nodes (0.00s)
    --- PASS: TestRuleSolver/ruleReplicasUniqueNodes_-_0_available_nodes (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_required_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_required_locality_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_prohibited_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_prohibited_locality_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_positive_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleConstraints_-_positive_locality_constraints (0.00s)
    --- PASS: TestRuleSolver/ruleDiversity_-_no_existing_replicas (0.00s)
    --- PASS: TestRuleSolver/ruleDiversity_-_one_existing_replicas (0.00s)
    --- PASS: TestRuleSolver/ruleCapacity (0.00s)
=== RUN   TestCanonicalTierOrder
=== RUN   TestCanonicalTierOrder/no_tiers_at_all
=== RUN   TestCanonicalTierOrder/one_store_with_two_empty_tiers
=== RUN   TestCanonicalTierOrder/one_store_with_three_tiers
=== RUN   TestCanonicalTierOrder/3_stores_with_the_same_tiers,_one_with_an_extra_one
=== RUN   TestCanonicalTierOrder/two_stores_with_completely_different_tiers
--- PASS: TestCanonicalTierOrder (0.01s)
    --- PASS: TestCanonicalTierOrder/no_tiers_at_all (0.00s)
    --- PASS: TestCanonicalTierOrder/one_store_with_two_empty_tiers (0.00s)
    --- PASS: TestCanonicalTierOrder/one_store_with_three_tiers (0.00s)
    --- PASS: TestCanonicalTierOrder/3_stores_with_the_same_tiers,_one_with_an_extra_one (0.00s)
    --- PASS: TestCanonicalTierOrder/two_stores_with_completely_different_tiers (0.00s)
=== RUN   TestScannerAddToQueues
I161116 07:20:36.479773 6051 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestScannerAddToQueues (0.01s)
=== RUN   TestScannerTiming
I161116 07:20:36.594051 6023 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:36.594302 6023 storage/scanner_test.go:260  0: average scan: 16.602398ms
I161116 07:20:36.694840 6023 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:36.695005 6023 storage/scanner_test.go:260  1: average scan: 25.150981ms
--- PASS: TestScannerTiming (0.21s)
=== RUN   TestScannerPaceInterval
--- PASS: TestScannerPaceInterval (0.01s)
=== RUN   TestScannerDisabled
I161116 07:20:36.711973 6052 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestScannerDisabled (0.01s)
=== RUN   TestScannerDisabledWithZeroInterval
--- PASS: TestScannerDisabledWithZeroInterval (0.00s)
=== RUN   TestScannerEmptyRangeSet
I161116 07:20:36.739378 6014 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestScannerEmptyRangeSet (0.03s)
=== RUN   TestRangeIDChunk
--- PASS: TestRangeIDChunk (0.02s)
=== RUN   TestRangeIDQueue
--- PASS: TestRangeIDQueue (0.01s)
=== RUN   TestSchedulerLoop
I161116 07:20:36.784287 6042 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSchedulerLoop (0.01s)
=== RUN   TestSchedulerBuffering
I161116 07:20:36.791663 6016 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSchedulerBuffering (0.01s)
=== RUN   TestSplitQueueShouldQueue
I161116 07:20:36.798904 6067 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.799015 6067 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.799155 6067 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.799204 6067 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.808498 6067 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.810345 6071 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.820620 6067 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSplitQueueShouldQueue (0.10s)
=== RUN   TestRangeStatsEmpty
I161116 07:20:36.898480 6104 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.898566 6104 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.898691 6104 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.898741 6104 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.904290 6104 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:36.907510 6104 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeStatsEmpty (0.04s)
=== RUN   TestRangeStatsInit
I161116 07:20:36.939582 6057 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.939669 6057 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.939825 6057 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.939877 6057 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:36.952108 6061 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:36.957376 6057 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeStatsInit (0.03s)
=== RUN   TestStorePoolGossipUpdate
I161116 07:20:36.989873 6183 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.990015 6183 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.990162 6183 base/node_id.go:62  NodeID set to 1
I161116 07:20:36.991763 6183 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStorePoolGossipUpdate (0.03s)
=== RUN   TestStorePoolDies
I161116 07:20:36.999558 6213 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:36.999674 6213 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:36.999888 6213 base/node_id.go:62  NodeID set to 1
W161116 07:20:37.009106 6196 storage/store_pool.go:83  store 2 on node 2 is now considered offline
W161116 07:20:37.016320 6196 storage/store_pool.go:83  store 2 on node 2 is now considered offline
I161116 07:20:37.019154 6213 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStorePoolDies (0.03s)
=== RUN   TestStorePoolGetStoreList
I161116 07:20:37.048776 6197 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.048877 6197 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.049032 6197 base/node_id.go:62  NodeID set to 1
W161116 07:20:37.051263 6197 storage/store_pool.go:83  store 5 on node 1 is now considered offline
I161116 07:20:37.051341 6197 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.051399 6197 util/stop/stopper.go:468  quiescing; tasks left:
6      gossip/infostore.go:301
--- PASS: TestStorePoolGetStoreList (0.03s)
=== RUN   TestStorePoolGetStoreDetails
I161116 07:20:37.055860 6028 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.055963 6028 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.056107 6028 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.059076 6028 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStorePoolGetStoreDetails (0.02s)
=== RUN   TestStorePoolFindDeadReplicas
I161116 07:20:37.078270 6199 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.078380 6199 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.078525 6199 base/node_id.go:62  NodeID set to 1
W161116 07:20:37.087091 6201 storage/store_pool.go:83  store 1 on node 1 is now considered offline
W161116 07:20:37.087195 6201 storage/store_pool.go:83  store 2 on node 2 is now considered offline
W161116 07:20:37.087309 6201 storage/store_pool.go:83  store 3 on node 3 is now considered offline
W161116 07:20:37.087394 6201 storage/store_pool.go:83  store 4 on node 4 is now considered offline
W161116 07:20:37.087466 6201 storage/store_pool.go:83  store 5 on node 5 is now considered offline
I161116 07:20:37.092274 6199 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.092351 6199 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:37.092426 6199 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestStorePoolFindDeadReplicas (0.03s)
=== RUN   TestStorePoolDefaultState
I161116 07:20:37.098827 6226 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.098937 6226 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.099092 6226 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.099379 6226 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStorePoolDefaultState (0.02s)
=== RUN   TestStorePoolThrottle
I161116 07:20:37.120124 6229 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.120218 6229 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.120342 6229 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.121109 6229 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStorePoolThrottle (0.01s)
=== RUN   TestStoreInitAndBootstrap
I161116 07:20:37.130277 6215 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.152694 6215 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreInitAndBootstrap (0.10s)
=== RUN   TestBootstrapOfNonEmptyStore
I161116 07:20:37.226309 6254 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.227734 6254 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestBootstrapOfNonEmptyStore (0.01s)
=== RUN   TestStoreAddRemoveRanges
I161116 07:20:37.235321 6233 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.235412 6233 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.235555 6233 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.235815 6233 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.246958 6261 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.251412 6233 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreAddRemoveRanges (0.02s)
=== RUN   TestReplicasByKey
I161116 07:20:37.266053 6121 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.266139 6121 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.266309 6121 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.266540 6121 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.275466 6325 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.279097 6121 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.279173 6121 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
--- PASS: TestReplicasByKey (0.03s)
=== RUN   TestStoreRemoveReplicaOldDescriptor
I161116 07:20:37.320496 6350 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.320586 6350 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.320757 6350 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.321010 6350 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.330643 6356 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.336591 6350 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRemoveReplicaOldDescriptor (0.05s)
=== RUN   TestStoreRemoveReplicaDestroy
I161116 07:20:37.355247 6394 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.355333 6394 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.355570 6394 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.355798 6394 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.367068 6299 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.369328 6394 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRemoveReplicaDestroy (0.05s)
=== RUN   TestStoreReplicaVisitor
I161116 07:20:37.395424 6381 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.395514 6381 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.395701 6381 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.395941 6381 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.404135 6451 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.413226 6381 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreReplicaVisitor (0.08s)
=== RUN   TestHasOverlappingReplica
I161116 07:20:37.476647 6489 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.476734 6489 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.476854 6489 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.477067 6489 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.485496 6503 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.491697 6489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestHasOverlappingReplica (0.09s)
=== RUN   TestProcessRangeDescriptorUpdate
I161116 07:20:37.563213 6303 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.563301 6303 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.563484 6303 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.563770 6303 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.572895 6565 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.576613 6303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestProcessRangeDescriptorUpdate (0.03s)
=== RUN   TestStoreSend
I161116 07:20:37.601347 6423 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.601434 6423 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.601613 6423 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.601834 6423 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.615555 6590 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.619030 6423 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSend (0.03s)
=== RUN   TestStoreObservedTimestamp
I161116 07:20:37.633730 6654 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.633843 6654 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.634074 6654 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.634366 6654 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.649132 6636 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.651758 6637 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: boom
I161116 07:20:37.652137 6654 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.653319 6654 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.653410 6654 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.653532 6654 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.653767 6654 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.667689 6698 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.671394 6654 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreObservedTimestamp (0.05s)
=== RUN   TestStoreAnnotateNow
I161116 07:20:37.714419 6732 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.714506 6732 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.714667 6732 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.714925 6732 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.724215 6738 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m38.622327949s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:37.72408961 +0000 UTC]
I161116 07:20:37.727566 6739 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: boom
I161116 07:20:37.728056 6732 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.729298 6732 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.729383 6732 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.729511 6732 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.729742 6732 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.747502 6783 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m38.635894525s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:37.747385326 +0000 UTC]
I161116 07:20:37.751040 6732 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.752715 6732 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.752819 6732 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.752977 6732 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.754479 6732 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.765442 6683 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m38.663387288s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:37.765313055 +0000 UTC]
I161116 07:20:37.768550 6685 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: boom
I161116 07:20:37.768940 6732 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.770120 6732 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.770201 6732 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.770333 6732 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.770623 6732 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.778493 6826 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m38.676664654s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:37.778368913 +0000 UTC]
I161116 07:20:37.785444 6732 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreAnnotateNow (0.12s)
=== RUN   TestStoreExecuteNoop
I161116 07:20:37.800070 6854 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.800155 6854 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.800353 6854 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.800620 6854 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.808904 6916 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.811616 6854 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreExecuteNoop (0.02s)
=== RUN   TestStoreVerifyKeys
I161116 07:20:37.822447 6905 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.822537 6905 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.822665 6905 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.822910 6905 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.832292 6875 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.838114 6905 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreVerifyKeys (0.09s)
=== RUN   TestStoreSendUpdateTime
I161116 07:20:37.909902 7000 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.910003 7000 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.910199 7000 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.910481 7000 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.921011 7006 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.923020 7000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSendUpdateTime (0.02s)
=== RUN   TestStoreSendWithZeroTime
I161116 07:20:37.938288 7051 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:37.938373 7051 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:37.938527 7051 base/node_id.go:62  NodeID set to 1
I161116 07:20:37.938745 7051 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:37.946086 7057 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:37.948193 7051 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:37.948294 7051 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
--- PASS: TestStoreSendWithZeroTime (0.08s)
=== RUN   TestStoreSendWithClockOffset
I161116 07:20:38.011379 7093 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.011465 7093 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.011636 7093 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.011970 7093 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.020555 7099 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.024176 7093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSendWithClockOffset (0.06s)
=== RUN   TestStoreSendBadRange
I161116 07:20:38.069479 6906 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.069592 6906 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.069761 6906 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.070010 6906 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.079428 7145 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.081347 6906 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSendBadRange (0.08s)
=== RUN   TestStoreSendOutOfRange
I161116 07:20:38.151943 7201 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.152033 7201 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.153457 7201 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.156089 7201 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.164980 7023 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.171586 7021 storage/replica_proposal.go:332  [s1,r2/1:{"b"-/Max}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.172865 7201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSendOutOfRange (0.11s)
=== RUN   TestStoreRangeIDAllocation
I161116 07:20:38.252023 7128 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.252115 7128 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.252310 7128 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.252581 7128 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.262086 7134 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.274557 7128 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeIDAllocation (0.04s)
=== RUN   TestStoreReplicasByKey
I161116 07:20:38.286165 7241 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.286252 7241 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.286435 7241 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.286664 7241 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.295240 7307 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.304657 7241 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreReplicasByKey (0.03s)
=== RUN   TestStoreSetRangesMaxBytes
I161116 07:20:38.318683 7244 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.318789 7244 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.318989 7244 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.319256 7244 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.334748 7335 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.343582 7244 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSetRangesMaxBytes (0.04s)
=== RUN   TestStoreLongTxnStarvation
I161116 07:20:38.356222 7247 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.356371 7247 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.356542 7247 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.356808 7247 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.366862 7374 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m39.264590363s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:38.366692136 +0000 UTC]
I161116 07:20:38.391926 7247 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreLongTxnStarvation (0.05s)
=== RUN   TestStoreResolveWriteIntent
I161116 07:20:38.412569 7248 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.412668 7248 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.412812 7248 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.413076 7248 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.424239 7361 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.442957 7248 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreResolveWriteIntent (0.05s)
=== RUN   TestStoreResolveWriteIntentRollback
I161116 07:20:38.450096 7451 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.450205 7451 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.450396 7451 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.450690 7451 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.470059 7463 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.478128 7451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreResolveWriteIntentRollback (0.04s)
=== RUN   TestStoreResolveWriteIntentPushOnRead
I161116 07:20:38.506873 7506 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.506962 7506 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.507097 7506 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.507322 7506 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.518528 7487 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m39.416116374s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:38.518407354 +0000 UTC]
I161116 07:20:38.569601 7506 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreResolveWriteIntentPushOnRead (0.09s)
	store_test.go:1403: 0: unsetting WriteTooOld flag as a hack to keep this test passing; should address the TODO
	store_test.go:1403: 1: unsetting WriteTooOld flag as a hack to keep this test passing; should address the TODO
	store_test.go:1403: 2: unsetting WriteTooOld flag as a hack to keep this test passing; should address the TODO
	store_test.go:1403: 3: unsetting WriteTooOld flag as a hack to keep this test passing; should address the TODO
=== RUN   TestStoreResolveWriteIntentSnapshotIsolation
I161116 07:20:38.589065 7498 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.589151 7498 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.589284 7498 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.589526 7498 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.602066 7544 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.620992 7498 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreResolveWriteIntentSnapshotIsolation (0.05s)
=== RUN   TestStoreResolveWriteIntentNoTxn
I161116 07:20:38.630072 7591 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.630163 7591 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.630311 7591 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.630564 7591 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.644927 7597 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:38.658048 7591 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreResolveWriteIntentNoTxn (0.09s)
=== RUN   TestStoreReadInconsistent
I161116 07:20:38.728252 6913 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.728351 6913 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.728468 6913 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.728731 6913 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.737705 7627 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
W161116 07:20:38.752123 7657 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: failed to push "testA" id=20b2afca key="true-a" rw=true pri=0.00000005 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,29 orig=0.000000123,29 max=0.000000123,31 wto=false rop=false
W161116 07:20:38.758997 7698 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: failed to push "testA" id=20b2afca key="true-a" rw=true pri=0.00000005 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,29 orig=0.000000123,29 max=0.000000123,31 wto=false rop=false
W161116 07:20:38.770027 7563 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: failed to push "testA" id=d32ad666 key="false-a" rw=true pri=100.00000000 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,136 orig=0.000000123,136 max=0.000000123,138 wto=false rop=false
I161116 07:20:38.775648 6913 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:38.775753 6913 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/intent_resolver.go:317
W161116 07:20:38.776990 7088 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["false-b",/Min)
W161116 07:20:38.777146 7088 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
I161116 07:20:38.777245 6913 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
W161116 07:20:38.780050 7089 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["false-a",/Min)
W161116 07:20:38.780196 7089 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
--- PASS: TestStoreReadInconsistent (0.07s)
=== RUN   TestStoreScanIntents
I161116 07:20:38.801139 7499 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.801227 7499 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.801369 7499 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.801602 7499 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.809761 7715 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m39.708049708s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:38.809639062 +0000 UTC]
W161116 07:20:38.923797 7741 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: failed to push "test-2" id=1f966db7 key="key2-00" rw=true pri=0.00000005 iso=SERIALIZABLE stat=PENDING epo=0 ts=1479280838.905379819,0 orig=1479280838.905379819,0 max=1479280838.905379820,0 wto=false rop=false
I161116 07:20:38.933972 7499 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:38.934054 7499 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
W161116 07:20:38.934547 7712 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command PushTxn ["key3-00",/Min)
W161116 07:20:38.934693 7712 storage/intent_resolver.go:314  [n1,s1,r1/1:/M{in-ax}]: failed to push during intent resolution: result is ambiguous
--- PASS: TestStoreScanIntents (0.15s)
=== RUN   TestStoreScanInconsistentResolvesIntents
I161116 07:20:38.944885 7748 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:38.944986 7748 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:38.945192 7748 base/node_id.go:62  NodeID set to 1
I161116 07:20:38.945476 7748 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:38.960320 7754 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m39.858112768s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:38.96019424 +0000 UTC]
I161116 07:20:39.275246 7748 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreScanInconsistentResolvesIntents (0.35s)
=== RUN   TestStoreBadRequests
I161116 07:20:39.293113 7861 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.293210 7861 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.293339 7861 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.293603 7861 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.307630 7833 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.318076 7861 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreBadRequests (0.04s)
=== RUN   TestMaybeRemove
I161116 07:20:39.338665 7804 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.338756 7804 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.338955 7804 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.339209 7804 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.346600 7804 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:39.348575 7907 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m40.246735991s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:39.34845745 +0000 UTC]
I161116 07:20:39.350593 7804 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestMaybeRemove (0.09s)
=== RUN   TestStoreChangeFrozen
I161116 07:20:39.418861 7820 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.418947 7820 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.419083 7820 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.419138 7820 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.424292 7820 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:39.426810 7872 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
W161116 07:20:39.429256 7820 storage/replica_command.go:2098  freeze range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2  issued from notvalidversion is applied by {go1.7.3 unknown   gcc 4.9.2 linux amd64}
I161116 07:20:39.437313 7820 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreChangeFrozen (0.03s)
=== RUN   TestStoreNoConcurrentRaftSnapshots
I161116 07:20:39.447640 7937 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.447738 7937 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.447902 7937 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.448130 7937 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.457242 8021 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.458878 7937 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreNoConcurrentRaftSnapshots (0.03s)
=== RUN   TestStoreGCThreshold
I161116 07:20:39.474458 8032 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.474543 8032 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.474708 8032 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.474758 8032 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.480466 8032 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:39.482436 8036 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.486635 8032 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreGCThreshold (0.02s)
=== RUN   TestStoreRangePlaceholders
I161116 07:20:39.511038 8066 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.511266 8066 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.511690 8066 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.511867 8066 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.524818 7983 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.529319 8066 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangePlaceholders (0.04s)
=== RUN   TestStoreRemovePlaceholderOnError
I161116 07:20:39.542425 8105 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.542520 8105 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.542738 8105 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.542795 8105 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.551469 8105 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:39.553210 7992 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.555945 8105 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:39.556017 8105 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestStoreRemovePlaceholderOnError (0.08s)
=== RUN   TestStoreRemovePlaceholderOnRaftIgnored
I161116 07:20:39.618393 8109 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.618499 8109 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.618631 8109 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.618679 8109 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.633006 8165 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.633818 8109 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
W161116 07:20:39.636730 8109 storage/replica.go:2810  [s1,r1/2:{-}] failed to look up recipient replica 0 in range 1 while sending MsgAppResp: replica 0 not present in {2 2 2}, []
I161116 07:20:39.773825 8109 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRemovePlaceholderOnRaftIgnored (0.16s)
=== RUN   TestCanCampaignIdleReplica
I161116 07:20:39.791733 8112 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:39.791823 8112 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:39.792038 8112 base/node_id.go:62  NodeID set to 1
I161116 07:20:39.792162 8112 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.802355 8210 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:39.803131 8112 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:39.805129 8112 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:39.805210 8112 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestCanCampaignIdleReplica (0.09s)
=== RUN   TestSendSnapshotThrottling
I161116 07:20:39.875124 8247 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
--- PASS: TestSendSnapshotThrottling (0.01s)
=== RUN   TestStoresAddStore
--- PASS: TestStoresAddStore (0.02s)
=== RUN   TestStoresRemoveStore
--- PASS: TestStoresRemoveStore (0.00s)
=== RUN   TestStoresGetStoreCount
--- PASS: TestStoresGetStoreCount (0.02s)
=== RUN   TestStoresVisitStores
--- PASS: TestStoresVisitStores (0.03s)
=== RUN   TestStoresGetStore
--- PASS: TestStoresGetStore (0.01s)
=== RUN   TestStoresLookupReplica
I161116 07:20:39.983035 8238 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:39.998540 8238 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
W161116 07:20:40.000947 8238 storage/stores.go:218  range not contained in one range: ["b","d"), but have [/Min,"c")
I161116 07:20:40.001569 8238 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoresLookupReplica (0.04s)
=== RUN   TestStoresGossipStorage
I161116 07:20:40.032233 8252 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.033881 8252 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.036258 8252 storage/stores.go:296  read 0 node addresses from persistent storage
I161116 07:20:40.036674 8252 storage/stores.go:312  wrote 1 node addresses to persistent storage
I161116 07:20:40.036766 8252 storage/stores.go:296  read 1 node addresses from persistent storage
I161116 07:20:40.037033 8252 storage/stores.go:296  read 1 node addresses from persistent storage
I161116 07:20:40.037161 8252 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoresGossipStorage (0.02s)
=== RUN   TestStoresGossipStorageReadLatest
I161116 07:20:40.047601 6970 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.049104 6970 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.051086 6970 storage/stores.go:312  wrote 1 node addresses to persistent storage
I161116 07:20:40.051313 6970 storage/stores.go:312  wrote 2 node addresses to persistent storage
I161116 07:20:40.051531 6970 storage/stores.go:296  read 2 node addresses from persistent storage
I161116 07:20:40.051908 6970 storage/stores.go:296  read 2 node addresses from persistent storage
I161116 07:20:40.052339 6970 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoresGossipStorageReadLatest (0.02s)
=== RUN   TestTimestampCache
--- PASS: TestTimestampCache (0.03s)
=== RUN   TestTimestampCacheSetLowWater
--- PASS: TestTimestampCacheSetLowWater (0.01s)
=== RUN   TestTimestampCacheEviction
--- PASS: TestTimestampCacheEviction (0.03s)
=== RUN   TestTimestampCacheNoEviction
--- PASS: TestTimestampCacheNoEviction (0.01s)
=== RUN   TestTimestampCacheMergeInto
--- PASS: TestTimestampCacheMergeInto (0.01s)
=== RUN   TestTimestampCacheLayeredIntervals
--- PASS: TestTimestampCacheLayeredIntervals (0.02s)
	timestamp_cache_test.go:473: test case 1
	timestamp_cache_test.go:479: simultaneous: false
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:479: simultaneous: true
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:473: test case 2
	timestamp_cache_test.go:479: simultaneous: false
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:479: simultaneous: true
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:473: test case 3
	timestamp_cache_test.go:479: simultaneous: false
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:479: simultaneous: true
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:473: test case 4
	timestamp_cache_test.go:479: simultaneous: false
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:479: simultaneous: true
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:473: test case 5
	timestamp_cache_test.go:479: simultaneous: false
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:479: simultaneous: true
	timestamp_cache_test.go:488: reverse: false
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
	timestamp_cache_test.go:488: reverse: true
	timestamp_cache_test.go:493: sameTxn: false
	timestamp_cache_test.go:493: sameTxn: true
=== RUN   TestTimestampCacheClear
--- PASS: TestTimestampCacheClear (0.01s)
=== RUN   TestTimestampCacheReadVsWrite
--- PASS: TestTimestampCacheReadVsWrite (0.01s)
=== RUN   TestTimestampCacheEqualTimestamps
--- PASS: TestTimestampCacheEqualTimestamps (0.02s)
=== RUN   TestBelowRaftProtos
--- PASS: TestBelowRaftProtos (0.02s)
=== RUN   TestStoreRangeMergeTwoEmptyRanges
I161116 07:20:40.226343 8256 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.228428 8256 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:40.228524 8256 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:40.230041 8256 base/node_id.go:62  NodeID set to 1
I161116 07:20:40.230353 8256 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:40.241558 8279 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m41.139141073s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:40.241398551 +0000 UTC]
I161116 07:20:40.260340 8256 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:20:40.269252 8265 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:40.281955 8256 storage/replica_command.go:2835  [s1,r1/1:{/Min-"b"}] initiating a merge of [n1,s1,r2/1:{"b"-/Max}] into this range
W161116 07:20:40.287035 8256 storage/stores.go:218  range not contained in one range: [/Min,"b\x00"), but have [/Min,"b")
W161116 07:20:40.295439 8138 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"b"}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2897 (*Replica).AdminMerge" id=086aac27 key=/Local/Range/""/RangeDescriptor rw=true pri=0.00766669 iso=SERIALIZABLE stat=PENDING epo=0 ts=1479280840.282228982,0 orig=1479280840.282228982,0 max=1479280840.282228982,0 wto=false rop=false
I161116 07:20:40.300954 8256 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:40.301031 8256 util/stop/stopper.go:468  quiescing; tasks left:
1      kv/txn_coord_sender.go:918
--- PASS: TestStoreRangeMergeTwoEmptyRanges (0.10s)
=== RUN   TestStoreRangeMergeMetadataCleanup
I161116 07:20:40.326700 8271 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.327748 8271 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:40.327845 8271 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:40.327986 8271 base/node_id.go:62  NodeID set to 1
I161116 07:20:40.328127 8271 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:40.340244 8271 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:40.342153 8326 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m41.239985508s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:40.342015078 +0000 UTC]
I161116 07:20:40.350354 8271 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:20:40.359118 8371 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:40.365042 8271 storage/replica_command.go:2835  [s1,r1/1:{/Min-"b"}] initiating a merge of [n1,s1,r2/1:{"b"-/Max}] into this range
W161116 07:20:40.369519 8271 storage/stores.go:218  range not contained in one range: [/Min,"b\x00"), but have [/Min,"b")
W161116 07:20:40.382366 8376 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"b"}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2897 (*Replica).AdminMerge" id=3264138e key=/Local/Range/""/RangeDescriptor rw=true pri=0.02877819 iso=SERIALIZABLE stat=PENDING epo=0 ts=1479280840.365485601,0 orig=1479280840.365485601,0 max=1479280840.365485601,0 wto=false rop=false
I161116 07:20:40.390611 8271 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeMergeMetadataCleanup (0.08s)
=== RUN   TestStoreRangeMergeWithData
I161116 07:20:40.408312 8377 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.409261 8377 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:40.409343 8377 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:40.409480 8377 base/node_id.go:62  NodeID set to 1
I161116 07:20:40.409616 8377 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:40.416047 8377 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:40.418341 8384 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m41.316193579s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:40.418223249 +0000 UTC]
I161116 07:20:40.423575 8377 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:20:40.439631 8352 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:40.441197 8377 storage/replica_command.go:2835  [s1,r1/1:{/Min-"b"}] initiating a merge of [n1,s1,r2/1:{"b"-/Max}] into this range
W161116 07:20:40.449352 8377 storage/stores.go:218  range not contained in one range: [/Min,"b\x00"), but have [/Min,"b")
W161116 07:20:40.455134 8367 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"b"}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2897 (*Replica).AdminMerge" id=ecfb53c1 key=/Local/Range/""/RangeDescriptor rw=true pri=0.01141410 iso=SERIALIZABLE stat=PENDING epo=0 ts=1479280840.441618770,0 orig=1479280840.441618770,0 max=1479280840.441618770,0 wto=false rop=false
I161116 07:20:40.462221 8377 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeMergeWithData (0.06s)
=== RUN   TestStoreRangeMergeLastRange
I161116 07:20:40.481127 8308 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.482110 8308 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:40.482234 8308 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:40.482404 8308 base/node_id.go:62  NodeID set to 1
I161116 07:20:40.482543 8308 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:40.492610 8308 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:40.494740 8315 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m41.392570457s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:40.494584926 +0000 UTC]
I161116 07:20:40.498796 8308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:40.498869 8308 util/stop/stopper.go:468  quiescing; tasks left:
2      gossip/infostore.go:301
I161116 07:20:40.500057 8308 util/stop/stopper.go:468  quiescing; tasks left:
1      gossip/infostore.go:301
--- PASS: TestStoreRangeMergeLastRange (0.05s)
=== RUN   TestStoreRangeMergeNonCollocated
I161116 07:20:40.523116 8425 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.524257 8425 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:40.524363 8425 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:40.524540 8425 base/node_id.go:62  NodeID set to 1
I161116 07:20:40.541708 8425 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:40.541875 8425 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:48782" > attrs:<> locality:<> 
I161116 07:20:40.545205 8497 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:40.549490 8425 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.550328 8425 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48782]
W161116 07:20:40.550486 8425 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:40.550613 8425 base/node_id.go:62  NodeID set to 2
I161116 07:20:40.577015 8425 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:40.577186 8425 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:50964" > attrs:<> locality:<> 
I161116 07:20:40.578670 8425 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.580131 8425 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48782]
W161116 07:20:40.580218 8425 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:40.581316 8556 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:48782
I161116 07:20:40.590174 8425 base/node_id.go:62  NodeID set to 3
I161116 07:20:40.597131 8576 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:48782
I161116 07:20:40.636498 8425 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:52152" > attrs:<> locality:<> 
I161116 07:20:40.639496 8425 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:40.640519 8425 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48782]
W161116 07:20:40.640630 8425 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:40.640777 8425 base/node_id.go:62  NodeID set to 4
I161116 07:20:40.680899 8425 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:20:40.681082 8425 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:59105" > attrs:<> locality:<> 
I161116 07:20:40.682718 8693 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:48782
I161116 07:20:40.692228 8425 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "d" [r2]
E161116 07:20:40.700772 8479 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"d"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:40.701777 8425 storage/replica_command.go:2361  [s1,r1/1:{/Min-"d"}] initiating a split of this range at key "b" [r3]
E161116 07:20:40.708488 8479 storage/queue.go:586  [replicate,s1,r2/1:{"d"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:40.718621 8479 storage/queue.go:586  [replicate,s1,r3/1:"{b"-d"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:40.720171 8425 storage/replica_raftstorage.go:443  [s1,r1/1:{/Min-"b"}] generated snapshot d02a86c4 at index 20
I161116 07:20:40.725130 8425 storage/store.go:3134  [s1,r1/1:{/Min-"b"}] streamed snapshot: kv pairs: 24, log entries: 10
I161116 07:20:40.725869 8727 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 20 (id=d02a86c4, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:20:40.727074 8727 storage/replica_raftstorage.go:590  [s2,r1/?:{/Min-"b"}] applied preemptive snapshot in 0.001s
I161116 07:20:40.728975 8425 storage/replica_command.go:3245  [s1,r1/1:{/Min-"b"}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"b" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:40.733177 6974 storage/replica.go:2066  [s1,r1/1:{/Min-"b"}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:40.746469 8425 storage/replica_raftstorage.go:443  [s1,r1/1:{/Min-"b"}] generated snapshot 9eaa3e4a at index 22
I161116 07:20:40.750207 8791 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:40.751731 8425 storage/store.go:3134  [s1,r1/1:{/Min-"b"}] streamed snapshot: kv pairs: 27, log entries: 12
I161116 07:20:40.752460 8759 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 22 (id=9eaa3e4a, encoded size=16, 1 rocksdb batches, 12 log entries)
I161116 07:20:40.766123 8759 storage/replica_raftstorage.go:590  [s3,r1/?:{/Min-"b"}] applied preemptive snapshot in 0.014s
I161116 07:20:40.775760 8425 storage/replica_command.go:3245  [s1,r1/1:{/Min-"b"}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"b" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:40.784605 8825 storage/replica.go:2066  [s1,r1/1:{/Min-"b"}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:40.829313 8735 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:40.838753 8425 storage/replica_raftstorage.go:443  [s1,r3/1:"{b"-d"}] generated snapshot f7315b7e at index 11
I161116 07:20:40.841013 8425 storage/store.go:3134  [s1,r3/1:"{b"-d"}] streamed snapshot: kv pairs: 9, log entries: 1
I161116 07:20:40.841760 8769 storage/replica_raftstorage.go:587  [s2,r3/?:{-}] applying preemptive snapshot at index 11 (id=f7315b7e, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:40.842587 8769 storage/replica_raftstorage.go:590  [s2,r3/?:"{b"-d"}] applied preemptive snapshot in 0.001s
I161116 07:20:40.846681 8425 storage/replica_command.go:3245  [s1,r3/1:"{b"-d"}] change replicas: read existing descriptor range_id:3 start_key:"b" end_key:"d" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:40.854923 8866 storage/replica.go:2066  [s1,r3/1:"{b"-d"}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:40.858568 8425 storage/replica_raftstorage.go:443  [s1,r3/1:"{b"-d"}] generated snapshot b375a758 at index 13
I161116 07:20:40.860034 8425 storage/store.go:3134  [s1,r3/1:"{b"-d"}] streamed snapshot: kv pairs: 11, log entries: 3
I161116 07:20:40.860717 8870 storage/replica_raftstorage.go:587  [s4,r3/?:{-}] applying preemptive snapshot at index 13 (id=b375a758, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:40.869956 8870 storage/replica_raftstorage.go:590  [s4,r3/?:"{b"-d"}] applied preemptive snapshot in 0.009s
I161116 07:20:40.871872 8425 storage/replica_command.go:3245  [s1,r3/1:"{b"-d"}] change replicas: read existing descriptor range_id:3 start_key:"b" end_key:"d" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:40.920444 8854 storage/replica.go:2066  [s1,r3/1:"{b"-d"}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:20:40.952398 8899 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:40.992727 8425 storage/replica_raftstorage.go:443  [s1,r2/1:{"d"-/Max}] generated snapshot 132e2d1b at index 11
I161116 07:20:41.004196 8425 storage/store.go:3134  [s1,r2/1:{"d"-/Max}] streamed snapshot: kv pairs: 28, log entries: 1
I161116 07:20:41.005371 8773 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 11 (id=132e2d1b, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:41.006497 8773 storage/replica_raftstorage.go:590  [s2,r2/?:{"d"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:41.019966 8425 storage/replica_command.go:3245  [s1,r2/1:{"d"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"d" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:41.034200 8922 storage/replica.go:2066  [s1,r2/1:{"d"-/Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:41.037898 8425 storage/replica_raftstorage.go:443  [s1,r2/1:{"d"-/Max}] generated snapshot 37630239 at index 13
W161116 07:20:41.041311 8499 raft/raft.go:794  [s1,r2/1:{"d"-/Max}] 1 stepped down to follower since quorum is not active
I161116 07:20:41.042675 8425 storage/store.go:3134  [s1,r2/1:{"d"-/Max}] streamed snapshot: kv pairs: 30, log entries: 3
I161116 07:20:41.044120 8924 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 13 (id=37630239, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:41.047843 8924 storage/replica_raftstorage.go:590  [s3,r2/?:{"d"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:41.051494 8425 storage/replica_command.go:3245  [s1,r2/1:{"d"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"d" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:41.466492 8949 storage/replica.go:2066  [s1,r2/1:{"d"-/Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:41.491975 8425 storage/replica_command.go:2835  initiating a merge of [n1,s1,r3/1:"{b"-d"}] into this range
I161116 07:20:41.512322 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:41.513779 8835 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:3}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
I161116 07:20:41.513849 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:41.514967 8737 storage/store.go:2990  [s3] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
I161116 07:20:41.515235 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:41.515438 8735 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:20:41.550636 8980 storage/raft_transport.go:437  raft transport stream to node 1 established
W161116 07:20:41.551459 9026 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:0}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:0}
W161116 07:20:41.552261 8982 storage/raft_transport.go:478  no handler found for store 3 in response range_id:0 from_replica:<node_id:1 store_id:1 replica_id:0 > to_replica:<node_id:3 store_id:3 replica_id:0 > union:<error:<message:"store 1 was not found" transaction_restart:NONE origin_node:0 detail:<store_not_found:<store_id:1 > > now:<wall_time:0 logical:0 > > > 
I161116 07:20:41.556059 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.561031 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.562426 8610 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:52152->127.0.0.1:35575: use of closed network connection
I161116 07:20:41.563219 8465 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:59105->127.0.0.1:47253: use of closed network connection
I161116 07:20:41.563391 8510 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50964->127.0.0.1:54052: use of closed network connection
I161116 07:20:41.564952 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.565207 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.565396 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.565606 9000 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeMergeNonCollocated (1.05s)
=== RUN   TestStoreRangeMergeStats
I161116 07:20:41.575919 8967 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:41.577060 8967 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:41.577139 8967 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:41.577271 8967 base/node_id.go:62  NodeID set to 1
I161116 07:20:41.577404 8967 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:41.584801 8967 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:41.588257 8958 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:41.593930 8967 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:20:41.604130 9067 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:41.934977 8967 storage/replica_command.go:2835  [s1,r1/1:{/Min-"b"}] initiating a merge of [n1,s1,r2/1:{"b"-/Max}] into this range
W161116 07:20:41.942073 8967 storage/stores.go:218  range not contained in one range: [/Min,"b\x00"), but have [/Min,"b")
W161116 07:20:41.950108 8983 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"b"}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2897 (*Replica).AdminMerge" id=82c19922 key=/Local/Range/""/RangeDescriptor rw=true pri=0.01203176 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000223,3 orig=0.000000223,3 max=0.000000223,3 wto=false rop=false
I161116 07:20:41.957328 8967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:41.957423 8967 util/stop/stopper.go:468  quiescing; tasks left:
1      kv/txn_coord_sender.go:918
--- PASS: TestStoreRangeMergeStats (0.40s)
=== RUN   TestStoreMetrics
--- SKIP: TestStoreMetrics (0.01s)
	client_metrics_test.go:169: TODO(mrtracy): #9204
=== RUN   TestRaftLogQueue
I161116 07:20:41.975539 9080 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:41.976567 9080 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:41.976672 9080 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:41.976798 9080 base/node_id.go:62  NodeID set to 1
I161116 07:20:41.985999 9080 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:41.986173 9080 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:36433" > attrs:<> locality:<> 
I161116 07:20:41.988184 8991 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 1789h34m10.941000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:41.990963 9080 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:41.991899 9080 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:36433]
W161116 07:20:41.991993 9080 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:41.992128 9080 base/node_id.go:62  NodeID set to 2
I161116 07:20:41.997058 9151 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:36433
I161116 07:20:42.003608 9080 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:55513" > attrs:<> locality:<> 
I161116 07:20:42.004011 9080 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.005035 9080 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:36433]
W161116 07:20:42.005118 9080 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:42.005260 9080 base/node_id.go:62  NodeID set to 3
I161116 07:20:42.013568 9156 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:36433
I161116 07:20:42.018578 9080 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:57928" > attrs:<> locality:<> 
I161116 07:20:42.226111 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.227269 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.228440 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.229747 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.230232 9203 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57928->127.0.0.1:41914: use of closed network connection
I161116 07:20:42.230395 9014 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:55513->127.0.0.1:57191: use of closed network connection
I161116 07:20:42.230612 9144 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:42.230771 9089 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36433->127.0.0.1:37024: use of closed network connection
I161116 07:20:42.231164 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.231413 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.231568 9180 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftLogQueue (0.26s)
=== RUN   TestStoreRecoverFromEngine
I161116 07:20:42.238520 9270 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.239660 9270 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.239767 9270 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.239905 9270 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.240074 9270 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:42.247894 9270 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.249697 9277 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m43.147472172s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:42.249529344 +0000 UTC]
I161116 07:20:42.258524 9270 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
E161116 07:20:42.266221 9331 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:42.269349 9270 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.270790 9270 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.270874 9270 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.271000 9270 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.271125 9270 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:42.284255 9270 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.296566 9270 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRecoverFromEngine (0.07s)
=== RUN   TestStoreRecoverWithErrors
I161116 07:20:42.304872 9320 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.305865 9320 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.305947 9320 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.306070 9320 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.306205 9320 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:42.312735 9320 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.316027 9328 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h20m43.212930467s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:20:42.31589027 +0000 UTC]
I161116 07:20:42.320786 9437 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:20:42.322328 9320 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.322424 9320 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:20:42.322995 9437 storage/queue.go:575  [split,s1,r1/1:/M{in-ax}] unable to split [n1,s1,r1/1:/M{in-ax}] at key "/Table/11/0": node unavailable; try another peer
I161116 07:20:42.324269 9320 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.324354 9320 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.324485 9320 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.324659 9320 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:20:42.331877 9320 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.338463 9336 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:20:42.338735 9320 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.338816 9320 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:20:42.339350 9336 storage/queue.go:575  [split,s1,r1/1:/M{in-ax}] unable to split [n1,s1,r1/1:/M{in-ax}] at key "/Table/11/0": node unavailable; try another peer
--- PASS: TestStoreRecoverWithErrors (0.05s)
=== RUN   TestReplicateRange
I161116 07:20:42.352447 9396 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.353409 9396 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.353507 9396 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.353637 9396 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.364107 9396 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.364295 9396 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:45845" > attrs:<> locality:<> 
I161116 07:20:42.368910 9497 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:42.371719 9396 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.372745 9396 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:45845]
W161116 07:20:42.372828 9396 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:42.372965 9396 base/node_id.go:62  NodeID set to 2
I161116 07:20:42.385008 9556 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:45845
I161116 07:20:42.386415 9396 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:42.386595 9396 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:46790" > attrs:<> locality:<> 
I161116 07:20:42.392740 9396 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot e8a71a2a at index 14
I161116 07:20:42.394564 9396 storage/store.go:3134  streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:42.395323 9599 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=e8a71a2a, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:42.396260 9599 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:42.398060 9396 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:42.401430 9528 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:42.404958 9531 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.405935 9531 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.406809 9531 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.407111 9490 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:45845->127.0.0.1:55856: use of closed network connection
I161116 07:20:42.407250 9483 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:42.407345 9481 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46790->127.0.0.1:40759: use of closed network connection
I161116 07:20:42.407680 9531 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.407907 9531 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateRange (0.06s)
=== RUN   TestRestoreReplicas
I161116 07:20:42.414889 9607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.415860 9607 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:42.415956 9607 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:42.416118 9607 base/node_id.go:62  NodeID set to 1
I161116 07:20:42.423721 9607 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:42.423892 9607 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:44524" > attrs:<> locality:<> 
I161116 07:20:42.424510 9607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:42.425350 9607 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:44524]
W161116 07:20:42.425438 9607 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:42.425580 9607 base/node_id.go:62  NodeID set to 2
I161116 07:20:42.429579 9640 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:42.430192 9674 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:44524
I161116 07:20:42.432827 9607 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:42.433016 9607 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:41634" > attrs:<> locality:<> 
I161116 07:20:42.438633 9607 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 9843747f at index 14
I161116 07:20:42.440264 9607 storage/store.go:3134  streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:42.441137 9680 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=9843747f, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:42.442061 9680 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:42.443999 9607 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:42.447442 9473 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:42.582786 9748 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:42.950221 9607 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:42.951276 9607 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.479697 9810 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.480650 9810 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.481400 9810 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:43.482593 9748 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:43.483083 9621 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:41634->127.0.0.1:40332: use of closed network connection
I161116 07:20:43.483393 9618 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:44524->127.0.0.1:35112: use of closed network connection
I161116 07:20:43.483717 9810 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.483977 9810 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRestoreReplicas (1.07s)
=== RUN   TestFailedReplicaChange
I161116 07:20:43.493590 9739 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:43.494636 9739 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:43.494729 9739 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:43.494869 9739 base/node_id.go:62  NodeID set to 1
I161116 07:20:43.503976 9739 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:43.504174 9739 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:48294" > attrs:<> locality:<> 
I161116 07:20:43.505678 9842 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:43.508402 9739 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:43.511958 9739 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48294]
W161116 07:20:43.512040 9739 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:43.512177 9739 base/node_id.go:62  NodeID set to 2
I161116 07:20:43.516467 9728 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:48294
I161116 07:20:43.522549 9739 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:46537" > attrs:<> locality:<> 
I161116 07:20:43.524069 9739 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot d777c237 at index 13
I161116 07:20:43.528293 9950 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=d777c237, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:43.529194 9950 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:43.529304 9739 storage/store.go:3134  streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:43.530851 9739 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:43.534066 9954 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:43.534996 9845 storage/replica_command.go:87  [s1,r1/1:/M{in-ax}] test injecting error: boom
I161116 07:20:43.539423 9739 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 2693577b at index 16
I161116 07:20:43.544662 9739 storage/store.go:3134  streamed snapshot: kv pairs: 32, log entries: 6
I161116 07:20:43.548468 9952 storage/replica_raftstorage.go:587  [s2,r1/?:/M{in-ax}] applying preemptive snapshot at index 16 (id=2693577b, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:43.550582 9952 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:43.556652 9739 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:43.562292 9930 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:43.671281 9934 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:43.712513 9987 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.713628 9987 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.714696 9987 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.715341 9822 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46537->127.0.0.1:55015: use of closed network connection
I161116 07:20:43.715702 9740 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:48294->127.0.0.1:59073: use of closed network connection
I161116 07:20:43.716153 9987 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.716529 9987 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestFailedReplicaChange (0.24s)
=== RUN   TestPreemptiveSnapshotReleasedAfterApply
I161116 07:20:43.730532 9977 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:43.732967 9977 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:43.733191 9977 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:43.733464 9977 base/node_id.go:62  NodeID set to 1
I161116 07:20:43.774229 9977 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:43.774466 9977 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:47564" > attrs:<> locality:<> 
I161116 07:20:43.774756 10028 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:43.778116 9977 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:43.782270 9977 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:47564]
W161116 07:20:43.782353 9977 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:43.782491 9977 base/node_id.go:62  NodeID set to 2
I161116 07:20:43.790066 9966 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:47564
I161116 07:20:43.791399 9977 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:43.791603 9977 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:39375" > attrs:<> locality:<> 
I161116 07:20:43.808300 9977 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot da14a0db at index 13
I161116 07:20:43.810121 9977 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:43.811155 10116 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=da14a0db, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:43.812122 10116 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:43.816091 9977 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:43.823646 10059 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:43.941684 10147 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:43.963311 9706 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.964237 9706 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.965303 9706 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.965686 10018 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:47564->127.0.0.1:37942: use of closed network connection
I161116 07:20:43.965964 9921 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39375->127.0.0.1:55258: use of closed network connection
I161116 07:20:43.966273 9963 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:20:43.966708 10119 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:20:43.966752 9965 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:39375: operation was canceled"; Reconnecting to {"127.0.0.1:39375" <nil>}
I161116 07:20:43.966866 9965 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:43.966923 9706 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:43.967123 9706 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestPreemptiveSnapshotReleasedAfterApply (0.25s)
=== RUN   TestReplicateAfterTruncation
I161116 07:20:43.978762 10124 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:43.979764 10124 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:43.979858 10124 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:43.980017 10124 base/node_id.go:62  NodeID set to 1
I161116 07:20:43.993728 10124 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:43.993942 10124 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:51893" > attrs:<> locality:<> 
I161116 07:20:43.995467 10182 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:43.999703 10124 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.012357 10124 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51893]
W161116 07:20:44.012460 10124 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.012602 10124 base/node_id.go:62  NodeID set to 2
I161116 07:20:44.021042 10133 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:51893
I161116 07:20:44.023136 10124 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:44.023345 10124 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34243" > attrs:<> locality:<> 
I161116 07:20:44.041427 10124 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot e8dfdc77 at index 16
I161116 07:20:44.047656 10124 storage/store.go:3134  streamed snapshot: kv pairs: 34, log entries: 2
I161116 07:20:44.049080 10224 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 16 (id=e8dfdc77, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:20:44.050004 10224 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.052225 10124 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:44.067472 10273 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:44.123773 10247 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:44.163765 10291 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.167760 10291 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.169024 10291 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.170299 10165 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51893->127.0.0.1:48599: use of closed network connection
W161116 07:20:44.170416 10306 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:44.171230 10237 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34243->127.0.0.1:47677: use of closed network connection
I161116 07:20:44.171431 10291 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.171630 10291 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateAfterTruncation (0.21s)
=== RUN   TestSnapshotAfterTruncation
I161116 07:20:44.191124 10252 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.195865 10252 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:44.195970 10252 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:44.196107 10252 base/node_id.go:62  NodeID set to 1
I161116 07:20:44.211041 10252 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:44.211634 10252 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:43868" > attrs:<> locality:<> 
I161116 07:20:44.219994 10349 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:44.222348 10252 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.223262 10252 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:43868]
W161116 07:20:44.223346 10252 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.223483 10252 base/node_id.go:62  NodeID set to 2
I161116 07:20:44.232007 10315 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:43868
I161116 07:20:44.240180 10252 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34003" > attrs:<> locality:<> 
I161116 07:20:44.241642 10252 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.242679 10252 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:43868]
W161116 07:20:44.242762 10252 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.242895 10252 base/node_id.go:62  NodeID set to 3
I161116 07:20:44.261720 10482 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:43868
I161116 07:20:44.264660 10252 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:44.264867 10252 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:47665" > attrs:<> locality:<> 
I161116 07:20:44.282741 10252 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 8fdfb92a at index 15
I161116 07:20:44.285310 10252 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 34, log entries: 5
I161116 07:20:44.286191 10484 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 15 (id=8fdfb92a, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:20:44.287354 10484 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.289305 10252 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:44.293902 10488 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:44.311055 10252 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 332d53d2 at index 18
I161116 07:20:44.313233 10252 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 38, log entries: 8
I161116 07:20:44.314551 10447 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 18 (id=332d53d2, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:44.315770 10447 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.318097 10252 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:44.326593 10396 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:44.342310 10398 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:44.415557 10583 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:44.424352 10252 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:20:44.427160 10434 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
W161116 07:20:44.432279 10395 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:44.432524 10395 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:44.432698 10464 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:20:44.432811 10462 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:44.443572 10563 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:44.444102 10597 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:44.444464 10565 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:44.446350 10598 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:44.447026 10569 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:44.447749 10567 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:44.461788 10505 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:44.468922 10356 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot cf8491a0 at index 23
I161116 07:20:44.478110 10592 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 43, log entries: 1
I161116 07:20:44.478618 10539 storage/replica_raftstorage.go:587  [s2,r1/2:/M{in-ax}] applying Raft snapshot at index 23 (id=cf8491a0, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:44.480198 10539 storage/replica_raftstorage.go:590  [s2,r1/2:/M{in-ax}] applied Raft snapshot in 0.001s
I161116 07:20:44.481616 10658 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
I161116 07:20:44.486250 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:44.488114 10502 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:20:44.488619 10449 storage/store.go:2990  [s2] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:20:44.488760 10396 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:20:44.491450 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.497749 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.501609 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.503707 9709 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:47665->127.0.0.1:46090: use of closed network connection
I161116 07:20:44.506872 10140 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:44.507199 10142 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:47665: operation was canceled"; Reconnecting to {"127.0.0.1:47665" <nil>}
I161116 07:20:44.507263 10142 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:44.508006 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.508265 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.508426 10593 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSnapshotAfterTruncation (0.32s)
=== RUN   TestFailedSnapshotFillsReservation
I161116 07:20:44.515798 10552 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.517366 10552 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:44.517451 10552 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:44.517587 10552 base/node_id.go:62  NodeID set to 1
I161116 07:20:44.575598 10552 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:44.575813 10552 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:59884" > attrs:<> locality:<> 
I161116 07:20:44.576634 10543 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:44.579085 10552 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.580096 10552 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:59884]
W161116 07:20:44.580170 10552 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.580299 10552 base/node_id.go:62  NodeID set to 2
I161116 07:20:44.589383 10552 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:44.589675 10552 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34668" > attrs:<> locality:<> 
I161116 07:20:44.589718 10662 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:59884
I161116 07:20:44.590468 10552 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.594633 10552 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:59884]
W161116 07:20:44.594719 10552 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.594845 10552 base/node_id.go:62  NodeID set to 3
I161116 07:20:44.613945 10805 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:59884
I161116 07:20:44.625262 10552 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:44.625457 10552 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:35638" > attrs:<> locality:<> 
I161116 07:20:44.632292 10867 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
I161116 07:20:44.632690 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:20:44.633020 10666 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:20:44.634631 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.639339 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.640438 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.641664 10634 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34668->127.0.0.1:56852: use of closed network connection
I161116 07:20:44.641918 10540 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:59884->127.0.0.1:44671: use of closed network connection
I161116 07:20:44.642261 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.642531 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:44.642675 10866 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestFailedSnapshotFillsReservation (0.21s)
=== RUN   TestConcurrentRaftSnapshots
I161116 07:20:44.721586 10669 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.722555 10669 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:44.722647 10669 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:44.722773 10669 base/node_id.go:62  NodeID set to 1
I161116 07:20:44.736906 10669 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:44.737113 10669 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:40321" > attrs:<> locality:<> 
I161116 07:20:44.740964 10896 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:44.744217 10669 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.747761 10669 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40321]
W161116 07:20:44.747859 10669 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.748033 10669 base/node_id.go:62  NodeID set to 2
I161116 07:20:44.761440 10963 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:40321
I161116 07:20:44.767972 10669 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:38609" > attrs:<> locality:<> 
I161116 07:20:44.769076 10669 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.770144 10669 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40321]
W161116 07:20:44.770227 10669 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.770357 10669 base/node_id.go:62  NodeID set to 3
I161116 07:20:44.781381 10785 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:40321
I161116 07:20:44.781937 10669 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:44.782131 10669 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:57346" > attrs:<> locality:<> 
I161116 07:20:44.783062 10669 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.784066 10669 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40321]
W161116 07:20:44.784155 10669 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.784289 10669 base/node_id.go:62  NodeID set to 4
I161116 07:20:44.792032 10968 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:40321
I161116 07:20:44.794611 10669 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:20:44.794966 10669 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:50316" > attrs:<> locality:<> 
I161116 07:20:44.815366 10669 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:44.820184 10669 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40321]
W161116 07:20:44.820310 10669 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:44.820521 10669 base/node_id.go:62  NodeID set to 5
I161116 07:20:44.846865 11142 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:40321
I161116 07:20:44.851558 11146 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:57346})
I161116 07:20:44.852655 10669 storage/store.go:1188  [n5,s5]: failed initial metrics computation: [n5,s5]: system config not yet available
I161116 07:20:44.852839 10669 gossip/gossip.go:283  [n5] NodeDescriptor set to node_id:5 address:<network_field:"tcp" address_field:"127.0.0.1:49731" > attrs:<> locality:<> 
I161116 07:20:44.855106 11146 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 2 ({tcp 127.0.0.1:38609})
I161116 07:20:44.860574 11142 gossip/client.go:130  [n5] closing client to node 1 (127.0.0.1:40321): received forward from node 1 to 3 (127.0.0.1:57346)
I161116 07:20:44.863253 11182 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:57346
I161116 07:20:44.867379 10669 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot dbade8c1 at index 17
I161116 07:20:44.869502 10669 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 36, log entries: 7
I161116 07:20:44.880824 11049 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 17 (id=dbade8c1, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:44.881920 11049 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.886970 10669 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:44.893491 11233 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:44.897906 10669 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 59211d29 at index 19
I161116 07:20:44.904861 10669 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 39, log entries: 9
I161116 07:20:44.908988 11208 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 19 (id=59211d29, encoded size=16, 1 rocksdb batches, 9 log entries)
I161116 07:20:44.910161 11208 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.911777 11261 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:44.912770 10669 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:44.926500 11300 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:44.943289 10669 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot ae97347b at index 23
I161116 07:20:44.945238 10669 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 44, log entries: 13
I161116 07:20:44.945959 11292 storage/replica_raftstorage.go:587  [s4,r1/?:{-}] applying preemptive snapshot at index 23 (id=ae97347b, encoded size=16, 1 rocksdb batches, 13 log entries)
I161116 07:20:44.947213 11292 storage/replica_raftstorage.go:590  [s4,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:44.949325 10669 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:44.958285 11294 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:20:44.986125 10669 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 2f51a3b7 at index 25
I161116 07:20:45.001693 10669 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 47, log entries: 15
I161116 07:20:45.002447 11108 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:45.002483 11378 storage/replica_raftstorage.go:587  [s5,r1/?:{-}] applying preemptive snapshot at index 25 (id=2f51a3b7, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:20:45.004107 11378 storage/replica_raftstorage.go:590  [s5,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:45.012522 10669 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:20:45.015037 11053 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:45.035286 11112 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:20:45.111474 11416 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:45.132382 10669 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:45.132884 11260 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:45.133443 11258 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 0}: store 2 was not found
W161116 07:20:45.133578 11256 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:45.134212 10669 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.153138 11323 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:45.153983 11120 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:45.154365 11279 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.154553 11118 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:20:45.155011 11277 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:45.155142 11275 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:45.158796 11369 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:45.159298 11422 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.159700 11430 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:45.160324 11368 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:45.161016 11432 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:45.161442 11402 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:45.171652 11389 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:45.172201 11325 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:45.172599 11442 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:45.172637 11390 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:45.180349 11391 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:45.180938 11337 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.181179 11337 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.181227 11445 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:45.181582 11434 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:45.181630 11435 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:45.209553 11392 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:45.233949 11393 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:45.240037 10906 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 2a12debe at index 35
I161116 07:20:45.242209 11375 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 57, log entries: 2
I161116 07:20:45.243086 11528 storage/replica_raftstorage.go:587  [s2,r1/2:/M{in-ax}] applying Raft snapshot at index 35 (id=2a12debe, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:20:45.255763 11528 storage/replica_raftstorage.go:590  [s2,r1/2:/M{in-ax}] applied Raft snapshot in 0.013s
I161116 07:20:45.262958 10909 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot e6399c69 at index 36
I161116 07:20:45.265406 11500 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 58, log entries: 3
I161116 07:20:45.265836 11531 storage/replica_raftstorage.go:587  [s3,r1/3:/M{in-ax}] applying Raft snapshot at index 36 (id=e6399c69, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:45.267389 11531 storage/replica_raftstorage.go:590  [s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.001s
I161116 07:20:45.277973 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.298045 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.299223 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.301784 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.302819 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.304585 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.306269 10943 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:38609->127.0.0.1:50724: use of closed network connection
I161116 07:20:45.307237 11069 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50316->127.0.0.1:39302: use of closed network connection
I161116 07:20:45.307583 11013 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57346->127.0.0.1:44889: use of closed network connection
I161116 07:20:45.307810 11045 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49731->127.0.0.1:52163: use of closed network connection
I161116 07:20:45.308229 10885 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:40321->127.0.0.1:52108: use of closed network connection
W161116 07:20:45.309354 11400 storage/raft_transport.go:443  raft transport stream to node 5 failed: rpc error: code = 13 desc = transport is closing
W161116 07:20:45.310082 11350 storage/raft_transport.go:443  raft transport stream to node 4 failed: rpc error: code = 13 desc = transport is closing
W161116 07:20:45.310178 11416 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:45.310427 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.310686 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.310890 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.311088 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.311252 11544 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestConcurrentRaftSnapshots (0.59s)
=== RUN   TestReplicateAfterRemoveAndSplit
I161116 07:20:45.314986 11484 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:45.316023 11484 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:45.316118 11484 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:45.316249 11484 base/node_id.go:62  NodeID set to 1
I161116 07:20:45.324290 11484 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:45.324466 11484 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:51420" > attrs:<> locality:<> 
I161116 07:20:45.328294 11597 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:45.330557 11484 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:45.335679 11484 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51420]
W161116 07:20:45.335774 11484 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:45.337195 11484 base/node_id.go:62  NodeID set to 2
I161116 07:20:45.350319 11667 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:51420
I161116 07:20:45.351162 11484 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:45.351344 11484 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34042" > attrs:<> locality:<> 
I161116 07:20:45.353084 11484 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:45.355199 11484 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51420]
W161116 07:20:45.355310 11484 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:45.355445 11484 base/node_id.go:62  NodeID set to 3
I161116 07:20:45.362534 11655 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:51420
I161116 07:20:45.365436 11484 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:41299" > attrs:<> locality:<> 
I161116 07:20:45.373172 11484 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot abe37ae8 at index 13
I161116 07:20:45.376518 11484 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:45.377967 11583 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=abe37ae8, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:45.378880 11583 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:45.388942 11484 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:45.392407 11798 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:45.397979 11484 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot ea761b99 at index 16
I161116 07:20:45.401643 11484 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 36, log entries: 6
I161116 07:20:45.402332 11805 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 16 (id=ea761b99, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:45.403360 11805 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:45.405329 11484 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:45.412204 11809 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:45.428793 11829 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:45.517184 11757 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:45.578770 11484 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:45.585131 11484 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
W161116 07:20:45.587026 11756 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.587546 11642 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:45.587693 11784 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:45.588516 11649 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:45.588993 11864 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.589373 11774 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:45.590571 11891 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:45.592440 11892 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:45.592994 11894 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.593321 11894 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:45.593499 11877 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:45.602421 11484 storage/replica_command.go:2361  initiating a split of this range at key "m" [r2]
E161116 07:20:45.614928 11627 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:45.630020 11627 storage/queue.go:586  [replicate,s1,r2/1:{"m"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:45.631674 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 056f9073 at index 13
I161116 07:20:45.634618 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 7f113ed4 at index 13
I161116 07:20:45.637581 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 1b1be6e9 at index 13
I161116 07:20:45.648449 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 26cdbae8 at index 13
I161116 07:20:45.656975 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 6320731b at index 13
I161116 07:20:45.664895 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 5698ffb0 at index 13
I161116 07:20:45.668318 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 4436d96f at index 13
I161116 07:20:45.671371 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 20640a12 at index 13
I161116 07:20:45.676050 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot b0508b04 at index 13
I161116 07:20:45.678654 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 951b7ab7 at index 13
I161116 07:20:45.681296 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot a0dd0270 at index 13
I161116 07:20:45.684557 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot a1f78a42 at index 13
I161116 07:20:45.687727 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot e2678c88 at index 13
I161116 07:20:45.701387 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 877bd203 at index 13
I161116 07:20:45.705907 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot da967116 at index 13
I161116 07:20:45.709245 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 10cec3e9 at index 13
I161116 07:20:45.713517 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 46ee08c9 at index 13
I161116 07:20:45.720585 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 5d13e83a at index 13
I161116 07:20:45.727875 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 04e1d5d0 at index 13
I161116 07:20:45.736037 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot c925c030 at index 13
I161116 07:20:45.738906 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot c242bbf0 at index 13
I161116 07:20:45.744470 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 62831226 at index 13
I161116 07:20:45.748211 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 3c7f001e at index 13
I161116 07:20:45.752882 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot dfb34b25 at index 13
I161116 07:20:45.759670 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 4e018060 at index 13
I161116 07:20:45.771449 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot d26c555d at index 13
I161116 07:20:45.792435 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 4aaba8ec at index 13
I161116 07:20:45.829520 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 5fafdd8f at index 13
I161116 07:20:45.899899 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot f7329766 at index 13
I161116 07:20:45.921603 11759 storage/store.go:2986  [s3,r1/3:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:45.922188 11840 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:45.923184 12082 storage/store.go:2986  [s3,r1/3:/M{in-ax}] added to replica GC queue (peer suggestion)
W161116 07:20:45.924021 11923 storage/replica.go:3861  [s3] could not acquire lease for range gossip: range 1 was not found
W161116 07:20:45.924183 11923 storage/store.go:1237  [s3] error gossiping first range descriptor: range 1 was not found
W161116 07:20:45.924254 11924 storage/replica.go:3861  [s3] could not acquire lease for range gossip: range 1 was not found
W161116 07:20:45.924323 11924 storage/store.go:1237  [s3] error gossiping system config: range 1 was not found
I161116 07:20:46.037286 11484 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot cdbb06e4 at index 13
I161116 07:20:46.038813 11484 storage/store.go:3134  streamed snapshot: kv pairs: 28, log entries: 3
I161116 07:20:46.039614 12072 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 13 (id=cdbb06e4, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:46.040596 12072 storage/replica_raftstorage.go:590  [s3,r2/?:{"m"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:46.042402 11484 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:2 start_key:"m" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
W161116 07:20:46.047210 12022 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"m\x00"), but have [/Min,"m")
I161116 07:20:46.052378 12043 storage/replica.go:2066  [s1,r2/1:{"m"-/Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:46.057108 12084 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/client_test.go:501
1      storage/intent_resolver.go:383
1      kv/txn_coord_sender.go:918
I161116 07:20:46.057290 12084 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/client_test.go:501
1      storage/intent_resolver.go:383
W161116 07:20:46.057351 12044 storage/replica.go:1810  [s1,r1/1:{/Min-"m"}] shutdown cancellation of command [txn: 9d58bd2a], BeginTransaction [/System/NodeLiveness/1,/Min), ConditionalPut [/System/NodeLiveness/1,/Min), EndTransaction [/System/NodeLiveness/1,/Min)
W161116 07:20:46.057802 12045 storage/replica.go:1810  [s1,r1/1:{/Min-"m"}] shutdown cancellation of command ResolveIntent [/Meta2/Max,/Min)
E161116 07:20:46.057877 11633 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
I161116 07:20:46.058047 12084 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
W161116 07:20:46.058213 12075 storage/intent_resolver.go:337  [n1,s1,r2/1:{"m"-/Max}]: failed to resolve intents: result is ambiguous
I161116 07:20:46.058346 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:46.058908 11816 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:20:46.059333 11827 storage/store.go:2990  [s2] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:20:46.059583 11809 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:20:46.060533 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:46.062756 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:46.064204 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:46.064983 11639 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:20:46.065578 11653 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:41299->127.0.0.1:47866: use of closed network connection
I161116 07:20:46.066437 11452 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51420->127.0.0.1:54097: use of closed network connection
I161116 07:20:46.066523 11532 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34042->127.0.0.1:50428: use of closed network connection
I161116 07:20:46.066852 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:46.067128 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:46.067353 12083 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateAfterRemoveAndSplit (0.77s)
=== RUN   TestRefreshPendingCommands
I161116 07:20:46.081546 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:46.082636 12087 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:46.082722 12087 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:46.082850 12087 base/node_id.go:62  NodeID set to 1
I161116 07:20:46.094212 12087 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:46.094431 12087 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:42584" > attrs:<> locality:<> 
I161116 07:20:46.095216 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:46.096297 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:42584]
W161116 07:20:46.096539 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:46.096950 12087 base/node_id.go:62  NodeID set to 2
I161116 07:20:46.106141 12087 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:46.106322 12087 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:58222" > attrs:<> locality:<> 
I161116 07:20:46.106472 12193 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:42584
I161116 07:20:46.111060 12132 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:46.111655 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:46.112778 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:42584]
W161116 07:20:46.112917 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:46.115245 12087 base/node_id.go:62  NodeID set to 3
I161116 07:20:46.125696 12063 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:42584
I161116 07:20:46.126099 12087 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:46.126282 12087 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:47934" > attrs:<> locality:<> 
I161116 07:20:46.134298 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot d046868f at index 14
I161116 07:20:46.140281 12219 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=d046868f, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:46.140884 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:46.141332 12219 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:46.144038 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:46.147831 12269 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:46.152276 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot b5972f83 at index 17
I161116 07:20:46.153896 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:46.154598 12224 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=b5972f83, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:46.155841 12224 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:46.157747 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:46.161092 12107 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:46.165806 12204 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:46.275902 12171 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:46.313020 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:46.313255 12087 storage/client_test.go:997  engine 2: missing key "a"
I161116 07:20:46.313566 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:46.315309 12110 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:46.316003 12309 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:46.316168 12307 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:46.320160 12340 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:46.320835 12286 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:46.321335 12313 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:46.321407 12286 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
I161116 07:20:46.323259 12341 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:46.323789 12354 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:46.324155 12209 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:46.324680 12354 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
I161116 07:20:46.325497 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:46.744578 12327 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:46.745383 12297 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:46.746033 12411 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:47.009314 12187 storage/replica_raftstorage.go:443  [s2,r1/2:/M{in-ax}] generated snapshot 717a8764 at index 25
I161116 07:20:47.011661 12412 storage/store.go:3134  [s2,r1/2:/M{in-ax}] streamed snapshot: kv pairs: 45, log entries: 1
I161116 07:20:47.011930 12301 storage/replica_raftstorage.go:587  [s3,r1/3:/M{in-ax}] applying Raft snapshot at index 25 (id=717a8764, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:47.013234 12301 storage/replica_raftstorage.go:590  [s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.001s
I161116 07:20:47.017081 12184 storage/replica_proposal.go:381  [s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 3
I161116 07:20:47.018333 12398 storage/replica_proposal.go:332  [s3,r1/3:/M{in-ax}] new range lease replica {3 3 3} 1970-01-01 00:00:00.900000124 +0000 UTC 5.400000006s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:05.400000129 +0000 UTC]
I161116 07:20:47.019535 12179 storage/replica_proposal.go:381  [s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 3
I161116 07:20:47.432966 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.434198 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.435582 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.436593 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.437724 12115 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:58222->127.0.0.1:50784: use of closed network connection
I161116 07:20:47.438543 12079 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:47934->127.0.0.1:56972: use of closed network connection
I161116 07:20:47.439659 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.439941 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.440171 12303 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:47.440631 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:47.441555 12087 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:47.441637 12087 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:47.441764 12087 base/node_id.go:62  NodeID set to 1
I161116 07:20:47.449249 12087 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:47.449425 12087 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:46357" > attrs:<> locality:<> 
I161116 07:20:47.449982 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:47.450956 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:46357]
W161116 07:20:47.451053 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:47.451186 12087 base/node_id.go:62  NodeID set to 2
I161116 07:20:47.454579 12486 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:47.456177 12366 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:46357
I161116 07:20:47.458460 12087 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:47.459085 12087 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:50006" > attrs:<> locality:<> 
I161116 07:20:47.459796 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:47.460851 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:46357]
W161116 07:20:47.460954 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:47.461086 12087 base/node_id.go:62  NodeID set to 3
I161116 07:20:47.467826 12510 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:46357
I161116 07:20:47.469468 12087 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:47.469648 12087 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:57427" > attrs:<> locality:<> 
I161116 07:20:47.482437 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 3e565d20 at index 13
I161116 07:20:47.484274 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:47.484942 12613 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=3e565d20, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:47.485818 12613 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:47.487767 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:47.491165 12570 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:47.506538 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 0bb812da at index 15
I161116 07:20:47.512273 12622 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:47.515860 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 35, log entries: 5
I161116 07:20:47.520985 12513 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 15 (id=0bb812da, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:20:47.521998 12513 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:47.527706 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:47.535752 12560 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:47.621076 12632 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:47.692847 12087 storage/client_test.go:997  engine 1: missing key "a"
I161116 07:20:47.693435 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:47.696218 12463 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:47.697004 12662 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:47.697151 12660 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:47.698929 12678 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:47.700017 12667 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:47.700379 12680 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:47.700458 12667 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
I161116 07:20:47.702723 12668 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:47.703509 12649 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
I161116 07:20:47.703727 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:47.703900 12723 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:47.706083 12575 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:20:47.706550 12573 storage/store.go:2990  [s2] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:20:47.706680 12622 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:20:47.716786 12475 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:48.159320 12790 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:48.161387 12728 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:48.162957 12522 storage/replica_raftstorage.go:443  [s2,r1/2:/M{in-ax}] generated snapshot 6c685ed7 at index 25
I161116 07:20:48.165385 12685 storage/store.go:3134  [s2,r1/2:/M{in-ax}] streamed snapshot: kv pairs: 45, log entries: 1
I161116 07:20:48.165642 12479 storage/replica_raftstorage.go:587  [s3,r1/3:/M{in-ax}] applying Raft snapshot at index 25 (id=6c685ed7, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:48.166027 12526 storage/replica_proposal.go:381  [s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 3
I161116 07:20:48.167718 12479 storage/replica_raftstorage.go:590  [s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.002s
I161116 07:20:48.171341 12779 storage/replica_proposal.go:332  [s3,r1/3:/M{in-ax}] new range lease replica {3 3 3} 1970-01-01 00:00:00.900000124 +0000 UTC 5.400000006s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:05.400000129 +0000 UTC]
I161116 07:20:48.175377 12795 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:48.272971 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:48.273871 12674 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:0}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:0}
W161116 07:20:48.274336 12634 storage/store.go:2990  [s3] raft error: node 1 claims to not contain store 1 for replica {1 1 0}: store 1 was not found
W161116 07:20:48.274478 12632 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:20:48.280312 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.281474 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.283174 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.284825 12549 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57427->127.0.0.1:59995: use of closed network connection
W161116 07:20:48.285011 12728 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:20:48.285440 12469 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50006->127.0.0.1:47396: use of closed network connection
W161116 07:20:48.285688 12617 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:48.286511 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.286742 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.286997 12758 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.287415 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:48.288314 12087 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:48.288412 12087 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:48.288546 12087 base/node_id.go:62  NodeID set to 1
I161116 07:20:48.296573 12087 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:48.297312 12087 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:50499" > attrs:<> locality:<> 
I161116 07:20:48.298927 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:48.299941 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:50499]
W161116 07:20:48.300048 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:48.300573 12087 base/node_id.go:62  NodeID set to 2
I161116 07:20:48.309890 12768 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:48.311092 12872 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:50499
I161116 07:20:48.315559 12087 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:41123" > attrs:<> locality:<> 
I161116 07:20:48.315962 12087 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:48.316911 12087 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:50499]
W161116 07:20:48.317015 12087 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:48.317147 12087 base/node_id.go:62  NodeID set to 3
I161116 07:20:48.322313 12962 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:50499
I161116 07:20:48.324986 12087 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:48.325156 12087 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:36620" > attrs:<> locality:<> 
I161116 07:20:48.337088 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 6afcde41 at index 14
I161116 07:20:48.339251 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:48.340279 12718 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=6afcde41, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:48.341228 12718 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:48.343113 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:48.346576 12814 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:48.351701 12087 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 7a7eee0c at index 16
I161116 07:20:48.353799 12087 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 36, log entries: 6
I161116 07:20:48.354589 12994 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 16 (id=7a7eee0c, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:48.355786 12994 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:48.358126 12087 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:48.362856 13012 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:48.372488 12966 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:48.388032 13028 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:48.398437 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.398579 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.398877 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.398953 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.399208 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.399280 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.399620 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.399696 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.399840 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.399897 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.400069 12087 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:48.400127 12087 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:48.400324 12087 storage/client_test.go:997  engine 2: missing key "a"
I161116 07:20:48.400611 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:48.408506 13027 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:48.408929 12993 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:20:48.409069 12881 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:48.410078 12844 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:48.410872 12925 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:48.411275 13017 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:48.412764 12845 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:48.413362 13030 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:48.413747 13030 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:48.413951 12997 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:48.415246 12087 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:48.738500 13103 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:48.739950 12848 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:48.740172 13036 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:20:49.021654 12898 storage/replica_raftstorage.go:443  [s2,r1/2:/M{in-ax}] generated snapshot b21c65ba at index 23
I161116 07:20:49.023901 12926 storage/store.go:3134  [s2,r1/2:/M{in-ax}] streamed snapshot: kv pairs: 42, log entries: 2
I161116 07:20:49.024337 13108 storage/replica_raftstorage.go:587  [s3,r1/3:/M{in-ax}] applying Raft snapshot at index 23 (id=b21c65ba, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:20:49.025693 13108 storage/replica_raftstorage.go:590  [s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.001s
I161116 07:20:49.042132 13085 storage/replica_proposal.go:332  [s3,r1/3:/M{in-ax}] new range lease replica {3 3 3} 1970-01-01 00:00:00.900000124 +0000 UTC 5.400000006s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:05.400000129 +0000 UTC]
I161116 07:20:49.048260 12894 storage/replica_proposal.go:381  [s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 3
I161116 07:20:49.531399 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.532396 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.534255 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.534973 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.536059 12800 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36620->127.0.0.1:38208: use of closed network connection
I161116 07:20:49.536240 12937 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:20:49.536386 13103 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:20:49.536749 12825 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50499->127.0.0.1:33610: use of closed network connection
I161116 07:20:49.537012 12836 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:41123->127.0.0.1:55013: use of closed network connection
I161116 07:20:49.538107 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.538421 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.538552 12967 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRefreshPendingCommands (3.46s)
=== RUN   TestStoreRangeUpReplicate
I161116 07:20:49.548987 13127 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.550188 13127 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:49.550314 13127 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:49.550454 13127 base/node_id.go:62  NodeID set to 1
I161116 07:20:49.562646 13127 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:49.562824 13127 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:34168" > attrs:<> locality:<> 
I161116 07:20:49.575884 13194 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:49.578995 13127 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.581509 13127 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:34168]
W161116 07:20:49.581598 13127 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.581736 13127 base/node_id.go:62  NodeID set to 2
I161116 07:20:49.588427 13234 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:34168
I161116 07:20:49.590155 13127 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:49.590360 13127 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:43328" > attrs:<> locality:<> 
I161116 07:20:49.608011 13127 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.610916 13127 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:34168]
W161116 07:20:49.611026 13127 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.611212 13127 base/node_id.go:62  NodeID set to 3
I161116 07:20:49.617135 13217 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:34168
I161116 07:20:49.621547 13127 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:36309" > attrs:<> locality:<> 
I161116 07:20:49.629849 13127 storage/client_test.go:414  gossip network initialized
I161116 07:20:49.630676 13127 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot e4c8d975 at index 15
I161116 07:20:49.634067 13127 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 34, log entries: 5
I161116 07:20:49.634983 13378 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 15 (id=e4c8d975, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:20:49.639275 13378 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.004s
I161116 07:20:49.642587 13127 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:49.651052 13380 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2}]
I161116 07:20:49.657169 13230 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot d8ef22df at index 17
I161116 07:20:49.659706 13230 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:49.660393 13295 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 17 (id=d8ef22df, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:49.667554 13295 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.007s
I161116 07:20:49.668330 13398 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:20:49.669179 13230 storage/queue.go:575  [replicate,s1,r1/1:/M{in-ax}] change replicas of range 1 failed: node unavailable; try another peer
I161116 07:20:49.669300 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.675042 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.676163 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.677213 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.677592 13212 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:43328->127.0.0.1:34751: use of closed network connection
I161116 07:20:49.677731 13301 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:49.678360 13111 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:49.678509 13177 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36309->127.0.0.1:33261: use of closed network connection
I161116 07:20:49.678566 13136 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34168->127.0.0.1:56117: use of closed network connection
I161116 07:20:49.678617 13303 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:36309: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:36309" <nil>}
I161116 07:20:49.679024 13113 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:34168: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:34168" <nil>}
I161116 07:20:49.688137 13113 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:20:49.691637 13303 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:20:49.691943 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.692154 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:49.692391 13397 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeUpReplicate (0.15s)
=== RUN   TestStoreRangeCorruptionChangeReplicas
I161116 07:20:49.700136 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.701068 13385 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:49.701162 13385 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:49.701296 13385 base/node_id.go:62  NodeID set to 1
I161116 07:20:49.709636 13385 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:49.709857 13385 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:55660" > attrs:<> locality:<> 
I161116 07:20:49.712173 13418 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 83h20m0.000000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:49.715220 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.718876 13385 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55660]
W161116 07:20:49.718981 13385 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.720106 13385 base/node_id.go:62  NodeID set to 2
I161116 07:20:49.723894 13248 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:55660
I161116 07:20:49.727009 13385 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:49.727351 13385 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:39350" > attrs:<> locality:<> 
I161116 07:20:49.730884 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.732019 13385 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55660]
W161116 07:20:49.732798 13385 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.733198 13385 base/node_id.go:62  NodeID set to 3
I161116 07:20:49.745752 13278 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:55660
I161116 07:20:49.747591 13385 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:49.747783 13385 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:35015" > attrs:<> locality:<> 
I161116 07:20:49.748938 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.750491 13385 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55660]
W161116 07:20:49.750578 13385 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.750723 13385 base/node_id.go:62  NodeID set to 4
I161116 07:20:49.758208 13583 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:55660
I161116 07:20:49.760012 13385 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:20:49.760265 13385 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:36039" > attrs:<> locality:<> 
I161116 07:20:49.762975 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.763931 13385 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55660]
W161116 07:20:49.764106 13385 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.764253 13385 base/node_id.go:62  NodeID set to 5
I161116 07:20:49.774024 13531 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:55660
I161116 07:20:49.774469 13153 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 4 ({tcp 127.0.0.1:36039})
I161116 07:20:49.775661 13385 storage/store.go:1188  [n5,s5]: failed initial metrics computation: [n5,s5]: system config not yet available
I161116 07:20:49.775839 13385 gossip/gossip.go:283  [n5] NodeDescriptor set to node_id:5 address:<network_field:"tcp" address_field:"127.0.0.1:42310" > attrs:<> locality:<> 
I161116 07:20:49.784512 13385 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:49.786692 13385 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55660]
W161116 07:20:49.786780 13385 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:49.786912 13385 base/node_id.go:62  NodeID set to 6
I161116 07:20:49.787868 13531 gossip/client.go:130  [n5] closing client to node 1 (127.0.0.1:55660): received forward from node 1 to 4 (127.0.0.1:36039)
I161116 07:20:49.792014 13778 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:36039
I161116 07:20:49.801817 13780 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:55660
I161116 07:20:49.802963 13385 storage/store.go:1188  [n6,s6]: failed initial metrics computation: [n6,s6]: system config not yet available
I161116 07:20:49.803147 13385 gossip/gossip.go:283  [n6] NodeDescriptor set to node_id:6 address:<network_field:"tcp" address_field:"127.0.0.1:43650" > attrs:<> locality:<> 
I161116 07:20:49.803191 13784 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:35015})
I161116 07:20:49.805871 13784 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:35015})
I161116 07:20:49.808833 13780 gossip/client.go:130  [n6] closing client to node 1 (127.0.0.1:55660): received forward from node 1 to 3 (127.0.0.1:35015)
I161116 07:20:49.811863 13853 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:35015
I161116 07:20:49.841272 13385 storage/client_test.go:414  gossip network initialized
I161116 07:20:49.842174 13385 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot feb44e41 at index 18
I161116 07:20:49.843972 13385 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 8
I161116 07:20:49.844868 13774 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 18 (id=feb44e41, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:49.847238 13774 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:49.850214 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:49.854604 13776 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2}]
I161116 07:20:49.860064 13385 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot 0535cd41 at index 20
I161116 07:20:49.862486 13385 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 40, log entries: 10
I161116 07:20:49.863310 13956 storage/replica_raftstorage.go:587  [s5,r1/?:{-}] applying preemptive snapshot at index 20 (id=0535cd41, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:20:49.864543 13956 storage/replica_raftstorage.go:590  [s5,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:49.866675 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > next_replica_id:3 
I161116 07:20:49.870469 13960 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:49.877347 13964 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:3}]
I161116 07:20:49.885156 14005 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:49.885311 13556 storage/replica.go:4086  [s3,r1/2:/M{in-ax}] stalling replica due to: boom
I161116 07:20:49.889778 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:3 > next_replica_id:4 
W161116 07:20:49.892001 13959 storage/store.go:2994  [s1] got error from range 1, replica {3 3 2}: replica corruption (processed=true): boom
W161116 07:20:49.893308 13959 storage/store.go:2994  [s1] got error from range 1, replica {3 3 2}: replica corruption (processed=true): boom
I161116 07:20:49.895016 13917 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:3}]
W161116 07:20:49.896433 13959 storage/store.go:2994  [s1] got error from range 1, replica {3 3 2}: replica corruption (processed=true): boom
W161116 07:20:49.897754 13959 storage/store.go:2994  [s1] got error from range 1, replica {3 3 2}: replica corruption (processed=true): boom
I161116 07:20:49.901147 13437 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot 399b3890 at index 25
I161116 07:20:49.903316 13437 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 47, log entries: 15
I161116 07:20:49.904041 14013 storage/replica_raftstorage.go:587  [s4,r1/?:{-}] applying preemptive snapshot at index 25 (id=399b3890, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:20:49.905403 14013 storage/replica_raftstorage.go:590  [s4,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:49.907737 13437 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:3 > next_replica_id:4 
I161116 07:20:49.912959 14015 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:20:49.931048 13927 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:49.931562 13720 storage/replica.go:4086  [s5,r1/3:/M{in-ax}] stalling replica due to: boom
I161116 07:20:49.939819 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
W161116 07:20:49.942091 13912 storage/store.go:2994  [s1] got error from range 1, replica {5 5 3}: replica corruption (processed=true): boom
W161116 07:20:49.944128 13912 storage/store.go:2994  [s1] got error from range 1, replica {5 5 3}: replica corruption (processed=true): boom
I161116 07:20:49.944771 13982 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:4}]
W161116 07:20:49.946028 13912 storage/store.go:2994  [s1] got error from range 1, replica {5 5 3}: replica corruption (processed=true): boom
W161116 07:20:49.948150 13912 storage/store.go:2994  [s1] got error from range 1, replica {5 5 3}: replica corruption (processed=true): boom
I161116 07:20:49.951514 13385 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot bb14f289 at index 30
I161116 07:20:49.954215 13385 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 54, log entries: 20
W161116 07:20:49.960709 13912 storage/store.go:2994  [s1] got error from range 1, replica {5 5 3}: replica corruption (processed=true): boom
I161116 07:20:49.961710 14051 storage/replica_raftstorage.go:587  [s6,r1/?:{-}] applying preemptive snapshot at index 30 (id=bb14f289, encoded size=16, 1 rocksdb batches, 20 log entries)
I161116 07:20:49.964668 14051 storage/replica_raftstorage.go:590  [s6,r1/?:/M{in-ax}] applied preemptive snapshot in 0.003s
I161116 07:20:49.968672 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:20:49.993702 14053 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:6 StoreID:6 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:4} {NodeID:6 StoreID:6 ReplicaID:5}]
E161116 07:20:49.999357 13646 storage/replica.go:4086  [s4,r1/4:/M{in-ax}] stalling replica due to: boom
W161116 07:20:50.002650 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
I161116 07:20:50.011956 14033 storage/raft_transport.go:437  raft transport stream to node 1 established
W161116 07:20:50.020039 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
I161116 07:20:50.027929 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:4 > replicas:<node_id:6 store_id:6 replica_id:5 > next_replica_id:6 
W161116 07:20:50.031722 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
W161116 07:20:50.033568 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
I161116 07:20:50.034523 14101 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:6 StoreID:6 ReplicaID:5}]
W161116 07:20:50.035775 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
W161116 07:20:50.039087 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
I161116 07:20:50.040643 13385 storage/replica_raftstorage.go:443  [replicate,s1,r1/1:/M{in-ax}] generated snapshot c42b5049 at index 35
I161116 07:20:50.043044 13385 storage/store.go:3134  [replicate,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 61, log entries: 25
I161116 07:20:50.043826 14063 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 35 (id=c42b5049, encoded size=16, 1 rocksdb batches, 25 log entries)
I161116 07:20:50.045461 14063 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:50.047649 13385 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:6 store_id:6 replica_id:5 > next_replica_id:6 
I161116 07:20:50.052652 14105 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:6 StoreID:6 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
W161116 07:20:50.060161 13902 storage/store.go:2994  [s1] got error from range 1, replica {4 4 4}: replica corruption (processed=true): boom
I161116 07:20:50.061291 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.062603 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.067440 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.068642 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.072443 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.073704 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.075137 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:50.077406 14055 storage/raft_transport.go:443  raft transport stream to node 6 failed: EOF
I161116 07:20:50.078159 13147 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36039->127.0.0.1:56907: use of closed network connection
I161116 07:20:50.078563 13281 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:50.079089 13151 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:42310->127.0.0.1:60854: use of closed network connection
I161116 07:20:50.079370 13606 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:50.079438 13635 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:36039: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:36039" <nil>}
I161116 07:20:50.079470 13623 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:43650->127.0.0.1:42379: use of closed network connection
I161116 07:20:50.079880 13608 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:42310: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:42310" <nil>}
I161116 07:20:50.080269 13608 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:20:50.080408 13456 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39350->127.0.0.1:58971: use of closed network connection
I161116 07:20:50.080600 13635 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:20:50.080944 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.081106 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.081283 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.081426 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.081629 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.081771 14073 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeCorruptionChangeReplicas (0.44s)
=== RUN   TestUnreplicateFirstRange
I161116 07:20:50.153191 14130 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.154309 14130 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:50.154404 14130 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:50.154533 14130 base/node_id.go:62  NodeID set to 1
I161116 07:20:50.169277 14130 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:50.169470 14130 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:53763" > attrs:<> locality:<> 
I161116 07:20:50.173617 14156 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:50.176594 14130 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.177578 14130 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:53763]
W161116 07:20:50.177662 14130 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.177795 14130 base/node_id.go:62  NodeID set to 2
I161116 07:20:50.187376 14130 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:50.187581 14130 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:49834" > attrs:<> locality:<> 
I161116 07:20:50.189104 14130 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.190056 14130 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:53763]
W161116 07:20:50.190164 14130 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.190295 14130 base/node_id.go:62  NodeID set to 3
I161116 07:20:50.190876 14241 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:53763
I161116 07:20:50.202195 14198 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:53763
I161116 07:20:50.218434 14130 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:53335" > attrs:<> locality:<> 
I161116 07:20:50.225174 14130 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot bf1da918 at index 14
I161116 07:20:50.227224 14130 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:50.228049 14300 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=bf1da918, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:50.229009 14300 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:50.231511 14130 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:50.237291 14348 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:50.262409 14125 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:50.282633 14130 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:50.288001 14360 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:50.321922 14358 storage/store.go:2986  [s1,r1/1:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:50.690908 14224 storage/replica_proposal.go:332  [s2,r1/2:/M{in-ax}] new range lease replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 1.800000002s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:01.800000125 +0000 UTC]
I161116 07:20:50.696849 14130 storage/replica_raftstorage.go:443  [s2,r1/2:/M{in-ax}] generated snapshot 4365712e at index 22
I161116 07:20:50.700335 14130 storage/store.go:3134  [s2,r1/2:/M{in-ax}] streamed snapshot: kv pairs: 41, log entries: 12
I161116 07:20:50.702486 13937 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 22 (id=4365712e, encoded size=16, 1 rocksdb batches, 12 log entries)
I161116 07:20:50.703718 13937 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:50.707639 14130 storage/replica_command.go:3245  [s2,r1/2:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:50.713777 14266 storage/replica.go:2066  [s2,r1/2:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:50.726105 14400 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:50.734271 14453 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
E161116 07:20:50.735238 14134 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:20:50.735358 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.736664 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.740525 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.742126 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.743764 14112 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49834->127.0.0.1:44247: use of closed network connection
W161116 07:20:50.743840 14400 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:50.743950 14196 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:53335->127.0.0.1:58909: use of closed network connection
I161116 07:20:50.744331 14131 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:53763->127.0.0.1:34459: use of closed network connection
W161116 07:20:50.744567 14125 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:50.744965 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.745251 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.745543 14451 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestUnreplicateFirstRange (0.62s)
=== RUN   TestStoreRangeDownReplicate
--- SKIP: TestStoreRangeDownReplicate (0.01s)
	client_raft_test.go:1155: #9603, #10171, #10536
=== RUN   TestChangeReplicasDescriptorInvariant
I161116 07:20:50.782970 14270 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.785299 14270 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:50.785386 14270 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:50.785514 14270 base/node_id.go:62  NodeID set to 1
I161116 07:20:50.795461 14270 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:50.795671 14270 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49139" > attrs:<> locality:<> 
I161116 07:20:50.796784 14508 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:50.799731 14270 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.801680 14270 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49139]
W161116 07:20:50.804220 14270 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.804402 14270 base/node_id.go:62  NodeID set to 2
I161116 07:20:50.809555 14563 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:49139
I161116 07:20:50.814581 14270 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:44463" > attrs:<> locality:<> 
I161116 07:20:50.814936 14270 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.815885 14270 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49139]
W161116 07:20:50.815972 14270 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.816095 14270 base/node_id.go:62  NodeID set to 3
I161116 07:20:50.820650 14547 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:49139
I161116 07:20:50.827853 14270 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:37754" > attrs:<> locality:<> 
I161116 07:20:50.838002 14270 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4bc1eec7 at index 14
I161116 07:20:50.844320 14270 storage/store.go:3134  streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:50.847263 14681 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=4bc1eec7, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:50.848610 14681 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:50.854687 14270 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:50.860616 14690 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:50.864299 14270 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 72cfabe4 at index 16
I161116 07:20:50.866704 14270 storage/store.go:3134  streamed snapshot: kv pairs: 36, log entries: 6
I161116 07:20:50.867583 14551 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 16 (id=72cfabe4, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:50.868743 14551 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:50.871638 14270 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:50.872575 14554 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:50.886643 14270 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 2e627f00 at index 18
I161116 07:20:50.888328 14270 storage/store.go:3134  streamed snapshot: kv pairs: 37, log entries: 8
I161116 07:20:50.888804 14689 storage/replica_raftstorage.go:587  [s3,r1/?:/M{in-ax}] applying preemptive snapshot at index 18 (id=2e627f00, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:50.890350 14689 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:50.895084 14270 storage/replica_command.go:3245  change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:50.900352 14725 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:50.913209 14740 util/stop/stopper.go:468  quiescing; tasks left:
1      kv/txn_coord_sender.go:918
I161116 07:20:50.913492 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.914783 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.924965 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.926176 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.927252 14628 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:37754->127.0.0.1:40150: use of closed network connection
I161116 07:20:50.927612 14565 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:50.928243 14567 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:37754: operation was canceled"; Reconnecting to {"127.0.0.1:37754" <nil>}
I161116 07:20:50.928313 14567 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:50.929943 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.930176 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:50.930448 14739 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestChangeReplicasDescriptorInvariant (0.17s)
=== RUN   TestProgressWithDownNode
I161116 07:20:50.942166 14743 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.943156 14743 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:50.943256 14743 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:50.943384 14743 base/node_id.go:62  NodeID set to 1
I161116 07:20:50.964135 14743 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:50.964347 14743 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:48524" > attrs:<> locality:<> 
I161116 07:20:50.965977 14766 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:50.968410 14743 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.969394 14743 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48524]
W161116 07:20:50.969481 14743 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.969619 14743 base/node_id.go:62  NodeID set to 2
I161116 07:20:50.976414 14743 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:50.976687 14743 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:40185" > attrs:<> locality:<> 
I161116 07:20:50.977568 14743 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:50.978703 14743 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48524]
W161116 07:20:50.978804 14743 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:50.978935 14743 base/node_id.go:62  NodeID set to 3
I161116 07:20:50.980072 14790 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:48524
I161116 07:20:50.999938 14795 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:48524
I161116 07:20:51.005944 14743 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:46156" > attrs:<> locality:<> 
I161116 07:20:51.009446 14743 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 9ec8a16f at index 13
I161116 07:20:51.016522 14743 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:51.017455 14904 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=9ec8a16f, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:51.021092 14904 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.004s
I161116 07:20:51.029431 14743 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:51.038556 14907 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:51.044008 14743 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 6a2a50ec at index 17
I161116 07:20:51.046223 14743 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:51.049298 14952 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=6a2a50ec, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:51.050351 14952 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:51.052518 14743 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:51.058247 14962 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:51.066180 14854 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:51.156718 14699 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:51.218318 14743 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:51.220462 14913 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.220870 14938 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:20:51.220996 14936 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:51.222710 14974 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:51.223442 15010 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.223841 14976 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:51.314400 15000 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:51.375910 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.377090 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.389204 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.391061 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.392930 14871 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46156->127.0.0.1:53946: use of closed network connection
W161116 07:20:51.393787 14962 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:51.394600 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.394821 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.394970 15013 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestProgressWithDownNode (0.47s)
=== RUN   TestReplicateRestartAfterTruncationWithRemoveAndReAdd
I161116 07:20:51.408835 15057 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:51.409865 15057 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:51.409954 15057 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:51.410083 15057 base/node_id.go:62  NodeID set to 1
I161116 07:20:51.418228 15057 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:51.418404 15057 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:37543" > attrs:<> locality:<> 
I161116 07:20:51.422753 14992 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 83h20m0.000000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:51.425629 15057 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:51.426607 15057 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37543]
W161116 07:20:51.426707 15057 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:51.426851 15057 base/node_id.go:62  NodeID set to 2
I161116 07:20:51.432005 15005 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:37543
I161116 07:20:51.434079 15057 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:51.434268 15057 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:54384" > attrs:<> locality:<> 
I161116 07:20:51.435812 15057 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:51.436843 15057 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37543]
W161116 07:20:51.436986 15057 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:51.439330 15057 base/node_id.go:62  NodeID set to 3
I161116 07:20:51.452135 15219 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:37543
I161116 07:20:51.453385 15057 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:51.453587 15057 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:51672" > attrs:<> locality:<> 
I161116 07:20:51.460561 15057 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot cddeebb0 at index 14
I161116 07:20:51.464922 15057 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:51.467339 14860 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=cddeebb0, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:51.468334 14860 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:51.475715 15057 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:51.479567 15303 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:51.484023 15057 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 35138f4a at index 17
I161116 07:20:51.488508 15057 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:51.490650 15310 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=35138f4a, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:51.491773 15310 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:51.494005 15057 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:51.498180 15313 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:51.507135 15330 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:51.603269 15223 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:51.656991 15057 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:51.657064 15057 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:51.657223 15057 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:51.657323 15057 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:51.657566 15057 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:51.657632 15057 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:20:51.659272 15057 storage/client_test.go:997  engine 1: missing key "a"
I161116 07:20:51.659696 15057 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:51.663384 15057 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
W161116 07:20:51.665296 15274 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.665741 15312 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:20:51.665862 15272 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:51.667424 15318 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:51.668540 15196 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.670458 15196 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:51.670572 15339 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:51.671980 15341 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:51.673153 15342 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:51.673952 15286 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.674375 15344 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:51.675364 15345 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:51.676502 15288 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:51.677000 15278 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:51.710986 15057 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4912704c at index 25
I161116 07:20:51.712904 15057 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 45, log entries: 3
I161116 07:20:51.713368 15294 storage/replica_raftstorage.go:587  [s2,r1/2:/M{in-ax}] applying Raft snapshot at index 25 (id=4912704c, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:51.714674 15294 storage/replica_raftstorage.go:590  [s2,r1/2:/M{in-ax}] applied Raft snapshot in 0.001s
I161116 07:20:51.716814 15057 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:51.724395 15390 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:4}]
W161116 07:20:51.872505 15385 storage/replica.go:3861  [s2] could not acquire lease for range gossip: range 1 was not found
W161116 07:20:51.872585 15385 storage/store.go:1237  [s2] error gossiping system config: range 1 was not found
I161116 07:20:52.004876 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.006009 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.007199 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.008709 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.010762 15115 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:54384->127.0.0.1:34146: use of closed network connection
I161116 07:20:52.011223 15017 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:37543->127.0.0.1:48941: use of closed network connection
I161116 07:20:52.012054 15151 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51672->127.0.0.1:35046: use of closed network connection
I161116 07:20:52.012989 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.013242 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.013462 14863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateRestartAfterTruncationWithRemoveAndReAdd (0.63s)
=== RUN   TestReplicateRestartAfterTruncation
I161116 07:20:52.037648 15410 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.039687 15410 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:52.039773 15410 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:52.039905 15410 base/node_id.go:62  NodeID set to 1
I161116 07:20:52.073521 15443 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 83h20m0.000000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:52.077812 15410 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:40911" > attrs:<> locality:<> 
I161116 07:20:52.078769 15410 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.083763 15410 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40911]
W161116 07:20:52.083941 15410 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:52.085244 15410 base/node_id.go:62  NodeID set to 2
I161116 07:20:52.093203 15518 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:40911
I161116 07:20:52.094263 15410 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:52.094460 15410 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:43889" > attrs:<> locality:<> 
I161116 07:20:52.095712 15410 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.097855 15410 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40911]
W161116 07:20:52.098094 15410 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:52.098247 15410 base/node_id.go:62  NodeID set to 3
I161116 07:20:52.105814 15232 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:40911
I161116 07:20:52.108898 15410 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:52.109153 15410 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:46102" > attrs:<> locality:<> 
I161116 07:20:52.131185 15410 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 5dff3eba at index 14
I161116 07:20:52.133235 15410 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:52.134044 15590 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=5dff3eba, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:52.135223 15590 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:52.137473 15410 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:52.144032 15536 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:52.151604 15410 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 9036b9bb at index 17
I161116 07:20:52.156620 15410 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:52.159123 15592 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=9036b9bb, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:52.161462 15592 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:52.165302 15410 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:52.177904 15654 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:52.185500 15596 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:52.306026 15673 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:52.356438 15410 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:52.358802 15653 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:52.359225 15642 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:20:52.359366 15549 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:52.361616 15682 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.363502 15699 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:52.363763 15699 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:52.364114 15684 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:20:52.421688 15678 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:52.516473 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.520660 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.521827 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.522916 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.525491 15532 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46102->127.0.0.1:36391: use of closed network connection
I161116 07:20:52.525777 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.526057 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:52.526276 15685 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateRestartAfterTruncation (0.51s)
=== RUN   TestReplicateAddAndRemove
I161116 07:20:52.539931 15607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.540937 15607 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:52.541022 15607 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:52.541154 15607 base/node_id.go:62  NodeID set to 1
I161116 07:20:52.549943 15607 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:52.550147 15607 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49855" > attrs:<> locality:<> 
I161116 07:20:52.552571 15786 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:52.555645 15607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.559826 15607 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49855]
W161116 07:20:52.560929 15607 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:52.561077 15607 base/node_id.go:62  NodeID set to 2
I161116 07:20:52.570422 15607 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:52.570622 15607 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:58129" > attrs:<> locality:<> 
I161116 07:20:52.575306 15607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.577501 15821 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:49855
I161116 07:20:52.592427 15607 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49855]
W161116 07:20:52.592539 15607 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:52.592707 15607 base/node_id.go:62  NodeID set to 3
I161116 07:20:52.610675 15755 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:49855
I161116 07:20:52.616302 15607 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:38398" > attrs:<> locality:<> 
I161116 07:20:52.616698 15607 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:52.617763 15607 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49855]
W161116 07:20:52.617850 15607 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:52.618000 15607 base/node_id.go:62  NodeID set to 4
I161116 07:20:52.636644 15913 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:49855
I161116 07:20:52.639695 15607 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:20:52.639894 15607 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:55826" > attrs:<> locality:<> 
I161116 07:20:52.643835 15607 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4fbbb918 at index 15
I161116 07:20:52.645828 15607 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 34, log entries: 5
I161116 07:20:52.648238 15633 storage/replica_raftstorage.go:587  [s4,r1/?:{-}] applying preemptive snapshot at index 15 (id=4fbbb918, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:20:52.655818 15633 storage/replica_raftstorage.go:590  [s4,r1/?:/M{in-ax}] applied preemptive snapshot in 0.007s
I161116 07:20:52.657815 15607 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:52.662136 16008 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2}]
I161116 07:20:52.668227 15607 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot acc2bb0b at index 18
I161116 07:20:52.671547 15607 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 38, log entries: 8
I161116 07:20:52.672724 16010 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 18 (id=acc2bb0b, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:52.674125 16010 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:52.679441 15607 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > next_replica_id:3 
I161116 07:20:52.688248 16013 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:52.702209 16024 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2} {NodeID:2 StoreID:2 ReplicaID:3}]
I161116 07:20:52.743544 16037 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:52.792888 15607 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:52.802056 16036 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:52.802555 16052 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 0}: store 2 was not found
W161116 07:20:52.803735 16050 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:52.806988 16068 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:52.807809 15607 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 38efe7ee at index 23
W161116 07:20:52.808927 16099 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
I161116 07:20:52.810571 15607 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 44, log entries: 13
W161116 07:20:52.810850 16070 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.812081 16073 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 23 (id=38efe7ee, encoded size=16, 1 rocksdb batches, 13 log entries)
I161116 07:20:52.813500 16073 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:52.816451 15743 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:20:52.816851 15607 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > replicas:<node_id:2 store_id:2 replica_id:3 > next_replica_id:4 
W161116 07:20:52.817269 16077 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.817715 16075 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.820529 16079 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.821103 16114 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.821774 16103 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.826237 16131 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.826804 16086 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.829758 16133 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.835055 16080 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.837514 16029 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
I161116 07:20:52.837734 16116 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2} {NodeID:2 StoreID:2 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:4}]
W161116 07:20:52.837788 16029 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.837932 16088 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.838870 16117 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.839575 16105 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.839991 16119 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
W161116 07:20:52.840139 16105 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
I161116 07:20:52.901855 16108 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.902654 16059 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:52.903063 16111 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 0}: store 2 was not found
I161116 07:20:52.910715 16091 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:52.920804 16063 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.922233 16163 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.922921 16065 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.925096 16122 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.925723 16032 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.926170 16148 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.951954 16178 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.952906 16151 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:52.953320 16180 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 0}: store 2 was not found
I161116 07:20:52.984970 15607 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > replicas:<node_id:2 store_id:2 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:20:52.987312 16170 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.987937 16153 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.988163 16153 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.988403 16172 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.992398 16226 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.995950 16181 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:52.996277 16181 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
I161116 07:20:52.996568 16183 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
W161116 07:20:52.996689 16228 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:52.997745 16184 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:52.999684 16176 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:53.000085 16138 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:53.068319 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.069599 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.070960 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.072422 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.087133 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.090096 15681 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49855->127.0.0.1:51902: use of closed network connection
I161116 07:20:53.090546 15736 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:58129->127.0.0.1:36363: use of closed network connection
I161116 07:20:53.091457 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.091704 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.091836 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.092057 16292 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateAddAndRemove (0.57s)
=== RUN   TestReplicateRemoveAndAdd
I161116 07:20:53.113063 16243 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.114064 16243 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:53.114148 16243 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:53.114278 16243 base/node_id.go:62  NodeID set to 1
I161116 07:20:53.126374 16243 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:53.126563 16243 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:33858" > attrs:<> locality:<> 
I161116 07:20:53.129470 16316 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:53.134909 16243 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.135889 16243 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:33858]
W161116 07:20:53.135982 16243 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:53.136114 16243 base/node_id.go:62  NodeID set to 2
I161116 07:20:53.144498 16126 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:33858
I161116 07:20:53.146422 16243 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:53.146640 16243 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:36335" > attrs:<> locality:<> 
I161116 07:20:53.148823 16243 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.149967 16243 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:33858]
W161116 07:20:53.150096 16243 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:53.153140 16243 base/node_id.go:62  NodeID set to 3
I161116 07:20:53.163484 16419 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:33858
I161116 07:20:53.166821 16243 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:53.167007 16243 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:51037" > attrs:<> locality:<> 
I161116 07:20:53.168824 16243 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.169785 16243 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:33858]
W161116 07:20:53.169881 16243 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:53.170019 16243 base/node_id.go:62  NodeID set to 4
I161116 07:20:53.187019 16425 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:33858
I161116 07:20:53.190678 16243 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:20:53.190860 16243 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:50832" > attrs:<> locality:<> 
I161116 07:20:53.200934 16243 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot d338f1b2 at index 16
I161116 07:20:53.209878 16243 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 35, log entries: 6
I161116 07:20:53.228346 16578 storage/replica_raftstorage.go:587  [s4,r1/?:{-}] applying preemptive snapshot at index 16 (id=d338f1b2, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:53.229378 16578 storage/replica_raftstorage.go:590  [s4,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:53.231416 16243 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:53.235483 16574 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2}]
I161116 07:20:53.246747 16243 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 8fc17fbb at index 18
I161116 07:20:53.248756 16243 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 38, log entries: 8
I161116 07:20:53.249459 16583 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 18 (id=8fc17fbb, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:53.251748 16583 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:53.269215 16243 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > next_replica_id:3 
I161116 07:20:53.276177 16598 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:53.287819 16556 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2} {NodeID:2 StoreID:2 ReplicaID:3}]
I161116 07:20:53.325342 16613 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:53.336987 16243 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.341260 16243 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > replicas:<node_id:2 store_id:2 replica_id:3 > next_replica_id:4 
W161116 07:20:53.344203 16462 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:53.344629 16612 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
W161116 07:20:53.344770 16610 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
I161116 07:20:53.346170 16394 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:53.346696 16463 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:53.347144 16588 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:53.348531 16607 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2}]
I161116 07:20:53.349619 16618 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:53.350154 16396 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:53.351282 16396 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:3}
W161116 07:20:53.351464 16620 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 3}: store 2 was not found
I161116 07:20:53.359458 16243 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 27d16916 at index 25
I161116 07:20:53.361571 16243 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 47, log entries: 15
I161116 07:20:53.362437 16629 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 25 (id=27d16916, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:20:53.363946 16629 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:53.366875 16243 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:2 > next_replica_id:4 
I161116 07:20:53.372003 16648 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:20:53.373320 16649 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:53.382159 16653 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:0}
W161116 07:20:53.382600 16651 storage/store.go:2990  [s1] raft error: node 2 claims to not contain store 2 for replica {2 2 0}: store 2 was not found
I161116 07:20:53.504979 16663 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:53.621588 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.623081 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.624667 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.630692 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.633052 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:53.634124 16663 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
W161116 07:20:53.634214 16585 storage/raft_transport.go:443  raft transport stream to node 4 failed: EOF
I161116 07:20:53.634290 16423 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50832->127.0.0.1:33369: use of closed network connection
I161116 07:20:53.634615 16490 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:53.634903 16492 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:50832: operation was canceled"; Reconnecting to {"127.0.0.1:50832" <nil>}
I161116 07:20:53.635361 16492 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:53.635494 16304 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:53.635635 16161 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51037->127.0.0.1:42397: use of closed network connection
I161116 07:20:53.635730 16276 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:33858->127.0.0.1:59919: use of closed network connection
I161116 07:20:53.635767 16124 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36335->127.0.0.1:45667: use of closed network connection
I161116 07:20:53.636862 16434 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:51037: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:51037" <nil>}
I161116 07:20:53.636936 16434 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:53.637077 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.637351 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.637599 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:53.637912 16695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateRemoveAndAdd (0.53s)
=== RUN   TestRaftHeartbeats
I161116 07:20:53.646457 16700 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.647455 16700 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:53.647569 16700 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:53.647704 16700 base/node_id.go:62  NodeID set to 1
I161116 07:20:53.657266 16700 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:53.657473 16700 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:55028" > attrs:<> locality:<> 
I161116 07:20:53.659040 16813 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:53.661818 16700 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.662926 16700 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55028]
W161116 07:20:53.663052 16700 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:53.663236 16700 base/node_id.go:62  NodeID set to 2
I161116 07:20:53.670633 16882 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:55028
I161116 07:20:53.672552 16700 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:53.673131 16700 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:49108" > attrs:<> locality:<> 
I161116 07:20:53.674432 16700 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:53.675528 16700 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55028]
W161116 07:20:53.675616 16700 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:53.675834 16700 base/node_id.go:62  NodeID set to 3
I161116 07:20:53.682940 16933 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:55028
I161116 07:20:53.685018 16700 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:53.685211 16700 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:39968" > attrs:<> locality:<> 
I161116 07:20:53.689351 16700 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot e33a908c at index 14
I161116 07:20:53.691973 16700 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:53.692788 16718 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=e33a908c, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:53.694150 16718 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:53.697147 16700 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:53.701080 17010 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:53.705919 16700 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 7bb5a47a at index 17
I161116 07:20:53.708072 16700 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:53.713371 17026 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=7bb5a47a, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:53.714527 17026 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:53.718561 16700 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:53.724084 16938 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:53.731918 16942 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:53.785666 17015 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:54.357781 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.359098 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.360376 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.361742 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.363887 16670 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:55028->127.0.0.1:44015: use of closed network connection
I161116 07:20:54.364412 16715 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39968->127.0.0.1:57329: read: connection reset by peer
I161116 07:20:54.364851 16672 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49108->127.0.0.1:34985: use of closed network connection
I161116 07:20:54.365343 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.365608 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:54.365819 17007 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftHeartbeats (0.73s)
=== RUN   TestReportUnreachableHeartbeats
I161116 07:20:54.377714 17052 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:54.381309 17052 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:54.381403 17052 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:54.381544 17052 base/node_id.go:62  NodeID set to 1
I161116 07:20:54.390744 17052 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:54.391212 17052 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:37603" > attrs:<> locality:<> 
I161116 07:20:54.393764 17071 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:54.396877 17052 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:54.397871 17052 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37603]
W161116 07:20:54.397967 17052 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:54.398103 17052 base/node_id.go:62  NodeID set to 2
I161116 07:20:54.402647 17022 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:37603
I161116 07:20:54.404571 17052 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:54.404745 17052 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:55319" > attrs:<> locality:<> 
I161116 07:20:54.406382 17052 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:54.407941 17052 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37603]
W161116 07:20:54.408039 17052 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:54.408172 17052 base/node_id.go:62  NodeID set to 3
I161116 07:20:54.415342 17184 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:37603
I161116 07:20:54.431021 17052 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:34981" > attrs:<> locality:<> 
I161116 07:20:54.438927 17052 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot b5ee1a7d at index 14
I161116 07:20:54.451124 17100 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=b5ee1a7d, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:54.452310 17100 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:54.452854 17052 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:54.456783 17052 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:54.460657 17259 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:54.467761 17052 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot fa935033 at index 17
I161116 07:20:54.470700 17052 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:54.471462 17283 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=fa935033, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:54.473549 17283 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:54.482675 17052 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:54.487002 17262 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:54.493056 17248 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:54.583532 17304 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:54.644760 17052 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:54.645127 17052 storage/client_test.go:997  engine 2: missing key "a"
I161116 07:20:55.191170 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.193422 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.194859 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.197688 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.199056 17196 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34981->127.0.0.1:55379: use of closed network connection
I161116 07:20:55.200313 17093 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:37603->127.0.0.1:54079: use of closed network connection
W161116 07:20:55.200699 17262 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:55.201122 17085 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:55319->127.0.0.1:49041: use of closed network connection
I161116 07:20:55.201378 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.201648 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.201863 17417 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReportUnreachableHeartbeats (0.84s)
=== RUN   TestReplicateAfterSplit
I161116 07:20:55.213236 17421 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:55.214266 17421 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:55.214354 17421 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:55.214486 17421 base/node_id.go:62  NodeID set to 1
I161116 07:20:55.223167 17421 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:55.223396 17421 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:39320" > attrs:<> locality:<> 
I161116 07:20:55.224826 17446 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:55.227296 17421 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:55.228250 17421 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:39320]
W161116 07:20:55.228342 17421 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:55.228482 17421 base/node_id.go:62  NodeID set to 2
I161116 07:20:55.233177 17399 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:39320
I161116 07:20:55.236005 17421 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:55.236172 17421 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:56854" > attrs:<> locality:<> 
I161116 07:20:55.244306 17421 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
E161116 07:20:55.254176 17366 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:55.254953 17366 storage/queue.go:586  [replicate,s1,r2/1:{"m"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:55.255616 17421 storage/replica_raftstorage.go:443  [s1,r2/1:{"m"-/Max}] generated snapshot 334fe9ea at index 12
I161116 07:20:55.257442 17421 storage/store.go:3134  [s1,r2/1:{"m"-/Max}] streamed snapshot: kv pairs: 29, log entries: 2
I161116 07:20:55.258166 17563 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 12 (id=334fe9ea, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:20:55.259063 17563 storage/replica_raftstorage.go:590  [s2,r2/?:{"m"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:55.261094 17421 storage/replica_command.go:3245  [s1,r2/1:{"m"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"m" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
W161116 07:20:55.264391 17565 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"m\x00"), but have [/Min,"m")
I161116 07:20:55.268834 17567 storage/replica.go:2066  [s1,r2/1:{"m"-/Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:55.273672 17586 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:55.279292 17602 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
1      storage/client_test.go:501
I161116 07:20:55.279893 17602 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:317
I161116 07:20:55.280065 17489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.282111 17489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.283239 17489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:55.284049 17586 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
I161116 07:20:55.284181 16798 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:56854->127.0.0.1:41945: use of closed network connection
I161116 07:20:55.284360 17382 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39320->127.0.0.1:59732: use of closed network connection
I161116 07:20:55.284676 17489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:55.284999 17489 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateAfterSplit (0.08s)
=== RUN   TestReplicaRemovalCampaign
I161116 07:20:55.292767 17574 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:55.293756 17574 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:55.293858 17574 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:55.294004 17574 base/node_id.go:62  NodeID set to 1
I161116 07:20:55.302280 17574 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:55.302473 17574 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:46486" > attrs:<> locality:<> 
I161116 07:20:55.304533 17623 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:55.307150 17574 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:55.308067 17574 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:46486]
W161116 07:20:55.308170 17574 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:55.308321 17574 base/node_id.go:62  NodeID set to 2
I161116 07:20:55.312669 17614 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:46486
I161116 07:20:55.314941 17574 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:55.315145 17574 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:57460" > attrs:<> locality:<> 
I161116 07:20:55.320431 17574 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 53312516 at index 13
I161116 07:20:55.325396 17694 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=53312516, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:55.326366 17694 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:55.327377 17574 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:55.329270 17574 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:55.333051 17531 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:55.464732 17534 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:55.480841 17574 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
E161116 07:20:55.492409 17494 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:55.493146 17494 storage/queue.go:586  [replicate,s1,r2/1:{"m"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
W161116 07:20:55.509235 17536 storage/store.go:2994  [s2] got error from range 2, replica {1 1 1}: raft group deleted
W161116 07:20:55.509338 17536 storage/store.go:2994  [s2] got error from range 2, replica {1 1 1}: raft group deleted
W161116 07:20:55.515349 17536 storage/store.go:2994  [s2] got error from range 2, replica {1 1 1}: raft group deleted
W161116 07:20:55.916472 17536 storage/store.go:2994  [s2] got error from range 2, replica {1 1 1}: raft group deleted
W161116 07:20:56.315291 17536 storage/store.go:2994  [s2] got error from range 2, replica {1 1 1}: raft group deleted
I161116 07:20:56.517468 17722 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.519057 17722 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.520155 17722 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.521322 17612 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57460->127.0.0.1:35032: use of closed network connection
I161116 07:20:56.522021 17604 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46486->127.0.0.1:36407: read: connection reset by peer
I161116 07:20:56.522316 17722 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.522520 17722 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.522934 17574 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:56.523995 17574 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:56.524080 17574 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:56.524199 17574 base/node_id.go:62  NodeID set to 1
I161116 07:20:56.535512 17574 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:56.539603 17574 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:38033" > attrs:<> locality:<> 
I161116 07:20:56.540275 17812 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:56.542980 17574 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:56.544116 17574 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:38033]
W161116 07:20:56.544224 17574 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:56.544380 17574 base/node_id.go:62  NodeID set to 2
I161116 07:20:56.549272 17874 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:38033
I161116 07:20:56.572942 17574 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:55687" > attrs:<> locality:<> 
I161116 07:20:56.587284 17574 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 8b577166 at index 13
I161116 07:20:56.589078 17574 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:20:56.589949 17940 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=8b577166, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:20:56.590855 17940 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:56.593339 17574 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:56.598663 17863 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:56.710684 17729 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:56.752077 17574 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
E161116 07:20:56.774390 17751 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:56.775381 17751 storage/queue.go:586  [replicate,s1,r2/1:{"m"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:56.784218 17959 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.791639 17959 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.794801 17959 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:56.795029 17928 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:20:56.795302 17928 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
I161116 07:20:56.795860 17767 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:38033->127.0.0.1:33819: use of closed network connection
W161116 07:20:56.795920 17916 storage/raft_transport.go:478  no handler found for store 1 in response range_id:2 from_replica:<node_id:2 store_id:2 replica_id:2 > to_replica:<node_id:1 store_id:1 replica_id:1 > union:<error:<message:"store 2 was not found" transaction_restart:NONE origin_node:0 detail:<store_not_found:<store_id:2 > > now:<wall_time:0 logical:0 > > > 
I161116 07:20:56.796022 17708 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:56.797721 17710 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:38033: operation was canceled"; Reconnecting to {"127.0.0.1:38033" <nil>}
I161116 07:20:56.797806 17710 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:56.798588 17959 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:56.798902 17959 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaRemovalCampaign (1.52s)
=== RUN   TestRaftAfterRemoveRange
I161116 07:20:56.819237 17962 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:56.820238 17962 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:56.820334 17962 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:56.820471 17962 base/node_id.go:62  NodeID set to 1
I161116 07:20:56.835632 17987 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:56.839099 17962 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:39053" > attrs:<> locality:<> 
I161116 07:20:56.839830 17962 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:56.843098 17962 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:39053]
W161116 07:20:56.843186 17962 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:56.843329 17962 base/node_id.go:62  NodeID set to 2
I161116 07:20:56.852608 18020 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:39053
I161116 07:20:56.861069 17962 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:42901" > attrs:<> locality:<> 
I161116 07:20:56.863479 17962 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:56.864470 17962 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:39053]
W161116 07:20:56.864568 17962 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:56.864699 17962 base/node_id.go:62  NodeID set to 3
I161116 07:20:56.871445 18146 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:39053
I161116 07:20:56.884452 17962 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:56.884745 17962 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:50597" > attrs:<> locality:<> 
I161116 07:20:56.890301 17962 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:20:56.901149 17889 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:56.902889 17889 storage/queue.go:586  [replicate,s1,r2/1:{"b"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:56.903704 17962 storage/replica_raftstorage.go:443  [s1,r2/1:{"b"-/Max}] generated snapshot 6dccf5c9 at index 11
I161116 07:20:56.905470 17962 storage/store.go:3134  [s1,r2/1:{"b"-/Max}] streamed snapshot: kv pairs: 28, log entries: 1
I161116 07:20:56.906208 18180 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 11 (id=6dccf5c9, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:20:56.907229 18180 storage/replica_raftstorage.go:590  [s2,r2/?:{"b"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:56.910738 17962 storage/replica_command.go:3245  [s1,r2/1:{"b"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"b" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
W161116 07:20:56.915755 18168 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"b\x00"), but have [/Min,"b")
I161116 07:20:56.941805 18172 storage/replica.go:2066  [s1,r2/1:{"b"-/Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
W161116 07:20:56.942315 18171 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"b"}]: failed to push during intent resolution: failed to push "change-replica" id=baa83cb2 key=/Local/Range/"b"/RangeDescriptor rw=true pri=0.00075046 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,115 orig=0.000000123,115 max=0.000000123,115 wto=false rop=false
I161116 07:20:56.951230 17962 storage/replica_raftstorage.go:443  [s1,r2/1:{"b"-/Max}] generated snapshot b3350c93 at index 14
I161116 07:20:56.953018 17962 storage/store.go:3134  [s1,r2/1:{"b"-/Max}] streamed snapshot: kv pairs: 30, log entries: 4
I161116 07:20:56.954347 18175 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 14 (id=b3350c93, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:56.955762 18175 storage/replica_raftstorage.go:590  [s3,r2/?:{"b"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:20:56.964986 17962 storage/replica_command.go:3245  [s1,r2/1:{"b"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"b" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:56.965189 18181 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:56.982719 17947 storage/replica.go:2066  [s1,r2/1:{"b"-/Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:56.991774 18159 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:57.001504 17962 storage/replica_command.go:3245  [s1,r2/1:{"b"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"b" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:57.014827 17953 storage/replica.go:2066  [s1,r2/1:{"b"-/Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.020823 18228 storage/store.go:2986  [s3,r2/3:{"b"-/Max}] added to replica GC queue (peer suggestion)
I161116 07:20:57.036837 17962 storage/replica_command.go:3245  [s1,r2/1:{"b"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"b" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:4 
I161116 07:20:57.054156 18231 storage/replica.go:2066  [s1,r2/1:{"b"-/Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1}]
I161116 07:20:57.066263 18129 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:20:57.068614 18264 storage/store.go:2994  [s3] got error from range 2, replica {2 2 2}: raft group deleted
I161116 07:20:57.069203 17962 storage/replica_raftstorage.go:443  [s1,r1/1:{/Min-"b"}] generated snapshot 34faeff6 at index 29
I161116 07:20:57.071147 17962 storage/store.go:3134  [s1,r1/1:{/Min-"b"}] streamed snapshot: kv pairs: 27, log entries: 19
I161116 07:20:57.072268 18279 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 29 (id=34faeff6, encoded size=16, 1 rocksdb batches, 19 log entries)
I161116 07:20:57.073708 18279 storage/replica_raftstorage.go:590  [s2,r1/?:{/Min-"b"}] applied preemptive snapshot in 0.001s
I161116 07:20:57.075825 17962 storage/replica_command.go:3245  [s1,r1/1:{/Min-"b"}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"b" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:57.079256 18282 storage/replica.go:2066  [s1,r1/1:{/Min-"b"}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
W161116 07:20:57.083818 18112 storage/store.go:2994  [s1] got error from range 2, replica {2 2 2}: raft group deleted
I161116 07:20:57.223243 18294 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
I161116 07:20:57.223727 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:20:57.224177 18096 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:20:57.225263 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:57.227479 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:57.230118 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:57.230549 17976 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:50597->127.0.0.1:37810: use of closed network connection
I161116 07:20:57.230727 18104 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:57.232435 17885 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39053->127.0.0.1:39591: use of closed network connection
I161116 07:20:57.232545 17963 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:20:57.232835 17965 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:39053: operation was canceled"; Reconnecting to {"127.0.0.1:39053" <nil>}
I161116 07:20:57.232910 17965 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:20:57.233415 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:57.233686 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:57.233849 18293 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftAfterRemoveRange (0.43s)
=== RUN   TestRaftRemoveRace
I161116 07:20:57.246178 18253 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:57.247308 18253 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:57.247430 18253 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:57.247583 18253 base/node_id.go:62  NodeID set to 1
I161116 07:20:57.262912 18318 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:57.267710 18253 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:51379" > attrs:<> locality:<> 
I161116 07:20:57.268104 18253 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:57.272004 18253 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51379]
W161116 07:20:57.272097 18253 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:57.272227 18253 base/node_id.go:62  NodeID set to 2
I161116 07:20:57.278730 18240 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:51379
I161116 07:20:57.299850 18253 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:60923" > attrs:<> locality:<> 
I161116 07:20:57.300487 18253 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:57.303721 18253 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51379]
W161116 07:20:57.304078 18253 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:57.308633 18253 base/node_id.go:62  NodeID set to 3
I161116 07:20:57.314311 18414 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:51379
I161116 07:20:57.319767 18253 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:35110" > attrs:<> locality:<> 
I161116 07:20:57.323406 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot fb03ea31 at index 14
I161116 07:20:57.326584 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:57.327425 18440 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=fb03ea31, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:57.328735 18440 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:57.331095 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:57.335911 18491 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.346167 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 22d06087 at index 17
I161116 07:20:57.349047 18524 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=22d06087, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:57.350124 18524 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:57.350561 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:57.352347 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:57.362619 18384 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:57.371794 18528 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:57.454725 18578 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:57.462940 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:57.470589 18510 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.480314 18580 storage/store.go:2986  [s3,r1/3:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:57.482778 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 1d3ac8c4 at index 22
I161116 07:20:57.487314 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 44, log entries: 12
I161116 07:20:57.488793 18494 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 22 (id=1d3ac8c4, encoded size=16, 1 rocksdb batches, 12 log entries)
I161116 07:20:57.490096 18494 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:57.492232 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:4 
I161116 07:20:57.497241 18573 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
W161116 07:20:57.518898 18449 storage/store.go:2994  [s1] got error from range 1, replica {3 3 3}: replicaID cannot move backwards from 4 to 3
I161116 07:20:57.523954 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:20:57.533087 18558 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.569704 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 8c2221da at index 28
I161116 07:20:57.572503 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 52, log entries: 18
I161116 07:20:57.572739 18580 storage/store.go:2986  [s3,r1/4:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:57.582832 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:5 
I161116 07:20:57.587995 18202 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:5}]
W161116 07:20:57.610629 18449 storage/store.go:2994  [s1] got error from range 1, replica {3 3 4}: raft group deleted
I161116 07:20:57.641053 18333 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 1f872482 at index 31
I161116 07:20:57.645272 18192 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 56, log entries: 21
I161116 07:20:57.645719 18622 storage/replica_raftstorage.go:587  [s3,r1/5:{-}] applying Raft snapshot at index 31 (id=1f872482, encoded size=16, 1 rocksdb batches, 21 log entries)
I161116 07:20:57.647474 18622 storage/replica_raftstorage.go:590  [s3,r1/5:/M{in-ax}] applied Raft snapshot in 0.002s
I161116 07:20:57.675186 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:20:57.686633 18601 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.718114 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 5d42add6 at index 35
I161116 07:20:57.724346 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 61, log entries: 25
I161116 07:20:57.725510 18692 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 35 (id=5d42add6, encoded size=16, 1 rocksdb batches, 25 log entries)
E161116 07:20:57.726476 18580 storage/store.go:2984  [s3,r1/?:{-}] unable to add to replica GC queue: replica not initialized
I161116 07:20:57.730101 18692 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.004s
I161116 07:20:57.732442 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:6 
I161116 07:20:57.741085 18629 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:6}]
I161116 07:20:57.826068 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:6 > next_replica_id:7 
I161116 07:20:57.834544 18544 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:57.841202 18580 storage/store.go:2986  [s3,r1/6:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:57.841576 18580 storage/store.go:2986  [s3,r1/6:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:57.851951 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 78c7f374 at index 40
I161116 07:20:57.856087 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 68, log entries: 30
I161116 07:20:57.859850 18652 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 40 (id=78c7f374, encoded size=16, 1 rocksdb batches, 30 log entries)
I161116 07:20:57.862083 18652 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:57.874761 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:7 
I161116 07:20:57.909254 18655 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:7}]
I161116 07:20:58.064193 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:7 > next_replica_id:8 
I161116 07:20:58.078787 18758 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.084281 18580 storage/store.go:2986  [s3,r1/7:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:58.087293 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4731e7ec at index 49
I161116 07:20:58.090403 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 79, log entries: 39
I161116 07:20:58.091469 18787 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 49 (id=4731e7ec, encoded size=16, 1 rocksdb batches, 39 log entries)
I161116 07:20:58.093947 18787 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:20:58.096552 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:8 
I161116 07:20:58.102026 18803 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:20:58.194428 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:20:58.201419 18751 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.217054 18580 storage/store.go:2986  [s3,r1/8:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:58.220962 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 609cc845 at index 55
I161116 07:20:58.230089 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 87, log entries: 45
I161116 07:20:58.232014 18806 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 55 (id=609cc845, encoded size=16, 1 rocksdb batches, 45 log entries)
I161116 07:20:58.240741 18806 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.005s
I161116 07:20:58.243168 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:9 
I161116 07:20:58.250064 18766 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:9}]
I161116 07:20:58.334815 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:9 > next_replica_id:10 
I161116 07:20:58.343597 18714 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.360382 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 79b657be at index 61
I161116 07:20:58.365197 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 95, log entries: 51
I161116 07:20:58.366641 18580 storage/store.go:2986  [s3,r1/9:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:58.366906 18733 storage/replica_raftstorage.go:587  [s3,r1/9:/M{in-ax}] applying Raft snapshot at index 61 (id=79b657be, encoded size=16, 1 rocksdb batches, 51 log entries)
I161116 07:20:58.373196 18733 storage/replica_raftstorage.go:590  [s3,r1/9:/M{in-ax}] applied Raft snapshot in 0.006s
I161116 07:20:58.377130 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:10 
I161116 07:20:58.385858 18718 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:10}]
I161116 07:20:58.387814 18322 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:10}]
I161116 07:20:58.409645 18328 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot a5f1945d at index 66
I161116 07:20:58.414371 18854 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 99, log entries: 56
I161116 07:20:58.420453 18867 storage/replica_raftstorage.go:587  [s3,r1/10:{-}] applying Raft snapshot at index 66 (id=a5f1945d, encoded size=16, 1 rocksdb batches, 56 log entries)
I161116 07:20:58.427154 18867 storage/replica_raftstorage.go:590  [s3,r1/10:/M{in-ax}] applied Raft snapshot in 0.007s
I161116 07:20:58.441192 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:10 > next_replica_id:11 
I161116 07:20:58.446141 18735 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.453528 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot ff85ff13 at index 69
I161116 07:20:58.464132 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 103, log entries: 59
I161116 07:20:58.465335 18860 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 69 (id=ff85ff13, encoded size=16, 1 rocksdb batches, 59 log entries)
I161116 07:20:58.468702 18860 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.003s
I161116 07:20:58.470944 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:11 
I161116 07:20:58.476460 18869 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:11}]
I161116 07:20:58.567362 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:11 > next_replica_id:12 
I161116 07:20:58.585398 18892 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.596952 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot c73ad2f1 at index 75
I161116 07:20:58.608689 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 111, log entries: 65
I161116 07:20:58.610943 18580 storage/store.go:2986  [s3,r1/11:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:58.627833 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:12 
I161116 07:20:58.633500 18895 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:20:58.716182 18323 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 33c1ae61 at index 79
I161116 07:20:58.721404 18877 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 116, log entries: 69
I161116 07:20:58.723057 18964 storage/replica_raftstorage.go:587  [s3,r1/12:{-}] applying Raft snapshot at index 79 (id=33c1ae61, encoded size=16, 1 rocksdb batches, 69 log entries)
I161116 07:20:58.729967 18964 storage/replica_raftstorage.go:590  [s3,r1/12:/M{in-ax}] applied Raft snapshot in 0.007s
I161116 07:20:58.784378 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:20:58.789771 18980 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:58.803722 18580 storage/store.go:2986  [s3,r1/12:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:20:58.808400 18253 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot de48694e at index 83
I161116 07:20:58.813174 18253 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 121, log entries: 73
I161116 07:20:58.815027 18969 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 83 (id=de48694e, encoded size=16, 1 rocksdb batches, 73 log entries)
I161116 07:20:58.819833 18969 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.005s
I161116 07:20:58.822245 18253 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:13 
I161116 07:20:58.828703 18973 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:13}]
I161116 07:20:58.904488 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:58.907072 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:58.908637 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:58.910200 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:58.911987 18578 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
W161116 07:20:58.912259 18384 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
I161116 07:20:58.912383 18457 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35110->127.0.0.1:55770: use of closed network connection
I161116 07:20:58.913222 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:58.913460 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:58.913643 19015 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftRemoveRace (1.68s)
=== RUN   TestStoreRangeRemoveDead
I161116 07:20:58.931636 18976 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:58.932898 18976 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:58.933007 18976 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:58.933210 18976 base/node_id.go:62  NodeID set to 1
I161116 07:20:58.947065 18976 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:58.947264 18976 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:47532" > attrs:<> locality:<> 
I161116 07:20:58.951223 19008 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:58.954651 18976 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:58.955685 18976 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:47532]
W161116 07:20:58.955766 18976 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:58.955904 18976 base/node_id.go:62  NodeID set to 2
I161116 07:20:58.962015 18937 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:47532
I161116 07:20:58.963827 18976 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:58.964025 18976 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:54784" > attrs:<> locality:<> 
I161116 07:20:58.966141 18976 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:58.977812 18976 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:47532]
W161116 07:20:58.977914 18976 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:58.978094 18976 base/node_id.go:62  NodeID set to 3
I161116 07:20:59.016958 19144 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:47532
I161116 07:20:59.018857 18976 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:59.019092 18976 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:47179" > attrs:<> locality:<> 
I161116 07:20:59.028602 18976 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot f39015ed at index 14
I161116 07:20:59.033241 18976 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:59.034148 19212 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=f39015ed, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:59.035302 19212 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:59.039471 18976 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:59.062658 19220 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:59.067825 18976 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 77d0a6dc at index 17
I161116 07:20:59.069622 18976 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:20:59.073742 19234 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=77d0a6dc, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:20:59.074826 19234 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:59.077016 18976 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:59.081209 19214 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:59.095968 19266 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:59.156390 19199 storage/raft_transport.go:437  raft transport stream to node 1 established
W161116 07:20:59.206219 19067 storage/store_pool.go:83  store 3 on node 3 is now considered offline
W161116 07:20:59.206334 19027 storage/store_pool.go:83  store 2 on node 2 is now considered offline
W161116 07:20:59.206560 19035 storage/store_pool.go:83  store 3 on node 3 is now considered offline
W161116 07:20:59.207116 19027 storage/store_pool.go:83  store 3 on node 3 is now considered offline
W161116 07:20:59.207233 19067 storage/store_pool.go:83  store 2 on node 2 is now considered offline
I161116 07:20:59.215241 18976 storage/replica_command.go:3245  [replicate,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:59.224508 19105 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:59.230399 19201 storage/store.go:2986  [s3,r1/3:/M{in-ax}] added to replica GC queue (peer suggestion)
E161116 07:20:59.234248 18910 storage/queue.go:586  [replicate,s1,r1/1:/M{in-ax}] purgatory: 0 of 2 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:20:59.235649 19293 storage/queue.go:586  [replicate,s1,r1/1:/M{in-ax}] purgatory: 0 of 2 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:20:59.236483 19311 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
I161116 07:20:59.243457 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.249601 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.251766 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.252934 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.254802 19090 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:54784->127.0.0.1:41959: use of closed network connection
W161116 07:20:59.255041 19250 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:59.255873 18935 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:47532->127.0.0.1:54156: use of closed network connection
I161116 07:20:59.256720 18940 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:47179->127.0.0.1:54024: use of closed network connection
I161116 07:20:59.256864 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.257054 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.257191 19308 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeRemoveDead (0.35s)
=== RUN   TestReplicateRogueRemovedNode
I161116 07:20:59.284401 19182 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.292895 19182 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:59.292999 19182 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:59.293171 19182 base/node_id.go:62  NodeID set to 1
I161116 07:20:59.316089 19182 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:20:59.316298 19182 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49101" > attrs:<> locality:<> 
I161116 07:20:59.320486 19279 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:59.323552 19182 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.325223 19182 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49101]
W161116 07:20:59.325665 19182 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:59.325834 19182 base/node_id.go:62  NodeID set to 2
I161116 07:20:59.330455 19231 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:49101
I161116 07:20:59.334090 19182 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:20:59.334315 19182 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:57430" > attrs:<> locality:<> 
I161116 07:20:59.355744 19182 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.356933 19182 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49101]
W161116 07:20:59.357046 19182 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:59.357231 19182 base/node_id.go:62  NodeID set to 3
I161116 07:20:59.364148 19182 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:59.364339 19182 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:48593" > attrs:<> locality:<> 
I161116 07:20:59.366433 19506 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:49101
I161116 07:20:59.372958 19182 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 41e5a656 at index 14
I161116 07:20:59.374648 19182 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:59.375401 19557 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=41e5a656, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:59.376395 19557 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:59.378270 19182 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:59.381813 19532 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:59.385873 19182 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 44657e7f at index 16
I161116 07:20:59.387666 19182 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 36, log entries: 6
I161116 07:20:59.388541 19544 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 16 (id=44657e7f, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:20:59.389562 19544 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:59.393844 19182 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:59.422705 19537 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:59.446452 19575 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:59.514446 19594 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:20:59.542897 19182 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:59.542981 19182 storage/client_test.go:997  engine 2: missing key "a"
I161116 07:20:59.544299 19182 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:20:59.558878 19552 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:59.559376 19564 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:59.561902 19182 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
W161116 07:20:59.563069 19609 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:20:59.563982 19567 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:59.564500 19448 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:59.564890 19569 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:59.566602 19636 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:59.567930 19626 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:59.568342 19508 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:59.569834 19638 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:59.575596 19639 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:20:59.576155 19450 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:59.576429 19450 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:20:59.577799 19641 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:20:59.579398 19182 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:4 
I161116 07:20:59.588345 19651 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1}]
E161116 07:20:59.606546 19182 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:59.716138 19182 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:59.721775 19182 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:20:59.721860 19182 storage/client_test.go:997  engine 2: missing key "a"
W161116 07:20:59.721943 19690 storage/replica.go:3861  [s3] could not acquire lease for range gossip: range 1 was not found
W161116 07:20:59.722016 19690 storage/store.go:1237  [s3] error gossiping system config: range 1 was not found
W161116 07:20:59.722066 19689 storage/replica.go:3861  [s3] could not acquire lease for range gossip: range 1 was not found
W161116 07:20:59.722131 19689 storage/store.go:1237  [s3] error gossiping first range descriptor: range 1 was not found
I161116 07:20:59.722464 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.723803 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.724953 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.726387 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.727047 19323 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:48593->127.0.0.1:58949: use of closed network connection
I161116 07:20:59.727289 19472 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:20:59.728111 19571 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:20:59.729233 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.729432 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:20:59.730023 19644 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateRogueRemovedNode (0.47s)
=== RUN   TestReplicateRemovedNodeDisruptiveElection
I161116 07:20:59.751068 19648 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.752282 19648 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:20:59.752369 19648 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:20:59.752528 19648 base/node_id.go:62  NodeID set to 1
I161116 07:20:59.766089 19757 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:20:59.769517 19648 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:40136" > attrs:<> locality:<> 
I161116 07:20:59.770036 19648 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.771915 19648 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40136]
W161116 07:20:59.772194 19648 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:59.772335 19648 base/node_id.go:62  NodeID set to 2
I161116 07:20:59.781510 19616 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:40136
I161116 07:20:59.787974 19648 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:55299" > attrs:<> locality:<> 
I161116 07:20:59.788402 19648 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.789373 19648 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40136]
W161116 07:20:59.789462 19648 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:59.789620 19648 base/node_id.go:62  NodeID set to 3
I161116 07:20:59.796465 19885 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:40136
I161116 07:20:59.797254 19648 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:20:59.797441 19648 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:35629" > attrs:<> locality:<> 
I161116 07:20:59.798377 19648 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:20:59.799360 19648 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:40136]
W161116 07:20:59.799452 19648 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:20:59.799652 19648 base/node_id.go:62  NodeID set to 4
I161116 07:20:59.813242 19851 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:40136
I161116 07:20:59.825241 19648 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:59053" > attrs:<> locality:<> 
I161116 07:20:59.831306 19648 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot aa7ecac3 at index 14
I161116 07:20:59.839335 19648 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:20:59.840032 19931 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=aa7ecac3, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:20:59.846310 19931 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.006s
I161116 07:20:59.851345 19648 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:20:59.865002 19947 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:20:59.872004 19648 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4da528ac at index 18
I161116 07:20:59.874440 19648 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 38, log entries: 8
I161116 07:20:59.876223 19936 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 18 (id=4da528ac, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:20:59.880121 19936 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.004s
I161116 07:20:59.883219 19648 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:20:59.888311 20035 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:59.898678 20051 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:20:59.906734 19648 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 13a6f582 at index 20
I161116 07:20:59.908876 19648 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 41, log entries: 10
I161116 07:20:59.909779 20010 storage/replica_raftstorage.go:587  [s4,r1/?:{-}] applying preemptive snapshot at index 20 (id=13a6f582, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:20:59.910996 20010 storage/replica_raftstorage.go:590  [s4,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:20:59.913325 19648 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:20:59.917479 20016 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:59.923129 20057 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:20:59.958429 20060 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:20:59.990304 19648 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:21:00.033888 20121 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:4 StoreID:4 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:00.064785 20013 storage/store.go:2986  [s1,r1/1:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:21:00.288586 20102 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:00.289069 20101 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:00.297936 20163 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:00.298548 20162 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:21:00.463134 19788 raft/raft.go:794  [s1,r1/1:/M{in-ax}] 1 stepped down to follower since quorum is not active
I161116 07:21:00.528195 20091 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:00.530811 20090 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:00.606563 19896 storage/replica_proposal.go:332  [s3,r1/3:/M{in-ax}] new range lease replica {3 3 3} 1970-01-01 00:00:00.900000124 +0000 UTC 1.800000002s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:01.800000125 +0000 UTC]
E161116 07:21:00.621462 19648 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:00.621547 19648 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:21:00.621633 19648 storage/client_test.go:997  engine 3: missing key "a"
E161116 07:21:00.623787 19648 storage/client_test.go:997  engine 0: missing key "a"
I161116 07:21:00.639936 20108 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:00.654383 20159 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
W161116 07:21:00.654614 20200 storage/replica.go:1810  [s3,r1/3:/M{in-ax}] shutdown cancellation of command [txn: ad846487], BeginTransaction [/System/NodeLiveness/3,/Min), ConditionalPut [/System/NodeLiveness/3,/Min), EndTransaction [/System/NodeLiveness/3,/Min)
I161116 07:21:00.656760 20160 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
I161116 07:21:00.657128 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:00.657164 19910 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
E161116 07:21:00.657310 19703 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
I161116 07:21:00.658844 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:00.659635 19993 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
I161116 07:21:00.660663 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.662094 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.663340 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.668992 19719 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:40136->127.0.0.1:36989: use of closed network connection
W161116 07:21:00.669808 20101 storage/raft_transport.go:443  raft transport stream to node 3 failed: EOF
W161116 07:21:00.670006 20108 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:00.670210 19745 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:00.670385 20102 storage/raft_transport.go:443  raft transport stream to node 4 failed: EOF
I161116 07:21:00.672835 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.673084 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.673314 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.673502 20201 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.683770 19829 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35629->127.0.0.1:52102: use of closed network connection
--- PASS: TestReplicateRemovedNodeDisruptiveElection (1.00s)
=== RUN   TestReplicaTooOldGC
--- SKIP: TestReplicaTooOldGC (0.01s)
	client_raft_test.go:2274: #10189
=== RUN   TestReplicaLazyLoad
I161116 07:21:00.752345 20242 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:00.753440 20242 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:00.753519 20242 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:00.753657 20242 base/node_id.go:62  NodeID set to 1
I161116 07:21:00.768873 20242 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:00.769088 20242 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:33433" > attrs:<> locality:<> 
I161116 07:21:00.784001 20269 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 9.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:00.786089 20242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.786179 20242 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
W161116 07:21:00.786448 20127 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command [txn: 2c9561db], BeginTransaction [/System/NodeLiveness/1,/Min), ConditionalPut [/System/NodeLiveness/1,/Min), EndTransaction [/System/NodeLiveness/1,/Min)
E161116 07:21:00.786986 20205 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
E161116 07:21:00.788021 20205 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:00.805584 20305 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.808927 20305 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:00.809271 20229 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:33433->127.0.0.1:50872: use of closed network connection
I161116 07:21:00.809400 20305 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaLazyLoad (0.08s)
=== RUN   TestReplicateReAddAfterDown
I161116 07:21:00.836872 20191 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:00.838023 20191 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:00.838112 20191 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:00.838256 20191 base/node_id.go:62  NodeID set to 1
I161116 07:21:00.852827 20336 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:00.856708 20191 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:42329" > attrs:<> locality:<> 
I161116 07:21:00.858103 20191 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:00.860776 20191 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:42329]
W161116 07:21:00.860867 20191 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:00.860998 20191 base/node_id.go:62  NodeID set to 2
I161116 07:21:00.868600 20253 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:42329
I161116 07:21:00.869605 20191 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:00.869790 20191 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:51360" > attrs:<> locality:<> 
I161116 07:21:00.871002 20191 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:00.872048 20191 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:42329]
W161116 07:21:00.872131 20191 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:00.875421 20191 base/node_id.go:62  NodeID set to 3
I161116 07:21:00.891737 20375 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:42329
I161116 07:21:00.896142 20191 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:00.896341 20191 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:52306" > attrs:<> locality:<> 
I161116 07:21:00.905655 20191 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot cdb58170 at index 14
I161116 07:21:00.908170 20191 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:00.911268 20504 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=cdb58170, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:00.912255 20504 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:00.914323 20191 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:00.918018 20535 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:00.922172 20191 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot de593abf at index 16
I161116 07:21:00.925392 20522 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 16 (id=de593abf, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:21:00.926491 20522 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:00.927066 20191 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 36, log entries: 6
I161116 07:21:00.930675 20191 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:00.943159 20525 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:00.963871 20529 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:01.044771 20561 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:01.080095 20191 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:01.086480 20501 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:01.089093 20191 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
W161116 07:21:01.094344 20545 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:01.094773 20568 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:21:01.094908 20560 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:21:01.096667 20601 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:21:01.097803 20511 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:01.098178 20603 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:21:01.100073 20512 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:01.100180 20605 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
W161116 07:21:01.101571 20628 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:0}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:0}
W161116 07:21:01.101859 20628 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:01.102550 20626 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 0}: store 3 was not found
I161116 07:21:01.106012 20569 storage/raft_transport.go:437  raft transport stream to node 3 established
W161116 07:21:01.109908 20607 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:1 StoreID:1 ReplicaID:1}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:01.111552 20620 storage/store.go:2990  [s1] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
I161116 07:21:01.138144 20191 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 1ea76903 at index 25
I161116 07:21:01.142484 20381 storage/replica_raftstorage.go:587  [s3,r1/3:/M{in-ax}] applying Raft snapshot at index 25 (id=1ea76903, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:21:01.144191 20381 storage/replica_raftstorage.go:590  [s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.002s
I161116 07:21:01.144540 20191 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 47, log entries: 15
I161116 07:21:01.148656 20191 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:4 
I161116 07:21:01.154478 20660 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:01.238138 20706 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/client_test.go:501
W161116 07:21:01.238403 20691 storage/replica.go:1810  [s1,r1/1:/M{in-ax}] shutdown cancellation of command [txn: e1ebfde1], BeginTransaction [/System/NodeLiveness/2,/Min), ConditionalPut [/System/NodeLiveness/2,/Min), EndTransaction [/System/NodeLiveness/2,/Min)
E161116 07:21:01.238951 20442 storage/node_liveness.go:141  [hb] failed liveness heartbeat: result is ambiguous
I161116 07:21:01.239128 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:01.240293 20596 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:4}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:21:01.240610 20556 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:21:01.240828 20595 storage/store.go:2990  [s3] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:21:01.241251 20527 storage/store.go:2990  [s2] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:21:01.241417 20525 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:21:01.241565 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.243358 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.245219 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.246104 20251 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51360->127.0.0.1:44166: use of closed network connection
I161116 07:21:01.246342 20207 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:42329->127.0.0.1:52779: use of closed network connection
I161116 07:21:01.246612 20402 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:01.247395 20465 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:52306->127.0.0.1:59108: use of closed network connection
I161116 07:21:01.247616 20467 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:01.248002 20469 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:52306: operation was canceled"; Reconnecting to {"127.0.0.1:52306" <nil>}
I161116 07:21:01.248272 20469 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W161116 07:21:01.248420 20561 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:21:01.248800 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.249050 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.249272 20577 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicateReAddAfterDown (0.42s)
=== RUN   TestLeaseHolderRemoveSelf
I161116 07:21:01.267785 20709 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:01.268805 20709 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:01.268893 20709 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:01.269024 20709 base/node_id.go:62  NodeID set to 1
I161116 07:21:01.280984 20709 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:01.283560 20709 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:48947" > attrs:<> locality:<> 
I161116 07:21:01.284150 20715 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:01.286698 20709 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:01.287760 20709 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48947]
W161116 07:21:01.287855 20709 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:01.288005 20709 base/node_id.go:62  NodeID set to 2
I161116 07:21:01.297950 20670 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:48947
I161116 07:21:01.300903 20709 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:01.301088 20709 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:39935" > attrs:<> locality:<> 
I161116 07:21:01.306202 20709 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot a7051cc6 at index 13
I161116 07:21:01.312895 20709 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:21:01.313625 20697 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=a7051cc6, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:01.314527 20697 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:01.316479 20709 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:01.320489 20699 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:01.451442 20703 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:01.466040 20709 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:01.474425 20814 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:2 StoreID:2 ReplicaID:2}]
E161116 07:21:01.482829 20719 storage/replica_proposal.go:519  [s1,r1/1:/M{in-ax}] unable to add to replica GC queue: queue disabled
I161116 07:21:01.486021 20855 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:01.487555 20749 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:01.487718 20855 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.520681 20855 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.522396 20768 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39935->127.0.0.1:41584: use of closed network connection
I161116 07:21:01.522521 20590 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:01.523501 20592 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:39935: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:39935" <nil>}
I161116 07:21:01.523564 20592 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:01.525852 20855 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.526183 20855 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestLeaseHolderRemoveSelf (0.29s)
=== RUN   TestRemoveRangeWithoutGC
I161116 07:21:01.550545 20791 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:01.552173 20791 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:01.552265 20791 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:01.552433 20791 base/node_id.go:62  NodeID set to 1
I161116 07:21:01.563057 20791 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:01.563243 20791 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:55909" > attrs:<> locality:<> 
I161116 07:21:01.567039 20888 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:01.569811 20791 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:01.572599 20791 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55909]
W161116 07:21:01.572711 20791 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:01.572851 20791 base/node_id.go:62  NodeID set to 2
I161116 07:21:01.599740 20868 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:55909
I161116 07:21:01.613825 20791 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:01.614074 20791 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:54365" > attrs:<> locality:<> 
I161116 07:21:01.619188 20791 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 49ca129d at index 13
I161116 07:21:01.653587 20791 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:21:01.654819 20832 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=49ca129d, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:01.655744 20832 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:01.660457 20791 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:01.671284 20984 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:01.756767 20999 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:01.812755 20791 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:01.818486 21012 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:2 StoreID:2 ReplicaID:2}]
E161116 07:21:01.827277 20895 storage/replica_proposal.go:519  [s1,r1/1:/M{in-ax}] unable to add to replica GC queue: queue disabled
I161116 07:21:01.830386 20791 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:01.830471 20791 util/stop/stopper.go:468  quiescing; tasks left:
1      kv/txn_coord_sender.go:918
E161116 07:21:01.834734 20791 storage/store.go:1051  [n1,s1,r1/?:/M{in-ax}]: unable to add replica to GC queue: queue disabled
W161116 07:21:01.838835 21062 storage/replica.go:3861  [s1] could not acquire lease for range gossip: range 1 was not found
W161116 07:21:01.838900 21062 storage/store.go:1237  [s1] error gossiping first range descriptor: range 1 was not found
W161116 07:21:01.839789 21063 storage/replica.go:3861  [s1] could not acquire lease for range gossip: range 1 was not found
W161116 07:21:01.839861 21063 storage/store.go:1237  [s1] error gossiping system config: range 1 was not found
I161116 07:21:02.116681 20973 storage/replica_proposal.go:332  [s2,r1/2:/M{in-ax}] new range lease replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 240h0m1.800000003s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-11 00:00:01.800000126 +0000 UTC]
I161116 07:21:02.126775 21009 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.134399 21009 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.135679 21009 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:02.137169 20999 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
I161116 07:21:02.137541 20939 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:54365->127.0.0.1:37726: use of closed network connection
I161116 07:21:02.137706 20866 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:55909->127.0.0.1:53322: use of closed network connection
I161116 07:21:02.138326 21009 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.138580 21009 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRemoveRangeWithoutGC (0.61s)
=== RUN   TestCheckConsistencyMultiStore
I161116 07:21:02.152760 21091 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.153868 21091 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:02.153967 21091 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:02.154105 21091 base/node_id.go:62  NodeID set to 1
I161116 07:21:02.164886 21021 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:02.167174 21091 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:43583" > attrs:<> locality:<> 
I161116 07:21:02.168256 21091 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.169273 21091 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:43583]
W161116 07:21:02.169360 21091 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.169519 21091 base/node_id.go:62  NodeID set to 2
I161116 07:21:02.174552 20833 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:43583
I161116 07:21:02.176798 21091 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:02.176984 21091 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34919" > attrs:<> locality:<> 
I161116 07:21:02.178612 21091 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.179632 21091 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:43583]
W161116 07:21:02.179739 21091 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.179885 21091 base/node_id.go:62  NodeID set to 3
I161116 07:21:02.185425 21206 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:43583
I161116 07:21:02.189666 21091 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:02.189865 21091 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:48939" > attrs:<> locality:<> 
I161116 07:21:02.201525 21091 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot ff6ba8de at index 14
I161116 07:21:02.203253 21091 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:02.204374 21153 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=ff6ba8de, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:02.205336 21153 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:02.207209 21091 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:02.211147 21314 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:02.218041 21091 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 495f299c at index 17
I161116 07:21:02.219912 21091 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:02.220688 21336 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=495f299c, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:02.221835 21336 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:02.224521 21091 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:02.228231 21309 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:02.236315 21345 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:02.339157 21352 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:02.428009 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.429728 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:02.444571 21343 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:0}
W161116 07:21:02.444772 21320 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:0}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:0}
W161116 07:21:02.445951 21311 storage/raft_transport.go:478  no handler found for store 2 in response range_id:0 from_replica:<node_id:1 store_id:1 replica_id:0 > to_replica:<node_id:2 store_id:2 replica_id:0 > union:<error:<message:"store 1 was not found" transaction_restart:NONE origin_node:0 detail:<store_not_found:<store_id:1 > > now:<wall_time:0 logical:0 > > > 
W161116 07:21:02.446241 21379 storage/store.go:2990  [s3] raft error: node 1 claims to not contain store 1 for replica {1 1 0}: store 1 was not found
W161116 07:21:02.446381 21352 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:21:02.449159 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.461165 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.462805 21046 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34919->127.0.0.1:46904: use of closed network connection
I161116 07:21:02.462846 21117 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:21:02.463189 21309 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
I161116 07:21:02.463722 21013 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:43583->127.0.0.1:58747: use of closed network connection
I161116 07:21:02.463826 21119 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:34919: operation was canceled"; Reconnecting to {"127.0.0.1:34919" <nil>}
I161116 07:21:02.463901 21119 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:02.464579 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.464877 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.465130 21386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestCheckConsistencyMultiStore (0.34s)
=== RUN   TestCheckInconsistent
I161116 07:21:02.496476 21325 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.497661 21325 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:02.497824 21325 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:02.500561 21325 base/node_id.go:62  NodeID set to 1
I161116 07:21:02.513222 21325 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:02.513418 21325 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:48295" > attrs:<> locality:<> 
I161116 07:21:02.514629 21429 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:02.517457 21325 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.518496 21325 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48295]
W161116 07:21:02.518584 21325 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.518716 21325 base/node_id.go:62  NodeID set to 2
I161116 07:21:02.523162 21372 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:48295
I161116 07:21:02.545786 21325 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:02.546047 21325 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:49877" > attrs:<> locality:<> 
I161116 07:21:02.551026 21325 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.552058 21325 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:48295]
W161116 07:21:02.552142 21325 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.552274 21325 base/node_id.go:62  NodeID set to 3
I161116 07:21:02.556612 21132 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:48295
I161116 07:21:02.563761 21325 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:35271" > attrs:<> locality:<> 
I161116 07:21:02.566908 21325 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 32189d67 at index 14
I161116 07:21:02.569989 21511 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=32189d67, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:02.571039 21511 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:02.572692 21325 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:02.574571 21325 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:02.579486 21618 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:02.585939 21325 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot ed781fb2 at index 17
I161116 07:21:02.591795 21590 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=ed781fb2, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:02.592876 21590 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:02.593321 21325 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:02.596857 21325 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:02.600632 21596 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:02.610942 21622 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:02.708413 21667 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:21:02.783307 21633 storage/stores_server.go:86  consistency check failed on range ID 1: expected checksum d36c40e6c4ebb684f5d90884924ce9987a77491c68dfa901e5cc045be3392838620d7fdf610db5833fedc315a445143f1e19710db6cb8332f8bb1a4744f95daa, got 5f34cfac18de9caa358eeaaf5d85ded00b2d35b8f7555a18914681d871eae2b97bc2fe960552f41e31f150969f5767e38a77b4646204b7cd3a8618e1c70fb0dc
E161116 07:21:02.784188 21685 storage/replica_command.go:1887  [s1,r1/1:/M{in-ax}] 
replica {2 2 2} is inconsistent: expected checksum d36c40e6c4ebb684f5d90884924ce9987a77491c68dfa901e5cc045be3392838620d7fdf610db5833fedc315a445143f1e19710db6cb8332f8bb1a4744f95daa, got 5f34cfac18de9caa358eeaaf5d85ded00b2d35b8f7555a18914681d871eae2b97bc2fe960552f41e31f150969f5767e38a77b4646204b7cd3a8618e1c70fb0dc
E161116 07:21:02.789636 21677 storage/replica_command.go:1908  [s1,r1/1:/M{in-ax}] consistency check failed with 1 inconsistent replicas; fetching details
E161116 07:21:02.805843 21582 storage/stores_server.go:86  consistency check failed on range ID 1: expected checksum 5e1a2d9bbd530db99ae545b316697a4f5d667b2057d8721134d535022b6443b66ba7ab90b0cdf28a243d8fb840c6e706b936faa11d6e2f5bc80128925d84ac02, got 0420456309d20b8523fc8702acc69e55c4b4e0b8628be23c48df7bf8b9481bafd597b3b19d380455eac837b63f8b95b0b3f1002691d00e63358626048c15e131
E161116 07:21:02.806843 21580 storage/replica_command.go:1887  [s1,r1/1:/M{in-ax}] 
replica {2 2 2} is inconsistent: expected checksum 5e1a2d9bbd530db99ae545b316697a4f5d667b2057d8721134d535022b6443b66ba7ab90b0cdf28a243d8fb840c6e706b936faa11d6e2f5bc80128925d84ac02, got 0420456309d20b8523fc8702acc69e55c4b4e0b8628be23c48df7bf8b9481bafd597b3b19d380455eac837b63f8b95b0b3f1002691d00e63358626048c15e131--- leaseholder
+++ follower
+0.000000123,196 "e"
+  ts:1970-01-01 00:00:00.000000123 +0000 UTC
+  value:    T
+  raw_key:"e" raw_value:000000000154
E161116 07:21:02.807192 21578 storage/replica_command.go:1903  [s1,r1/1:/M{in-ax}] consistency check failed with 1 inconsistent replicas
I161116 07:21:02.807505 21643 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/replica_command.go:1916
1      storage/client_test.go:501
I161116 07:21:02.807690 21643 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/replica_command.go:1916
I161116 07:21:02.808036 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.809494 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.810856 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.812176 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.813567 21415 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35271->127.0.0.1:34552: use of closed network connection
I161116 07:21:02.813793 21464 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49877->127.0.0.1:53173: use of closed network connection
I161116 07:21:02.814836 21387 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:48295->127.0.0.1:38459: use of closed network connection
W161116 07:21:02.815349 21632 storage/raft_transport.go:443  raft transport stream to node 3 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:02.817157 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.817442 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:02.817711 21688 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestCheckInconsistent (0.33s)
=== RUN   TestTransferRaftLeadership
I161116 07:21:02.825234 21689 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.826295 21689 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:02.826383 21689 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:02.826528 21689 base/node_id.go:62  NodeID set to 1
I161116 07:21:02.855288 21689 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:02.855476 21689 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:33533" > attrs:<> locality:<> 
I161116 07:21:02.859976 21705 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 8h20m0.000000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:02.862574 21689 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.863594 21689 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:33533]
W161116 07:21:02.863703 21689 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.863840 21689 base/node_id.go:62  NodeID set to 2
I161116 07:21:02.870407 21606 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:33533
I161116 07:21:02.870822 21689 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:02.871052 21689 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:56421" > attrs:<> locality:<> 
I161116 07:21:02.871924 21689 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:02.873020 21689 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:33533]
W161116 07:21:02.873140 21689 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:02.873307 21689 base/node_id.go:62  NodeID set to 3
I161116 07:21:02.898114 21689 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:02.898321 21689 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:56875" > attrs:<> locality:<> 
I161116 07:21:02.901405 21549 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:33533
I161116 07:21:02.912125 21818 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
E161116 07:21:02.923677 21754 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:02.924876 21754 storage/queue.go:586  [replicate,s1,r2/1:{"a"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:02.945326 21689 storage/replica_raftstorage.go:443  [s1,r2/1:{"a"-/Max}] generated snapshot 7a3f10fe at index 11
I161116 07:21:02.947104 21689 storage/store.go:3134  [s1,r2/1:{"a"-/Max}] streamed snapshot: kv pairs: 28, log entries: 1
I161116 07:21:02.947800 21897 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 11 (id=7a3f10fe, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:21:02.948674 21897 storage/replica_raftstorage.go:590  [s2,r2/?:{"a"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:21:02.950674 21689 storage/replica_command.go:3245  [s1,r2/1:{"a"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"a" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
W161116 07:21:02.953703 21835 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"a\x00"), but have [/Min,"a")
I161116 07:21:02.962874 21900 storage/replica.go:2066  [s1,r2/1:{"a"-/Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:02.975346 21689 storage/replica_raftstorage.go:443  [s1,r2/1:{"a"-/Max}] generated snapshot ecffc58f at index 13
I161116 07:21:02.977189 21689 storage/store.go:3134  [s1,r2/1:{"a"-/Max}] streamed snapshot: kv pairs: 30, log entries: 3
I161116 07:21:02.978137 21880 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 13 (id=ecffc58f, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:02.980090 21880 storage/replica_raftstorage.go:590  [s3,r2/?:{"a"-/Max}] applied preemptive snapshot in 0.002s
I161116 07:21:02.983005 21689 storage/replica_command.go:3245  [s1,r2/1:{"a"-/Max}] change replicas: read existing descriptor range_id:2 start_key:"a" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:02.986372 21938 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:02.999697 21848 storage/replica.go:2066  [s1,r2/1:{"a"-/Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:03.017927 21883 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:03.034751 21730 storage/replica_proposal.go:381  [s1,r2/1:{"a"-/Max}] range [n1,s1,r2/1:{"a"-/Max}]: transferring raft leadership to replica ID 2
I161116 07:21:03.037821 21778 storage/replica_proposal.go:332  [s2,r2/2:{"a"-/Max}] new range lease replica {2 2 2} 1970-01-01 08:20:00.000000124 +0000 UTC 16h40m0.000000002s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 8h20m0.000000124s [physicalTime=1970-01-01 16:40:00.000000125 +0000 UTC]
I161116 07:21:03.048914 21930 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:03.051277 21973 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:03.058553 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.059892 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.061238 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.062435 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.064178 21827 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:56875->127.0.0.1:37833: use of closed network connection
I161116 07:21:03.065591 21646 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:33533->127.0.0.1:51035: use of closed network connection
I161116 07:21:03.066500 21678 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:56421->127.0.0.1:52723: use of closed network connection
W161116 07:21:03.066766 21903 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:03.067125 21930 storage/raft_transport.go:443  raft transport stream to node 3 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:03.067288 21958 storage/raft_transport.go:443  raft transport stream to node 3 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:03.067506 21883 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:03.070691 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.071101 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.071535 21660 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestTransferRaftLeadership (0.29s)
=== RUN   TestFailedPreemptiveSnapshot
I161116 07:21:03.120036 21976 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.121270 21976 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:03.121359 21976 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:03.121499 21976 base/node_id.go:62  NodeID set to 1
I161116 07:21:03.140023 21976 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:03.140210 21976 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:42871" > attrs:<> locality:<> 
I161116 07:21:03.144186 21993 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:03.148607 21976 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.149645 21976 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:42871]
W161116 07:21:03.149732 21976 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:03.149866 21976 base/node_id.go:62  NodeID set to 2
I161116 07:21:03.154386 21889 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:42871
I161116 07:21:03.158209 21976 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:59267" > attrs:<> locality:<> 
I161116 07:21:03.160828 21976 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 038a35c6 at index 13
I161116 07:21:03.169531 21976 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:21:03.170433 22043 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=038a35c6, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:03.172554 22043 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.002s
I161116 07:21:03.174670 21976 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:03.178356 22149 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:03.308012 22028 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:03.323494 21976 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 16aea7ec at index 16
I161116 07:21:03.324403 22029 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.325655 22029 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.326909 22029 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.329122 21918 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:42871->127.0.0.1:34439: use of closed network connection
I161116 07:21:03.329184 21965 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:03.329251 21953 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:21:03.329488 22025 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:03.329607 22028 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
I161116 07:21:03.329699 22066 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:59267->127.0.0.1:42120: use of closed network connection
I161116 07:21:03.329807 22051 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:59267: operation was canceled"; Reconnecting to {"127.0.0.1:59267" <nil>}
I161116 07:21:03.329857 22029 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.330086 22051 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:03.330149 22029 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestFailedPreemptiveSnapshot (0.23s)
=== RUN   TestRaftBlockedReplica
I161116 07:21:03.347117 21856 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.348122 21856 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:03.348214 21856 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:03.348345 21856 base/node_id.go:62  NodeID set to 1
I161116 07:21:03.362191 21856 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:03.362384 21856 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49870" > attrs:<> locality:<> 
I161116 07:21:03.362429 22183 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:03.365538 21856 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.366403 21856 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49870]
W161116 07:21:03.366477 21856 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:03.366622 21856 base/node_id.go:62  NodeID set to 2
I161116 07:21:03.379487 22157 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:49870
I161116 07:21:03.388560 21856 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:03.388755 21856 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:53422" > attrs:<> locality:<> 
I161116 07:21:03.389329 21856 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.390414 21856 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49870]
W161116 07:21:03.390496 21856 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:03.390652 21856 base/node_id.go:62  NodeID set to 3
I161116 07:21:03.395986 22219 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:49870
I161116 07:21:03.397362 21856 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:03.397547 21856 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:41111" > attrs:<> locality:<> 
I161116 07:21:03.404444 21856 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "b" [r2]
E161116 07:21:03.415776 22104 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:03.416470 22104 storage/queue.go:586  [replicate,s1,r2/1:{"b"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:03.417778 21856 storage/replica_raftstorage.go:443  [s1,r1/1:{/Min-"b"}] generated snapshot 48c3737c at index 18
I161116 07:21:03.419598 21856 storage/store.go:3134  [s1,r1/1:{/Min-"b"}] streamed snapshot: kv pairs: 20, log entries: 8
I161116 07:21:03.421581 22357 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 18 (id=48c3737c, encoded size=16, 1 rocksdb batches, 8 log entries)
I161116 07:21:03.424063 22357 storage/replica_raftstorage.go:590  [s2,r1/?:{/Min-"b"}] applied preemptive snapshot in 0.001s
I161116 07:21:03.426047 21856 storage/replica_command.go:3245  [s1,r1/1:{/Min-"b"}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"b" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:03.429682 22333 storage/replica.go:2066  [s1,r1/1:{/Min-"b"}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:03.437551 21856 storage/replica_raftstorage.go:443  [s1,r1/1:{/Min-"b"}] generated snapshot aeea6d9b at index 20
I161116 07:21:03.439608 21856 storage/store.go:3134  [s1,r1/1:{/Min-"b"}] streamed snapshot: kv pairs: 23, log entries: 10
I161116 07:21:03.440448 22143 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 20 (id=aeea6d9b, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:21:03.448058 22143 storage/replica_raftstorage.go:590  [s3,r1/?:{/Min-"b"}] applied preemptive snapshot in 0.007s
I161116 07:21:03.450326 21856 storage/replica_command.go:3245  [s1,r1/1:{/Min-"b"}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"b" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:03.455938 22375 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:03.462596 22172 storage/replica.go:2066  [s1,r1/1:{/Min-"b"}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:03.559570 22177 storage/raft_transport.go:437  raft transport stream to node 1 established
E161116 07:21:03.862110 21856 storage/client_test.go:997  engine 1: missing key "a"
E161116 07:21:03.862190 21856 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:21:03.863691 21856 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:21:03.864213 21856 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:21:03.864381 21856 storage/client_test.go:997  engine 2: missing key "a"
E161116 07:21:03.864617 21856 storage/client_test.go:997  engine 2: missing key "a"
I161116 07:21:03.865289 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.866447 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.868409 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.870610 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.873732 22162 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49870->127.0.0.1:49971: use of closed network connection
W161116 07:21:03.874037 22361 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:21:03.874446 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.874639 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:03.874784 22345 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRaftBlockedReplica (0.53s)
=== RUN   TestRangeQuiescence
I161116 07:21:03.892189 22438 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.893206 22438 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:03.893292 22438 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:03.893422 22438 base/node_id.go:62  NodeID set to 1
I161116 07:21:03.905463 22438 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:03.905689 22438 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:44583" > attrs:<> locality:<> 
I161116 07:21:03.906968 22438 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.907935 22438 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:44583]
W161116 07:21:03.908080 22438 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:03.908227 22438 base/node_id.go:62  NodeID set to 2
I161116 07:21:03.912189 22401 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:03.914228 22514 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:44583
I161116 07:21:03.918844 22438 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:03.919064 22438 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:35326" > attrs:<> locality:<> 
I161116 07:21:03.919499 22438 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:03.921782 22438 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:44583]
W161116 07:21:03.921881 22438 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:03.922054 22438 base/node_id.go:62  NodeID set to 3
I161116 07:21:03.927241 22517 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:44583
I161116 07:21:03.931898 22438 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:44043" > attrs:<> locality:<> 
I161116 07:21:03.935569 22438 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 594eb7a7 at index 14
I161116 07:21:03.940427 22438 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:03.941335 22605 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=594eb7a7, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:03.942382 22605 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:03.944605 22438 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:03.948457 22425 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:03.954485 22438 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 7f12dd34 at index 17
I161116 07:21:03.956904 22438 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:03.957544 22495 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=7f12dd34, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:03.958613 22495 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:03.960758 22438 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:03.970379 22429 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:03.990618 22661 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:04.031940 22524 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:04.719888 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.720807 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.721742 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.722646 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.724061 22447 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:44583->127.0.0.1:56040: use of closed network connection
I161116 07:21:04.724394 22532 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:44043->127.0.0.1:59907: use of closed network connection
I161116 07:21:04.724768 22368 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35326->127.0.0.1:41127: use of closed network connection
I161116 07:21:04.725142 22567 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:04.725732 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.726025 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:04.726257 22580 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeQuiescence (0.85s)
=== RUN   TestReplicaGCQueueDropReplicaDirect
I161116 07:21:04.734315 22646 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:04.738506 22646 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:04.738596 22646 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:04.738820 22646 base/node_id.go:62  NodeID set to 1
I161116 07:21:04.755099 22691 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:04.759781 22646 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49776" > attrs:<> locality:<> 
I161116 07:21:04.760322 22646 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:04.767061 22646 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49776]
W161116 07:21:04.767158 22646 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:04.767286 22646 base/node_id.go:62  NodeID set to 2
I161116 07:21:04.773480 22755 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:49776
I161116 07:21:04.780545 22646 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:58841" > attrs:<> locality:<> 
I161116 07:21:04.781233 22646 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:04.788168 22646 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49776]
W161116 07:21:04.788257 22646 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:04.788396 22646 base/node_id.go:62  NodeID set to 3
I161116 07:21:04.794660 22818 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:49776
I161116 07:21:04.802308 22646 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:33962" > attrs:<> locality:<> 
I161116 07:21:04.804359 22646 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot b3ed2689 at index 14
I161116 07:21:04.807007 22646 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:04.807889 22869 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=b3ed2689, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:04.813137 22869 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.005s
I161116 07:21:04.817463 22646 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:04.821514 22873 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:04.827874 22646 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 31a4cf00 at index 17
I161116 07:21:04.829873 22646 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:04.830556 22887 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=31a4cf00, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:04.831627 22887 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:04.834198 22646 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:04.838254 22874 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:04.850039 22763 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:04.945485 22831 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:05.003842 22646 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:05.011319 22881 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:05.023580 22876 storage/store.go:2986  [s2,r1/2:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:21:05.034666 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.036043 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.037352 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.038991 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.040372 22724 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:58841->127.0.0.1:36067: use of closed network connection
I161116 07:21:05.040598 22736 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:33962->127.0.0.1:46020: use of closed network connection
I161116 07:21:05.041452 22584 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49776->127.0.0.1:47633: use of closed network connection
W161116 07:21:05.042730 22874 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:05.043169 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.043400 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.043568 22902 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaGCQueueDropReplicaDirect (0.38s)
=== RUN   TestReplicaGCQueueDropReplicaGCOnScan
I161116 07:21:05.106155 22766 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.107223 22766 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:05.108917 22766 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:05.109061 22766 base/node_id.go:62  NodeID set to 1
I161116 07:21:05.126226 22766 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:05.126427 22766 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:46130" > attrs:<> locality:<> 
I161116 07:21:05.128874 22991 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:05.131545 22766 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.132618 22766 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:46130]
W161116 07:21:05.132733 22766 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:05.132889 22766 base/node_id.go:62  NodeID set to 2
I161116 07:21:05.139274 22766 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:05.139462 22766 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:33878" > attrs:<> locality:<> 
I161116 07:21:05.140583 22970 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:46130
I161116 07:21:05.140737 22766 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.141895 22766 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:46130]
W161116 07:21:05.141987 22766 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:05.142120 22766 base/node_id.go:62  NodeID set to 3
I161116 07:21:05.152523 23107 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:46130
I161116 07:21:05.181899 22766 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:53280" > attrs:<> locality:<> 
I161116 07:21:05.215474 22766 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot a6d9dd00 at index 15
I161116 07:21:05.227491 22766 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 34, log entries: 5
I161116 07:21:05.228369 23171 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 15 (id=a6d9dd00, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:05.229534 23171 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:05.241971 22766 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:05.250521 23054 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:05.265155 22766 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 64077bed at index 17
I161116 07:21:05.274053 22766 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:05.276824 23163 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=64077bed, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:05.278001 23163 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:05.281815 22766 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:05.287783 23180 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:05.294328 23167 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:05.319956 23210 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:05.344602 22766 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:05.359934 23038 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:3}]
E161116 07:21:05.367854 22977 storage/store.go:2984  [s2,r1/2:/M{in-ax}] unable to add to replica GC queue: queue disabled
E161116 07:21:05.368011 22977 storage/store.go:2984  [s2,r1/2:/M{in-ax}] unable to add to replica GC queue: queue disabled
E161116 07:21:05.368340 23062 storage/replica_proposal.go:519  [s2,r1/2:/M{in-ax}] unable to add to replica GC queue: queue disabled
I161116 07:21:05.392591 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.393977 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.395307 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.397653 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.401876 23030 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:53280->127.0.0.1:52486: use of closed network connection
I161116 07:21:05.402065 22906 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:46130->127.0.0.1:60577: use of closed network connection
I161116 07:21:05.402293 23099 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:21:05.402750 23180 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport: write tcp 127.0.0.1:60577->127.0.0.1:46130: use of closed network connection
I161116 07:21:05.403938 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.404174 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.404406 23242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestReplicaGCQueueDropReplicaGCOnScan (0.35s)
=== RUN   TestRangeCommandClockUpdate
I161116 07:21:05.466159 23194 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.467144 23194 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:05.467230 23194 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:05.467357 23194 base/node_id.go:62  NodeID set to 1
I161116 07:21:05.477868 23194 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:05.480357 23194 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:35895" > attrs:<> locality:<> 
I161116 07:21:05.485300 23287 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 1.000000001s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000001 +0000 UTC]
I161116 07:21:05.488304 23194 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.489327 23194 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:35895]
W161116 07:21:05.489420 23194 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:05.489570 23194 base/node_id.go:62  NodeID set to 2
I161116 07:21:05.496071 23267 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:35895
I161116 07:21:05.501356 23194 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:44627" > attrs:<> locality:<> 
I161116 07:21:05.503425 23194 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.542050 23194 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:35895]
W161116 07:21:05.542153 23194 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:05.542342 23194 base/node_id.go:62  NodeID set to 3
I161116 07:21:05.548068 23335 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:35895
I161116 07:21:05.555834 23194 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:41789" > attrs:<> locality:<> 
I161116 07:21:05.567846 23194 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot b51c27e8 at index 14
I161116 07:21:05.591067 23194 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:05.592081 23463 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=b51c27e8, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:05.593525 23463 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:05.595911 23194 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:05.599598 23506 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:05.603150 23194 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot b6ce8478 at index 17
I161116 07:21:05.612219 23194 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 37, log entries: 7
I161116 07:21:05.613074 23449 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 17 (id=b6ce8478, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:05.614126 23449 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:05.620708 23194 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:05.633029 23466 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:05.641655 23524 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:05.677623 23545 storage/raft_transport.go:437  raft transport stream to node 1 established
W161116 07:21:05.747897 23478 util/hlc/hlc.go:213  remote wall time is too far ahead (500ms) to be trustworthy - updating anyway
W161116 07:21:05.749037 23364 util/hlc/hlc.go:213  remote wall time is too far ahead (500ms) to be trustworthy - updating anyway
I161116 07:21:05.750616 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:05.751222 23491 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:05.753511 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.754827 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.756098 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.756933 23270 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:41789->127.0.0.1:38610: use of closed network connection
I161116 07:21:05.757212 23409 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:21:05.759959 23280 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:21:05.760762 23195 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35895->127.0.0.1:59419: use of closed network connection
I161116 07:21:05.760826 23224 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:44627->127.0.0.1:46785: use of closed network connection
I161116 07:21:05.760889 23443 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:41789: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:41789" <nil>}
I161116 07:21:05.760961 23443 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:05.760996 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.761255 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.761516 23469 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeCommandClockUpdate (0.30s)
=== RUN   TestRejectFutureCommand
I161116 07:21:05.776086 23508 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.780338 23508 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:05.780423 23508 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:05.780558 23508 base/node_id.go:62  NodeID set to 1
I161116 07:21:05.809246 23508 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:05.809457 23508 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:52611" > attrs:<> locality:<> 
I161116 07:21:05.811555 23562 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 1.000000123s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:05.824683 23422 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:05.835470 23579 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:05.835926 23422 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:05.837368 23422 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRejectFutureCommand (0.14s)
=== RUN   TestTxnPutOutOfOrder
I161116 07:21:05.912352 23424 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:05.913631 23424 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:05.913739 23424 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:05.913976 23424 base/node_id.go:62  NodeID set to 1
I161116 07:21:05.914164 23424 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:05.941325 23424 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:05.944770 23624 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:05.948634 23121 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:05.952700 23121 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
E161116 07:21:05.965908 23650 storage/queue.go:586  [replicate,s1,r1/1:/{Min-Table/11}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:05.968252 23121 storage/replica_command.go:2361  [s1,r2/1:/{Table/11-Max}] initiating a split of this range at key /Table/12 [r3]
W161116 07:21:05.982118 23121 storage/stores.go:218  range not contained in one range: [/Meta2/Table/12,/Table/12/NULL), but have [/Min,/Table/11)
W161116 07:21:06.003692 23670 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/11}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=951fbde9 key=/Local/Range/"\x93"/RangeDescriptor rw=true pri=0.01688665 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,65 orig=0.000000123,65 max=0.000000123,65 wto=false rop=false
E161116 07:21:06.031600 23650 storage/queue.go:586  [replicate,s1,r2/1:/Table/1{1-2}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:06.039847 23121 storage/replica_command.go:2361  [s1,r3/1:/{Table/12-Max}] initiating a split of this range at key /Table/13 [r4]
I161116 07:21:06.070266 23424 storage/replica_command.go:87  [s1,r1/1:/{Min-Table/11}] test injecting error: Test
I161116 07:21:06.082645 23424 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.082759 23424 util/stop/stopper.go:468  quiescing; tasks left:
2      kv/txn_coord_sender.go:918
1      storage/queue.go:477
I161116 07:21:06.083393 23424 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
W161116 07:21:06.088173 23637 storage/intent_resolver.go:384  failed to resolve intents: node unavailable; try another peer
E161116 07:21:06.089344 23121 storage/queue.go:575  [split,s1,r1/1:/{Min-Table/11}] unable to split [n1,s1,r1/1:/{Min-Table/11}] at key "/Table/14/0": node unavailable; try another peer
--- PASS: TestTxnPutOutOfOrder (0.19s)
=== RUN   TestRangeLookupUseReverse
I161116 07:21:06.166173 23684 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:06.167328 23684 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:06.167405 23684 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:06.167546 23684 base/node_id.go:62  NodeID set to 1
I161116 07:21:06.167682 23684 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:06.187164 23701 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m7.085314284s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:06.187027843 +0000 UTC]
I161116 07:21:06.206325 23684 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "g" [r2]
I161116 07:21:06.216111 23684 storage/replica_command.go:2361  [s1,r1/1:{/Min-"g"}] initiating a split of this range at key "e" [r3]
E161116 07:21:06.217757 23616 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"g"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:06.253936 23616 storage/queue.go:586  [replicate,s1,r3/1:"{e"-g"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:06.258456 23684 storage/replica_command.go:2361  [s1,r1/1:{/Min-"e"}] initiating a split of this range at key "c" [r4]
E161116 07:21:06.267815 23616 storage/queue.go:586  [replicate,s1,r4/1:"{c"-e"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:06.268182 23684 storage/replica_command.go:2361  [s1,r1/1:{/Min-"c"}] initiating a split of this range at key "a" [r5]
I161116 07:21:06.281744 23684 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.281856 23684 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:06.295814 23616 storage/queue.go:586  [replicate,s1,r5/1:"{a"-c"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
--- PASS: TestRangeLookupUseReverse (0.22s)
=== RUN   TestRangeTransferLease
I161116 07:21:06.318608 23762 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:06.319573 23762 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:06.319655 23762 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:06.319781 23762 base/node_id.go:62  NodeID set to 1
I161116 07:21:06.333443 23762 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:06.333633 23762 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:43552" > attrs:<> locality:<> 
I161116 07:21:06.336318 23694 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:06.380495 23762 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:06.381551 23762 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:43552]
W161116 07:21:06.381651 23762 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:06.381864 23762 base/node_id.go:62  NodeID set to 2
I161116 07:21:06.386501 23497 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:43552
I161116 07:21:06.401320 23762 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:41195" > attrs:<> locality:<> 
I161116 07:21:06.411122 23762 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 4153e752 at index 15
I161116 07:21:06.428521 23513 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 15 (id=4153e752, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:06.429491 23513 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:06.430019 23762 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 34, log entries: 5
I161116 07:21:06.431963 23762 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:06.436005 23661 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:06.544256 23858 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:06.589814 23781 storage/replica_proposal.go:381  [s1,r1/1:/M{in-ax}] range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:21:06.592309 23837 storage/replica_proposal.go:332  [s2,r1/2:/M{in-ax}] new range lease replica {2 2 2} 1970-01-01 00:00:00.000000123 +0000 UTC 900.000001ms following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:06.632437 23824 storage/replica_proposal.go:381  [s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 1
I161116 07:21:06.635043 23780 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00.900000123 +0000 UTC 900.000001ms following replica {2 2 2} 1970-01-01 00:00:00.000000123 +0000 UTC 1.800000001s [physicalTime=1970-01-01 00:00:00.900000123 +0000 UTC]
I161116 07:21:06.638074 23863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:06.638343 23850 storage/node_liveness.go:141  [hb] failed liveness heartbeat: failed to send RPC: sending to all 2 replicas failed; last error: range 1: replica {1 1 1} not lease holder; node_id:2 store_id:2 replica_id:2  is
I161116 07:21:06.639666 23863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.641888 23863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.643130 23770 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:41195->127.0.0.1:34621: use of closed network connection
I161116 07:21:06.643676 23755 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:43552->127.0.0.1:43300: read: connection reset by peer
W161116 07:21:06.643894 23502 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:06.644274 23863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.644742 23863 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeTransferLease (0.34s)
=== RUN   TestLeaseNotUsedAfterRestart
I161116 07:21:06.676207 23857 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:06.678208 23857 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:06.678312 23857 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:06.678464 23857 base/node_id.go:62  NodeID set to 1
I161116 07:21:06.689382 23857 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:06.689584 23857 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:36981" > attrs:<> locality:<> 
I161116 07:21:06.692721 23804 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:06.702990 23857 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.714494 23992 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.715791 23992 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.716179 23866 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36981->127.0.0.1:46864: use of closed network connection
I161116 07:21:06.716248 23992 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestLeaseNotUsedAfterRestart (0.09s)
=== RUN   TestLeaseExtensionNotBlockedByRead
I161116 07:21:06.762742 24048 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:06.762869 24048 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:06.798106 24048 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:06.800099 24048 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:06.805259 24048 server/config.go:443  1 storage engine initialized
I161116 07:21:06.809475 24048 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:06.831861 24067 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m15.829952081s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:06.831693941 +0000 UTC]
I161116 07:21:06.834871 24048 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:06.835653 24048 server/node.go:350  [n?] **** cluster 7a66d692-31e3-4a2b-aa6e-58fae60c22e3 has been created
I161116 07:21:06.835749 24048 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:47608
I161116 07:21:06.836766 24048 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:06.859478 24056 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:06.860769 24048 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:06.860953 24048 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:06.861111 24048 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:47608" > attrs:<> locality:<> 
I161116 07:21:06.861414 24048 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:06.861607 24048 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:06.861724 24048 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "7a66d692-31e3-4a2b-aa6e-58fae60c22e3"
I161116 07:21:06.862128 24048 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:06.862792 24048 server/server.go:630  [n1] starting https server at 127.0.0.1:48267
I161116 07:21:06.862888 24048 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:47608
I161116 07:21:06.862965 24048 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:47608
I161116 07:21:06.909435 24124 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:47608} Attrs: Locality:} ClusterID:7a66d692-31e3-4a2b-aa6e-58fae60c22e3 StartedAt:1479280866861748195}
I161116 07:21:06.925522 24056 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:21:07.141499 24056 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
I161116 07:21:07.333628 24056 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
I161116 07:21:07.514868 24056 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
I161116 07:21:07.597169 24048 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:07.597291 24048 util/stop/stopper.go:468  quiescing; tasks left:
2      server/node.go:854
1      storage/queue.go:477
I161116 07:21:07.597991 24048 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
E161116 07:21:07.598943 24060 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:/{Min-Table/11}] node unavailable; try another peer
I161116 07:21:07.604108 23897 kv/transport_race.go:71  transport race promotion: ran 18 iterations on up to 205 requests
--- PASS: TestLeaseExtensionNotBlockedByRead (0.92s)
=== RUN   TestLeaseInfoRequest
I161116 07:21:07.679651 24140 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:07.679745 24140 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:07.734795 24140 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:07.761639 24140 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:07.762466 24140 server/config.go:443  1 storage engine initialized
I161116 07:21:07.775564 24140 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:07.789141 24161 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m16.787194736s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:07.789015399 +0000 UTC]
I161116 07:21:07.792073 24140 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:07.792866 24140 server/node.go:350  [n?] **** cluster 11255348-f77a-4cca-81ca-d753fd663321 has been created
I161116 07:21:07.792915 24140 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:50648
I161116 07:21:07.793924 24140 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:07.818847 24140 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:07.818944 24140 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:07.819054 24140 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:07.819212 24140 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:50648" > attrs:<> locality:<> 
I161116 07:21:07.819837 24140 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:07.819996 24140 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:07.820889 24140 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "11255348-f77a-4cca-81ca-d753fd663321"
I161116 07:21:07.821194 24140 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:07.821756 24140 server/server.go:630  [n1] starting https server at 127.0.0.1:55792
I161116 07:21:07.821797 24140 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:50648
I161116 07:21:07.821832 24140 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:50648
I161116 07:21:07.900342 24140 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:50648]
I161116 07:21:07.910561 24184 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:50648} Attrs: Locality:} ClusterID:11255348-f77a-4cca-81ca-d753fd663321 StartedAt:1479280867820929817}
W161116 07:21:07.911168 24140 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
W161116 07:21:07.934755 24140 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:07.979288 24140 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:07.980114 24140 server/config.go:443  1 storage engine initialized
I161116 07:21:07.981460 24140 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:07.981548 24140 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:07.981629 24140 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:08.051707 24012 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:50648
I161116 07:21:08.052016 24232 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:08.064337 24323 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:08.064792 24140 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "11255348-f77a-4cca-81ca-d753fd663321"
I161116 07:21:08.069414 24140 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:08.072387 24140 server/node.go:312  [n?] new node allocated ID 2
I161116 07:21:08.072509 24140 base/node_id.go:62  [n2] NodeID set to 2
I161116 07:21:08.072674 24140 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:49188" > attrs:<> locality:<> 
I161116 07:21:08.073392 24140 server/node.go:369  [n2] node=2: started with [[]=] engine(s) and attributes []
I161116 07:21:08.074019 24140 server/server.go:630  [n2] starting https server at 127.0.0.1:53546
I161116 07:21:08.074059 24140 server/server.go:631  [n2] starting grpc/postgres server at 127.0.0.1:49188
I161116 07:21:08.074094 24140 server/server.go:632  [n2] advertising CockroachDB node at 127.0.0.1:49188
I161116 07:21:08.075555 23926 storage/stores.go:312  [n1] wrote 1 node addresses to persistent storage
I161116 07:21:08.117459 24140 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:50648]
W161116 07:21:08.117560 24140 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:08.192635 24332 server/node.go:545  [n2] bootstrapped store [n2,s2]
W161116 07:21:08.216657 24140 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:08.248507 24140 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:08.249292 24140 server/config.go:443  1 storage engine initialized
I161116 07:21:08.250312 24140 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:08.250379 24140 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:08.250452 24140 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:08.312051 24335 sql/event_log.go:95  [n2] Event: "node_join", target: 2, info: {Descriptor:{NodeID:2 Address:{NetworkField:tcp AddressField:127.0.0.1:49188} Attrs: Locality:} ClusterID:11255348-f77a-4cca-81ca-d753fd663321 StartedAt:1479280868073077956}
I161116 07:21:08.368837 24406 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:50648
I161116 07:21:08.370332 24401 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:08.373163 24140 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "11255348-f77a-4cca-81ca-d753fd663321"
I161116 07:21:08.373465 24417 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:08.373809 24417 storage/stores.go:312  [n?] wrote 2 node addresses to persistent storage
I161116 07:21:08.387593 24140 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:08.390492 24140 server/node.go:312  [n?] new node allocated ID 3
I161116 07:21:08.394871 24140 base/node_id.go:62  [n3] NodeID set to 3
I161116 07:21:08.395151 24140 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:42639" > attrs:<> locality:<> 
I161116 07:21:08.397003 24376 storage/stores.go:312  [n1] wrote 2 node addresses to persistent storage
I161116 07:21:08.397271 24140 server/node.go:369  [n3] node=3: started with [[]=] engine(s) and attributes []
I161116 07:21:08.398147 24424 storage/stores.go:312  [n2] wrote 2 node addresses to persistent storage
I161116 07:21:08.402856 24140 server/server.go:630  [n3] starting https server at 127.0.0.1:41772
I161116 07:21:08.402941 24140 server/server.go:631  [n3] starting grpc/postgres server at 127.0.0.1:42639
I161116 07:21:08.402985 24140 server/server.go:632  [n3] advertising CockroachDB node at 127.0.0.1:42639
I161116 07:21:08.427312 24440 server/node.go:545  [n3] bootstrapped store [n3,s3]
I161116 07:21:08.444542 24140 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot 04ffeeb4 at index 88
I161116 07:21:08.483379 24443 sql/event_log.go:95  [n3] Event: "node_join", target: 3, info: {Descriptor:{NodeID:3 Address:{NetworkField:tcp AddressField:127.0.0.1:42639} Attrs: Locality:} ClusterID:11255348-f77a-4cca-81ca-d753fd663321 StartedAt:1479280868396870706}
I161116 07:21:08.608138 24140 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 597, log entries: 78
I161116 07:21:08.609894 24541 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 88 (id=04ffeeb4, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:21:08.621435 24541 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.011s
I161116 07:21:08.653516 24140 storage/replica_command.go:3245  [n1,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:08.666547 24140 storage/replica.go:2066  [n1,s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:08.681228 24140 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot c0e04e33 at index 135
I161116 07:21:08.684787 24568 storage/raft_transport.go:437  [n2] raft transport stream to node 1 established
I161116 07:21:08.875021 24140 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 790, log entries: 125
I161116 07:21:08.877456 24574 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 135 (id=c0e04e33, encoded size=16, 1 rocksdb batches, 125 log entries)
I161116 07:21:08.889555 24574 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.012s
I161116 07:21:08.899743 24140 storage/replica_command.go:3245  [n1,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:08.922609 24140 storage/replica.go:2066  [n1,s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:08.935702 24195 storage/replica_proposal.go:381  [n1,s1,r1/1:/M{in-ax}] range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:21:08.937773 24354 storage/replica_proposal.go:332  [n2,s2,r1/2:/M{in-ax}] new range lease replica {2 2 2} 2016-11-16 07:21:08.931761556 +0000 UTC 9.25s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m17.06985418s [physicalTime=2016-11-16 07:21:08.937649463 +0000 UTC]
I161116 07:21:08.960474 24472 storage/raft_transport.go:437  [n3] raft transport stream to node 1 established
I161116 07:21:08.962861 24200 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot 85f4b0d2 at index 168
I161116 07:21:09.018914 24577 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 798, log entries: 12
I161116 07:21:09.019072 24366 storage/replica_proposal.go:381  [n2,s2,r1/2:/M{in-ax}] range [n2,s2,r1/2:/M{in-ax}]: transferring raft leadership to replica ID 3
I161116 07:21:09.019931 24491 storage/replica_raftstorage.go:587  [n3,s3,r1/?:/M{in-ax}] applying Raft snapshot at index 168 (id=85f4b0d2, encoded size=16, 1 rocksdb batches, 12 log entries)
I161116 07:21:09.022563 24140 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:09.022944 24589 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/raft_transport.go:364
I161116 07:21:09.023245 24588 util/stop/stopper.go:468  quiescing; tasks left:
1      server/node.go:854
W161116 07:21:09.023889 24586 storage/raft_transport.go:443  [n2] raft transport stream to node 3 failed: rpc error: code = 13 desc = grpc: the client connection is closing
I161116 07:21:09.024110 24587 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
W161116 07:21:09.026954 24582 storage/raft_transport.go:443  [n1] raft transport stream to node 3 failed: EOF
E161116 07:21:09.029508 24223 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:/M{in-ax}] node unavailable; try another peer
W161116 07:21:09.029661 24472 storage/raft_transport.go:443  [n3] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:09.029812 24563 storage/raft_transport.go:443  [n1] raft transport stream to node 2 failed: EOF
W161116 07:21:09.030300 24568 storage/raft_transport.go:443  [n2] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:09.031115 24597 /go/src/google.golang.org/grpc/clientconn.go:472  Failed to dial 127.0.0.1:42639: connection error: desc = "transport: context canceled"; please retry.
I161116 07:21:09.031301 24475 /go/src/google.golang.org/grpc/server.go:369  grpc: Server.Serve failed to complete security handshake from "127.0.0.1:53394": EOF
W161116 07:21:09.032670 24577 storage/raft_transport.go:648  [n1,s1,r1/1:/M{in-ax}] failed to close snapshot stream: rpc error: code = 13 desc = transport is closing
W161116 07:21:09.032854 24577 storage/replica.go:2843  [n1,s1,r1/1:/M{in-ax}] failed to send snapshot: range=1: remote failed to apply snapshot: rpc error: code = 13 desc = transport is closing
I161116 07:21:09.047646 24491 storage/replica_raftstorage.go:590  [n3,s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.028s
I161116 07:21:09.048105 24140 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:09.048703 24242 kv/transport_race.go:71  transport race promotion: ran 33 iterations on up to 197 requests
I161116 07:21:09.051100 24140 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:09.056694 24140 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestLeaseInfoRequest (1.50s)
=== RUN   TestErrorHandlingForNonKVCommand
I161116 07:21:09.217917 24554 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:09.218718 24554 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:09.302581 24554 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:09.304669 24554 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:09.305682 24554 server/config.go:443  1 storage engine initialized
I161116 07:21:09.306683 24554 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:09.314583 24655 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m18.312612708s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:09.314458171 +0000 UTC]
I161116 07:21:09.317731 24554 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:09.318537 24554 server/node.go:350  [n?] **** cluster cbed0794-c61b-4421-b7b1-de31608509b2 has been created
I161116 07:21:09.318588 24554 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:35533
I161116 07:21:09.319636 24554 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:09.323738 24554 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:09.323856 24554 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:09.323994 24554 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:09.324179 24554 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:35533" > attrs:<> locality:<> 
I161116 07:21:09.327463 24554 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:09.328305 24554 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:09.328390 24554 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "cbed0794-c61b-4421-b7b1-de31608509b2"
I161116 07:21:09.330452 24706 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:09.341377 24706 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:21:09.356134 24554 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:09.356734 24554 server/server.go:630  [n1] starting https server at 127.0.0.1:60997
I161116 07:21:09.356809 24554 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:35533
I161116 07:21:09.356852 24554 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:35533
I161116 07:21:09.413317 24706 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
I161116 07:21:09.439024 24679 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:35533} Attrs: Locality:} ClusterID:cbed0794-c61b-4421-b7b1-de31608509b2 StartedAt:1479280869328422261}
I161116 07:21:09.538142 24706 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
I161116 07:21:09.679314 24706 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
I161116 07:21:09.764481 24554 storage/replica_command.go:87  [n1,s1,r1/1:/{Min-Table/11}] test injecting error: storage/client_replica_test.go:919: injected error
I161116 07:21:09.769318 24554 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:09.770154 24617 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:09.770512 24544 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:35533: operation was canceled"; Reconnecting to {"127.0.0.1:35533" <nil>}
I161116 07:21:09.770580 24544 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:09.828969 24542 kv/transport_race.go:71  transport race promotion: ran 21 iterations on up to 128 requests
--- PASS: TestErrorHandlingForNonKVCommand (0.67s)
=== RUN   TestRangeInfo
I161116 07:21:09.834017 24633 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:09.835006 24633 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:09.835095 24633 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:09.835260 24633 base/node_id.go:62  NodeID set to 1
I161116 07:21:09.844262 24633 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:09.844441 24633 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:55870" > attrs:<> locality:<> 
I161116 07:21:09.846390 24778 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:09.848908 24633 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:09.849879 24633 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:55870]
W161116 07:21:09.849965 24633 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:09.850095 24633 base/node_id.go:62  NodeID set to 2
I161116 07:21:09.862486 24633 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:09.862779 24861 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:55870
I161116 07:21:09.864666 24633 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:56132" > attrs:<> locality:<> 
I161116 07:21:09.871711 24633 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 81f2f8d5 at index 14
I161116 07:21:09.875683 24633 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 33, log entries: 4
I161116 07:21:09.876529 24863 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 14 (id=81f2f8d5, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:09.877491 24863 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:09.880237 24633 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:09.883795 24768 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:10.012638 24864 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:10.033195 24633 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
E161116 07:21:10.068814 24716 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:10.069630 24716 storage/queue.go:586  [replicate,s1,r2/1:{"a"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
W161116 07:21:10.100668 24905 storage/stores.go:218  range not contained in one range: [/System/Max,/Max), but have [/Min,"a")
I161116 07:21:10.110038 24779 storage/replica_proposal.go:381  [s1,r1/1:{/Min-"a"}] range [n1,s1,r1/1:{/Min-"a"}]: transferring raft leadership to replica ID 2
I161116 07:21:10.116484 24845 storage/replica_proposal.go:332  [s2,r1/2:{/Min-"a"}] new range lease replica {2 2 2} 1970-01-01 00:00:00.000000123 +0000 UTC 900.000001ms following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:10.119537 24786 storage/replica_proposal.go:381  [s1,r2/1:{"a"-/Max}] range [n1,s1,r2/1:{"a"-/Max}]: transferring raft leadership to replica ID 2
I161116 07:21:10.120708 24850 storage/replica_proposal.go:332  [s2,r2/2:{"a"-/Max}] new range lease replica {2 2 2} 1970-01-01 00:00:00.000000123 +0000 UTC 900.000001ms following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:10.134060 24895 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.136160 24895 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.137335 24895 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.138825 24895 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.139104 24895 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestRangeInfo (0.31s)
=== RUN   TestStoreRangeSplitAtIllegalKeys
I161116 07:21:10.161341 24873 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.162484 24873 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.162573 24873 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.162706 24873 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.162849 24873 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.177447 24873 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:10.180247 24955 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:10.183710 24975 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:10.184657 24873 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.184749 24873 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:10.187363 24975 storage/queue.go:575  [split,s1,r1/1:/M{in-ax}] unable to split [n1,s1,r1/1:/M{in-ax}] at key "/Table/11/0": node unavailable; try another peer
--- PASS: TestStoreRangeSplitAtIllegalKeys (0.05s)
=== RUN   TestStoreRangeSplitAtTablePrefix
I161116 07:21:10.207008 24831 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.208156 24831 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.208258 24831 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.208407 24831 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.208552 24831 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.242054 24831 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:10.243061 25014 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.138841475s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:10.242934518 +0000 UTC]
I161116 07:21:10.256637 24831 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50 [r2]
E161116 07:21:10.266975 24984 storage/queue.go:586  [replicate,s1,r2/1:/{Table/50-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
W161116 07:21:10.273223 24831 gossip/gossip.go:789  [n1] raw gossip callback registered on system-db, consider using RegisterSystemConfigChannel
I161116 07:21:10.273553 24831 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSplitAtTablePrefix (0.09s)
=== RUN   TestStoreRangeSplitInsideRow
I161116 07:21:10.278549 24992 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.279600 24992 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.279678 24992 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.279805 24992 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.279944 24992 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.295479 24992 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:10.298631 25063 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.196252188s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:10.298463264 +0000 UTC]
I161116 07:21:10.360422 24992 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50/1/1/"a" [r2]
I161116 07:21:10.368887 24992 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.368978 24992 util/stop/stopper.go:468  quiescing; tasks left:
1      kv/txn_coord_sender.go:918
--- PASS: TestStoreRangeSplitInsideRow (0.16s)
=== RUN   TestStoreRangeSplitIntents
I161116 07:21:10.444060 25041 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.445131 25041 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.445230 25041 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.445568 25041 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.445756 25041 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.462900 25041 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:10.465733 25112 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.363137138s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:10.465602423 +0000 UTC]
I161116 07:21:10.478329 25041 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
I161116 07:21:10.486317 25041 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.486409 25041 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:10.486811 25087 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
--- PASS: TestStoreRangeSplitIntents (0.05s)
=== RUN   TestStoreRangeSplitAtRangeBounds
I161116 07:21:10.497233 24932 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.498317 24932 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.498402 24932 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.498535 24932 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.498679 24932 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.511467 24942 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.409550565s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:10.511341926 +0000 UTC]
I161116 07:21:10.526527 24932 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
E161116 07:21:10.534330 25205 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:10.535041 24932 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:10.535148 24932 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      kv/txn_coord_sender.go:918
I161116 07:21:10.535534 24932 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
--- PASS: TestStoreRangeSplitAtRangeBounds (0.11s)
=== RUN   TestStoreRangeSplitConcurrent
I161116 07:21:10.605494 25148 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:10.606600 25148 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:10.606686 25148 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:10.606816 25148 base/node_id.go:62  NodeID set to 1
I161116 07:21:10.606952 25148 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:10.618557 25148 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:10.625279 25235 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.519642824s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:10.625138816 +0000 UTC]
I161116 07:21:10.663925 25267 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r4]
I161116 07:21:10.663970 25270 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r5]
I161116 07:21:10.664014 25275 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r3]
I161116 07:21:10.664110 25271 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r7]
I161116 07:21:10.664173 25268 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r6]
I161116 07:21:10.664296 25266 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
I161116 07:21:10.664479 25273 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r9]
I161116 07:21:10.665257 25272 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r8]
I161116 07:21:10.665707 25269 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r10]
I161116 07:21:10.667457 25274 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r11]
E161116 07:21:10.684230 25280 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
W161116 07:21:10.684834 25271 storage/stores.go:218  range not contained in one range: [/Min,"a\x00"), but have [/Min,"a")
I161116 07:21:11.003545 25148 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSplitConcurrent (0.46s)
=== RUN   TestStoreRangeSplitIdempotency
I161116 07:21:11.070917 25002 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:11.073556 25002 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:11.073666 25002 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:11.073845 25002 base/node_id.go:62  NodeID set to 1
I161116 07:21:11.074022 25002 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:11.099883 25009 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m11.998007492s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:11.099757553 +0000 UTC]
I161116 07:21:11.115786 25002 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
E161116 07:21:11.125424 25259 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"m"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:11.130882 25002 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSplitIdempotency (0.09s)
=== RUN   TestStoreRangeSplitStats
I161116 07:21:11.160908 25223 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:11.163907 25223 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:11.163993 25223 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:11.164128 25223 base/node_id.go:62  NodeID set to 1
I161116 07:21:11.164279 25223 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:11.181850 25168 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:11.188894 25223 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50 [r2]
E161116 07:21:11.207983 25233 storage/queue.go:586  [replicate,s1,r2/1:/{Table/50-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:11.367898 25223 storage/replica_command.go:2361  [s1,r2/1:/{Table/50-Max}] initiating a split of this range at key /Table/50/0/"Z" [r3]
W161116 07:21:11.371077 25223 storage/stores.go:218  range not contained in one range: [/Meta2/Table/50/0/"Z",/Table/50/0/"Z\x00"), but have [/Min,/Table/50)
W161116 07:21:11.379662 25355 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/50}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=f162b67e key=/Local/Range/"\xba"/RangeDescriptor rw=true pri=0.01947833 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000223,3 orig=0.000000223,3 max=0.000000223,3 wto=false rop=false
E161116 07:21:11.383962 25233 storage/queue.go:586  [replicate,s1,r3/1:/{Table/50/0/"-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:11.389029 25223 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSplitStats (0.24s)
=== RUN   TestStoreRangeSplitStatsWithMerges
I161116 07:21:11.401552 25175 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:11.402586 25175 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:11.402683 25175 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:11.402816 25175 base/node_id.go:62  NodeID set to 1
I161116 07:21:11.402960 25175 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:11.411973 25175 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:11.415482 25373 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:11.422645 25175 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50 [r2]
E161116 07:21:11.433644 25416 storage/queue.go:586  [replicate,s1,r2/1:/{Table/50-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:11.695361 25175 storage/replica_command.go:2361  [s1,r2/1:/{Table/50-Max}] initiating a split of this range at key /Table/50/0/360000000000000 [r3]
W161116 07:21:11.698235 25175 storage/stores.go:218  range not contained in one range: [/Meta2/Table/50/0/360000000000000,/Table/50/0/360000000000000/NULL), but have [/Min,/Table/50)
W161116 07:21:11.719133 25428 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/50}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=c0e10d39 key=/Local/Range/"\xba"/RangeDescriptor rw=true pri=0.02082852 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000223,3 orig=0.000000223,3 max=0.000000223,3 wto=false rop=false
E161116 07:21:11.728097 25416 storage/queue.go:586  [replicate,s1,r3/1:/{Table/50/0/3-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:11.728512 25175 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:11.728611 25175 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
W161116 07:21:11.729540 25382 storage/replica.go:1810  [s1,r1/1:/{Min-Table/50}] shutdown cancellation of command ResolveIntent [/Meta2/Table/50/0/360000000000000,/Min), ResolveIntent [/Meta2/Max,/Min)
W161116 07:21:11.730039 25382 storage/intent_resolver.go:337  [n1,s1,r2/1:/Table/50{-/0/36000}]: failed to resolve intents: result is ambiguous
--- PASS: TestStoreRangeSplitStatsWithMerges (0.36s)
=== RUN   TestStoreZoneUpdateAndRangeSplit
I161116 07:21:11.779791 25430 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:11.782823 25430 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:11.782941 25430 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:11.783090 25430 base/node_id.go:62  NodeID set to 1
I161116 07:21:11.783265 25430 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:11.795626 25430 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:11.800655 25447 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:11.803133 25324 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/50/0]
I161116 07:21:11.807988 25324 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50 [r2]
E161116 07:21:11.817664 25325 storage/queue.go:586  [replicate,s1,r1/1:/{Min-Table/50}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:11.818196 25325 storage/queue.go:575  [replicate,s1,r2/1:/{Table/50-Max}] could not select an appropriate replica to be removed
I161116 07:21:12.330158 25324 storage/split_queue.go:120  [split,s1,r2/1:/{Table/50-Max}] splitting size=65585 max=65536
I161116 07:21:12.331549 25324 storage/replica_command.go:2361  [split,s1,r2/1:/{Table/50-Max}] initiating a split of this range at key /Table/50/"YsaXTYxLDwuncKjSMuLeoweuOMRPERBjlcscGQjFxqrXtNxYwXdRtnKcOMNBmwvewObjgoJlqotZOkRuCgdKJPDMsdCltBNtbyWw" [r3]
W161116 07:21:12.335356 25324 storage/stores.go:218  range not contained in one range: [/Meta2/Table/50/"YsaXTYxLDwuncKjSMuLeoweuOMRPERBjlcscGQjFxqrXtNxYwXdRtnKcOMNBmwvewObjgoJlqotZOkRuCgdKJPDMsdCltBNtbyWw",/Table/50/"YsaXTYxLDwuncKjSMuLeoweuOMRPERBjlcscGQjFxqrXtNxYwXdRtnKcOMNBmwvewObjgoJlqotZOkRuCgdKJPDMsdCltBNtbyWw\x00"), but have [/Min,/Table/50)
W161116 07:21:12.365466 25384 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/50}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=ed722cc6 key=/Local/Range/"\xba"/RangeDescriptor rw=true pri=0.02122046 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,1398 orig=0.000000123,1398 max=0.000000123,1398 wto=false rop=false
I161116 07:21:12.372502 25430 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:12.372635 25430 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      storage/intent_resolver.go:383
1      kv/txn_coord_sender.go:918
I161116 07:21:12.373026 25430 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
1      kv/txn_coord_sender.go:918
I161116 07:21:12.373391 25430 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
W161116 07:21:12.374279 25438 storage/replica.go:1810  [s1,r1/1:/{Min-Table/50}] shutdown cancellation of command ResolveIntent [/Meta2/Table/50/"YsaXTYxLDwuncKjSMuLeoweuOMRPERBjlcscGQjFxqrXtNxYwXdRtnKcOMNBmwvewObjgoJlqotZOkRuCgdKJPDMsdCltBNtbyWw",/Min), ResolveIntent [/Meta2/Max,/Min)
W161116 07:21:12.376015 25438 storage/intent_resolver.go:337  [n1,s1,r2/1:/Table/50{-/"YsaXTY}]: failed to resolve intents: result is ambiguous
--- PASS: TestStoreZoneUpdateAndRangeSplit (0.63s)
=== RUN   TestStoreRangeSplitWithMaxBytesUpdate
I161116 07:21:12.388316 25386 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:12.389798 25386 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:12.390086 25386 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:12.390269 25386 base/node_id.go:62  NodeID set to 1
I161116 07:21:12.390442 25386 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:12.397948 25386 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:12.405482 25393 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:12.408222 25522 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/50/0]
I161116 07:21:12.418242 25522 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/50 [r2]
E161116 07:21:12.430148 25523 storage/queue.go:586  [replicate,s1,r1/1:/{Min-Table/50}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:12.430834 25523 storage/queue.go:575  [replicate,s1,r2/1:/{Table/50-Max}] could not select an appropriate replica to be removed
I161116 07:21:12.432418 25386 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSplitWithMaxBytesUpdate (0.05s)
=== RUN   TestStoreRangeSystemSplits
I161116 07:21:12.443942 25555 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:12.445031 25555 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:12.445115 25555 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:12.445256 25555 base/node_id.go:62  NodeID set to 1
I161116 07:21:12.445409 25555 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:12.455016 25535 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:12.458920 25557 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:12.463002 25557 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
E161116 07:21:12.471356 25558 storage/queue.go:586  [replicate,s1,r1/1:/{Min-Table/11}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.472490 25557 storage/replica_command.go:2361  [s1,r2/1:/{Table/11-Max}] initiating a split of this range at key /Table/12 [r3]
W161116 07:21:12.481831 25557 storage/stores.go:218  range not contained in one range: [/Meta2/Table/12,/Table/12/NULL), but have [/Min,/Table/11)
W161116 07:21:12.491796 25595 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/11}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=40c8d1a8 key=/Local/Range/"\x93"/RangeDescriptor rw=true pri=0.02039573 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,67 orig=0.000000123,67 max=0.000000123,67 wto=false rop=false
E161116 07:21:12.500045 25558 storage/queue.go:586  [replicate,s1,r2/1:/Table/1{1-2}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.503271 25557 storage/replica_command.go:2361  [s1,r3/1:/{Table/12-Max}] initiating a split of this range at key /Table/13 [r4]
E161116 07:21:12.537163 25558 storage/queue.go:586  [replicate,s1,r3/1:/Table/1{2-3}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.557994 25557 storage/replica_command.go:2361  [s1,r4/1:/{Table/13-Max}] initiating a split of this range at key /Table/14 [r5]
E161116 07:21:12.600617 25558 storage/queue.go:586  [replicate,s1,r4/1:/Table/1{3-4}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.604631 25557 storage/split_queue.go:103  [split,s1,r5/1:/{Table/14-Max}] splitting at keys [/Table/50/0 /Table/51/0 /Table/52/0 /Table/53/0 /Table/54/0 /Table/55/0 /Table/56/0 /Table/57/0 /Table/58/0 /Table/59/0 /Table/60/0 /Table/61/0 /Table/62/0 /Table/63/0 /Table/64/0 /Table/65/0 /Table/66/0 /Table/67/0 /Table/68/0]
I161116 07:21:12.605840 25557 storage/replica_command.go:2361  [s1,r5/1:/{Table/14-Max}] initiating a split of this range at key /Table/50 [r6]
I161116 07:21:12.619783 25557 storage/replica_command.go:2361  [s1,r6/1:/{Table/50-Max}] initiating a split of this range at key /Table/51 [r7]
E161116 07:21:12.622506 25558 storage/queue.go:586  [replicate,s1,r5/1:/Table/{14-50}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.649485 25557 storage/replica_command.go:2361  [s1,r7/1:/{Table/51-Max}] initiating a split of this range at key /Table/52 [r8]
E161116 07:21:12.655174 25558 storage/queue.go:586  [replicate,s1,r6/1:/Table/5{0-1}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:12.698949 25558 storage/queue.go:586  [replicate,s1,r7/1:/Table/5{1-2}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.700374 25557 storage/replica_command.go:2361  [s1,r8/1:/{Table/52-Max}] initiating a split of this range at key /Table/53 [r9]
E161116 07:21:12.715802 25558 storage/queue.go:586  [replicate,s1,r8/1:/Table/5{2-3}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.717852 25557 storage/replica_command.go:2361  [s1,r9/1:/{Table/53-Max}] initiating a split of this range at key /Table/54 [r10]
E161116 07:21:12.732123 25558 storage/queue.go:586  [replicate,s1,r9/1:/Table/5{3-4}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.735925 25557 storage/replica_command.go:2361  [s1,r10/1:/{Table/54-Max}] initiating a split of this range at key /Table/55 [r11]
E161116 07:21:12.818250 25558 storage/queue.go:586  [replicate,s1,r10/1:/Table/5{4-5}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.819871 25557 storage/replica_command.go:2361  [s1,r11/1:/{Table/55-Max}] initiating a split of this range at key /Table/56 [r12]
E161116 07:21:12.835197 25558 storage/queue.go:586  [replicate,s1,r11/1:/Table/5{5-6}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.839289 25557 storage/replica_command.go:2361  [s1,r12/1:/{Table/56-Max}] initiating a split of this range at key /Table/57 [r13]
I161116 07:21:12.870089 25557 storage/replica_command.go:2361  [s1,r13/1:/{Table/57-Max}] initiating a split of this range at key /Table/58 [r14]
E161116 07:21:12.890403 25558 storage/queue.go:586  [replicate,s1,r12/1:/Table/5{6-7}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:12.906816 25558 storage/queue.go:586  [replicate,s1,r13/1:/Table/5{7-8}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.907189 25557 storage/replica_command.go:2361  [s1,r14/1:/{Table/58-Max}] initiating a split of this range at key /Table/59 [r15]
I161116 07:21:12.927064 25557 storage/replica_command.go:2361  [s1,r15/1:/{Table/59-Max}] initiating a split of this range at key /Table/60 [r16]
E161116 07:21:12.928169 25558 storage/queue.go:586  [replicate,s1,r14/1:/Table/5{8-9}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:12.947995 25558 storage/queue.go:586  [replicate,s1,r15/1:/Table/{59-60}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.949532 25557 storage/replica_command.go:2361  [s1,r16/1:/{Table/60-Max}] initiating a split of this range at key /Table/61 [r17]
I161116 07:21:12.965432 25557 storage/replica_command.go:2361  [s1,r17/1:/{Table/61-Max}] initiating a split of this range at key /Table/62 [r18]
E161116 07:21:12.969971 25558 storage/queue.go:586  [replicate,s1,r16/1:/Table/6{0-1}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:12.988941 25557 storage/replica_command.go:2361  [s1,r18/1:/{Table/62-Max}] initiating a split of this range at key /Table/63 [r19]
E161116 07:21:12.993555 25558 storage/queue.go:586  [replicate,s1,r17/1:/Table/6{1-2}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:13.008267 25558 storage/queue.go:586  [replicate,s1,r18/1:/Table/6{2-3}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.008826 25557 storage/replica_command.go:2361  [s1,r19/1:/{Table/63-Max}] initiating a split of this range at key /Table/64 [r20]
I161116 07:21:13.030894 25557 storage/replica_command.go:2361  [s1,r20/1:/{Table/64-Max}] initiating a split of this range at key /Table/65 [r21]
E161116 07:21:13.035546 25558 storage/queue.go:586  [replicate,s1,r19/1:/Table/6{3-4}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:13.068540 25558 storage/queue.go:586  [replicate,s1,r20/1:/Table/6{4-5}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.073312 25557 storage/replica_command.go:2361  [s1,r21/1:/{Table/65-Max}] initiating a split of this range at key /Table/66 [r22]
E161116 07:21:13.089211 25558 storage/queue.go:586  [replicate,s1,r21/1:/Table/6{5-6}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.092145 25557 storage/replica_command.go:2361  [s1,r22/1:/{Table/66-Max}] initiating a split of this range at key /Table/67 [r23]
E161116 07:21:13.111838 25558 storage/queue.go:586  [replicate,s1,r22/1:/Table/6{6-7}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.114848 25557 storage/replica_command.go:2361  [s1,r23/1:/{Table/67-Max}] initiating a split of this range at key /Table/68 [r24]
E161116 07:21:13.139016 25558 storage/queue.go:586  [replicate,s1,r23/1:/Table/6{7-8}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:13.139898 25558 storage/queue.go:586  [replicate,s1,r24/1:/{Table/68-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.156721 25557 storage/split_queue.go:103  [split,s1,r24/1:/{Table/68-Max}] splitting at keys [/Table/69/0 /Table/70/0 /Table/71/0]
I161116 07:21:13.158428 25557 storage/replica_command.go:2361  [s1,r24/1:/{Table/68-Max}] initiating a split of this range at key /Table/69 [r25]
I161116 07:21:13.205133 25557 storage/replica_command.go:2361  [s1,r25/1:/{Table/69-Max}] initiating a split of this range at key /Table/70 [r26]
E161116 07:21:13.227280 25558 storage/queue.go:586  [replicate,s1,r25/1:/Table/{69-70}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.228706 25557 storage/replica_command.go:2361  [s1,r26/1:/{Table/70-Max}] initiating a split of this range at key /Table/71 [r27]
E161116 07:21:13.256282 25558 storage/queue.go:586  [replicate,s1,r26/1:/Table/7{0-1}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:13.257079 25558 storage/queue.go:586  [replicate,s1,r27/1:/{Table/71-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.262124 25555 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreRangeSystemSplits (0.89s)
=== RUN   TestSplitSnapshotRace_SplitWins
I161116 07:21:13.328272 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.329338 25520 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:13.329438 25520 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:13.329580 25520 base/node_id.go:62  NodeID set to 1
I161116 07:21:13.341661 25520 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:13.341885 25520 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:57156" > attrs:<> locality:<> 
I161116 07:21:13.345776 25656 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:13.352905 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.353905 25520 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:57156]
W161116 07:21:13.354006 25520 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:13.354160 25520 base/node_id.go:62  NodeID set to 2
I161116 07:21:13.360213 25684 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:57156
I161116 07:21:13.360661 25520 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:13.360841 25520 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:58953" > attrs:<> locality:<> 
I161116 07:21:13.361404 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.362351 25520 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:57156]
W161116 07:21:13.362466 25520 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:13.362600 25520 base/node_id.go:62  NodeID set to 3
I161116 07:21:13.372426 25718 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:57156
I161116 07:21:13.385487 25520 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:49641" > attrs:<> locality:<> 
I161116 07:21:13.386331 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.387386 25520 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:57156]
W161116 07:21:13.387561 25520 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:13.387746 25520 base/node_id.go:62  NodeID set to 4
I161116 07:21:13.397341 25520 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:21:13.397544 25520 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:57003" > attrs:<> locality:<> 
I161116 07:21:13.399438 25894 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:57156
I161116 07:21:13.401411 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.402666 25520 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:57156]
W161116 07:21:13.402799 25520 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:13.402966 25520 base/node_id.go:62  NodeID set to 5
I161116 07:21:13.413612 25955 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:57156
I161116 07:21:13.414758 25722 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 4 ({tcp 127.0.0.1:57003})
I161116 07:21:13.416775 25520 storage/store.go:1188  [n5,s5]: failed initial metrics computation: [n5,s5]: system config not yet available
I161116 07:21:13.416957 25520 gossip/gossip.go:283  [n5] NodeDescriptor set to node_id:5 address:<network_field:"tcp" address_field:"127.0.0.1:38223" > attrs:<> locality:<> 
I161116 07:21:13.420337 25520 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:13.420512 25955 gossip/client.go:130  [n5] closing client to node 1 (127.0.0.1:57156): received forward from node 1 to 4 (127.0.0.1:57003)
I161116 07:21:13.421281 25994 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:57003
I161116 07:21:13.421405 25520 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:57156]
W161116 07:21:13.421538 25520 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:13.421697 25520 base/node_id.go:62  NodeID set to 6
I161116 07:21:13.436228 25960 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:57156
I161116 07:21:13.437862 25775 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:49641})
I161116 07:21:13.438924 25520 storage/store.go:1188  [n6,s6]: failed initial metrics computation: [n6,s6]: system config not yet available
I161116 07:21:13.439112 25520 gossip/gossip.go:283  [n6] NodeDescriptor set to node_id:6 address:<network_field:"tcp" address_field:"127.0.0.1:35824" > attrs:<> locality:<> 
I161116 07:21:13.444760 25775 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:49641})
I161116 07:21:13.445270 25960 gossip/client.go:130  [n6] closing client to node 1 (127.0.0.1:57156): received forward from node 1 to 3 (127.0.0.1:49641)
I161116 07:21:13.445521 25775 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 2 ({tcp 127.0.0.1:58953})
I161116 07:21:13.446705 25775 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 4 ({tcp 127.0.0.1:57003})
I161116 07:21:13.447208 26069 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:49641
I161116 07:21:13.456150 25520 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /System/Max [r2]
E161116 07:21:13.465688 25680 storage/queue.go:586  [replicate,s1,r1/1:/{Min-System/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:13.467134 25680 storage/queue.go:586  [replicate,s1,r2/1:/{System/Max-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:13.468533 25520 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot ba83f719 at index 11
I161116 07:21:13.472259 25520 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 30, log entries: 1
I161116 07:21:13.473646 26103 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 11 (id=ba83f719, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:21:13.474837 26103 storage/replica_raftstorage.go:590  [s2,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:13.477424 25520 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
W161116 07:21:13.481897 26060 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"\x05\x00"), but have [/Min,/System/Max)
I161116 07:21:13.486937 26105 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:13.492624 25520 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot eb8a6a95 at index 13
I161116 07:21:13.496875 26166 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:13.498773 25520 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:21:13.499661 26178 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 13 (id=eb8a6a95, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:13.500861 26178 storage/replica_raftstorage.go:590  [s3,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:13.504374 25520 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:13.521724 26179 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:13.544428 25520 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot c031a306 at index 17
I161116 07:21:13.548088 25520 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 33, log entries: 7
I161116 07:21:13.558104 25793 storage/replica_raftstorage.go:587  [s4,r2/?:{-}] applying preemptive snapshot at index 17 (id=c031a306, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:13.570289 26175 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:13.573524 25793 storage/replica_raftstorage.go:590  [s4,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.015s
I161116 07:21:13.579585 25520 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:13.599058 26157 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:21:13.625815 26192 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:13.632305 25520 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:21:13.641149 26248 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:4 StoreID:4 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
E161116 07:21:13.646772 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.646863 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.647169 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.647269 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.647533 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.647698 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.648177 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.648271 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.648537 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.648626 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.648848 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.648972 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.649187 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.649261 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.649503 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.649571 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.649770 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.649828 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.650024 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.650088 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.650273 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.650328 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.650551 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.650614 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.650810 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.650864 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.651058 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.651120 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.651309 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.651374 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.651698 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.651761 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.652075 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.652133 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.653959 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.654020 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.654387 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.654442 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.654937 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.654990 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.655748 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.655801 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.657074 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.657126 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.659462 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.659536 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.668141 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.668215 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.677834 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.677901 25520 storage/client_test.go:997  engine 5: missing key "a"
I161116 07:21:13.693302 26162 storage/store.go:2986  [s1,r2/1:/{System/Max-Max}] added to replica GC queue (peer suggestion)
E161116 07:21:13.695014 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.695098 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.729080 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.729162 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.797674 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.797755 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:13.932311 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:13.932399 25520 storage/client_test.go:997  engine 5: missing key "a"
I161116 07:21:14.060904 26367 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:14.060965 26368 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:14.062940 26320 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:14.064785 26389 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:14.071504 25746 storage/replica_proposal.go:332  [s2,r2/2:/{System/Max-Max}] new range lease replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 1.800000002s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:01.800000125 +0000 UTC]
E161116 07:21:14.201146 25520 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:14.201329 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:14.202530 25520 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:14.202630 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.202739 25520 storage/client_test.go:997  engine 4: missing key "z"
E161116 07:21:14.202794 25520 storage/client_test.go:997  engine 5: missing key "z"
I161116 07:21:14.202841 25520 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:14.206443 26319 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.206882 26370 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
W161116 07:21:14.207025 26368 storage/raft_transport.go:443  raft transport stream to node 4 failed: store 4 was not found
I161116 07:21:14.210360 26287 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.211106 26335 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.211488 26333 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.221044 26285 storage/replica_command.go:2361  [s2,r2/2:/{System/Max-Max}] initiating a split of this range at key "m" [r11]
I161116 07:21:14.273654 26337 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.274478 26469 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.276230 26467 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.277147 26451 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.278406 26483 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.278825 26401 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.284022 26427 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.284560 26473 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.284939 26429 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.296064 26474 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.296909 26457 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.297117 26457 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.297258 26457 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.297486 26455 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.308085 26479 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.308858 26461 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.309069 26461 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:14.309577 26459 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:14.365596 25520 storage/replica_raftstorage.go:443  [s2,r11/2:{"m"-/Max}] generated snapshot 09a6bca5 at index 10
I161116 07:21:14.367469 25520 storage/store.go:3134  [s2,r11/2:{"m"-/Max}] streamed snapshot: kv pairs: 29, log entries: 0
I161116 07:21:14.368301 26517 storage/replica_raftstorage.go:587  [s5,r11/?:{-}] applying preemptive snapshot at index 10 (id=09a6bca5, encoded size=16, 1 rocksdb batches, 0 log entries)
I161116 07:21:14.369156 26517 storage/replica_raftstorage.go:590  [s5,r11/?:{"m"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:21:14.371107 25520 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:14.376481 26504 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.377074 26444 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.377498 26377 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:14.379134 26518 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.379671 26507 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.380098 26379 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:14.386920 26380 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:14.397449 26446 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:14.410184 26447 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.410812 26349 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.411276 26511 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.439425 25520 storage/replica_raftstorage.go:443  [s2,r11/2:{"m"-/Max}] generated snapshot ca65ffa9 at index 15
I161116 07:21:14.442659 25520 storage/store.go:3134  [s2,r11/2:{"m"-/Max}] streamed snapshot: kv pairs: 30, log entries: 5
I161116 07:21:14.443328 26547 storage/replica_raftstorage.go:587  [s6,r11/?:{-}] applying preemptive snapshot at index 15 (id=ca65ffa9, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:14.444406 26547 storage/replica_raftstorage.go:590  [s6,r11/?:{"m"-/Max}] applied preemptive snapshot in 0.001s
I161116 07:21:14.457635 25520 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:14.463860 26494 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.464610 26562 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.465090 26496 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:14.474104 26550 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing ADD_REPLICA {NodeID:6 StoreID:6 ReplicaID:5}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:6 StoreID:6 ReplicaID:5}]
I161116 07:21:14.508490 26553 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:14.511636 26594 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.513484 26599 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.515177 26596 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.519666 25520 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:6 store_id:6 replica_id:5 > next_replica_id:6 
I161116 07:21:14.531027 26558 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:6 StoreID:6 ReplicaID:5} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:14.547886 26391 storage/store.go:2986  [s3,r11/3:{"m"-/Max}] added to replica GC queue (peer suggestion)
I161116 07:21:14.563369 25520 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:6 store_id:6 replica_id:5 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:6 
I161116 07:21:14.565779 26643 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.575684 26647 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.576131 26645 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:14.603086 26618 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:6 StoreID:6 ReplicaID:5}]
I161116 07:21:14.610644 26559 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.611342 26621 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.611787 26561 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.611906 26540 storage/store.go:2986  [s2,r11/2:{"m"-/Max}] added to replica GC queue (peer suggestion)
I161116 07:21:14.662252 26695 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.663209 26683 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.663837 26632 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.763973 26634 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.764824 26574 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.765233 26609 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.837962 26727 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.838822 26744 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
I161116 07:21:14.838867 26726 storage/raft_transport.go:437  raft transport stream to node 5 established
W161116 07:21:14.839243 26742 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
W161116 07:21:14.839397 26727 storage/raft_transport.go:443  raft transport stream to node 4 failed: store 4 was not found
I161116 07:21:14.841072 26729 storage/raft_transport.go:437  raft transport stream to node 6 established
I161116 07:21:14.842602 26759 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.844015 26748 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.844409 26761 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:14.851965 26038 storage/replica_proposal.go:332  [s6,r11/5:{"m"-/Max}] new range lease replica {6 6 5} 1970-01-01 00:00:04.500000128 +0000 UTC 1.800000002s following replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 3.600000004s [physicalTime=1970-01-01 00:00:05.400000129 +0000 UTC]
E161116 07:21:14.873226 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.873370 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.873762 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.873866 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.874077 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.874181 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.874821 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.874902 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.875067 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.875147 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.875304 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.875381 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.875549 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.875648 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.875817 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.875891 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.876048 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.876124 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.876277 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.876350 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.876502 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.876572 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.876744 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.876817 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.876972 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.877042 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.877195 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.877269 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.877449 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.877530 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.877870 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.877948 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.878235 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.878310 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.878621 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.878700 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.879025 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.879108 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.879546 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.879668 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.880466 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.880580 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.881924 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.882063 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.884838 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.884940 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.891696 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.891847 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.901408 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.901544 25520 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:14.911745 26668 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.912363 26698 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.912845 26670 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
E161116 07:21:14.921247 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.921360 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:14.955303 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:14.955414 25520 storage/client_test.go:997  engine 2: missing key "z"
W161116 07:21:14.959707 25736 raft/raft.go:794  [s2,r11/2:{"m"-/Max}] 2 stepped down to follower since quorum is not active
I161116 07:21:14.987654 26714 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.988440 26764 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:14.988891 26802 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:14.996564 26699 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:14.998346 26775 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:14.999455 26805 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:15.013582 26807 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:15.014123 26701 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:15.014580 26778 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
E161116 07:21:15.022895 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:15.023002 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:15.023079 25520 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:15.023202 25520 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:15.025868 25520 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:15.027992 25520 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:15.029844 25520 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:15.567327 26957 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:15.567481 26925 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:15.569119 26827 storage/raft_transport.go:437  raft transport stream to node 4 established
E161116 07:21:15.868971 25520 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:15.869276 25520 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:15.869348 25520 storage/client_test.go:997  engine 5: missing key "a"
I161116 07:21:16.185108 27074 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:16.188322 27079 storage/raft_transport.go:437  raft transport stream to node 6 established
E161116 07:21:16.222958 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.223051 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.223110 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.223635 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.223718 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.223779 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.224993 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.225828 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.225934 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.226450 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.226517 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.226687 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.229021 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.229088 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.229146 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.230354 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.230429 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.230490 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.234323 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.234389 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.234446 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.236171 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.236251 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.236309 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.236540 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.236615 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.236677 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.238782 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.238850 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.238907 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.242993 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.243065 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.243125 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.243309 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.243370 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.243425 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.243623 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.243683 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.243736 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.243910 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.243981 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.244036 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.244206 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.244266 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.244320 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.244865 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.244926 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.244981 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.245403 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.245480 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.245538 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.246390 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.246467 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.246526 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.247061 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.247127 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.247184 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.247896 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.247962 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.248018 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.248804 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.248884 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.248943 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.250293 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.250369 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.250434 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.253225 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.253332 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.253412 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.257940 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.258025 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.258084 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.266765 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.266840 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.266900 25520 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:16.284024 25520 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:16.284110 25520 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:16.284173 25520 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:16.285175 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.302773 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.309517 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.330129 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.331656 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.333049 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.334592 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.340133 25820 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57003->127.0.0.1:33018: use of closed network connection
I161116 07:21:16.340396 25760 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:49641->127.0.0.1:35627: use of closed network connection
W161116 07:21:16.341643 26726 storage/raft_transport.go:443  raft transport stream to node 5 failed: EOF
I161116 07:21:16.341904 25861 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken read tcp 127.0.0.1:33018->127.0.0.1:57003: read: connection reset by peer.
I161116 07:21:16.341944 25482 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:57156->127.0.0.1:57914: use of closed network connection
I161116 07:21:16.342660 25857 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:38223->127.0.0.1:46415: use of closed network connection
W161116 07:21:16.342913 26729 storage/raft_transport.go:443  raft transport stream to node 6 failed: EOF
I161116 07:21:16.343252 25715 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:58953->127.0.0.1:60328: use of closed network connection
I161116 07:21:16.344072 25897 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:16.344617 25863 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:57003: getsockopt: connection reset by peer"; Reconnecting to {"127.0.0.1:57003" <nil>}
I161116 07:21:16.344869 25899 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:38223: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:38223" <nil>}
W161116 07:21:16.345110 26446 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:16.345277 26064 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:16.345691 26957 storage/raft_transport.go:443  raft transport stream to node 3 failed: EOF
I161116 07:21:16.346567 25863 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:21:16.346657 25899 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
W161116 07:21:16.347875 26389 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:16.348148 26192 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:16.348829 26382 storage/raft_transport.go:443  raft transport stream to node 6 failed: EOF
I161116 07:21:16.349327 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.349588 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.349793 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.350002 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.350199 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:16.350424 27093 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSplitSnapshotRace_SplitWins (3.08s)
=== RUN   TestSplitSnapshotRace_SnapshotWins
I161116 07:21:16.407637 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.409549 27100 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:16.409632 27100 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:16.409766 27100 base/node_id.go:62  NodeID set to 1
I161116 07:21:16.418817 27100 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:16.419012 27100 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:37928" > attrs:<> locality:<> 
I161116 07:21:16.422002 27124 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:16.427904 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.430712 27100 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37928]
W161116 07:21:16.430799 27100 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:16.430931 27100 base/node_id.go:62  NodeID set to 2
I161116 07:21:16.435790 26910 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:37928
I161116 07:21:16.443155 27100 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:59651" > attrs:<> locality:<> 
I161116 07:21:16.443680 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.444774 27100 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37928]
W161116 07:21:16.444865 27100 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:16.445015 27100 base/node_id.go:62  NodeID set to 3
I161116 07:21:16.451141 27114 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:37928
I161116 07:21:16.462069 27100 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:52144" > attrs:<> locality:<> 
I161116 07:21:16.462762 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.463763 27100 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37928]
W161116 07:21:16.463864 27100 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:16.464011 27100 base/node_id.go:62  NodeID set to 4
I161116 07:21:16.473436 27228 gossip/client.go:125  [n4] started gossip client to 127.0.0.1:37928
I161116 07:21:16.498175 27100 storage/store.go:1188  [n4,s4]: failed initial metrics computation: [n4,s4]: system config not yet available
I161116 07:21:16.498379 27100 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:59410" > attrs:<> locality:<> 
I161116 07:21:16.499808 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.500791 27100 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37928]
W161116 07:21:16.500874 27100 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:16.501024 27100 base/node_id.go:62  NodeID set to 5
I161116 07:21:16.509456 27273 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:37928
I161116 07:21:16.510305 27276 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 4 ({tcp 127.0.0.1:59410})
I161116 07:21:16.513381 27100 storage/store.go:1188  [n5,s5]: failed initial metrics computation: [n5,s5]: system config not yet available
I161116 07:21:16.513625 27100 gossip/gossip.go:283  [n5] NodeDescriptor set to node_id:5 address:<network_field:"tcp" address_field:"127.0.0.1:37843" > attrs:<> locality:<> 
I161116 07:21:16.513859 27273 gossip/client.go:130  [n5] closing client to node 1 (127.0.0.1:37928): received forward from node 1 to 4 (127.0.0.1:59410)
I161116 07:21:16.515179 27100 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:16.516411 27100 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:37928]
W161116 07:21:16.516512 27100 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:16.516665 27100 base/node_id.go:62  NodeID set to 6
I161116 07:21:16.519889 27399 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:59410
I161116 07:21:16.523484 27168 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:37928
I161116 07:21:16.526621 27100 storage/store.go:1188  [n6,s6]: failed initial metrics computation: [n6,s6]: system config not yet available
I161116 07:21:16.526809 27100 gossip/gossip.go:283  [n6] NodeDescriptor set to node_id:6 address:<network_field:"tcp" address_field:"127.0.0.1:60730" > attrs:<> locality:<> 
I161116 07:21:16.528136 27492 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 4 ({tcp 127.0.0.1:59410})
I161116 07:21:16.529483 27492 gossip/server.go:263  [n1] refusing gossip from node 6 (max 3 conns); forwarding to 2 ({tcp 127.0.0.1:59651})
I161116 07:21:16.535965 27168 gossip/client.go:130  [n6] closing client to node 1 (127.0.0.1:37928): received forward from node 1 to 4 (127.0.0.1:59410)
I161116 07:21:16.537615 27496 gossip/client.go:125  [n6] started gossip client to 127.0.0.1:59410
I161116 07:21:16.549882 27100 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /System/Max [r2]
E161116 07:21:16.560575 27055 storage/queue.go:586  [replicate,s1,r1/1:/{Min-System/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:16.561671 27055 storage/queue.go:586  [replicate,s1,r2/1:/{System/Max-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:16.562540 27100 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot 4606f0d4 at index 11
I161116 07:21:16.565340 27573 storage/replica_raftstorage.go:587  [s2,r2/?:{-}] applying preemptive snapshot at index 11 (id=4606f0d4, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:21:16.566185 27100 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 30, log entries: 1
I161116 07:21:16.566243 27573 storage/replica_raftstorage.go:590  [s2,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:16.569627 27100 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
W161116 07:21:16.572748 27393 storage/stores.go:218  range not contained in one range: [/Meta2/Max,"\x05\x00"), but have [/Min,/System/Max)
I161116 07:21:16.577335 27605 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:16.582777 27561 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:16.592676 27100 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot 0c87bf65 at index 15
I161116 07:21:16.595605 27600 storage/replica_raftstorage.go:587  [s3,r2/?:{-}] applying preemptive snapshot at index 15 (id=0c87bf65, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:16.596594 27600 storage/replica_raftstorage.go:590  [s3,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:16.597029 27100 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 31, log entries: 5
I161116 07:21:16.600828 27100 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:16.640327 27636 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:16.655170 27100 storage/replica_raftstorage.go:443  [s1,r2/1:/{System/Max-Max}] generated snapshot bf84e6ec at index 17
I161116 07:21:16.658481 27100 storage/store.go:3134  [s1,r2/1:/{System/Max-Max}] streamed snapshot: kv pairs: 33, log entries: 7
I161116 07:21:16.660249 27651 storage/replica_raftstorage.go:587  [s4,r2/?:{-}] applying preemptive snapshot at index 17 (id=bf84e6ec, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:16.661834 27651 storage/replica_raftstorage.go:590  [s4,r2/?:/{System/Max-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:16.663133 27682 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:16.665640 27100 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:16.677038 27645 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:21:16.723393 27717 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:16.798144 27100 storage/replica_command.go:3245  [s1,r2/1:/{System/Max-Max}] change replicas: read existing descriptor range_id:2 start_key:"\005" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:21:16.823069 27625 storage/replica.go:2066  [s1,r2/1:/{System/Max-Max}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:4 StoreID:4 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
E161116 07:21:16.840344 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.840426 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.840952 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.841037 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.841263 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.841327 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.841536 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.841608 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.841819 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.841908 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.842169 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.842255 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.842534 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.842621 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.843326 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.843424 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.846070 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.846160 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.851304 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.851384 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.851640 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.851699 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.851909 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.851969 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.860850 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.860918 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.861143 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.861205 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.861401 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.861455 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.861847 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.861911 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.862284 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.862342 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.862665 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.862721 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.863101 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.863158 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.867373 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.867464 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.868379 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.868465 27100 storage/client_test.go:997  engine 5: missing key "a"
I161116 07:21:16.869766 27649 storage/store.go:2986  [s1,r2/1:/{System/Max-Max}] added to replica GC queue (peer suggestion)
E161116 07:21:16.875274 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.875363 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.877796 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.877865 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.882385 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.882475 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.891255 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.891391 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.908581 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.908686 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:16.942593 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:16.942667 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:17.010744 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:17.010824 27100 storage/client_test.go:997  engine 5: missing key "a"
I161116 07:21:17.061748 27782 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:17.062247 27783 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:17.065957 27815 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:17.069570 27818 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:17.086982 27262 storage/replica_proposal.go:381  [s3,r2/3:/{System/Max-Max}] range [n3,s3,r2/3:/{System/Max-Max}]: transferring raft leadership to replica ID 2
I161116 07:21:17.091358 27207 storage/replica_proposal.go:332  [s2,r2/2:/{System/Max-Max}] new range lease replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 1.800000002s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms [physicalTime=1970-01-01 00:00:01.800000125 +0000 UTC]
I161116 07:21:17.092825 27842 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:17.094469 27845 storage/raft_transport.go:437  raft transport stream to node 2 established
E161116 07:21:17.145334 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:17.145477 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:17.145550 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:17.145623 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:17.145725 27100 storage/client_test.go:997  engine 4: missing key "z"
E161116 07:21:17.145776 27100 storage/client_test.go:997  engine 5: missing key "z"
I161116 07:21:17.145824 27100 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:17.175806 27844 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.176769 27831 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
W161116 07:21:17.177388 27842 storage/raft_transport.go:443  raft transport stream to node 4 failed: store 4 was not found
W161116 07:21:17.177821 27844 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
I161116 07:21:17.182573 27859 storage/replica_command.go:2361  [s2,r2/2:/{System/Max-Max}] initiating a split of this range at key "m" [r11]
I161116 07:21:17.236197 27894 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.236934 27802 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.237430 27896 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.245766 27803 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.247095 27879 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.248554 27908 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.272482 27807 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.273387 27923 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.273804 27809 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.282569 27788 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.285132 27793 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.285393 27793 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.285766 27790 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.294226 27897 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.294750 27883 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.295173 27865 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.341158 27834 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.343452 27838 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.343935 27836 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.346935 27940 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.349654 27901 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:4}
W161116 07:21:17.352446 27867 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 4}: store 4 was not found
I161116 07:21:17.393577 27914 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:17.398136 27100 storage/replica_raftstorage.go:443  [s2,r11/2:{"m"-/Max}] generated snapshot bbdc6524 at index 10
I161116 07:21:17.401384 27100 storage/store.go:3134  [s2,r11/2:{"m"-/Max}] streamed snapshot: kv pairs: 29, log entries: 0
I161116 07:21:17.402278 27872 storage/replica_raftstorage.go:587  [s5,r11/?:{-}] applying preemptive snapshot at index 10 (id=bbdc6524, encoded size=16, 1 rocksdb batches, 0 log entries)
I161116 07:21:17.404883 27872 storage/replica_raftstorage.go:590  [s5,r11/?:{"m"-/Max}] applied preemptive snapshot in 0.003s
W161116 07:21:17.406300 27918 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
I161116 07:21:17.406964 27100 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
W161116 07:21:17.407075 27916 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.409362 27887 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.409878 27920 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.410273 27889 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:17.413089 27921 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.414343 28002 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.414760 27987 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:17.435186 28006 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:17.445923 27100 storage/replica_raftstorage.go:443  [s2,r11/2:{"m"-/Max}] generated snapshot b723d9ce at index 14
I161116 07:21:17.448898 28024 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:17.450954 27981 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:17.451028 27100 storage/store.go:3134  [s2,r11/2:{"m"-/Max}] streamed snapshot: kv pairs: 31, log entries: 4
W161116 07:21:17.451795 28026 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.452219 27960 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:17.453765 27992 storage/replica_raftstorage.go:587  [s6,r11/?:{-}] applying preemptive snapshot at index 14 (id=b723d9ce, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:17.455876 27992 storage/replica_raftstorage.go:590  [s6,r11/?:{"m"-/Max}] applied preemptive snapshot in 0.002s
I161116 07:21:17.460041 27100 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:17.478940 27963 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing ADD_REPLICA {NodeID:6 StoreID:6 ReplicaID:5}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:6 StoreID:6 ReplicaID:5}]
I161116 07:21:17.491575 28050 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:17.493518 28053 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.494067 27942 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.494491 28055 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.504211 27100 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:6 store_id:6 replica_id:5 > next_replica_id:6 
I161116 07:21:17.519291 28012 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:6 StoreID:6 ReplicaID:5} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:17.530442 27785 storage/store.go:2986  [s3,r11/3:{"m"-/Max}] added to replica GC queue (peer suggestion)
I161116 07:21:17.538350 27100 storage/replica_command.go:3245  [s2,r11/2:{"m"-/Max}] change replicas: read existing descriptor range_id:11 start_key:"m" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:6 store_id:6 replica_id:5 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:6 
I161116 07:21:17.545991 27997 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.547805 27948 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.548619 27999 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
I161116 07:21:17.556434 27953 storage/replica.go:2066  [s2,r11/2:{"m"-/Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:4 StoreID:4 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:6 StoreID:6 ReplicaID:5}]
I161116 07:21:17.593940 27958 storage/store.go:2986  [s2,r11/2:{"m"-/Max}] added to replica GC queue (peer suggestion)
I161116 07:21:17.594152 28098 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.594732 27935 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.595246 28100 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.693077 28093 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.694270 28075 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.694714 28095 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.794018 28194 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.794797 28017 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.795240 28180 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:17.812933 28211 storage/raft_transport.go:437  raft transport stream to node 6 established
I161116 07:21:17.813450 28212 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.813968 28151 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:5 StoreID:5 ReplicaID:4}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.814409 28120 storage/store.go:2990  [s5] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
W161116 07:21:17.814541 28212 storage/raft_transport.go:443  raft transport stream to node 4 failed: store 4 was not found
I161116 07:21:17.826985 28063 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:17.827565 28064 storage/raft_transport.go:437  raft transport stream to node 5 established
W161116 07:21:17.827692 28214 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:17.828145 28153 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
W161116 07:21:17.828277 28063 storage/raft_transport.go:443  raft transport stream to node 4 failed: store 4 was not found
I161116 07:21:17.893001 28126 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.893858 28157 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.894321 28128 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
W161116 07:21:17.942395 27183 raft/raft.go:794  [s2,r11/2:{"m"-/Max}] 2 stepped down to follower since quorum is not active
I161116 07:21:17.992951 28232 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:17.993542 28234 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:17.994010 28193 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:18.093121 28237 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:18.093849 28280 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:18.094458 28239 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:18.193020 28251 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:18.193691 28138 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:18.194129 28253 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
I161116 07:21:18.229203 28288 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:18.229801 28255 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
W161116 07:21:18.230899 28140 storage/store.go:2990  [s6] raft error: node 4 claims to not contain store 4 for replica {4 4 1}: store 4 was not found
W161116 07:21:18.230970 28255 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:6 StoreID:6 ReplicaID:5}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:1}
I161116 07:21:18.238832 27506 storage/replica_proposal.go:332  [s6,r11/5:{"m"-/Max}] new range lease replica {6 6 5} 1970-01-01 00:00:04.500000128 +0000 UTC 1.800000002s following replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 3.600000004s [physicalTime=1970-01-01 00:00:05.400000129 +0000 UTC]
I161116 07:21:18.243068 28269 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:18.243938 28306 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:0}: no handler registered for {NodeID:4 StoreID:4 ReplicaID:0}
W161116 07:21:18.244395 28271 storage/store.go:2990  [s2] raft error: node 4 claims to not contain store 4 for replica {4 4 0}: store 4 was not found
E161116 07:21:18.250969 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.251116 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.251392 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.251542 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.251842 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.251950 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.252173 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.252275 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.252481 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.252564 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.252794 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.252917 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.253143 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.253258 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.253437 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.253539 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.253746 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.253839 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.254048 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.254146 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.254386 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.254478 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.254766 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.254890 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:18.255105 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:18.255174 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:18.255232 27100 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:18.255334 27100 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:18.260504 27100 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:18.261919 27100 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:18.263438 27100 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:18.671475 27824 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:4 StoreID:4 ReplicaID:4}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:21:18.671572 27822 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:4 StoreID:4 ReplicaID:4}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:18.672013 27847 storage/store.go:2990  [s4] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
W161116 07:21:18.672055 27820 storage/store.go:2990  [s4] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:21:18.672195 27845 storage/raft_transport.go:443  raft transport stream to node 2 failed: store 2 was not found
W161116 07:21:18.672252 27818 storage/raft_transport.go:443  raft transport stream to node 3 failed: store 3 was not found
I161116 07:21:18.692385 28445 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:18.694480 28448 storage/raft_transport.go:437  raft transport stream to node 5 established
I161116 07:21:18.695725 28370 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot a3f3488a at index 32
W161116 07:21:18.697846 28453 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:18.699421 28375 storage/replica_proposal.go:332  [s5,r11/4:{"m"-/Max}] new range lease replica {5 5 4} 1970-01-01 00:00:06.30000013 +0000 UTC 1.800000002s following replica {6 6 5} 1970-01-01 00:00:04.500000128 +0000 UTC 1.800000002s [physicalTime=1970-01-01 00:00:07.200000131 +0000 UTC]
I161116 07:21:18.822831 28373 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 419a60f2 at index 37
W161116 07:21:18.824931 28468 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:18.972803 28349 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 2758239a at index 37
W161116 07:21:18.974738 28499 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.072966 28374 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 1c1ed46e at index 37
W161116 07:21:19.075019 28503 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.171996 28316 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:19.173036 28317 storage/raft_transport.go:437  raft transport stream to node 2 established
W161116 07:21:19.174301 28515 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:4 StoreID:4 ReplicaID:4}: no handler registered for {NodeID:2 StoreID:2 ReplicaID:2}
W161116 07:21:19.174936 28517 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:4 StoreID:4 ReplicaID:4}: no handler registered for {NodeID:3 StoreID:3 ReplicaID:3}
W161116 07:21:19.175355 28319 storage/store.go:2990  [s4] raft error: node 3 claims to not contain store 3 for replica {3 3 3}: store 3 was not found
W161116 07:21:19.175667 28321 storage/store.go:2990  [s4] raft error: node 2 claims to not contain store 2 for replica {2 2 2}: store 2 was not found
I161116 07:21:19.175998 28375 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 0635397a at index 37
W161116 07:21:19.177642 28459 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.218428 28352 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 32d24964 at index 37
W161116 07:21:19.222959 28513 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range [n4,s4,r2/4:/{System/Max-Max}]
E161116 07:21:19.229009 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:19.229091 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:19.229149 27100 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:19.323726 28347 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 1387e0d2 at index 38
W161116 07:21:19.330231 28481 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.472682 28371 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot ecc80b64 at index 38
W161116 07:21:19.476202 28521 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.571940 28609 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:19.572790 28348 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 7f7e32cb at index 38
I161116 07:21:19.572879 28642 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:19.574763 28649 storage/raft_transport.go:437  raft transport stream to node 4 established
W161116 07:21:19.576360 28658 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.678126 28351 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot e9f2816d at index 38
W161116 07:21:19.683079 28300 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.722711 28377 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 0b1636f8 at index 38
W161116 07:21:19.726422 28305 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.872921 28352 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 889d43b7 at index 38
W161116 07:21:19.876672 28657 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.925423 28373 storage/replica_raftstorage.go:443  [s5,r11/4:{"m"-/Max}] generated snapshot 2094ad56 at index 38
W161116 07:21:19.927915 28617 storage/replica.go:2843  [s5,r11/4:{"m"-/Max}] failed to send snapshot: range=11: remote couldn't accept snapshot with error: [n4,s4],r11: cannot apply snapshot: snapshot intersects existing range; initiated GC: [n4,s4,r2/4:/{System/Max-Max}]
I161116 07:21:19.972272 28574 storage/replica_proposal.go:381  [s3,r2/3:{/System/Max-"m"}] range [n3,s3,r2/3:{/System/Max-"m"}]: transferring raft leadership to replica ID 2
I161116 07:21:19.972825 28174 storage/replica_proposal.go:332  [s4,r2/4:{/System/Max-"m"}] new range lease replica {4 4 4} 1970-01-01 00:00:04.500000128 +0000 UTC 3.600000004s following replica {2 2 2} 1970-01-01 00:00:00.900000124 +0000 UTC 3.600000004s [physicalTime=1970-01-01 00:00:09.000000133 +0000 UTC]
I161116 07:21:19.978411 28535 storage/replica_proposal.go:332  [s2,r2/2:{/System/Max-"m"}] new range lease replica {2 2 2} 1970-01-01 00:00:08.100000132 +0000 UTC 1.800000002s following replica {4 4 4} 1970-01-01 00:00:04.500000128 +0000 UTC 3.600000004s [physicalTime=1970-01-01 00:00:09.000000133 +0000 UTC]
E161116 07:21:20.007870 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.008016 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.008072 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.009920 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.010102 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.010177 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.010316 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.010453 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.010508 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.010641 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.010758 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.010817 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.010961 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.011072 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.011121 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.011246 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.011357 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.011406 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.011553 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.011681 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.011737 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.011875 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.012024 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.012088 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.012219 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.012343 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.012395 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.012517 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.012665 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.012719 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.012852 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.012966 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.013050 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.013169 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.013269 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.013320 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.013442 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.013556 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.013637 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.013758 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.013865 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.013918 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.014054 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.014190 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.014244 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.015707 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.015893 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.015957 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.016275 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.016406 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.016465 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.016856 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.016981 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.017037 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.017391 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.017565 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.017649 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.019530 27100 storage/client_test.go:997  engine 0: missing key "a"
E161116 07:21:20.019679 27100 storage/client_test.go:997  engine 4: missing key "a"
E161116 07:21:20.019738 27100 storage/client_test.go:997  engine 5: missing key "a"
E161116 07:21:20.069375 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.069478 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.069620 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.073955 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.074076 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.074179 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.080341 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.080464 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.080555 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.082181 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.082302 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.082398 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.083157 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.083243 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.083349 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.083614 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.083726 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.083824 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.084033 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.084095 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.084164 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.085001 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.085086 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.085154 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.085377 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.085480 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.085566 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.085837 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.085906 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.085962 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.086172 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.086242 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.086301 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.086520 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.086580 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.086636 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.087210 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.087281 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.087337 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.087538 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.087614 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.087669 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.087843 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.087898 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.087950 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.088150 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.088205 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.088257 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.088546 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.088640 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.088697 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.088989 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.089047 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.089098 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.089580 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.089674 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.089737 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.090275 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.090344 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.090399 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.091221 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.091325 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.091385 27100 storage/client_test.go:997  engine 2: missing key "z"
E161116 07:21:20.092705 27100 storage/client_test.go:997  engine 0: missing key "z"
E161116 07:21:20.092784 27100 storage/client_test.go:997  engine 1: missing key "z"
E161116 07:21:20.092841 27100 storage/client_test.go:997  engine 2: missing key "z"
I161116 07:21:20.094439 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.096099 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.097701 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.099888 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.107754 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.130038 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.131786 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:20.135664 28050 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
W161116 07:21:20.137854 28023 storage/raft_transport.go:443  raft transport stream to node 5 failed: EOF
W161116 07:21:20.138947 27682 storage/raft_transport.go:443  raft transport stream to node 1 failed: EOF
W161116 07:21:20.140593 28448 storage/raft_transport.go:443  raft transport stream to node 5 failed: EOF
W161116 07:21:20.140993 28064 storage/raft_transport.go:443  raft transport stream to node 5 failed: EOF
W161116 07:21:20.144787 28211 storage/raft_transport.go:443  raft transport stream to node 6 failed: EOF
I161116 07:21:20.145121 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.145301 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.145570 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.145848 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.146075 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.146283 28665 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestSplitSnapshotRace_SnapshotWins (3.75s)
=== RUN   TestStoreSplitTimestampCacheReadRace
I161116 07:21:20.153322 28695 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:20.154516 28695 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:20.154595 28695 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:20.154724 28695 base/node_id.go:62  NodeID set to 1
I161116 07:21:20.154865 28695 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:20.162284 28695 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:20.166968 28702 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m21.062567539s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:20.166767686 +0000 UTC]
I161116 07:21:20.176070 28695 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
E161116 07:21:20.187782 28741 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:20.205106 28695 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSplitTimestampCacheReadRace (0.06s)
=== RUN   TestStoreSplitTimestampCacheDifferentLeaseHolder
I161116 07:21:20.222996 28749 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:20.223089 28749 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:20.257065 28749 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:20.258933 28749 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:20.259846 28749 server/config.go:443  1 storage engine initialized
I161116 07:21:20.261364 28749 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:20.281222 28784 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m29.277507268s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:20.281100693 +0000 UTC]
I161116 07:21:20.284725 28749 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:20.285545 28749 server/node.go:350  [n?] **** cluster 66177bcf-993c-42bf-a1b1-522161f8ae8a has been created
I161116 07:21:20.285594 28749 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:34040
I161116 07:21:20.286611 28749 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:20.308990 28749 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:20.309102 28749 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:20.309211 28749 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:20.309376 28749 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:34040" > attrs:<> locality:<> 
I161116 07:21:20.310003 28749 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:20.310165 28749 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:20.310663 28749 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "66177bcf-993c-42bf-a1b1-522161f8ae8a"
I161116 07:21:20.311060 28749 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:20.317243 28749 server/server.go:630  [n1] starting https server at 127.0.0.1:51880
I161116 07:21:20.317305 28749 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:34040
I161116 07:21:20.317347 28749 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:34040
I161116 07:21:20.368949 28749 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:34040]
W161116 07:21:20.369082 28749 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:20.394404 28841 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:34040} Attrs: Locality:} ClusterID:66177bcf-993c-42bf-a1b1-522161f8ae8a StartedAt:1479280880310696631}
W161116 07:21:20.420384 28749 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:20.423018 28749 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:20.423909 28749 server/config.go:443  1 storage engine initialized
I161116 07:21:20.429039 28749 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:20.429110 28749 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:20.429183 28749 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:20.497000 28898 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:34040
I161116 07:21:20.498480 28867 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:20.501727 28933 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:20.502234 28749 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "66177bcf-993c-42bf-a1b1-522161f8ae8a"
I161116 07:21:20.508416 28749 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:20.548984 28749 server/node.go:312  [n?] new node allocated ID 2
I161116 07:21:20.549131 28749 base/node_id.go:62  [n2] NodeID set to 2
I161116 07:21:20.549290 28749 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:40831" > attrs:<> locality:<> 
I161116 07:21:20.550050 28749 server/node.go:369  [n2] node=2: started with [[]=] engine(s) and attributes []
I161116 07:21:20.554606 28749 server/server.go:630  [n2] starting https server at 127.0.0.1:60094
I161116 07:21:20.554659 28749 server/server.go:631  [n2] starting grpc/postgres server at 127.0.0.1:40831
I161116 07:21:20.554696 28749 server/server.go:632  [n2] advertising CockroachDB node at 127.0.0.1:40831
I161116 07:21:20.646730 28955 storage/stores.go:312  [n1] wrote 1 node addresses to persistent storage
I161116 07:21:20.705750 28939 server/node.go:545  [n2] bootstrapped store [n2,s2]
I161116 07:21:20.731152 28942 sql/event_log.go:95  [n2] Event: "node_join", target: 2, info: {Descriptor:{NodeID:2 Address:{NetworkField:tcp AddressField:127.0.0.1:40831} Attrs: Locality:} ClusterID:66177bcf-993c-42bf-a1b1-522161f8ae8a StartedAt:1479280880549711009}
I161116 07:21:20.741182 28749 storage/replica_command.go:2361  [n1,s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
I161116 07:21:20.798105 28749 storage/replica_command.go:2361  [n1,s1,r2/1:{"a"-/Max}] initiating a split of this range at key "c" [r3]
I161116 07:21:20.945087 28749 storage/replica_raftstorage.go:443  [n1,s1,r2/1:"{a"-c"}] generated snapshot 3238724e at index 16
I161116 07:21:21.083959 28749 storage/store.go:3134  [n1,s1,r2/1:"{a"-c"}] streamed snapshot: kv pairs: 10, log entries: 6
I161116 07:21:21.084907 29006 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 16 (id=3238724e, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:21:21.085949 29006 storage/replica_raftstorage.go:590  [n2,s2,r2/?:"{a"-c"}] applied preemptive snapshot in 0.001s
I161116 07:21:21.088223 28749 storage/replica_command.go:3245  [n1,s1,r2/1:"{a"-c"}] change replicas: read existing descriptor range_id:2 start_key:"a" end_key:"c" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:21.151510 28749 storage/replica.go:2066  [n1,s1,r2/1:"{a"-c"}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:21.172708 28368 storage/raft_transport.go:437  [n2] raft transport stream to node 1 established
I161116 07:21:21.221651 28749 storage/client_split_test.go:1280  blacklisting replica {NodeID:1 StoreID:1 ReplicaID:1} for leases
I161116 07:21:21.221796 28749 storage/client_split_test.go:1295  splitting at "b"
I161116 07:21:21.237101 28749 storage/replica_command.go:2361  [n1,s1,r2/1:"{a"-c"}] initiating a split of this range at key "b" [r4]
I161116 07:21:21.388078 28749 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.388605 29043 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
1      kv/txn_coord_sender.go:918
W161116 07:21:21.389402 28990 kv/txn_coord_sender.go:707  [n1] node unavailable; try another peer
W161116 07:21:21.390032 28368 storage/raft_transport.go:443  [n2] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:21.390875 28926 storage/raft_transport.go:443  [n1] raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:21.391383 29043 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
I161116 07:21:21.391952 29043 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:21.392684 28811 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:{/Min-"a"}] node unavailable; try another peer
I161116 07:21:21.392801 28749 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.414153 28673 kv/transport_race.go:71  transport race promotion: ran 35 iterations on up to 214 requests
I161116 07:21:21.459432 28749 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestStoreSplitTimestampCacheDifferentLeaseHolder (1.25s)
=== RUN   TestStoreRangeSplitRaceUninitializedRHS
--- SKIP: TestStoreRangeSplitRaceUninitializedRHS (0.02s)
	client_split_test.go:1336: #10172
=== RUN   TestLeaderAfterSplit
I161116 07:21:21.488623 29008 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:21.489672 29008 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:21.489759 29008 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:21.489893 29008 base/node_id.go:62  NodeID set to 1
I161116 07:21:21.499127 29008 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:21.499310 29008 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:54353" > attrs:<> locality:<> 
I161116 07:21:21.501932 29075 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 83h20m0.000000124s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:21.522848 29008 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:21.524099 29008 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:54353]
W161116 07:21:21.524213 29008 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:21.524391 29008 base/node_id.go:62  NodeID set to 2
I161116 07:21:21.559253 29008 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:21.559448 29008 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:58954" > attrs:<> locality:<> 
I161116 07:21:21.560328 29008 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:21.561383 29008 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:54353]
W161116 07:21:21.561474 29008 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:21.561615 29008 base/node_id.go:62  NodeID set to 3
I161116 07:21:21.568442 29008 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:21.568633 29008 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:53022" > attrs:<> locality:<> 
I161116 07:21:21.573739 29156 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:54353
I161116 07:21:21.573915 29071 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:54353
I161116 07:21:21.586090 29008 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 7820b3d7 at index 13
I161116 07:21:21.587996 29008 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 32, log entries: 3
I161116 07:21:21.588829 29163 storage/replica_raftstorage.go:587  [s2,r1/?:{-}] applying preemptive snapshot at index 13 (id=7820b3d7, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:21.589763 29163 storage/replica_raftstorage.go:590  [s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:21.591698 29008 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:21.597288 29172 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:21.611607 29008 storage/replica_raftstorage.go:443  [s1,r1/1:/M{in-ax}] generated snapshot 934e5cc5 at index 15
I161116 07:21:21.613381 29008 storage/store.go:3134  [s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 35, log entries: 5
I161116 07:21:21.614102 29130 storage/replica_raftstorage.go:587  [s3,r1/?:{-}] applying preemptive snapshot at index 15 (id=934e5cc5, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:21.615130 29130 storage/replica_raftstorage.go:590  [s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.001s
I161116 07:21:21.617230 29008 storage/replica_command.go:3245  [s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:21.621305 29181 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:21.635740 29286 storage/replica.go:2066  [s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:21.768352 29288 storage/raft_transport.go:437  raft transport stream to node 1 established
I161116 07:21:21.794044 29304 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "m" [r2]
I161116 07:21:21.832293 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:21.833579 29282 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:2 StoreID:2 ReplicaID:2}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:21:21.834098 29183 storage/store.go:2990  [s2] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:21:21.834248 29181 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:21:21.834291 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:21.834431 29303 storage/raft_transport.go:258  unable to accept Raft message from {NodeID:3 StoreID:3 ReplicaID:3}: no handler registered for {NodeID:1 StoreID:1 ReplicaID:1}
W161116 07:21:21.834907 29290 storage/store.go:2990  [s3] raft error: node 1 claims to not contain store 1 for replica {1 1 1}: store 1 was not found
W161116 07:21:21.835071 29288 storage/raft_transport.go:443  raft transport stream to node 1 failed: store 1 was not found
I161116 07:21:21.836435 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.843414 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.852150 28961 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:53022->127.0.0.1:37081: use of closed network connection
W161116 07:21:21.852548 29298 storage/raft_transport.go:443  raft transport stream to node 3 failed: EOF
I161116 07:21:21.853055 29068 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:58954->127.0.0.1:55501: use of closed network connection
I161116 07:21:21.854150 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.858028 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:21.858243 29242 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestLeaderAfterSplit (0.39s)
=== RUN   TestStoreSplitBeginTxnPushMetaIntentRace
I161116 07:21:21.882891 29314 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:21.897304 29314 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:21.897392 29314 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:21.897522 29314 base/node_id.go:62  NodeID set to 1
I161116 07:21:21.897655 29314 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:21:21.949592 29314 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:21.950926 29321 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 01:00:00.000000124 +0000 UTC]
I161116 07:21:22.020287 29314 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /System/"" [r2]
E161116 07:21:22.034942 29347 storage/queue.go:586  [replicate,s1,r1/1:/{Min-System/""}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.038113 29365 storage/replica_command.go:2361  [s1,r2/1:/{System/""-Max}] initiating a split of this range at key "a" [r3]
I161116 07:21:22.039977 29328 storage/replica_command.go:87  [s1,r2/1:/{System/""-Max}] test injecting error: node unavailable; try another peer
E161116 07:21:22.102618 29347 storage/queue.go:586  [replicate,s1,r2/1:{/System/""-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.127966 29314 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.128083 29314 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/intent_resolver.go:383
W161116 07:21:22.128748 29351 storage/intent_resolver.go:380  could not GC completed transaction anchored at /Local/Range/"\x04"/RangeDescriptor: node unavailable; try another peer
--- PASS: TestStoreSplitBeginTxnPushMetaIntentRace (0.28s)
=== RUN   TestComputeStatsForKeySpan
I161116 07:21:22.160888 29246 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.161965 29246 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:22.162060 29246 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:22.162199 29246 base/node_id.go:62  NodeID set to 1
I161116 07:21:22.175858 29246 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:22.176026 29400 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:22.176085 29246 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:51190" > attrs:<> locality:<> 
I161116 07:21:22.184395 29246 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.185454 29246 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51190]
W161116 07:21:22.185557 29246 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:22.185701 29246 base/node_id.go:62  NodeID set to 2
I161116 07:21:22.196111 29501 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:51190
I161116 07:21:22.196683 29246 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:22.196883 29246 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:34499" > attrs:<> locality:<> 
I161116 07:21:22.197569 29246 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.198717 29246 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:51190]
W161116 07:21:22.201422 29246 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:22.201579 29246 base/node_id.go:62  NodeID set to 3
I161116 07:21:22.214057 29246 storage/store.go:1188  [n3,s3]: failed initial metrics computation: [n3,s3]: system config not yet available
I161116 07:21:22.214257 29246 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:39319" > attrs:<> locality:<> 
I161116 07:21:22.220097 29277 gossip/client.go:125  [n3] started gossip client to 127.0.0.1:51190
I161116 07:21:22.245020 29246 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "a" [r2]
E161116 07:21:22.254716 29442 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"a"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:22.255354 29442 storage/queue.go:586  [replicate,s1,r2/1:{"a"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.257273 29246 storage/replica_command.go:2361  [s1,r2/1:{"a"-/Max}] initiating a split of this range at key "c" [r3]
W161116 07:21:22.260720 29570 storage/stores.go:218  range not contained in one range: [/Meta2/"c","c\x00"), but have [/Min,"a")
W161116 07:21:22.273791 29551 storage/intent_resolver.go:314  [n1,s1,r1/1:{/Min-"a"}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=68687386 key=/Local/Range/"a"/RangeDescriptor rw=true pri=0.02224166 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,96 orig=0.000000123,96 max=0.000000123,96 wto=false rop=false
E161116 07:21:22.275318 29442 storage/queue.go:586  [replicate,s1,r3/1:{"c"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.283370 29246 storage/replica_command.go:2361  [s1,r3/1:{"c"-/Max}] initiating a split of this range at key "e" [r4]
E161116 07:21:22.300038 29442 storage/queue.go:586  [replicate,s1,r4/1:{"e"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.303947 29246 storage/replica_command.go:2361  [s1,r4/1:{"e"-/Max}] initiating a split of this range at key "g" [r5]
I161116 07:21:22.322960 29246 storage/replica_command.go:2361  [s1,r5/1:{"g"-/Max}] initiating a split of this range at key "i" [r6]
E161116 07:21:22.346638 29442 storage/queue.go:586  [replicate,s1,r5/1:"{g"-i"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:22.348603 29442 storage/queue.go:586  [replicate,s1,r6/1:{"i"-/Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:22.353227 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.354878 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.356446 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.357951 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.360150 29515 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:39319->127.0.0.1:40181: use of closed network connection
I161116 07:21:22.360587 29232 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:51190->127.0.0.1:36059: read: connection reset by peer
I161116 07:21:22.360760 29460 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34499->127.0.0.1:43913: use of closed network connection
I161116 07:21:22.364178 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.364495 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.364685 29624 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestComputeStatsForKeySpan (0.21s)
=== RUN   TestSortRangeDescByAge
--- PASS: TestSortRangeDescByAge (0.02s)
=== RUN   TestGossipFirstRange
I161116 07:21:22.406590 29575 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:22.406698 29575 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:22.462809 29575 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:22.464564 29575 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.465356 29575 server/config.go:443  1 storage engine initialized
I161116 07:21:22.466405 29575 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:22.473606 29672 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m31.471732284s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:22.473477144 +0000 UTC]
I161116 07:21:22.476781 29575 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:22.477598 29575 server/node.go:350  [n?] **** cluster 09d11b58-63e6-482c-91d9-c01fd6051984 has been created
I161116 07:21:22.477648 29575 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:35667
I161116 07:21:22.478730 29575 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:22.482428 29575 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:22.482510 29575 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:22.482615 29575 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:22.482768 29575 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:35667" > attrs:<> locality:<> 
I161116 07:21:22.483378 29575 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:22.483513 29575 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:22.505228 29575 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "09d11b58-63e6-482c-91d9-c01fd6051984"
I161116 07:21:22.505573 29575 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:22.506231 29575 server/server.go:630  [n1] starting https server at 127.0.0.1:36757
I161116 07:21:22.519410 29575 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:35667
I161116 07:21:22.519481 29575 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:35667
I161116 07:21:22.546958 29713 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:35667} Attrs: Locality:} ClusterID:09d11b58-63e6-482c-91d9-c01fd6051984 StartedAt:1479280882505269759}
I161116 07:21:22.561282 29575 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:35667]
W161116 07:21:22.561388 29575 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
W161116 07:21:22.644350 29575 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:22.646073 29575 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.646817 29575 server/config.go:443  1 storage engine initialized
I161116 07:21:22.654844 29575 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:22.654921 29575 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:22.654999 29575 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:22.741924 29617 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:35667
I161116 07:21:22.744516 29779 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:22.746537 29575 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "09d11b58-63e6-482c-91d9-c01fd6051984"
I161116 07:21:22.746726 29768 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:22.753173 29575 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:22.773639 29575 server/node.go:312  [n?] new node allocated ID 2
I161116 07:21:22.773781 29575 base/node_id.go:62  [n2] NodeID set to 2
I161116 07:21:22.773943 29575 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:47821" > attrs:<> locality:<> 
I161116 07:21:22.774592 29575 server/node.go:369  [n2] node=2: started with [[]=] engine(s) and attributes []
I161116 07:21:22.775162 29575 server/server.go:630  [n2] starting https server at 127.0.0.1:59350
I161116 07:21:22.775232 29575 server/server.go:631  [n2] starting grpc/postgres server at 127.0.0.1:47821
I161116 07:21:22.775272 29575 server/server.go:632  [n2] advertising CockroachDB node at 127.0.0.1:47821
I161116 07:21:22.777885 29313 storage/stores.go:312  [n1] wrote 1 node addresses to persistent storage
I161116 07:21:22.847895 29575 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:35667]
W161116 07:21:22.848001 29575 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:22.853118 29786 server/node.go:545  [n2] bootstrapped store [n2,s2]
I161116 07:21:22.855600 29789 sql/event_log.go:95  [n2] Event: "node_join", target: 2, info: {Descriptor:{NodeID:2 Address:{NetworkField:tcp AddressField:127.0.0.1:47821} Attrs: Locality:} ClusterID:09d11b58-63e6-482c-91d9-c01fd6051984 StartedAt:1479280882774312490}
W161116 07:21:22.867513 29575 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:22.869089 29575 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:22.869885 29575 server/config.go:443  1 storage engine initialized
I161116 07:21:22.870948 29575 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:22.871018 29575 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:22.871104 29575 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:23.062509 29724 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:35667
I161116 07:21:23.062871 29801 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:23.065445 29575 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "09d11b58-63e6-482c-91d9-c01fd6051984"
I161116 07:21:23.066144 29820 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:23.066955 29821 storage/stores.go:312  [n?] wrote 2 node addresses to persistent storage
I161116 07:21:23.082833 29575 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:23.085789 29575 server/node.go:312  [n?] new node allocated ID 3
I161116 07:21:23.085923 29575 base/node_id.go:62  [n3] NodeID set to 3
I161116 07:21:23.086091 29575 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:38691" > attrs:<> locality:<> 
I161116 07:21:23.086751 29575 server/node.go:369  [n3] node=3: started with [[]=] engine(s) and attributes []
I161116 07:21:23.087375 29575 server/server.go:630  [n3] starting https server at 127.0.0.1:47437
I161116 07:21:23.087415 29575 server/server.go:631  [n3] starting grpc/postgres server at 127.0.0.1:38691
I161116 07:21:23.087450 29575 server/server.go:632  [n3] advertising CockroachDB node at 127.0.0.1:38691
I161116 07:21:23.091431 29866 storage/stores.go:312  [n1] wrote 2 node addresses to persistent storage
I161116 07:21:23.092564 29909 storage/stores.go:312  [n2] wrote 2 node addresses to persistent storage
I161116 07:21:23.124218 29942 sql/event_log.go:95  [n3] Event: "node_join", target: 3, info: {Descriptor:{NodeID:3 Address:{NetworkField:tcp AddressField:127.0.0.1:38691} Attrs: Locality:} ClusterID:09d11b58-63e6-482c-91d9-c01fd6051984 StartedAt:1479280883086452031}
I161116 07:21:23.193858 29939 server/node.go:545  [n3] bootstrapped store [n3,s3]
I161116 07:21:23.198469 29575 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot 62918887 at index 102
I161116 07:21:23.352480 29575 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 593, log entries: 92
I161116 07:21:23.354001 29985 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 102 (id=62918887, encoded size=16, 1 rocksdb batches, 92 log entries)
I161116 07:21:23.365786 29985 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/M{in-ax}] applied preemptive snapshot in 0.012s
I161116 07:21:23.369129 29575 storage/replica_command.go:3245  [n1,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:23.406116 29575 storage/replica.go:2066  [n1,s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:23.413877 29575 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot d1d69f65 at index 155
I161116 07:21:23.414494 30070 storage/raft_transport.go:437  [n2] raft transport stream to node 1 established
I161116 07:21:23.555444 29575 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 790, log entries: 145
I161116 07:21:23.573591 30083 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 155 (id=d1d69f65, encoded size=16, 1 rocksdb batches, 145 log entries)
I161116 07:21:23.631501 30083 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/M{in-ax}] applied preemptive snapshot in 0.058s
I161116 07:21:23.634028 29575 storage/replica_command.go:3245  [n1,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:23.672158 29575 storage/replica.go:2066  [n1,s1,r1/1:/M{in-ax}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:23.689313 30086 storage/raft_transport.go:437  [n3] raft transport stream to node 1 established
I161116 07:21:23.696984 29658 storage/replica_proposal.go:381  [n1,s1,r1/1:/M{in-ax}] range [n1,s1,r1/1:/M{in-ax}]: transferring raft leadership to replica ID 2
I161116 07:21:23.697859 29833 storage/replica_proposal.go:332  [n2,s2,r1/2:/M{in-ax}] new range lease replica {2 2 2} 2016-11-16 07:21:23.683835472 +0000 UTC 9.25s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m31.733666502s [physicalTime=2016-11-16 07:21:23.697732559 +0000 UTC]
I161116 07:21:23.697938 29658 storage/replica_raftstorage.go:443  [n1,s1,r1/1:/M{in-ax}] generated snapshot 9d541387 at index 181
I161116 07:21:23.712551 29575 storage/replica_command.go:3245  [n1,s1,r1/1:/M{in-ax}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:23.713316 30058 storage/store.go:3134  [n1,s1,r1/1:/M{in-ax}] streamed snapshot: kv pairs: 798, log entries: 25
I161116 07:21:23.714004 30048 storage/replica_raftstorage.go:587  [n3,s3,r1/?:/M{in-ax}] applying Raft snapshot at index 181 (id=9d541387, encoded size=16, 1 rocksdb batches, 25 log entries)
I161116 07:21:23.776101 30099 storage/raft_transport.go:437  [n2] raft transport stream to node 3 established
I161116 07:21:23.788956 30048 storage/replica_raftstorage.go:590  [n3,s3,r1/3:/M{in-ax}] applied Raft snapshot in 0.075s
I161116 07:21:23.794854 29930 storage/replica.go:2066  [n2,s2,r1/2:/M{in-ax}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:3 StoreID:3 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:23.803324 30053 storage/store.go:2986  [n1,s1,r1/1:/M{in-ax}] added to replica GC queue (peer suggestion)
I161116 07:21:23.805981 29575 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:23.806773 30065 util/stop/stopper.go:468  quiescing; tasks left:
1      server/node.go:854
I161116 07:21:23.807087 30064 util/stop/stopper.go:468  quiescing; tasks left:
2      storage/queue.go:477
W161116 07:21:23.807296 30040 storage/raft_transport.go:443  [n1] raft transport stream to node 3 failed: EOF
W161116 07:21:23.807602 30133 storage/replica.go:1810  [n2,s2,r1/2:/M{in-ax}] shutdown cancellation of command DeleteRange [/System/tsd/insufficient bytes to decode uvarint value,/System/tsd/cr.node.sql.mon.internal.txn.max-p99.9//10s/2016-10-17T07:00:00Z)
W161116 07:21:23.807750 30099 storage/raft_transport.go:443  [n2] raft transport stream to node 3 failed: EOF
W161116 07:21:23.808000 30149 storage/raft_transport.go:443  [n3] raft transport stream to node 2 failed: context canceled
E161116 07:21:23.809830 29714 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:/M{in-ax}] result is ambiguous
W161116 07:21:23.809955 30086 storage/raft_transport.go:443  [n3] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:23.810113 30064 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
W161116 07:21:23.812052 30051 storage/raft_transport.go:443  [n1] raft transport stream to node 2 failed: EOF
I161116 07:21:23.818555 29575 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:23.819148 29293 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:35667->127.0.0.1:53650: use of closed network connection
I161116 07:21:23.819319 29692 kv/transport_race.go:71  transport race promotion: ran 59 iterations on up to 225 requests
I161116 07:21:23.825800 29575 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:23.826339 29896 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:23.827034 29798 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:47821: getsockopt: connection refused"; Reconnecting to {"127.0.0.1:47821" <nil>}
I161116 07:21:23.828324 29798 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: context canceled
I161116 07:21:23.830724 29575 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:23.851931 30121 /go/src/google.golang.org/grpc/server.go:369  grpc: Server.Serve failed to complete security handshake from "127.0.0.1:54639": EOF
--- PASS: TestGossipFirstRange (1.51s)
=== RUN   TestLogSplits
I161116 07:21:23.915794 30104 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:23.915902 30104 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:23.945788 30104 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:23.953131 30104 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:23.953914 30104 server/config.go:443  1 storage engine initialized
I161116 07:21:23.955042 30104 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:23.995013 30205 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m32.990568425s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:23.994888176 +0000 UTC]
I161116 07:21:23.999460 30104 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:24.000332 30104 server/node.go:350  [n?] **** cluster 607adacb-d57a-4368-b8a3-387623b3f1b6 has been created
I161116 07:21:24.000375 30104 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:59183
I161116 07:21:24.001402 30104 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:24.005437 30104 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:24.005517 30104 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:24.005625 30104 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:24.005772 30104 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:59183" > attrs:<> locality:<> 
I161116 07:21:24.006324 30104 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:24.006440 30104 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:24.008090 30104 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "607adacb-d57a-4368-b8a3-387623b3f1b6"
I161116 07:21:24.008450 30104 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:24.009128 30104 server/server.go:630  [n1] starting https server at 127.0.0.1:55196
I161116 07:21:24.009186 30104 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:59183
I161116 07:21:24.009217 30104 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:59183
I161116 07:21:24.014510 30184 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:24.024454 30184 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:21:24.049542 30192 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:59183} Attrs: Locality:} ClusterID:607adacb-d57a-4368-b8a3-387623b3f1b6 StartedAt:1479280884008121739}
I161116 07:21:24.103393 30184 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
I161116 07:21:24.144031 30184 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
I161116 07:21:24.239666 30184 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
I161116 07:21:24.415904 30104 storage/replica_command.go:2361  [n1,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key "splitkey" [r6]
I161116 07:21:24.543485 30104 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:24.543612 30104 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:24.544360 30188 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:{/Min-"splitkey"}] node unavailable; try another peer
I161116 07:21:24.544702 30161 kv/transport_race.go:71  transport race promotion: ran 27 iterations on up to 162 requests
--- PASS: TestLogSplits (0.66s)
=== RUN   TestLogRebalances
I161116 07:21:24.568395 30282 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:24.568499 30282 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:24.615228 30282 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:24.616945 30282 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:24.618317 30282 server/config.go:443  1 storage engine initialized
I161116 07:21:24.619399 30282 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:24.627564 30303 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m33.625567084s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:24.627424648 +0000 UTC]
I161116 07:21:24.630749 30282 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:24.631670 30282 server/node.go:350  [n?] **** cluster a9a7faea-7c25-4c46-ba9d-4e862a624333 has been created
I161116 07:21:24.631716 30282 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:38588
I161116 07:21:24.632714 30282 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:24.636190 30282 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:24.643152 30282 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:24.643206 30370 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:24.643808 30282 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:24.643980 30282 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:38588" > attrs:<> locality:<> 
I161116 07:21:24.644310 30282 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:24.644557 30282 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:24.644640 30282 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "a9a7faea-7c25-4c46-ba9d-4e862a624333"
I161116 07:21:24.644966 30282 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:24.654353 30282 server/server.go:630  [n1] starting https server at 127.0.0.1:33362
I161116 07:21:24.659772 30282 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:38588
I161116 07:21:24.659842 30282 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:38588
I161116 07:21:24.662283 30363 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:38588} Attrs: Locality:} ClusterID:a9a7faea-7c25-4c46-ba9d-4e862a624333 StartedAt:1479280884644670453}
I161116 07:21:24.706938 30370 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:21:24.796773 30370 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
I161116 07:21:24.919355 30370 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
I161116 07:21:25.001300 30370 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
I161116 07:21:25.662750 30282 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.662875 30282 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
I161116 07:21:25.663974 30282 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
E161116 07:21:25.664725 30374 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:/{Min-Table/11}] node unavailable; try another peer
I161116 07:21:25.689030 29935 kv/transport_race.go:71  transport race promotion: ran 17 iterations on up to 313 requests
--- PASS: TestLogRebalances (1.14s)
=== RUN   TestNodeLiveness
--- SKIP: TestNodeLiveness (0.00s)
	node_liveness_test.go:62: #9973
=== RUN   TestNodeLivenessEpochIncrement
I161116 07:21:25.698076 30325 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:25.700232 30325 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:25.700329 30325 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:25.700463 30325 base/node_id.go:62  NodeID set to 1
I161116 07:21:25.714504 30325 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:25.714712 30325 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:60261" > attrs:<> locality:<> 
I161116 07:21:25.716283 30470 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:25.718840 30325 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:25.726291 30325 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:60261]
W161116 07:21:25.726395 30325 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:25.726536 30325 base/node_id.go:62  NodeID set to 2
I161116 07:21:25.746942 30325 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:25.747138 30325 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:33862" > attrs:<> locality:<> 
I161116 07:21:25.749652 30530 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:60261
I161116 07:21:25.837504 30384 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.838989 30384 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.841567 30384 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.843487 30437 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:60261->127.0.0.1:52934: use of closed network connection
I161116 07:21:25.844171 30384 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.844385 30384 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestNodeLivenessEpochIncrement (0.15s)
=== RUN   TestNodeLivenessRestart
I161116 07:21:25.860082 30509 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:25.861373 30509 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:25.861464 30509 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:25.861600 30509 base/node_id.go:62  NodeID set to 1
I161116 07:21:25.873202 30509 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:25.873400 30509 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:59412" > attrs:<> locality:<> 
I161116 07:21:25.876478 30602 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:25.880852 30509 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:25.881901 30509 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:59412]
W161116 07:21:25.881988 30509 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:25.882128 30509 base/node_id.go:62  NodeID set to 2
I161116 07:21:25.890817 30585 gossip/client.go:125  [n2] started gossip client to 127.0.0.1:59412
I161116 07:21:25.898431 30509 storage/store.go:1188  [n2,s2]: failed initial metrics computation: [n2,s2]: system config not yet available
I161116 07:21:25.898632 30509 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:43529" > attrs:<> locality:<> 
I161116 07:21:25.975278 30509 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:25.999878 30772 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.012063 30772 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.013524 30772 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.014277 30656 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
I161116 07:21:26.014354 30582 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:43529->127.0.0.1:60409: use of closed network connection
I161116 07:21:26.014848 30658 /go/src/google.golang.org/grpc/clientconn.go:667  grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial tcp 127.0.0.1:43529: context canceled"; Reconnecting to {"127.0.0.1:43529" <nil>}
I161116 07:21:26.015484 30658 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I161116 07:21:26.015546 30511 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:59412->127.0.0.1:38086: use of closed network connection
I161116 07:21:26.015890 30772 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.016157 30772 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestNodeLivenessRestart (0.17s)
=== RUN   TestNodeLivenessSelf
I161116 07:21:26.030575 30760 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:26.034832 30760 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:26.034917 30760 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:26.035053 30760 base/node_id.go:62  NodeID set to 1
I161116 07:21:26.047900 30814 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:21:26.076458 30760 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:34170" > attrs:<> locality:<> 
I161116 07:21:26.084065 30782 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
E161116 07:21:26.085686 30840 storage/node_liveness.go:141  [hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:21:26.085855 30782 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.086503 30782 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.100197 30776 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:34170->127.0.0.1:42410: use of closed network connection
--- PASS: TestNodeLivenessSelf (0.16s)
=== RUN   TestSendAndReceive
I161116 07:21:26.184444 30636 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:26.184558 30636 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:26.184691 30636 base/node_id.go:62  NodeID set to 1
I161116 07:21:26.279147 30866 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:26.279316 30868 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:26.280020 30867 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:26.294691 30855 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:26.295193 30785 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:26.295305 30784 storage/raft_transport.go:437  raft transport stream to node 4 established
I161116 07:21:26.302310 30869 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:26.303053 30871 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:26.303854 30870 storage/raft_transport.go:437  raft transport stream to node 3 established
I161116 07:21:26.902932 30636 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:26.903929 30702 http2_client.go:1053  transport: http2Client.notifyError got notified that the client transport was broken EOF.
W161116 07:21:26.904044 30871 storage/raft_transport.go:443  raft transport stream to node 3 failed: EOF
W161116 07:21:26.904167 30855 storage/raft_transport.go:443  raft transport stream to node 4 failed: EOF
I161116 07:21:26.904363 30875 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:37757->127.0.0.1:56517: use of closed network connection
I161116 07:21:26.905567 30704 /go/src/google.golang.org/grpc/clientconn.go:767  grpc: addrConn.transportMonitor exits due to: connection error: desc = "transport: context canceled"
W161116 07:21:26.905800 30785 storage/raft_transport.go:443  raft transport stream to node 4 failed: rpc error: code = 13 desc = transport is closing
W161116 07:21:26.905948 30866 storage/raft_transport.go:443  raft transport stream to node 2 failed: EOF
I161116 07:21:26.907775 30911 /go/src/google.golang.org/grpc/server.go:369  grpc: Server.Serve failed to complete security handshake from "127.0.0.1:56540": EOF
--- PASS: TestSendAndReceive (0.73s)
=== RUN   TestInOrderDelivery
I161116 07:21:26.930662 30912 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:26.930768 30912 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:26.930901 30912 base/node_id.go:62  NodeID set to 1
I161116 07:21:27.018463 30936 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:27.572982 30912 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:27.574004 30860 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:60919->127.0.0.1:50658: use of closed network connection
--- PASS: TestInOrderDelivery (0.74s)
=== RUN   TestRaftTransportCircuitBreaker
I161116 07:21:27.654585 30962 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:27.654689 30962 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:27.654856 30962 base/node_id.go:62  NodeID set to 1
W161116 07:21:27.656469 30969 storage/raft_transport.go:443  raft transport stream to node 2 failed: unable to look up descriptor for node 2
I161116 07:21:27.741036 30952 storage/raft_transport.go:437  raft transport stream to node 2 established
I161116 07:21:27.814220 30962 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
W161116 07:21:27.814777 30952 storage/raft_transport.go:443  raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
I161116 07:21:27.815561 30893 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:36042->127.0.0.1:36576: use of closed network connection
--- PASS: TestRaftTransportCircuitBreaker (0.25s)
=== RUN   TestRaftTransportIndependentRanges
I161116 07:21:27.924936 30941 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:27.925053 30941 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:21:27.925194 30941 base/node_id.go:62  NodeID set to 1
I161116 07:21:27.980553 30997 storage/raft_transport.go:437  raft transport stream to node 1 established
W161116 07:21:27.999943 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.012310 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.017770 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.034385 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.041169 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.058100 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.068352 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.077510 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.085569 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.095436 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.098991 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.107023 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.114937 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.121210 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.127487 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.139048 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.145972 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.162331 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.167483 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.173631 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.176572 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.183917 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.194838 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.203256 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.214948 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.221033 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.237554 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.252384 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.255709 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.268415 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.275829 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.285397 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.301802 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.317958 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.326034 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.331462 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.340599 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.345093 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.349637 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.356030 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.361613 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.378946 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.395969 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.410320 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.424941 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.426709 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.434963 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.451323 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
W161116 07:21:28.458543 31010 storage/raft_transport.go:478  no handler found for store 2 in response range_id:13 from_replica:<node_id:1 store_id:1 replica_id:1 > to_replica:<node_id:2 store_id:2 replica_id:2 > union:<error:<message:"storage/raft_transport_test.go:72: channelServer broken range" transaction_restart:NONE origin_node:0 now:<wall_time:0 logical:0 > > > 
I161116 07:21:28.465090 30941 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:28.465429 30865 http2_server.go:276  transport: http2Server.HandleStreams failed to read frame: read tcp 127.0.0.1:54720->127.0.0.1:50653: use of closed network connection
W161116 07:21:28.466104 30997 storage/raft_transport.go:443  raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
--- PASS: TestRaftTransportIndependentRanges (0.58s)
=== RUN   TestReplicateQueueRebalance
I161116 07:21:28.545026 30998 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:21:28.545171 30998 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:21:28.584354 30998 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:28.586801 30998 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:28.603240 30998 server/config.go:443  1 storage engine initialized
I161116 07:21:28.605596 30998 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:28.617120 31035 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m37.615237037s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:21:28.616993098 +0000 UTC]
I161116 07:21:28.620162 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:21:28.640121 30998 server/node.go:350  [n?] **** cluster c465f36c-cb1b-4ef5-bcd4-f7707120232a has been created
I161116 07:21:28.640181 30998 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:49136
I161116 07:21:28.641240 30998 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:21:28.644767 30998 storage/store.go:1188  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:21:28.644864 30998 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:21:28.644973 30998 server/node.go:319  [n1] node ID 1 initialized
I161116 07:21:28.645167 30998 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:49136" > attrs:<> locality:<> 
I161116 07:21:28.646762 30998 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:21:28.655695 30998 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:21:28.655789 30998 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "c465f36c-cb1b-4ef5-bcd4-f7707120232a"
I161116 07:21:28.656120 30998 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:21:28.656762 30998 server/server.go:630  [n1] starting https server at 127.0.0.1:33802
I161116 07:21:28.656802 30998 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:49136
I161116 07:21:28.656835 30998 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:49136
I161116 07:21:28.668539 31106 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:21:28.728946 31106 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:21:28.745113 31057 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:49136} Attrs: Locality:} ClusterID:c465f36c-cb1b-4ef5-bcd4-f7707120232a StartedAt:1479280888655812458}
E161116 07:21:28.915375 31107 storage/queue.go:586  [n1,replicate,s1,r1/1:/{Min-Table/11}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:28.916276 30734 storage/queue.go:586  [n1,replicate,s1,r1/1:/{Min-Table/11}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:28.917344 31106 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
E161116 07:21:29.305331 31107 storage/queue.go:586  [n1,replicate,s1,r2/1:/Table/1{1-2}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:29.307000 31106 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
E161116 07:21:29.467167 31107 storage/queue.go:586  [n1,replicate,s1,r3/1:/Table/1{2-3}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:29.478185 31106 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
E161116 07:21:29.565140 31107 storage/queue.go:586  [n1,replicate,s1,r4/1:/Table/1{3-4}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E161116 07:21:29.567305 31107 storage/queue.go:586  [n1,replicate,s1,r5/1:/{Table/14-Max}] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I161116 07:21:29.660074 30998 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49136]
W161116 07:21:29.660187 30998 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
W161116 07:21:29.689643 30998 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:29.731604 30998 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:29.735538 30998 server/config.go:443  1 storage engine initialized
I161116 07:21:29.739524 30998 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:29.739744 30998 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:29.739828 30998 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:29.779609 31081 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:49136
I161116 07:21:29.780577 30928 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:29.782249 30998 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "c465f36c-cb1b-4ef5-bcd4-f7707120232a"
I161116 07:21:29.783197 31159 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:29.787018 30998 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:29.790093 30998 server/node.go:312  [n?] new node allocated ID 2
I161116 07:21:29.790208 30998 base/node_id.go:62  [n2] NodeID set to 2
I161116 07:21:29.790368 30998 gossip/gossip.go:283  [n2] NodeDescriptor set to node_id:2 address:<network_field:"tcp" address_field:"127.0.0.1:36681" > attrs:<> locality:<> 
I161116 07:21:29.791061 30998 server/node.go:369  [n2] node=2: started with [[]=] engine(s) and attributes []
I161116 07:21:29.791695 30998 server/server.go:630  [n2] starting https server at 127.0.0.1:46775
I161116 07:21:29.791745 30998 server/server.go:631  [n2] starting grpc/postgres server at 127.0.0.1:36681
I161116 07:21:29.791780 30998 server/server.go:632  [n2] advertising CockroachDB node at 127.0.0.1:36681
I161116 07:21:29.794215 31163 storage/stores.go:312  [n1] wrote 1 node addresses to persistent storage
I161116 07:21:29.964770 31153 server/node.go:545  [n2] bootstrapped store [n2,s2]
I161116 07:21:29.997284 30734 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot b9811561 at index 52
I161116 07:21:30.001616 30998 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49136]
W161116 07:21:30.023210 30998 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:30.027556 31172 sql/event_log.go:95  [n2] Event: "node_join", target: 2, info: {Descriptor:{NodeID:2 Address:{NetworkField:tcp AddressField:127.0.0.1:36681} Attrs: Locality:} ClusterID:c465f36c-cb1b-4ef5-bcd4-f7707120232a StartedAt:1479280889790747042}
W161116 07:21:30.193065 30998 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:30.195274 30998 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:30.205771 30998 server/config.go:443  1 storage engine initialized
I161116 07:21:30.207939 30998 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:30.208012 30998 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:30.208090 30998 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:30.213924 30734 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 587, log entries: 42
I161116 07:21:30.225658 30737 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 52 (id=b9811561, encoded size=16, 1 rocksdb batches, 42 log entries)
I161116 07:21:30.262651 30737 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.037s
I161116 07:21:30.266933 30734 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:30.396491 30734 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:30.421191 31217 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:49136
I161116 07:21:30.421841 31285 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:30.424851 30998 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "c465f36c-cb1b-4ef5-bcd4-f7707120232a"
I161116 07:21:30.426385 31324 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:30.426563 31324 storage/stores.go:312  [n?] wrote 2 node addresses to persistent storage
I161116 07:21:30.433052 30734 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 73e08a10 at index 30
I161116 07:21:30.433874 30998 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:30.435538 30734 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 10, log entries: 20
I161116 07:21:30.436966 31274 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 30 (id=73e08a10, encoded size=16, 1 rocksdb batches, 20 log entries)
I161116 07:21:30.438546 31274 storage/replica_raftstorage.go:590  [n2,s2,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.001s
I161116 07:21:30.440770 30734 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:30.478312 31312 storage/raft_transport.go:437  [n2] raft transport stream to node 1 established
I161116 07:21:30.493870 30998 server/node.go:312  [n?] new node allocated ID 3
I161116 07:21:30.494030 30998 base/node_id.go:62  [n3] NodeID set to 3
I161116 07:21:30.494185 30998 gossip/gossip.go:283  [n3] NodeDescriptor set to node_id:3 address:<network_field:"tcp" address_field:"127.0.0.1:41957" > attrs:<> locality:<> 
I161116 07:21:30.495003 30998 server/node.go:369  [n3] node=3: started with [[]=] engine(s) and attributes []
I161116 07:21:30.495653 30998 server/server.go:630  [n3] starting https server at 127.0.0.1:34000
I161116 07:21:30.495692 30998 server/server.go:631  [n3] starting grpc/postgres server at 127.0.0.1:41957
I161116 07:21:30.495722 30998 server/server.go:632  [n3] advertising CockroachDB node at 127.0.0.1:41957
I161116 07:21:30.500780 30734 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:30.514047 31336 storage/stores.go:312  [n1] wrote 2 node addresses to persistent storage
I161116 07:21:30.514630 30734 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 82d7aca8 at index 19
I161116 07:21:30.525079 31337 storage/stores.go:312  [n2] wrote 2 node addresses to persistent storage
I161116 07:21:30.544736 31340 storage/replica_raftstorage.go:587  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 19 (id=82d7aca8, encoded size=16, 1 rocksdb batches, 9 log entries)
I161116 07:21:30.591684 30734 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 20, log entries: 9
I161116 07:21:30.646039 31340 storage/replica_raftstorage.go:590  [n2,s2,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.054s
I161116 07:21:30.651788 30734 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:30.652127 31395 server/node.go:545  [n3] bootstrapped store [n3,s3]
I161116 07:21:30.791859 31398 sql/event_log.go:95  [n3] Event: "node_join", target: 3, info: {Descriptor:{NodeID:3 Address:{NetworkField:tcp AddressField:127.0.0.1:41957} Attrs: Locality:} ClusterID:c465f36c-cb1b-4ef5-bcd4-f7707120232a StartedAt:1479280890494673417}
I161116 07:21:30.796945 30734 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:30.818347 30998 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49136]
W161116 07:21:30.818466 30998 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
I161116 07:21:30.848185 30734 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 69474ba6 at index 22
W161116 07:21:30.962706 30998 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:30.994110 30998 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:31.020373 30998 server/config.go:443  1 storage engine initialized
I161116 07:21:31.021455 30998 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:31.022376 30998 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:31.022464 30998 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:31.140620 30734 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 49, log entries: 12
I161116 07:21:31.141904 31508 storage/replica_raftstorage.go:587  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 22 (id=69474ba6, encoded size=16, 1 rocksdb batches, 12 log entries)
I161116 07:21:31.143227 31508 storage/replica_raftstorage.go:590  [n3,s3,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.001s
I161116 07:21:31.145452 30734 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:31.313037 31511 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:31.313434 31368 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:49136
I161116 07:21:31.339570 30998 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "c465f36c-cb1b-4ef5-bcd4-f7707120232a"
I161116 07:21:31.339961 31536 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:31.340155 31536 storage/stores.go:312  [n?] wrote 2 node addresses to persistent storage
I161116 07:21:31.340311 31536 storage/stores.go:312  [n?] wrote 3 node addresses to persistent storage
I161116 07:21:31.348427 30998 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:31.374291 30734 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2}]
I161116 07:21:31.430707 30734 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/{Table/14-Max}] generated snapshot 55292b27 at index 11
I161116 07:21:31.444661 30998 server/node.go:312  [n?] new node allocated ID 4
I161116 07:21:31.444876 30998 base/node_id.go:62  [n4] NodeID set to 4
I161116 07:21:31.445049 30998 gossip/gossip.go:283  [n4] NodeDescriptor set to node_id:4 address:<network_field:"tcp" address_field:"127.0.0.1:34313" > attrs:<> locality:<> 
I161116 07:21:31.445713 30998 server/node.go:369  [n4] node=4: started with [[]=] engine(s) and attributes []
I161116 07:21:31.446342 30998 server/server.go:630  [n4] starting https server at 127.0.0.1:55426
I161116 07:21:31.446385 30998 server/server.go:631  [n4] starting grpc/postgres server at 127.0.0.1:34313
I161116 07:21:31.446422 30998 server/server.go:632  [n4] advertising CockroachDB node at 127.0.0.1:34313
I161116 07:21:31.461614 31369 storage/stores.go:312  [n1] wrote 3 node addresses to persistent storage
I161116 07:21:31.476982 30734 storage/store.go:3134  [n1,replicate,s1,r5/1:/{Table/14-Max}] streamed snapshot: kv pairs: 9, log entries: 1
I161116 07:21:31.481708 31580 storage/stores.go:312  [n2] wrote 3 node addresses to persistent storage
I161116 07:21:31.502437 31478 storage/stores.go:312  [n3] wrote 3 node addresses to persistent storage
I161116 07:21:31.502942 31584 storage/raft_transport.go:437  [n3] raft transport stream to node 1 established
I161116 07:21:31.532307 31546 storage/replica_raftstorage.go:587  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 11 (id=55292b27, encoded size=16, 1 rocksdb batches, 1 log entries)
I161116 07:21:31.535736 31546 storage/replica_raftstorage.go:590  [n2,s2,r5/?:/{Table/14-Max}] applied preemptive snapshot in 0.003s
I161116 07:21:31.545427 30734 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/{Table/14-Max}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > next_replica_id:2 
I161116 07:21:31.575667 30998 gossip/gossip.go:241  [n?] initial resolvers: [127.0.0.1:49136]
W161116 07:21:31.575807 30998 gossip/gossip.go:1119  [n?] no incoming or outgoing connections
W161116 07:21:31.656189 30998 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:21:31.739687 30998 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:21:31.740455 30998 server/config.go:443  1 storage engine initialized
I161116 07:21:31.741484 30998 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:21:31.741562 30998 storage/stores.go:296  [n?] read 0 node addresses from persistent storage
I161116 07:21:31.741654 30998 server/node.go:564  [n?] connecting to gossip network to verify cluster ID...
I161116 07:21:31.742572 31437 server/node.go:545  [n4] bootstrapped store [n4,s4]
I161116 07:21:31.808068 31440 sql/event_log.go:95  [n4] Event: "node_join", target: 4, info: {Descriptor:{NodeID:4 Address:{NetworkField:tcp AddressField:127.0.0.1:34313} Attrs: Locality:} ClusterID:c465f36c-cb1b-4ef5-bcd4-f7707120232a StartedAt:1479280891445420945}
I161116 07:21:31.828458 30734 storage/replica.go:2066  [n1,s1,r5/1:/{Table/14-Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2}]
I161116 07:21:31.859946 30734 storage/queue.go:638  [n1,replicate] purgatory is now empty
I161116 07:21:31.865242 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot ffda3263 at index 134
I161116 07:21:31.893749 31617 gossip/client.go:125  [n?] started gossip client to 127.0.0.1:49136
I161116 07:21:31.990502 31662 gossip/server.go:285  [n1] received gossip from unknown node
I161116 07:21:32.030093 31700 storage/stores.go:312  [n?] wrote 1 node addresses to persistent storage
I161116 07:21:32.030511 31700 storage/stores.go:312  [n?] wrote 2 node addresses to persistent storage
I161116 07:21:32.030689 31700 storage/stores.go:312  [n?] wrote 3 node addresses to persistent storage
I161116 07:21:32.031123 31700 storage/stores.go:312  [n?] wrote 4 node addresses to persistent storage
I161116 07:21:32.041605 30998 server/node.go:584  [n?] node connected via gossip and verified as part of cluster "c465f36c-cb1b-4ef5-bcd4-f7707120232a"
I161116 07:21:32.053683 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 983, log entries: 20
I161116 07:21:32.056492 31595 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 134 (id=ffda3263, encoded size=16, 1 rocksdb batches, 20 log entries)
I161116 07:21:32.060274 31595 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.003s
I161116 07:21:32.071360 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:32.072578 30998 kv/dist_sender.go:331  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping
I161116 07:21:32.129761 30998 server/node.go:312  [n?] new node allocated ID 5
I161116 07:21:32.129938 30998 base/node_id.go:62  [n5] NodeID set to 5
I161116 07:21:32.130100 30998 gossip/gossip.go:283  [n5] NodeDescriptor set to node_id:5 address:<network_field:"tcp" address_field:"127.0.0.1:45008" > attrs:<> locality:<> 
I161116 07:21:32.130699 30998 server/node.go:369  [n5] node=5: started with [[]=] engine(s) and attributes []
I161116 07:21:32.131338 30998 server/server.go:630  [n5] starting https server at 127.0.0.1:59813
I161116 07:21:32.131375 30998 server/server.go:631  [n5] starting grpc/postgres server at 127.0.0.1:45008
I161116 07:21:32.131404 30998 server/server.go:632  [n5] advertising CockroachDB node at 127.0.0.1:45008
I161116 07:21:32.138759 31662 gossip/server.go:263  [n1] refusing gossip from node 5 (max 3 conns); forwarding to 3 ({tcp 127.0.0.1:41957})
I161116 07:21:32.139686 31775 storage/stores.go:312  [n1] wrote 4 node addresses to persistent storage
I161116 07:21:32.140992 31617 gossip/client.go:130  [n5] closing client to node 1 (127.0.0.1:49136): received forward from node 1 to 3 (127.0.0.1:41957)
I161116 07:21:32.150928 31710 storage/stores.go:312  [n4] wrote 4 node addresses to persistent storage
I161116 07:21:32.155327 31725 storage/stores.go:312  [n3] wrote 4 node addresses to persistent storage
I161116 07:21:32.233802 31726 storage/stores.go:312  [n2] wrote 4 node addresses to persistent storage
I161116 07:21:32.258369 31664 server/node.go:545  [n5] bootstrapped store [n5,s5]
I161116 07:21:32.333507 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:32.391489 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:32.436573 31763 sql/event_log.go:95  [n5] Event: "node_join", target: 5, info: {Descriptor:{NodeID:5 Address:{NetworkField:tcp AddressField:127.0.0.1:45008} Attrs: Locality:} ClusterID:c465f36c-cb1b-4ef5-bcd4-f7707120232a StartedAt:1479280892130447858}
I161116 07:21:32.482854 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:32.521701 31776 gossip/client.go:125  [n5] started gossip client to 127.0.0.1:41957
I161116 07:21:32.537563 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/{Table/14-Max}] generated snapshot 19595478 at index 14
I161116 07:21:32.905343 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/{Table/14-Max}] streamed snapshot: kv pairs: 10, log entries: 4
I161116 07:21:32.906053 31695 storage/replica_raftstorage.go:587  [n4,s4,r5/?:{-}] applying preemptive snapshot at index 14 (id=19595478, encoded size=16, 1 rocksdb batches, 4 log entries)
I161116 07:21:32.907070 31695 storage/replica_raftstorage.go:590  [n4,s4,r5/?:/{Table/14-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:32.909877 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/{Table/14-Max}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:32.941489 31107 storage/replica.go:2066  [n1,s1,r5/1:/{Table/14-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:32.980437 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 8c8d6561 at index 28
I161116 07:21:32.999456 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 36, log entries: 18
I161116 07:21:33.000577 31916 storage/replica_raftstorage.go:587  [n4,s4,r3/?:{-}] applying preemptive snapshot at index 28 (id=8c8d6561, encoded size=16, 1 rocksdb batches, 18 log entries)
I161116 07:21:33.002161 31916 storage/replica_raftstorage.go:590  [n4,s4,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.001s
I161116 07:21:33.018837 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:33.034139 31761 storage/raft_transport.go:437  [n4] raft transport stream to node 1 established
I161116 07:21:33.116518 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:33.185601 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot d71ae541 at index 34
I161116 07:21:33.189396 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 11, log entries: 24
I161116 07:21:33.207419 31920 storage/replica_raftstorage.go:587  [n4,s4,r2/?:{-}] applying preemptive snapshot at index 34 (id=d71ae541, encoded size=16, 1 rocksdb batches, 24 log entries)
I161116 07:21:33.213497 31920 storage/replica_raftstorage.go:590  [n4,s4,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.006s
I161116 07:21:33.220785 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > next_replica_id:3 
I161116 07:21:33.324100 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:33.331652 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot a14f1ca6 at index 37
I161116 07:21:33.349102 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 85, log entries: 27
I161116 07:21:33.353560 31851 storage/replica_raftstorage.go:587  [n4,s4,r4/?:{-}] applying preemptive snapshot at index 37 (id=a14f1ca6, encoded size=16, 1 rocksdb batches, 27 log entries)
I161116 07:21:33.359433 31851 storage/replica_raftstorage.go:590  [n4,s4,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.006s
I161116 07:21:33.361600 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > next_replica_id:3 
I161116 07:21:33.509997 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:33.713098 30998 storage/replica_command.go:2361  [n1,s1,r5/1:/{Table/14-Max}] initiating a split of this range at key /Table/50 [r6]
I161116 07:21:33.913559 30998 storage/replica_command.go:2361  [n1,s1,r6/1:/{Table/50-Max}] initiating a split of this range at key /Table/51 [r7]
I161116 07:21:34.122244 30998 storage/replica_command.go:2361  [n1,s1,r7/1:/{Table/51-Max}] initiating a split of this range at key /Table/52 [r8]
I161116 07:21:34.383808 30998 storage/replica_command.go:2361  [n1,s1,r8/1:/{Table/52-Max}] initiating a split of this range at key /Table/53 [r9]
I161116 07:21:34.637308 30998 storage/replica_command.go:2361  [n1,s1,r9/1:/{Table/53-Max}] initiating a split of this range at key /Table/54 [r10]
I161116 07:21:34.829148 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.839586 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.840847 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.842420 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.846258 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.847107 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.847282 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.847389 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.847493 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.847950 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.849501 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.849643 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.849873 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.850080 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.850212 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.850435 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.850661 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.850897 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.851310 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.851747 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.852503 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.854031 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.856337 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.860713 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.872855 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.896440 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 2 9 0]
I161116 07:21:34.899863 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r8/1:/Table/5{2-3}] generated snapshot fe600262 at index 16
I161116 07:21:34.910892 31107 storage/store.go:3134  [n1,replicate,s1,r8/1:/Table/5{2-3}] streamed snapshot: kv pairs: 10, log entries: 6
I161116 07:21:34.919695 32058 storage/replica_raftstorage.go:587  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 16 (id=fe600262, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:21:34.920975 32058 storage/replica_raftstorage.go:590  [n3,s3,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.001s
I161116 07:21:34.933433 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 3 9 0]
I161116 07:21:34.936693 31107 storage/replica_command.go:3245  [n1,replicate,s1,r8/1:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:34.996841 31107 storage/replica.go:2066  [n1,s1,r8/1:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:35.003223 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 3 9 0]
I161116 07:21:35.027129 31107 storage/replica_command.go:3245  [n1,replicate,s1,r8/1:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:35.124876 31107 storage/replica.go:2066  [n1,s1,r8/1:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:35.137754 30998 storage/replicate_queue_test.go:98  not balanced: [10 9 3 9 0]
I161116 07:21:35.171292 31378 storage/store.go:2986  [n2,s2,r8/2:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:35.172901 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r7/1:/Table/5{1-2}] generated snapshot 286f7b31 at index 17
I161116 07:21:35.205716 31107 storage/store.go:3134  [n1,replicate,s1,r7/1:/Table/5{1-2}] streamed snapshot: kv pairs: 10, log entries: 7
I161116 07:21:35.208228 32030 storage/replica_raftstorage.go:587  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 17 (id=286f7b31, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:35.224789 32030 storage/replica_raftstorage.go:590  [n3,s3,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.016s
I161116 07:21:35.228009 31107 storage/replica_command.go:3245  [n1,replicate,s1,r7/1:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:35.312288 31107 storage/replica.go:2066  [n1,s1,r7/1:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:35.326323 31107 storage/replica_command.go:3245  [n1,replicate,s1,r7/1:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:35.408265 30998 storage/replicate_queue_test.go:98  not balanced: [10 8 4 9 0]
I161116 07:21:35.474795 31107 storage/replica.go:2066  [n1,s1,r7/1:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:35.505529 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot dcbc7aa0 at index 350
I161116 07:21:35.506634 31378 storage/store.go:2986  [n2,s2,r7/2:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:35.558053 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1207, log entries: 18
I161116 07:21:35.564323 32033 storage/replica_raftstorage.go:587  [n4,s4,r1/?:{-}] applying preemptive snapshot at index 350 (id=dcbc7aa0, encoded size=16, 1 rocksdb batches, 18 log entries)
I161116 07:21:35.567392 32033 storage/replica_raftstorage.go:590  [n4,s4,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.003s
I161116 07:21:35.570190 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:4 
I161116 07:21:35.621657 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:4 StoreID:4 ReplicaID:4}]
I161116 07:21:35.657560 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:4 store_id:4 replica_id:4 > next_replica_id:5 
I161116 07:21:35.794096 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:35.848530 31378 storage/store.go:2986  [n2,s2,r1/2:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:35.889410 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 75354093 at index 37
I161116 07:21:35.991742 30998 storage/replicate_queue_test.go:98  not balanced: [10 6 4 10 0]
I161116 07:21:36.060095 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 12, log entries: 27
I161116 07:21:36.069098 32261 storage/replica_raftstorage.go:587  [n5,s5,r2/?:{-}] applying preemptive snapshot at index 37 (id=75354093, encoded size=16, 1 rocksdb batches, 27 log entries)
I161116 07:21:36.073652 32261 storage/replica_raftstorage.go:590  [n5,s5,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.004s
I161116 07:21:36.076115 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:36.111459 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:36.129763 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:36.143914 32268 storage/raft_transport.go:437  [n5] raft transport stream to node 1 established
I161116 07:21:36.299087 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:36.325896 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 99f6d8a0 at index 31
I161116 07:21:36.334476 31378 storage/store.go:2986  [n2,s2,r2/2:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:36.342826 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 37, log entries: 21
I161116 07:21:36.345939 32235 storage/replica_raftstorage.go:587  [n5,s5,r3/?:{-}] applying preemptive snapshot at index 31 (id=99f6d8a0, encoded size=16, 1 rocksdb batches, 21 log entries)
I161116 07:21:36.363363 32235 storage/replica_raftstorage.go:590  [n5,s5,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.017s
I161116 07:21:36.388711 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:36.447781 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:36.471066 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:36.569310 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:36.584085 31378 storage/store.go:2986  [n2,s2,r3/2:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:36.604582 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 486c69ee at index 17
I161116 07:21:36.616635 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 11, log entries: 7
I161116 07:21:36.619324 32253 storage/replica_raftstorage.go:587  [n5,s5,r9/?:{-}] applying preemptive snapshot at index 17 (id=486c69ee, encoded size=16, 1 rocksdb batches, 7 log entries)
I161116 07:21:36.630090 32253 storage/replica_raftstorage.go:590  [n5,s5,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.011s
I161116 07:21:36.635637 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:36.721415 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:36.739803 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:36.879453 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
W161116 07:21:36.916366 32170 storage/intent_resolver.go:314  [n4,s4,r1/4:/{Min-Table/11}]: failed to push during intent resolution: failed to push "change-replica" id=0773a3cd key=/Local/Range/"\xbd"/RangeDescriptor rw=true pri=0.01189122 iso=SERIALIZABLE stat=PENDING epo=0 ts=1479280896.735061867,0 orig=1479280896.735061867,0 max=1479280896.735061867,0 wto=false rop=false
I161116 07:21:36.920120 31378 storage/store.go:2986  [n2,s2,r9/2:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:36.943870 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot f4b70aed at index 23
I161116 07:21:36.970724 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 12, log entries: 13
I161116 07:21:36.972529 32301 storage/replica_raftstorage.go:587  [n5,s5,r5/?:{-}] applying preemptive snapshot at index 23 (id=f4b70aed, encoded size=16, 1 rocksdb batches, 13 log entries)
I161116 07:21:36.983535 32301 storage/replica_raftstorage.go:590  [n5,s5,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.001s
I161116 07:21:36.996352 30998 storage/replicate_queue_test.go:98  not balanced: [10 4 4 10 4]
I161116 07:21:37.007087 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:37.082623 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:37.099827 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:37.230747 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:37.253452 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot ac783daa at index 39
I161116 07:21:37.263050 31378 storage/store.go:2986  [n2,s2,r5/2:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:37.268222 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 39, log entries: 29
I161116 07:21:37.273113 32256 storage/replica_raftstorage.go:587  [n3,s3,r3/?:{-}] applying preemptive snapshot at index 39 (id=ac783daa, encoded size=16, 1 rocksdb batches, 29 log entries)
I161116 07:21:37.275735 32256 storage/replica_raftstorage.go:590  [n3,s3,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.003s
I161116 07:21:37.288427 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:37.348541 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:37.359967 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:37.475856 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:37.517770 31939 storage/store.go:2986  [n4,s4,r3/3:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:37.533166 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 4fb3e545 at index 16
I161116 07:21:37.543788 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 10, log entries: 6
I161116 07:21:37.616474 32372 storage/replica_raftstorage.go:587  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 16 (id=4fb3e545, encoded size=16, 1 rocksdb batches, 6 log entries)
I161116 07:21:37.646714 32372 storage/replica_raftstorage.go:590  [n3,s3,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.030s
I161116 07:21:37.649659 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:37.703341 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:37.733242 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:37.805138 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:37.822087 31939 storage/store.go:2986  [n4,s4,r6/3:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:37.823158 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 12b2a665 at index 31
I161116 07:21:37.834070 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 14, log entries: 21
I161116 07:21:37.850282 32363 storage/replica_raftstorage.go:587  [n3,s3,r5/?:{-}] applying preemptive snapshot at index 31 (id=12b2a665, encoded size=16, 1 rocksdb batches, 21 log entries)
I161116 07:21:37.859299 32363 storage/replica_raftstorage.go:590  [n3,s3,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.008s
I161116 07:21:37.863906 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:37.967009 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:37.987484 32319 storage/raft_transport.go:437  [n2] raft transport stream to node 4 established
I161116 07:21:37.988055 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:37.997391 30998 storage/replicate_queue_test.go:98  not balanced: [10 2 7 8 4]
I161116 07:21:37.999259 30791 storage/replica_proposal.go:332  [n2,s2,r10/2:/{Table/54-Max}] new range lease replica {2 2 2} 2016-11-16 07:21:37.894993179 +0000 UTC 9.338025333s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m37.894993179s [physicalTime=2016-11-16 07:21:37.999135877 +0000 UTC]
I161116 07:21:38.007379 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot f18c1dfa at index 13
I161116 07:21:38.021578 31063 storage/replica_proposal.go:381  [n1,s1,r8/1:/Table/5{2-3}] range [n1,s1,r8/1:/Table/5{2-3}]: transferring raft leadership to replica ID 3
I161116 07:21:38.026064 31566 storage/replica_proposal.go:332  [n4,s4,r8/3:/Table/5{2-3}] new range lease replica {4 4 3} 2016-11-16 07:21:37.894993179 +0000 UTC 9.369681343s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m37.894993179s [physicalTime=2016-11-16 07:21:38.025925116 +0000 UTC]
I161116 07:21:38.026252 32345 storage/raft_transport.go:437  [n4] raft transport stream to node 2 established
I161116 07:21:38.030320 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 9, log entries: 3
I161116 07:21:38.040179 32344 storage/replica_raftstorage.go:587  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 13 (id=f18c1dfa, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:21:38.047602 32365 storage/raft_transport.go:437  [n4] raft transport stream to node 3 established
I161116 07:21:38.052747 32344 storage/replica_raftstorage.go:590  [n3,s3,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.007s
I161116 07:21:38.056275 32420 storage/raft_transport.go:437  [n3] raft transport stream to node 4 established
I161116 07:21:38.080114 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:38.136305 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:38.149315 31939 storage/store.go:2986  [n4,s4,r5/3:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:38.162206 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 10b65b12 at index 45
I161116 07:21:38.176146 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 14, log entries: 35
I161116 07:21:38.180672 32369 storage/replica_raftstorage.go:587  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 45 (id=10b65b12, encoded size=16, 1 rocksdb batches, 35 log entries)
I161116 07:21:38.186993 32369 storage/replica_raftstorage.go:590  [n3,s3,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.006s
I161116 07:21:38.190359 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:38.253658 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:38.272588 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:38.289399 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:38.293729 32394 storage/raft_transport.go:437  [n3] raft transport stream to node 2 established
I161116 07:21:38.318069 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:38.410122 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:38.447987 32347 storage/store.go:2986  [n4,s4,r10/3:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:38.464410 30985 storage/replica_proposal.go:381  [n1,s1,r7/1:/Table/5{1-2}] range [n1,s1,r7/1:/Table/5{1-2}]: transferring raft leadership to replica ID 3
I161116 07:21:38.474497 31566 storage/replica_proposal.go:332  [n4,s4,r7/3:/Table/5{1-2}] new range lease replica {4 4 3} 2016-11-16 07:21:37.894993179 +0000 UTC 9.7906543s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h21m37.894993179s [physicalTime=2016-11-16 07:21:38.474342935 +0000 UTC]
I161116 07:21:38.525030 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:38.539601 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot fdff9e59 at index 24
I161116 07:21:38.553163 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 12, log entries: 14
I161116 07:21:38.564910 32474 storage/replica_raftstorage.go:587  [n5,s5,r6/?:{-}] applying preemptive snapshot at index 24 (id=fdff9e59, encoded size=16, 1 rocksdb batches, 14 log entries)
I161116 07:21:38.566462 32474 storage/replica_raftstorage.go:590  [n5,s5,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.001s
I161116 07:21:38.571261 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:38.611757 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:21:38.675835 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:5 store_id:5 replica_id:5 > next_replica_id:6 
I161116 07:21:38.794906 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot dcb41c8c at index 20
I161116 07:21:38.800549 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:38.833763 31378 storage/store.go:2986  [n2,s2,r6/2:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:38.838838 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot a1b5e2c9 at index 26
I161116 07:21:38.863186 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 13, log entries: 16
I161116 07:21:38.864454 32496 storage/replica_raftstorage.go:587  [n3,s3,r9/?:{-}] applying preemptive snapshot at index 26 (id=a1b5e2c9, encoded size=16, 1 rocksdb batches, 16 log entries)
I161116 07:21:38.919363 32496 storage/replica_raftstorage.go:590  [n3,s3,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.055s
I161116 07:21:38.933425 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:38.969032 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:38.981833 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:38.985317 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 11, log entries: 10
I161116 07:21:39.001804 30998 storage/replicate_queue_test.go:98  not balanced: [10 1 10 5 6]
I161116 07:21:39.005280 32548 storage/replica_raftstorage.go:587  [n5,s5,r10/?:{-}] applying preemptive snapshot at index 20 (id=dcb41c8c, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:21:39.006541 32548 storage/replica_raftstorage.go:590  [n5,s5,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.001s
I161116 07:21:39.008954 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:5 
I161116 07:21:39.106202 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:39.123545 31939 storage/store.go:2986  [n4,s4,r9/3:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:39.124347 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 84771fbd at index 550
I161116 07:21:39.197764 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:21:39.235466 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:5 store_id:5 replica_id:5 > next_replica_id:6 
I161116 07:21:39.241676 32573 storage/raft_transport.go:437  [n5] raft transport stream to node 2 established
I161116 07:21:39.266803 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1245, log entries: 5
I161116 07:21:39.267690 32442 storage/replica_raftstorage.go:587  [n5,s5,r1/?:{-}] applying preemptive snapshot at index 550 (id=84771fbd, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:21:39.271756 32442 storage/replica_raftstorage.go:590  [n5,s5,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.004s
I161116 07:21:39.280603 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:5 
I161116 07:21:39.311282 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:39.340136 31201 storage/store.go:2986  [n1,s1,r10/1:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:39.351741 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:21:39.376185 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:5 > next_replica_id:6 
I161116 07:21:39.442620 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:3}]
I161116 07:21:39.464220 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot fcb792af at index 25
I161116 07:21:39.474920 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 12, log entries: 15
I161116 07:21:39.479039 31939 storage/store.go:2986  [n4,s4,r1/4:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:39.485786 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 40556eba at index 116
I161116 07:21:39.485885 32603 storage/replica_raftstorage.go:587  [n5,s5,r8/?:{-}] applying preemptive snapshot at index 25 (id=fcb792af, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:21:39.491390 32603 storage/replica_raftstorage.go:590  [n5,s5,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.005s
E161116 07:21:39.497411 31107 storage/queue.go:575  [n1,replicate,s1,r4/1:/Table/1{3-4}] [n1,s1,r4/1:/Table/1{3-4}]: change replicas aborted due to failed preemptive snapshot: range=4: remote declined snapshot: reservation rejected
I161116 07:21:39.501039 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:39.724415 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:21:39.762382 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:5 > next_replica_id:6 
I161116 07:21:39.768846 32706 storage/raft_transport.go:437  [n5] raft transport stream to node 4 established
I161116 07:21:39.899221 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:39.915893 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot 349e1c44 at index 26
I161116 07:21:39.920248 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 12, log entries: 16
I161116 07:21:39.921647 32698 storage/replica_raftstorage.go:587  [n5,s5,r7/?:{-}] applying preemptive snapshot at index 26 (id=349e1c44, encoded size=16, 1 rocksdb batches, 16 log entries)
I161116 07:21:39.923392 32698 storage/replica_raftstorage.go:590  [n5,s5,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.002s
I161116 07:21:39.933917 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:5 
I161116 07:21:39.948060 31758 storage/store.go:2986  [n1,s1,r8/1:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:40.002186 30998 storage/replicate_queue_test.go:98  not balanced: [8 1 10 3 9]
I161116 07:21:40.037070 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:5}]
I161116 07:21:40.057476 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:5 > next_replica_id:6 
I161116 07:21:40.146367 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot af9a99dd at index 127
I161116 07:21:40.163379 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 301, log entries: 117
I161116 07:21:40.170852 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:40.194349 32670 storage/replica_raftstorage.go:587  [n5,s5,r4/?:{-}] applying preemptive snapshot at index 127 (id=af9a99dd, encoded size=16, 1 rocksdb batches, 117 log entries)
I161116 07:21:40.219380 31758 storage/store.go:2986  [n1,s1,r7/1:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:40.243963 32670 storage/replica_raftstorage.go:590  [n5,s5,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.049s
I161116 07:21:40.250688 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:4 
I161116 07:21:40.477664 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:40.507021 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:40.697926 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot 40f2421a at index 35
I161116 07:21:40.708588 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 14, log entries: 25
I161116 07:21:40.716314 32836 storage/replica_raftstorage.go:587  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 35 (id=40f2421a, encoded size=16, 1 rocksdb batches, 25 log entries)
I161116 07:21:40.718212 32836 storage/replica_raftstorage.go:590  [n2,s2,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.002s
I161116 07:21:40.720672 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:6 
I161116 07:21:40.729234 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:40.746472 31939 storage/store.go:2986  [n4,s4,r4/3:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:40.749097 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot cb50051c at index 46
I161116 07:21:40.758432 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 41, log entries: 36
I161116 07:21:40.761196 32763 storage/replica_raftstorage.go:587  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 46 (id=cb50051c, encoded size=16, 1 rocksdb batches, 36 log entries)
I161116 07:21:40.771205 32763 storage/replica_raftstorage.go:590  [n2,s2,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.009s
I161116 07:21:40.789435 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:40.812298 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:40.834814 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:40.901997 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:40.925446 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:40.945095 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:40.977591 32422 storage/store.go:2986  [n3,s3,r7/4:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:40.977849 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot a7a3b862 at index 32
I161116 07:21:41.003747 30998 storage/replicate_queue_test.go:98  not balanced: [7 3 10 2 10]
I161116 07:21:41.017184 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 14, log entries: 22
I161116 07:21:41.020786 32844 storage/replica_raftstorage.go:587  [n2,s2,r8/?:{-}] applying preemptive snapshot at index 32 (id=a7a3b862, encoded size=16, 1 rocksdb batches, 22 log entries)
I161116 07:21:41.029429 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.034760 32844 storage/replica_raftstorage.go:590  [n2,s2,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.014s
I161116 07:21:41.038345 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:6 
I161116 07:21:41.044759 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot ad37c5c8 at index 146
I161116 07:21:41.081908 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 333, log entries: 20
I161116 07:21:41.083499 32801 storage/replica_raftstorage.go:587  [n2,s2,r4/?:{-}] applying preemptive snapshot at index 146 (id=ad37c5c8, encoded size=16, 1 rocksdb batches, 20 log entries)
I161116 07:21:41.085543 32801 storage/replica_raftstorage.go:590  [n2,s2,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.002s
I161116 07:21:41.094680 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:5 
I161116 07:21:41.215191 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:5}]
I161116 07:21:41.222285 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.251704 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:5 > next_replica_id:6 
I161116 07:21:41.259730 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:41.374906 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:41.379889 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:2}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:5} {NodeID:5 StoreID:5 ReplicaID:4}]
I161116 07:21:41.415212 32422 storage/store.go:2986  [n3,s3,r8/4:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:41.421353 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 36cbfdf9 at index 51
I161116 07:21:41.442985 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 16, log entries: 41
I161116 07:21:41.444375 32890 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 51 (id=36cbfdf9, encoded size=16, 1 rocksdb batches, 41 log entries)
I161116 07:21:41.449145 32890 storage/replica_raftstorage.go:590  [n2,s2,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.005s
I161116 07:21:41.452015 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:41.527895 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.540291 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:41.609752 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.625384 31586 storage/store.go:2986  [n3,s3,r2/5:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:41.630302 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 77e56121 at index 707
I161116 07:21:41.710233 32925 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 707 (id=77e56121, encoded size=16, 1 rocksdb batches, 57 log entries)
I161116 07:21:41.716088 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1277, log entries: 57
I161116 07:21:41.716968 32925 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.007s
I161116 07:21:41.720203 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:3 > next_replica_id:6 
I161116 07:21:41.775352 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.804925 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:41.879350 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:3}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:41.930704 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 407b315c at index 38
I161116 07:21:41.935030 31586 storage/store.go:2986  [n3,s3,r1/3:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:41.948958 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 16, log entries: 28
I161116 07:21:41.960779 32984 storage/replica_raftstorage.go:587  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 38 (id=407b315c, encoded size=16, 1 rocksdb batches, 28 log entries)
I161116 07:21:41.962878 32984 storage/replica_raftstorage.go:590  [n2,s2,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.002s
I161116 07:21:41.966028 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:42.004131 30998 storage/replicate_queue_test.go:98  not balanced: [7 8 4 2 10]
I161116 07:21:42.079482 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:42.127893 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:42.228441 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:42.242926 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 78912187 at index 34
I161116 07:21:42.247784 31586 storage/store.go:2986  [n3,s3,r5/5:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:42.249813 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 15, log entries: 24
I161116 07:21:42.254087 33014 storage/replica_raftstorage.go:587  [n2,s2,r9/?:{-}] applying preemptive snapshot at index 34 (id=78912187, encoded size=16, 1 rocksdb batches, 24 log entries)
I161116 07:21:42.271860 33014 storage/replica_raftstorage.go:590  [n2,s2,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.018s
I161116 07:21:42.277962 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot de4cc800 at index 28
I161116 07:21:42.278765 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:6 
I161116 07:21:42.297594 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 13, log entries: 18
I161116 07:21:42.303855 32969 storage/replica_raftstorage.go:587  [n4,s4,r10/?:{-}] applying preemptive snapshot at index 28 (id=de4cc800, encoded size=16, 1 rocksdb batches, 18 log entries)
I161116 07:21:42.305519 32969 storage/replica_raftstorage.go:590  [n4,s4,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.002s
I161116 07:21:42.323147 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:6 
I161116 07:21:42.394824 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:3 StoreID:3 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:42.407581 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:3 store_id:3 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:42.444408 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:6}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:42.469240 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:7 
I161116 07:21:42.520606 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:5}]
I161116 07:21:42.557228 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 075e5027 at index 46
I161116 07:21:42.560206 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 18, log entries: 36
I161116 07:21:42.563263 33122 storage/replica_raftstorage.go:587  [n4,s4,r5/?:{-}] applying preemptive snapshot at index 46 (id=075e5027, encoded size=16, 1 rocksdb batches, 36 log entries)
I161116 07:21:42.563680 32270 storage/store.go:2986  [n5,s5,r9/4:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:42.568611 33122 storage/replica_raftstorage.go:590  [n4,s4,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.005s
I161116 07:21:42.576686 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:42.631594 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:42.672547 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:42.687830 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:42.794222 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:42.824902 32270 storage/store.go:2986  [n5,s5,r5/4:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:42.834492 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 41421737 at index 31
I161116 07:21:42.842671 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 14, log entries: 21
I161116 07:21:42.845136 33159 storage/replica_raftstorage.go:587  [n2,s2,r6/?:{-}] applying preemptive snapshot at index 31 (id=41421737, encoded size=16, 1 rocksdb batches, 21 log entries)
I161116 07:21:42.846851 33159 storage/replica_raftstorage.go:590  [n2,s2,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.002s
I161116 07:21:42.849721 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:6 
I161116 07:21:42.912064 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:42.947430 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:43.012554 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 2 4 8]
I161116 07:21:43.023373 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:4}]
I161116 07:21:43.040037 32270 storage/store.go:2986  [n5,s5,r6/5:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:43.043865 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 0a575ca7 at index 41
I161116 07:21:43.046658 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 17, log entries: 31
I161116 07:21:43.064770 33128 storage/replica_raftstorage.go:587  [n4,s4,r9/?:{-}] applying preemptive snapshot at index 41 (id=0a575ca7, encoded size=16, 1 rocksdb batches, 31 log entries)
I161116 07:21:43.094857 33128 storage/replica_raftstorage.go:590  [n4,s4,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.030s
I161116 07:21:43.097523 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:5 > next_replica_id:7 
I161116 07:21:43.172727 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:5} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.192893 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:5 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:43.258822 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.276891 31586 storage/store.go:2986  [n3,s3,r9/5:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:43.278561 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 7ad2ad24 at index 52
I161116 07:21:43.289360 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 43, log entries: 42
I161116 07:21:43.296988 33202 storage/replica_raftstorage.go:587  [n4,s4,r3/?:{-}] applying preemptive snapshot at index 52 (id=7ad2ad24, encoded size=16, 1 rocksdb batches, 42 log entries)
I161116 07:21:43.306380 33202 storage/replica_raftstorage.go:590  [n4,s4,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.009s
I161116 07:21:43.310099 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:43.418543 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.468314 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:43.621820 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:43.642920 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 38c7145f at index 38
I161116 07:21:43.646621 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 16, log entries: 28
I161116 07:21:43.647994 33114 storage/replica_raftstorage.go:587  [n4,s4,r6/?:{-}] applying preemptive snapshot at index 38 (id=38c7145f, encoded size=16, 1 rocksdb batches, 28 log entries)
I161116 07:21:43.649897 33114 storage/replica_raftstorage.go:590  [n4,s4,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.002s
I161116 07:21:43.650939 32270 storage/store.go:2986  [n5,s5,r3/4:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:43.658504 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:4 > next_replica_id:7 
I161116 07:21:43.740919 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.755945 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:43.847294 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.867560 31586 storage/store.go:2986  [n3,s3,r6/4:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:43.869374 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot c28447f4 at index 872
I161116 07:21:43.922613 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1304, log entries: 15
I161116 07:21:43.923720 33208 storage/replica_raftstorage.go:587  [n4,s4,r1/?:{-}] applying preemptive snapshot at index 872 (id=c28447f4, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:21:43.929281 33208 storage/replica_raftstorage.go:590  [n4,s4,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.005s
I161116 07:21:43.932389 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:43.967810 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:43.983301 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:44.015491 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 0 8 6]
I161116 07:21:44.039735 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:44.068901 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot dace9aa3 at index 204
I161116 07:21:44.072594 32270 storage/store.go:2986  [n5,s5,r1/5:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:44.104331 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 460, log entries: 78
I161116 07:21:44.108982 33153 storage/replica_raftstorage.go:587  [n4,s4,r4/?:{-}] applying preemptive snapshot at index 204 (id=dace9aa3, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:21:44.126873 33153 storage/replica_raftstorage.go:590  [n4,s4,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.018s
I161116 07:21:44.184316 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:5 > replicas:<node_id:5 store_id:5 replica_id:4 > next_replica_id:6 
I161116 07:21:44.239858 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:5} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:44.255666 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:5 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:7 
I161116 07:21:44.307414 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:5} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:44.321776 32270 storage/store.go:2986  [n5,s5,r4/4:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:44.324436 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 29bcd375 at index 58
I161116 07:21:44.334921 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 18, log entries: 48
I161116 07:21:44.336906 33301 storage/replica_raftstorage.go:587  [n4,s4,r2/?:{-}] applying preemptive snapshot at index 58 (id=29bcd375, encoded size=16, 1 rocksdb batches, 48 log entries)
I161116 07:21:44.339440 33301 storage/replica_raftstorage.go:590  [n4,s4,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.002s
I161116 07:21:44.356582 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:7 
I161116 07:21:44.423275 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:4} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:44.466765 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:4 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:44.501829 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:4}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:44.559713 32270 storage/store.go:2986  [n5,s5,r2/4:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:45.015893 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 0 10 3]
I161116 07:21:45.149799 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 64590cd1 at index 39
I161116 07:21:45.189067 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 16, log entries: 29
I161116 07:21:45.194815 33320 storage/replica_raftstorage.go:587  [n1,s1,r8/?:{-}] applying preemptive snapshot at index 39 (id=64590cd1, encoded size=16, 1 rocksdb batches, 29 log entries)
I161116 07:21:45.197081 33320 storage/replica_raftstorage.go:590  [n1,s1,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.002s
I161116 07:21:45.212751 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:7 
I161116 07:21:45.321957 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:7}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:1 StoreID:1 ReplicaID:7}]
I161116 07:21:45.334336 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:1 store_id:1 replica_id:7 > next_replica_id:8 
I161116 07:21:45.407070 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:45.413640 32708 storage/store.go:2986  [n5,s5,r8/5:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:45.415896 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot e0799038 at index 43
I161116 07:21:45.445609 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 16, log entries: 33
I161116 07:21:45.462725 33367 storage/replica_raftstorage.go:587  [n1,s1,r7/?:{-}] applying preemptive snapshot at index 43 (id=e0799038, encoded size=16, 1 rocksdb batches, 33 log entries)
I161116 07:21:45.466780 33367 storage/replica_raftstorage.go:590  [n1,s1,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.004s
I161116 07:21:45.474460 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:7 
I161116 07:21:45.553658 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:7}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:1 StoreID:1 ReplicaID:7}]
I161116 07:21:45.561536 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:1 store_id:1 replica_id:7 > next_replica_id:8 
I161116 07:21:45.616981 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:45.623915 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot d524c99b at index 48
I161116 07:21:45.625707 32708 storage/store.go:2986  [n5,s5,r7/5:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:45.626617 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 19, log entries: 38
I161116 07:21:45.627736 33372 storage/replica_raftstorage.go:587  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 48 (id=d524c99b, encoded size=16, 1 rocksdb batches, 38 log entries)
I161116 07:21:45.629943 33372 storage/replica_raftstorage.go:590  [n3,s3,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.002s
I161116 07:21:45.658474 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:8 
I161116 07:21:45.705925 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 023f2158 at index 1043
I161116 07:21:45.730911 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:45.738887 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:45.778746 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1322, log entries: 82
I161116 07:21:45.785960 33414 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 1043 (id=023f2158, encoded size=16, 1 rocksdb batches, 82 log entries)
I161116 07:21:45.794161 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:45.795380 33414 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.009s
I161116 07:21:45.798095 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:8 
I161116 07:21:45.799869 32321 storage/store.go:2986  [n2,s2,r7/6:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:45.845688 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:45.860456 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:45.900306 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:45.909660 31378 storage/store.go:2986  [n2,s2,r1/6:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:45.914876 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 97fdd2ae at index 232
I161116 07:21:45.958002 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 527, log entries: 106
I161116 07:21:45.959685 33524 storage/replica_raftstorage.go:587  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 232 (id=97fdd2ae, encoded size=16, 1 rocksdb batches, 106 log entries)
I161116 07:21:45.965865 33524 storage/replica_raftstorage.go:590  [n3,s3,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.006s
I161116 07:21:45.968341 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:5 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:7 
I161116 07:21:45.989290 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:5} {NodeID:4 StoreID:4 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:7}]
I161116 07:21:46.002081 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:5 > replicas:<node_id:4 store_id:4 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:7 > next_replica_id:8 
I161116 07:21:46.016424 30998 storage/replicate_queue_test.go:98  not balanced: [9 8 3 10 1]
I161116 07:21:46.043858 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:5}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:7} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:46.050164 31378 storage/store.go:2986  [n2,s2,r4/5:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:46.111587 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot fbeebb9a at index 49
I161116 07:21:46.115322 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 19, log entries: 39
I161116 07:21:46.116505 33503 storage/replica_raftstorage.go:587  [n3,s3,r9/?:{-}] applying preemptive snapshot at index 49 (id=fbeebb9a, encoded size=16, 1 rocksdb batches, 39 log entries)
I161116 07:21:46.118893 33503 storage/replica_raftstorage.go:590  [n3,s3,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.002s
I161116 07:21:46.121230 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:46.142787 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:46.152964 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:46.190596 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:7}]
I161116 07:21:46.218186 31378 storage/store.go:2986  [n2,s2,r9/6:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:46.313544 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 3ce4aa15 at index 54
I161116 07:21:46.317154 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 20, log entries: 44
I161116 07:21:46.318329 33485 storage/replica_raftstorage.go:587  [n3,s3,r5/?:{-}] applying preemptive snapshot at index 54 (id=3ce4aa15, encoded size=16, 1 rocksdb batches, 44 log entries)
I161116 07:21:46.320918 33485 storage/replica_raftstorage.go:590  [n3,s3,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.002s
I161116 07:21:46.323291 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:8 
I161116 07:21:46.354501 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:46.371384 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:46.439051 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:46.479624 31378 storage/store.go:2986  [n2,s2,r5/6:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:46.528664 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot b95a7fdc at index 44
I161116 07:21:46.532099 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 18, log entries: 34
I161116 07:21:46.534955 33544 storage/replica_raftstorage.go:587  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 44 (id=b95a7fdc, encoded size=16, 1 rocksdb batches, 34 log entries)
I161116 07:21:46.540699 33544 storage/replica_raftstorage.go:590  [n3,s3,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.006s
I161116 07:21:46.554315 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:8 
I161116 07:21:46.600060 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:46.613179 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:46.718600 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:46.728985 31939 storage/store.go:2986  [n4,s4,r6/7:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:46.741412 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot aed4f839 at index 36
I161116 07:21:46.757103 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 15, log entries: 26
I161116 07:21:46.765422 33634 storage/replica_raftstorage.go:587  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 36 (id=aed4f839, encoded size=16, 1 rocksdb batches, 26 log entries)
I161116 07:21:46.769857 33634 storage/replica_raftstorage.go:590  [n3,s3,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.004s
I161116 07:21:46.774132 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:7 
I161116 07:21:46.857335 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:5 StoreID:5 ReplicaID:5} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:7}]
I161116 07:21:46.874672 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:5 store_id:5 replica_id:5 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:7 > next_replica_id:8 
I161116 07:21:46.926537 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 11c14f90 at index 60
I161116 07:21:46.946817 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 45, log entries: 50
I161116 07:21:46.970846 33582 storage/replica_raftstorage.go:587  [n3,s3,r3/?:{-}] applying preemptive snapshot at index 60 (id=11c14f90, encoded size=16, 1 rocksdb batches, 50 log entries)
I161116 07:21:46.985636 33582 storage/replica_raftstorage.go:590  [n3,s3,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.015s
I161116 07:21:46.991842 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:8 
I161116 07:21:46.998158 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:5}: [{NodeID:3 StoreID:3 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:6}]
I161116 07:21:47.017571 30998 storage/replicate_queue_test.go:98  not balanced: [9 5 8 9 1]
I161116 07:21:47.057029 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:47.092504 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:47.170313 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:6}]
I161116 07:21:47.189768 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 008c2714 at index 66
I161116 07:21:47.209076 31939 storage/store.go:2986  [n4,s4,r3/7:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:47.220576 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 20, log entries: 56
I161116 07:21:47.229404 33624 storage/replica_raftstorage.go:587  [n5,s5,r2/?:{-}] applying preemptive snapshot at index 66 (id=008c2714, encoded size=16, 1 rocksdb batches, 56 log entries)
I161116 07:21:47.246784 33624 storage/replica_raftstorage.go:590  [n5,s5,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.017s
I161116 07:21:47.249757 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:8 
I161116 07:21:47.347476 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:47.368769 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:47.438814 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:47.486099 31378 storage/store.go:2986  [n2,s2,r2/6:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:47.506517 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 1ce3b35d at index 67
I161116 07:21:47.520675 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 47, log entries: 57
I161116 07:21:47.525139 33536 storage/replica_raftstorage.go:587  [n5,s5,r3/?:{-}] applying preemptive snapshot at index 67 (id=1ce3b35d, encoded size=16, 1 rocksdb batches, 57 log entries)
I161116 07:21:47.529552 33536 storage/replica_raftstorage.go:590  [n5,s5,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.004s
I161116 07:21:47.551099 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:6 > next_replica_id:9 
I161116 07:21:47.630928 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:47.653625 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:47.750905 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:47.758311 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot b5814729 at index 43
I161116 07:21:47.761969 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 17, log entries: 33
I161116 07:21:47.763789 33673 storage/replica_raftstorage.go:587  [n5,s5,r10/?:{-}] applying preemptive snapshot at index 43 (id=b5814729, encoded size=16, 1 rocksdb batches, 33 log entries)
I161116 07:21:47.766181 33673 storage/replica_raftstorage.go:590  [n5,s5,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.002s
I161116 07:21:47.766479 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 39be46d7 at index 73
I161116 07:21:47.775742 31378 storage/store.go:2986  [n2,s2,r3/6:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:47.777052 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:8 
I161116 07:21:47.783553 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 22, log entries: 63
I161116 07:21:47.787290 33675 storage/replica_raftstorage.go:587  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 73 (id=39be46d7, encoded size=16, 1 rocksdb batches, 63 log entries)
I161116 07:21:47.803365 33675 storage/replica_raftstorage.go:590  [n3,s3,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.013s
I161116 07:21:47.809146 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:47.812417 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 664d4d62 at index 47
I161116 07:21:47.819370 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 18, log entries: 37
I161116 07:21:47.827027 33746 storage/replica_raftstorage.go:587  [n5,s5,r8/?:{-}] applying preemptive snapshot at index 47 (id=664d4d62, encoded size=16, 1 rocksdb batches, 37 log entries)
I161116 07:21:47.829616 33746 storage/replica_raftstorage.go:590  [n5,s5,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.002s
I161116 07:21:47.832563 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:8 
I161116 07:21:47.893847 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:3 StoreID:3 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:4 StoreID:4 ReplicaID:6} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:47.941461 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:4 store_id:4 replica_id:6 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:48.010834 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:3 StoreID:3 ReplicaID:9}]
I161116 07:21:48.019703 30998 storage/replicate_queue_test.go:98  not balanced: [9 3 9 8 4]
I161116 07:21:48.030969 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:3 store_id:3 replica_id:9 > next_replica_id:10 
I161116 07:21:48.048852 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:48.082198 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:48.124554 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:6}: [{NodeID:3 StoreID:3 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:48.148208 32347 storage/store.go:2986  [n4,s4,r10/6:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:48.154622 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:48.187884 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot d9286565 at index 281
I161116 07:21:48.225591 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 635, log entries: 50
I161116 07:21:48.227360 33801 storage/replica_raftstorage.go:587  [n5,s5,r4/?:{-}] applying preemptive snapshot at index 281 (id=d9286565, encoded size=16, 1 rocksdb batches, 50 log entries)
I161116 07:21:48.260325 33801 storage/replica_raftstorage.go:590  [n5,s5,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.033s
I161116 07:21:48.261537 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:48.268544 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:4 store_id:4 replica_id:6 > next_replica_id:8 
I161116 07:21:48.297120 32321 storage/store.go:2986  [n2,s2,r8/6:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:48.379027 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:7} {NodeID:4 StoreID:4 ReplicaID:6} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:48.390389 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:4 store_id:4 replica_id:6 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:48.489341 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:48.500300 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 78df43c2 at index 55
I161116 07:21:48.507903 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 21, log entries: 45
I161116 07:21:48.509203 33834 storage/replica_raftstorage.go:587  [n5,s5,r9/?:{-}] applying preemptive snapshot at index 55 (id=78df43c2, encoded size=16, 1 rocksdb batches, 45 log entries)
I161116 07:21:48.511718 33834 storage/replica_raftstorage.go:590  [n5,s5,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.002s
I161116 07:21:48.521116 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:7 > next_replica_id:9 
I161116 07:21:48.595568 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:48.606884 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:48.681761 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:48.718582 31939 storage/store.go:2986  [n4,s4,r9/7:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:48.720072 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 4f0e1945 at index 62
I161116 07:21:48.723216 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 22, log entries: 52
I161116 07:21:48.726185 33909 storage/replica_raftstorage.go:587  [n5,s5,r5/?:{-}] applying preemptive snapshot at index 62 (id=4f0e1945, encoded size=16, 1 rocksdb batches, 52 log entries)
I161116 07:21:48.730006 33909 storage/replica_raftstorage.go:590  [n5,s5,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:21:48.733874 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:48.873420 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot 20df40ba at index 58
I161116 07:21:48.877384 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 20, log entries: 48
I161116 07:21:48.878861 33878 storage/replica_raftstorage.go:587  [n5,s5,r7/?:{-}] applying preemptive snapshot at index 58 (id=20df40ba, encoded size=16, 1 rocksdb batches, 48 log entries)
I161116 07:21:48.887326 33878 storage/replica_raftstorage.go:590  [n5,s5,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.008s
I161116 07:21:48.889888 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:9 
I161116 07:21:48.894849 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:48.914969 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:49.013918 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:49.022917 30998 storage/replicate_queue_test.go:98  not balanced: [9 2 9 4 8]
I161116 07:21:49.024918 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:49.037842 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:49.086199 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot bf54733f at index 1265
I161116 07:21:49.114428 31939 storage/store.go:2986  [n4,s4,r5/7:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:49.151305 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1372, log entries: 95
I161116 07:21:49.166831 33845 storage/replica_raftstorage.go:587  [n5,s5,r1/?:{-}] applying preemptive snapshot at index 1265 (id=bf54733f, encoded size=16, 1 rocksdb batches, 95 log entries)
I161116 07:21:49.220177 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:7}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:49.220503 33845 storage/replica_raftstorage.go:590  [n5,s5,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.054s
I161116 07:21:49.227580 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot f2c66eb5 at index 54
I161116 07:21:49.238320 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 20, log entries: 44
I161116 07:21:49.238383 31758 storage/store.go:2986  [n1,s1,r7/7:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:49.239721 33850 storage/replica_raftstorage.go:587  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 54 (id=f2c66eb5, encoded size=16, 1 rocksdb batches, 44 log entries)
I161116 07:21:49.244845 33850 storage/replica_raftstorage.go:590  [n3,s3,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.005s
I161116 07:21:49.252192 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:9 
I161116 07:21:49.284416 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:49.402132 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:7} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:49.438003 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:9}]
I161116 07:21:49.472196 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:9 > next_replica_id:10 
I161116 07:21:49.495253 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:7 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:49.572609 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:49.615124 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot f11bd644 at index 52
I161116 07:21:49.630915 31939 storage/store.go:2986  [n4,s4,r1/7:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:49.633967 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 20, log entries: 42
I161116 07:21:49.643591 33936 storage/replica_raftstorage.go:587  [n5,s5,r6/?:{-}] applying preemptive snapshot at index 52 (id=f11bd644, encoded size=16, 1 rocksdb batches, 42 log entries)
I161116 07:21:49.646511 33936 storage/replica_raftstorage.go:590  [n5,s5,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.003s
I161116 07:21:49.653266 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:9 
I161116 07:21:49.699825 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:7}: [{NodeID:3 StoreID:3 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:49.717562 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:6} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:49.729055 31758 storage/store.go:2986  [n1,s1,r8/7:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:49.733117 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:6 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:49.825617 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:6}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:49.835202 31378 storage/store.go:2986  [n2,s2,r6/6:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:50.023368 30998 storage/replicate_queue_test.go:98  not balanced: [7 1 10 2 10]
I161116 07:21:50.542972 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/3:/Table/5{1-2}] generated snapshot 89e53df7 at index 65
I161116 07:21:50.557936 31643 storage/store.go:3134  [n4,replicate,s4,r7/3:/Table/5{1-2}] streamed snapshot: kv pairs: 22, log entries: 55
I161116 07:21:50.559914 34042 storage/replica_raftstorage.go:587  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 65 (id=89e53df7, encoded size=16, 1 rocksdb batches, 55 log entries)
I161116 07:21:50.569317 34042 storage/replica_raftstorage.go:590  [n2,s2,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.009s
I161116 07:21:50.572123 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:10 
I161116 07:21:50.595029 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 3b92f8b1 at index 74
I161116 07:21:50.623900 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 49, log entries: 64
I161116 07:21:50.626928 34073 storage/replica_raftstorage.go:587  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 74 (id=3b92f8b1, encoded size=16, 1 rocksdb batches, 64 log entries)
I161116 07:21:50.636189 34073 storage/replica_raftstorage.go:590  [n2,s2,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.009s
I161116 07:21:50.639018 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:50.717323 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:50.726975 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:50.727911 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/3:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:50.785592 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:50.869211 31643 storage/replica.go:2066  [n4,s4,r7/3:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:50.888824 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:50.895487 32422 storage/store.go:2986  [n3,s3,r7/8:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:50.906939 31586 storage/store.go:2986  [n3,s3,r3/8:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:50.964635 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 04a77ea8 at index 61
I161116 07:21:50.964745 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 4d5208fd at index 69
E161116 07:21:50.968217 31643 storage/queue.go:575  [n4,replicate,s4,r8/3:/Table/5{2-3}] [n4,s4,r8/3:/Table/5{2-3}]: change replicas aborted due to failed preemptive snapshot: range=8: remote declined snapshot: reservation rejected
I161116 07:21:50.968278 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 24, log entries: 59
I161116 07:21:50.970033 34134 storage/replica_raftstorage.go:587  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 69 (id=4d5208fd, encoded size=16, 1 rocksdb batches, 59 log entries)
I161116 07:21:50.997136 34134 storage/replica_raftstorage.go:590  [n2,s2,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.027s
I161116 07:21:51.000524 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:10 
I161116 07:21:51.024722 30998 storage/replicate_queue_test.go:98  not balanced: [7 4 10 2 10]
I161116 07:21:51.132568 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:51.147637 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:51.222257 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:51.242960 31586 storage/store.go:2986  [n3,s3,r5/8:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:51.246996 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot e85e5a22 at index 62
I161116 07:21:51.259226 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 23, log entries: 52
I161116 07:21:51.273136 34152 storage/replica_raftstorage.go:587  [n2,s2,r9/?:{-}] applying preemptive snapshot at index 62 (id=e85e5a22, encoded size=16, 1 rocksdb batches, 52 log entries)
I161116 07:21:51.288385 34152 storage/replica_raftstorage.go:590  [n2,s2,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.015s
I161116 07:21:51.298786 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:10 
I161116 07:21:51.358408 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:51.375493 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:51.377090 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 286181b8 at index 61
I161116 07:21:51.386573 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 22, log entries: 51
I161116 07:21:51.396715 34168 storage/replica_raftstorage.go:587  [n2,s2,r8/?:{-}] applying preemptive snapshot at index 61 (id=286181b8, encoded size=16, 1 rocksdb batches, 51 log entries)
I161116 07:21:51.402870 34168 storage/replica_raftstorage.go:590  [n2,s2,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.006s
I161116 07:21:51.413403 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:10 
I161116 07:21:51.461308 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:9}]
I161116 07:21:51.475544 31586 storage/store.go:2986  [n3,s3,r9/8:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:51.481864 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 13ef03a4 at index 334
I161116 07:21:51.502332 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 753, log entries: 103
I161116 07:21:51.504075 34199 storage/replica_raftstorage.go:587  [n2,s2,r4/?:{-}] applying preemptive snapshot at index 334 (id=13ef03a4, encoded size=16, 1 rocksdb batches, 103 log entries)
I161116 07:21:51.513021 34199 storage/replica_raftstorage.go:590  [n2,s2,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.009s
I161116 07:21:51.517005 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:51.551356 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:3 StoreID:3 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:51.570100 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:51.604128 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:7} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:9}]
I161116 07:21:51.686169 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r10/2:/{Table/54-Max}] generated snapshot b0435831 at index 50
I161116 07:21:51.689990 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:9 > next_replica_id:10 
I161116 07:21:51.696540 31119 storage/store.go:3134  [n2,replicate,s2,r10/2:/{Table/54-Max}] streamed snapshot: kv pairs: 19, log entries: 40
I161116 07:21:51.697985 34231 storage/replica_raftstorage.go:587  [n4,s4,r10/?:{-}] applying preemptive snapshot at index 50 (id=b0435831, encoded size=16, 1 rocksdb batches, 40 log entries)
I161116 07:21:51.702969 34231 storage/replica_raftstorage.go:590  [n4,s4,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.005s
I161116 07:21:51.711717 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:9 
I161116 07:21:51.747443 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:51.791451 32422 storage/store.go:2986  [n3,s3,r8/9:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:51.938639 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:51.960189 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:9}: [{NodeID:3 StoreID:3 ReplicaID:7} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:9}]
I161116 07:21:51.989949 31586 storage/store.go:2986  [n3,s3,r4/7:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:52.006585 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot c3852318 at index 59
I161116 07:21:52.024693 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 22, log entries: 49
I161116 07:21:52.026283 34219 storage/replica_raftstorage.go:587  [n2,s2,r6/?:{-}] applying preemptive snapshot at index 59 (id=c3852318, encoded size=16, 1 rocksdb batches, 49 log entries)
I161116 07:21:52.027007 30998 storage/replicate_queue_test.go:98  not balanced: [7 8 5 3 10]
I161116 07:21:52.032251 31119 storage/replica_command.go:3245  [n2,replicate,s2,r10/2:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:7 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:9 > next_replica_id:10 
I161116 07:21:52.050581 34219 storage/replica_raftstorage.go:590  [n2,s2,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.024s
I161116 07:21:52.063355 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:10 
I161116 07:21:52.187391 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:52.217914 31119 storage/replica.go:2066  [n2,s2,r10/2:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:7}: [{NodeID:4 StoreID:4 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:52.237190 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:52.265488 32396 storage/store.go:2986  [n3,s3,r10/7:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:52.370537 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:52.381548 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 945aab5d at index 79
I161116 07:21:52.404053 32270 storage/store.go:2986  [n5,s5,r6/9:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:52.406130 34354 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 79 (id=945aab5d, encoded size=16, 1 rocksdb batches, 69 log entries)
I161116 07:21:52.413105 34354 storage/replica_raftstorage.go:590  [n2,s2,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.007s
I161116 07:21:52.414962 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 24, log entries: 69
I161116 07:21:52.419485 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:10 
I161116 07:21:52.525140 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:52.549591 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:52.638693 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:52.655473 31586 storage/store.go:2986  [n3,s3,r2/9:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:52.660635 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot d2129c0e at index 1550
I161116 07:21:52.782426 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1410, log entries: 42
I161116 07:21:52.790378 34359 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 1550 (id=d2129c0e, encoded size=16, 1 rocksdb batches, 42 log entries)
I161116 07:21:52.797647 34359 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.007s
I161116 07:21:52.802835 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:10 
I161116 07:21:52.834824 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:52.859335 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:52.916168 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:8}]
I161116 07:21:52.938601 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot ebc5fc4a at index 364
I161116 07:21:52.941659 32270 storage/store.go:2986  [n5,s5,r1/9:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:52.978752 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 815, log entries: 31
I161116 07:21:52.991657 34366 storage/replica_raftstorage.go:587  [n4,s4,r4/?:{-}] applying preemptive snapshot at index 364 (id=ebc5fc4a, encoded size=16, 1 rocksdb batches, 31 log entries)
I161116 07:21:52.996326 34366 storage/replica_raftstorage.go:590  [n4,s4,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.005s
I161116 07:21:52.998963 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:10 
I161116 07:21:53.027353 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 2 4 8]
I161116 07:21:53.028194 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:9} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:10}]
I161116 07:21:53.042822 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:9 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:10 > next_replica_id:11 
I161116 07:21:53.124006 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:9} {NodeID:4 StoreID:4 ReplicaID:10}]
I161116 07:21:53.135764 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot cfa1af2d at index 87
I161116 07:21:53.148774 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 26, log entries: 77
I161116 07:21:53.151319 34407 storage/replica_raftstorage.go:587  [n4,s4,r2/?:{-}] applying preemptive snapshot at index 87 (id=cfa1af2d, encoded size=16, 1 rocksdb batches, 77 log entries)
I161116 07:21:53.155557 34407 storage/replica_raftstorage.go:590  [n4,s4,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.004s
I161116 07:21:53.174097 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:11 
I161116 07:21:53.205779 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.223536 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:53.278419 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.293592 32270 storage/store.go:2986  [n5,s5,r2/8:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:53.294737 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot c20686cc at index 66
I161116 07:21:53.310346 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 24, log entries: 56
I161116 07:21:53.312425 34316 storage/replica_raftstorage.go:587  [n4,s4,r6/?:{-}] applying preemptive snapshot at index 66 (id=c20686cc, encoded size=16, 1 rocksdb batches, 56 log entries)
I161116 07:21:53.315640 34316 storage/replica_raftstorage.go:590  [n4,s4,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.003s
I161116 07:21:53.331691 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:11 
I161116 07:21:53.354183 31307 gossip/gossip.go:1133  [n3] node has connected to cluster via gossip
I161116 07:21:53.354784 31307 storage/stores.go:312  [n3] wrote 4 node addresses to persistent storage
I161116 07:21:53.377314 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.386014 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:53.437374 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.442399 31586 storage/store.go:2986  [n3,s3,r6/8:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:53.450191 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 606205f8 at index 81
I161116 07:21:53.456517 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 51, log entries: 71
I161116 07:21:53.458261 34470 storage/replica_raftstorage.go:587  [n4,s4,r3/?:{-}] applying preemptive snapshot at index 81 (id=606205f8, encoded size=16, 1 rocksdb batches, 71 log entries)
I161116 07:21:53.463405 34470 storage/replica_raftstorage.go:590  [n4,s4,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.005s
I161116 07:21:53.466044 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:11 
I161116 07:21:53.513997 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.527961 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:53.583635 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.593668 32270 storage/store.go:2986  [n5,s5,r3/9:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:53.599133 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 291b036e at index 69
I161116 07:21:53.616362 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 26, log entries: 59
I161116 07:21:53.618344 34432 storage/replica_raftstorage.go:587  [n4,s4,r9/?:{-}] applying preemptive snapshot at index 69 (id=291b036e, encoded size=16, 1 rocksdb batches, 59 log entries)
I161116 07:21:53.621426 34432 storage/replica_raftstorage.go:590  [n4,s4,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.003s
I161116 07:21:53.626943 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:9 > next_replica_id:11 
I161116 07:21:53.679798 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.705828 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:53.759402 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.790925 32270 storage/store.go:2986  [n5,s5,r9/9:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:53.800444 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 0e189535 at index 79
I161116 07:21:53.809472 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 26, log entries: 69
I161116 07:21:53.820140 34485 storage/replica_raftstorage.go:587  [n4,s4,r5/?:{-}] applying preemptive snapshot at index 79 (id=0e189535, encoded size=16, 1 rocksdb batches, 69 log entries)
I161116 07:21:53.839319 34485 storage/replica_raftstorage.go:590  [n4,s4,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.019s
I161116 07:21:53.846210 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:11 
I161116 07:21:53.929932 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:53.939348 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:54.024841 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:2 StoreID:2 ReplicaID:10}]
I161116 07:21:54.029079 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 1 9 4]
I161116 07:21:54.050846 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 848a8f38 at index 1612
I161116 07:21:54.052485 32270 storage/store.go:2986  [n5,s5,r5/9:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:54.151357 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1433, log entries: 104
I161116 07:21:54.153150 34532 storage/replica_raftstorage.go:587  [n4,s4,r1/?:{-}] applying preemptive snapshot at index 1612 (id=848a8f38, encoded size=16, 1 rocksdb batches, 104 log entries)
I161116 07:21:54.181787 34532 storage/replica_raftstorage.go:590  [n4,s4,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.028s
I161116 07:21:54.192362 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:8 > next_replica_id:11 
I161116 07:21:54.239167 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:54.285314 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:54.364092 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:8}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:54.392737 31586 storage/store.go:2986  [n3,s3,r1/8:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:55.029425 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 0 10 3]
I161116 07:21:55.245200 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 27fa16c2 at index 69
I161116 07:21:55.249598 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 24, log entries: 59
I161116 07:21:55.250890 34548 storage/replica_raftstorage.go:587  [n1,s1,r8/?:{-}] applying preemptive snapshot at index 69 (id=27fa16c2, encoded size=16, 1 rocksdb batches, 59 log entries)
I161116 07:21:55.255638 34548 storage/replica_raftstorage.go:590  [n1,s1,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.005s
I161116 07:21:55.258163 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:11 
I161116 07:21:55.280357 31619 storage/replica_proposal.go:381  [n4,s4,r7/3:/Table/5{1-2}] range [n4,s4,r7/3:/Table/5{1-2}]: transferring raft leadership to replica ID 9
I161116 07:21:55.287341 31783 storage/replica_proposal.go:332  [n5,s5,r7/9:/Table/5{1-2}] new range lease replica {5 5 9} 2016-11-16 07:21:54.88776614 +0000 UTC 9.63805455s following replica {4 4 3} 2016-11-16 07:21:37.894993179 +0000 UTC 16.992772961s [physicalTime=2016-11-16 07:21:55.287184888 +0000 UTC]
I161116 07:21:55.292023 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/9:/Table/5{1-2}] generated snapshot f507fd02 at index 73
I161116 07:21:55.296249 31828 storage/store.go:3134  [n5,replicate,s5,r7/9:/Table/5{1-2}] streamed snapshot: kv pairs: 24, log entries: 63
I161116 07:21:55.312434 34585 storage/replica_raftstorage.go:587  [n1,s1,r7/?:{-}] applying preemptive snapshot at index 73 (id=f507fd02, encoded size=16, 1 rocksdb batches, 63 log entries)
I161116 07:21:55.322186 34585 storage/replica_raftstorage.go:590  [n1,s1,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.010s
I161116 07:21:55.328518 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:11 
I161116 07:21:55.344859 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:11}: [{NodeID:2 StoreID:2 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:1 StoreID:1 ReplicaID:11}]
I161116 07:21:55.394300 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:1 store_id:1 replica_id:11 > next_replica_id:12 
I161116 07:21:55.429448 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:11}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:1 StoreID:1 ReplicaID:11}]
I161116 07:21:55.468159 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:1 store_id:1 replica_id:11 > next_replica_id:12 
I161116 07:21:55.542420 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot cf710e26 at index 88
I161116 07:21:55.553822 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 53, log entries: 78
I161116 07:21:55.555704 34632 storage/replica_raftstorage.go:587  [n3,s3,r3/?:{-}] applying preemptive snapshot at index 88 (id=cf710e26, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:21:55.559673 34632 storage/replica_raftstorage.go:590  [n3,s3,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.004s
I161116 07:21:55.571554 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:55.577715 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:8}: [{NodeID:2 StoreID:2 ReplicaID:10} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:55.582578 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:55.603527 32480 storage/store.go:2986  [n2,s2,r7/10:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:55.644136 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 35ab17b7 at index 74
I161116 07:21:55.666678 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 27, log entries: 64
I161116 07:21:55.671713 34722 storage/replica_raftstorage.go:587  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 74 (id=35ab17b7, encoded size=16, 1 rocksdb batches, 64 log entries)
I161116 07:21:55.718455 34722 storage/replica_raftstorage.go:590  [n3,s3,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.047s
I161116 07:21:55.722856 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:12 
I161116 07:21:55.727033 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:55.819380 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:55.850320 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:2 StoreID:2 ReplicaID:10} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:55.873132 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:55.918760 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:55.959919 31378 storage/store.go:2986  [n2,s2,r3/10:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:55.964314 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot addff4b6 at index 411
I161116 07:21:55.978315 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:3 StoreID:3 ReplicaID:12} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:56.004257 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 932, log entries: 78
I161116 07:21:56.006958 34671 storage/replica_raftstorage.go:587  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 411 (id=addff4b6, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:21:56.025412 34671 storage/replica_raftstorage.go:590  [n3,s3,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.018s
I161116 07:21:56.034549 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:9 > replicas:<node_id:4 store_id:4 replica_id:10 > next_replica_id:11 
I161116 07:21:56.035856 30998 storage/replicate_queue_test.go:98  not balanced: [9 8 3 10 2]
I161116 07:21:56.114298 30792 storage/replica_proposal.go:381  [n2,s2,r10/2:/{Table/54-Max}] range [n2,s2,r10/2:/{Table/54-Max}]: transferring raft leadership to replica ID 8
I161116 07:21:56.115369 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:9} {NodeID:4 StoreID:4 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:11}]
I161116 07:21:56.117374 31810 storage/replica_proposal.go:332  [n5,s5,r10/8:/{Table/54-Max}] new range lease replica {5 5 8} 2016-11-16 07:21:55.990513195 +0000 UTC 9.366008814s following replica {2 2 2} 2016-11-16 07:21:37.894993179 +0000 UTC 18.095520016s [physicalTime=2016-11-16 07:21:56.117216984 +0000 UTC]
I161116 07:21:56.119123 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot 72bebc60 at index 58
I161116 07:21:56.137717 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 21, log entries: 48
I161116 07:21:56.139241 34718 storage/replica_raftstorage.go:587  [n1,s1,r10/?:{-}] applying preemptive snapshot at index 58 (id=72bebc60, encoded size=16, 1 rocksdb batches, 48 log entries)
I161116 07:21:56.148830 34718 storage/replica_raftstorage.go:590  [n1,s1,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.009s
I161116 07:21:56.149996 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:9 > replicas:<node_id:4 store_id:4 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:11 > next_replica_id:12 
I161116 07:21:56.158883 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:10 
I161116 07:21:56.225399 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:9}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:10}]
I161116 07:21:56.248309 31378 storage/store.go:2986  [n2,s2,r4/9:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:56.261442 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:10}: [{NodeID:4 StoreID:4 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:2} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:1 StoreID:1 ReplicaID:10}]
I161116 07:21:56.268054 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 415f2778 at index 75
I161116 07:21:56.279943 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:2 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:1 store_id:1 replica_id:10 > next_replica_id:11 
I161116 07:21:56.304814 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 26, log entries: 65
I161116 07:21:56.324464 34793 storage/replica_raftstorage.go:587  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 75 (id=415f2778, encoded size=16, 1 rocksdb batches, 65 log entries)
I161116 07:21:56.327696 34793 storage/replica_raftstorage.go:590  [n3,s3,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.003s
I161116 07:21:56.332552 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:56.397773 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:2}: [{NodeID:4 StoreID:4 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:56.408255 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:56.412857 32480 storage/store.go:2986  [n2,s2,r10/2:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:56.434119 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:56.516616 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:56.549638 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 07f60074 at index 94
I161116 07:21:56.557253 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot 563e84f1 at index 65
E161116 07:21:56.559646 31828 storage/queue.go:575  [n5,replicate,s5,r10/8:/{Table/54-Max}] [n5,s5,r10/8:/{Table/54-Max}]: change replicas aborted due to failed preemptive snapshot: range=10: remote declined snapshot: reservation rejected
I161116 07:21:56.578473 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 28, log entries: 84
I161116 07:21:56.587726 34824 storage/replica_raftstorage.go:587  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 94 (id=07f60074, encoded size=16, 1 rocksdb batches, 84 log entries)
I161116 07:21:56.608767 34824 storage/replica_raftstorage.go:590  [n3,s3,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.021s
I161116 07:21:56.612779 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:56.707099 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:56.720212 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:56.761245 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot 37b4656f at index 66
I161116 07:21:56.767210 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 24, log entries: 56
I161116 07:21:56.770389 34873 storage/replica_raftstorage.go:587  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 66 (id=37b4656f, encoded size=16, 1 rocksdb batches, 56 log entries)
I161116 07:21:56.775054 34873 storage/replica_raftstorage.go:590  [n3,s3,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.005s
I161116 07:21:56.777737 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:11 
I161116 07:21:56.839574 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:56.861846 31939 storage/store.go:2986  [n4,s4,r2/11:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:56.868137 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 258285c5 at index 77
I161116 07:21:56.874175 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:4 StoreID:4 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:3 StoreID:3 ReplicaID:11}]
I161116 07:21:56.891900 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:3 store_id:3 replica_id:11 > next_replica_id:12 
I161116 07:21:56.897031 34931 storage/raft_transport.go:437  [n3] raft transport stream to node 5 established
I161116 07:21:56.916350 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 28, log entries: 67
I161116 07:21:56.916406 34815 storage/replica_raftstorage.go:587  [n3,s3,r9/?:{-}] applying preemptive snapshot at index 77 (id=258285c5, encoded size=16, 1 rocksdb batches, 67 log entries)
I161116 07:21:56.945561 34815 storage/replica_raftstorage.go:590  [n3,s3,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.029s
I161116 07:21:56.960874 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:57.024356 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.029667 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:9}: [{NodeID:3 StoreID:3 ReplicaID:11} {NodeID:1 StoreID:1 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:21:57.047003 30998 storage/replicate_queue_test.go:98  not balanced: [10 4 7 9 2]
I161116 07:21:57.107418 32639 storage/store.go:2986  [n4,s4,r10/9:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:21:57.108192 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:57.116614 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/9:/Table/5{1-2}] generated snapshot 2e52d29d at index 81
I161116 07:21:57.161993 31828 storage/store.go:3134  [n5,replicate,s5,r7/9:/Table/5{1-2}] streamed snapshot: kv pairs: 26, log entries: 71
I161116 07:21:57.181629 34877 storage/replica_raftstorage.go:587  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 81 (id=2e52d29d, encoded size=16, 1 rocksdb batches, 71 log entries)
I161116 07:21:57.191402 34877 storage/replica_raftstorage.go:590  [n3,s3,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.010s
I161116 07:21:57.205812 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:12 
I161116 07:21:57.248503 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.287248 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 5025a121 at index 87
I161116 07:21:57.296361 31939 storage/store.go:2986  [n4,s4,r9/11:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:57.323664 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 28, log entries: 77
I161116 07:21:57.333198 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.337546 34832 storage/replica_raftstorage.go:587  [n3,s3,r5/?:{-}] applying preemptive snapshot at index 87 (id=5025a121, encoded size=16, 1 rocksdb batches, 77 log entries)
I161116 07:21:57.350110 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:57.374880 34832 storage/replica_raftstorage.go:590  [n3,s3,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.037s
I161116 07:21:57.382644 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:2 store_id:2 replica_id:10 > next_replica_id:12 
I161116 07:21:57.494080 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.510909 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:57.543492 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.572509 32639 storage/store.go:2986  [n4,s4,r7/3:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:21:57.671373 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.690408 31378 storage/store.go:2986  [n2,s2,r5/10:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:57.699671 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot b4273f83 at index 84
I161116 07:21:57.705975 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 30, log entries: 74
I161116 07:21:57.708431 35062 storage/replica_raftstorage.go:587  [n5,s5,r9/?:{-}] applying preemptive snapshot at index 84 (id=b4273f83, encoded size=16, 1 rocksdb batches, 74 log entries)
I161116 07:21:57.713847 35062 storage/replica_raftstorage.go:590  [n5,s5,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.005s
I161116 07:21:57.726135 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:57.805848 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:57.812981 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:57.891376 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:57.928135 31378 storage/store.go:2986  [n2,s2,r9/10:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:57.929109 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 9062f38b at index 1937
I161116 07:21:58.023607 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1475, log entries: 13
I161116 07:21:58.024976 35031 storage/replica_raftstorage.go:587  [n5,s5,r1/?:{-}] applying preemptive snapshot at index 1937 (id=9062f38b, encoded size=16, 1 rocksdb batches, 13 log entries)
I161116 07:21:58.035073 35031 storage/replica_raftstorage.go:590  [n5,s5,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.010s
I161116 07:21:58.037416 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:12 
I161116 07:21:58.047396 30998 storage/replicate_queue_test.go:98  not balanced: [10 2 9 6 4]
I161116 07:21:58.078963 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:5 StoreID:5 ReplicaID:12}]
I161116 07:21:58.110760 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:5 store_id:5 replica_id:12 > next_replica_id:13 
I161116 07:21:58.187667 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11}]
I161116 07:21:58.214770 31378 storage/store.go:2986  [n2,s2,r1/10:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:58.234731 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 3f99ba12 at index 460
I161116 07:21:58.267783 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1024, log entries: 19
I161116 07:21:58.275789 35068 storage/replica_raftstorage.go:587  [n5,s5,r4/?:{-}] applying preemptive snapshot at index 460 (id=3f99ba12, encoded size=16, 1 rocksdb batches, 19 log entries)
I161116 07:21:58.295983 35068 storage/replica_raftstorage.go:590  [n5,s5,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.020s
I161116 07:21:58.299098 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:10 > next_replica_id:12 
I161116 07:21:58.363354 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:12}]
I161116 07:21:58.377362 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:12 > next_replica_id:13 
I161116 07:21:58.434814 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:11} {NodeID:5 StoreID:5 ReplicaID:12}]
I161116 07:21:58.449944 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 6e0fb133 at index 94
I161116 07:21:58.457019 31939 storage/store.go:2986  [n4,s4,r4/10:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:58.458159 31939 storage/store.go:2986  [n4,s4,r4/10:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:21:58.460893 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 30, log entries: 84
I161116 07:21:58.463492 35123 storage/replica_raftstorage.go:587  [n5,s5,r5/?:{-}] applying preemptive snapshot at index 94 (id=6e0fb133, encoded size=16, 1 rocksdb batches, 84 log entries)
I161116 07:21:58.467977 35123 storage/replica_raftstorage.go:590  [n5,s5,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:21:58.470640 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:58.528962 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:58.550860 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:58.644817 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:58.677897 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 86518cd3 at index 101
I161116 07:21:58.689340 31939 storage/store.go:2986  [n4,s4,r5/11:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:21:58.692109 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 30, log entries: 91
I161116 07:21:58.707963 35155 storage/replica_raftstorage.go:587  [n5,s5,r2/?:{-}] applying preemptive snapshot at index 101 (id=86518cd3, encoded size=16, 1 rocksdb batches, 91 log entries)
I161116 07:21:58.716380 35155 storage/replica_raftstorage.go:590  [n5,s5,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.008s
I161116 07:21:58.728826 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:21:58.764482 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:10} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:58.817860 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:10 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:58.891061 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:10}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:21:58.911808 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 7273103f at index 2008
I161116 07:21:58.982039 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1489, log entries: 84
I161116 07:21:58.986611 35116 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 2008 (id=7273103f, encoded size=16, 1 rocksdb batches, 84 log entries)
I161116 07:21:59.001354 35116 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.015s
I161116 07:21:59.027007 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:13 
I161116 07:21:59.048277 30998 storage/replicate_queue_test.go:98  not balanced: [10 0 10 4 7]
I161116 07:21:59.109379 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:13}]
I161116 07:21:59.124197 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot f3694a3d at index 83
I161116 07:21:59.127442 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 28, log entries: 73
I161116 07:21:59.129166 35134 storage/replica_raftstorage.go:587  [n5,s5,r8/?:{-}] applying preemptive snapshot at index 83 (id=f3694a3d, encoded size=16, 1 rocksdb batches, 73 log entries)
I161116 07:21:59.145990 35134 storage/replica_raftstorage.go:590  [n5,s5,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.017s
I161116 07:21:59.147423 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:13 > next_replica_id:14 
I161116 07:21:59.153176 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:13 
I161116 07:21:59.245198 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:3 StoreID:3 ReplicaID:13}]
I161116 07:21:59.247911 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:3 StoreID:3 ReplicaID:12} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:59.265326 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:59.273165 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 41ffcf12 at index 95
I161116 07:21:59.275535 31939 storage/store.go:2986  [n4,s4,r1/11:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:21:59.281046 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 55, log entries: 85
I161116 07:21:59.288324 35120 storage/replica_raftstorage.go:587  [n5,s5,r3/?:{-}] applying preemptive snapshot at index 95 (id=41ffcf12, encoded size=16, 1 rocksdb batches, 85 log entries)
I161116 07:21:59.325094 35120 storage/replica_raftstorage.go:590  [n5,s5,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.037s
I161116 07:21:59.329898 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:13 
I161116 07:21:59.453023 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:59.469047 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:11}: [{NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:21:59.485173 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:59.499252 31758 storage/store.go:2986  [n1,s1,r8/11:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:59.585480 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:59.608084 31939 storage/store.go:2986  [n4,s4,r3/11:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:21:59.704274 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 16cf908e at index 81
I161116 07:21:59.714565 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 28, log entries: 71
I161116 07:21:59.717513 35184 storage/replica_raftstorage.go:587  [n5,s5,r6/?:{-}] applying preemptive snapshot at index 81 (id=16cf908e, encoded size=16, 1 rocksdb batches, 71 log entries)
I161116 07:21:59.723041 35184 storage/replica_raftstorage.go:590  [n5,s5,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.005s
I161116 07:21:59.755429 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > next_replica_id:13 
I161116 07:21:59.794392 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:11} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:59.805345 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:11 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:21:59.831237 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot f13d956a at index 73
I161116 07:21:59.848702 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 26, log entries: 63
I161116 07:21:59.858272 35319 storage/replica_raftstorage.go:587  [n2,s2,r10/?:{-}] applying preemptive snapshot at index 73 (id=f13d956a, encoded size=16, 1 rocksdb batches, 63 log entries)
I161116 07:21:59.865281 35319 storage/replica_raftstorage.go:590  [n2,s2,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.007s
I161116 07:21:59.870130 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:21:59.887032 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:1 store_id:1 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:12 
I161116 07:21:59.904252 31939 storage/store.go:2986  [n4,s4,r6/11:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:21:59.971539 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:12}: [{NodeID:3 StoreID:3 ReplicaID:11} {NodeID:1 StoreID:1 ReplicaID:10} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:12}]
I161116 07:21:59.986317 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:1 store_id:1 replica_id:10 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:12 > next_replica_id:13 
I161116 07:22:00.048675 30998 storage/replicate_queue_test.go:98  not balanced: [9 1 10 1 10]
I161116 07:22:00.083649 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:10}: [{NodeID:3 StoreID:3 ReplicaID:11} {NodeID:2 StoreID:2 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:00.097110 32265 storage/store.go:2986  [n1,s1,r10/10:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:22:00.234962 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/9:/Table/5{1-2}] generated snapshot 9bf32d32 at index 88
I161116 07:22:00.238204 31828 storage/store.go:3134  [n5,replicate,s5,r7/9:/Table/5{1-2}] streamed snapshot: kv pairs: 28, log entries: 78
I161116 07:22:00.242029 35310 storage/replica_raftstorage.go:587  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 88 (id=9bf32d32, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:22:00.245755 35310 storage/replica_raftstorage.go:590  [n2,s2,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.004s
I161116 07:22:00.249215 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:13 
I161116 07:22:00.314459 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:13}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:11} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:2 StoreID:2 ReplicaID:13}]
I161116 07:22:00.330574 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:11 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:2 store_id:2 replica_id:13 > next_replica_id:14 
I161116 07:22:00.393480 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:11}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12}]
I161116 07:22:00.420910 32265 storage/store.go:2986  [n1,s1,r7/11:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:00.459511 31142 gossip/gossip.go:1133  [n2] node has connected to cluster via gossip
I161116 07:22:00.460123 31142 storage/stores.go:312  [n2] wrote 4 node addresses to persistent storage
I161116 07:22:00.577907 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 47c7f2f6 at index 88
I161116 07:22:00.581364 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 770aed41 at index 91
E161116 07:22:00.583656 31643 storage/queue.go:575  [n4,replicate,s4,r8/3:/Table/5{2-3}] [n4,s4,r8/3:/Table/5{2-3}]: change replicas aborted due to failed preemptive snapshot: range=8: remote declined snapshot: reservation rejected
I161116 07:22:00.583869 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 30, log entries: 78
I161116 07:22:00.585283 35375 storage/replica_raftstorage.go:587  [n2,s2,r6/?:{-}] applying preemptive snapshot at index 88 (id=47c7f2f6, encoded size=16, 1 rocksdb batches, 78 log entries)
I161116 07:22:00.588802 35375 storage/replica_raftstorage.go:590  [n2,s2,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.003s
I161116 07:22:00.591358 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:22:00.635177 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:00.643502 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:00.699819 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:22:00.723189 31586 storage/store.go:2986  [n3,s3,r6/12:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:00.779039 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot f78c7251 at index 506
I161116 07:22:00.783312 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot 87ca061c at index 91
E161116 07:22:00.786711 31643 storage/queue.go:575  [n4,replicate,s4,r8/3:/Table/5{2-3}] [n4,s4,r8/3:/Table/5{2-3}]: change replicas aborted due to failed preemptive snapshot: range=8: remote declined snapshot: reservation rejected
I161116 07:22:00.808039 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1126, log entries: 65
I161116 07:22:00.811501 35476 storage/replica_raftstorage.go:587  [n2,s2,r4/?:{-}] applying preemptive snapshot at index 506 (id=f78c7251, encoded size=16, 1 rocksdb batches, 65 log entries)
I161116 07:22:00.822798 35476 storage/replica_raftstorage.go:590  [n2,s2,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.011s
I161116 07:22:00.825456 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:5 store_id:5 replica_id:12 > next_replica_id:13 
I161116 07:22:00.873563 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:11} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:2 StoreID:2 ReplicaID:13}]
I161116 07:22:00.895950 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:2 store_id:2 replica_id:13 > next_replica_id:14 
I161116 07:22:00.984869 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r8/3:/Table/5{2-3}] generated snapshot a295b63c at index 91
I161116 07:22:00.993905 31643 storage/store.go:3134  [n4,replicate,s4,r8/3:/Table/5{2-3}] streamed snapshot: kv pairs: 30, log entries: 81
I161116 07:22:01.003128 35424 storage/replica_raftstorage.go:587  [n2,s2,r8/?:{-}] applying preemptive snapshot at index 91 (id=a295b63c, encoded size=16, 1 rocksdb batches, 81 log entries)
I161116 07:22:01.040886 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:5 StoreID:5 ReplicaID:12}]
I161116 07:22:01.056402 30998 storage/replicate_queue_test.go:98  not balanced: [7 5 9 1 10]
I161116 07:22:01.060796 35424 storage/replica_raftstorage.go:590  [n2,s2,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.057s
I161116 07:22:01.062663 31586 storage/store.go:2986  [n3,s3,r4/11:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:01.064964 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 46fd967b at index 108
I161116 07:22:01.067503 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:14 
I161116 07:22:01.068888 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 32, log entries: 98
I161116 07:22:01.073057 35450 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 108 (id=46fd967b, encoded size=16, 1 rocksdb batches, 98 log entries)
I161116 07:22:01.086223 35450 storage/replica_raftstorage.go:590  [n2,s2,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.013s
I161116 07:22:01.094254 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:14 
I161116 07:22:01.201556 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.209880 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.217146 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:01.229887 31643 storage/replica_command.go:3245  [n4,replicate,s4,r8/3:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:01.334252 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.352230 31586 storage/store.go:2986  [n3,s3,r2/12:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:01.353597 31643 storage/replica.go:2066  [n4,s4,r8/3:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:3}]
I161116 07:22:01.359919 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 916f4b19 at index 91
I161116 07:22:01.383879 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 32, log entries: 81
I161116 07:22:01.385498 35469 storage/replica_raftstorage.go:587  [n2,s2,r9/?:{-}] applying preemptive snapshot at index 91 (id=916f4b19, encoded size=16, 1 rocksdb batches, 81 log entries)
I161116 07:22:01.393390 35469 storage/replica_raftstorage.go:590  [n2,s2,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.007s
I161116 07:22:01.396071 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:14 
I161116 07:22:01.505678 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.511324 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/9:/Table/5{1-2}] generated snapshot 626e9ec0 at index 96
I161116 07:22:01.519063 31828 storage/store.go:3134  [n5,replicate,s5,r7/9:/Table/5{1-2}] streamed snapshot: kv pairs: 30, log entries: 86
I161116 07:22:01.520261 35472 storage/replica_raftstorage.go:587  [n4,s4,r7/?:{-}] applying preemptive snapshot at index 96 (id=626e9ec0, encoded size=16, 1 rocksdb batches, 86 log entries)
I161116 07:22:01.549566 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:01.555868 35472 storage/replica_raftstorage.go:590  [n4,s4,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.035s
I161116 07:22:01.583242 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:14 
I161116 07:22:01.637595 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.689198 31586 storage/store.go:2986  [n3,s3,r9/12:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:01.698022 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 2f712fb7 at index 101
I161116 07:22:01.721397 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 32, log entries: 91
I161116 07:22:01.724209 35563 storage/replica_raftstorage.go:587  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 101 (id=2f712fb7, encoded size=16, 1 rocksdb batches, 91 log entries)
I161116 07:22:01.728613 35563 storage/replica_raftstorage.go:590  [n2,s2,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:22:01.737472 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > next_replica_id:14 
I161116 07:22:01.749452 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:14}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:01.829412 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/9:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:15 
I161116 07:22:01.906172 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:01.906667 31031 gossip/gossip.go:1133  [n1] node has connected to cluster via gossip
I161116 07:22:01.907226 31031 storage/stores.go:312  [n1] wrote 4 node addresses to persistent storage
I161116 07:22:01.927990 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:01.940161 31828 storage/replica.go:2066  [n5,s5,r7/9:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:01.976537 34933 storage/store.go:2986  [n3,s3,r7/12:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:02.057193 30998 storage/replicate_queue_test.go:98  not balanced: [7 8 5 2 10]
I161116 07:22:02.069815 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:02.153835 31586 storage/store.go:2986  [n3,s3,r5/12:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:02.159152 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 53addd5f at index 2180
I161116 07:22:02.220137 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1528, log entries: 23
I161116 07:22:02.224145 35653 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 2180 (id=53addd5f, encoded size=16, 1 rocksdb batches, 23 log entries)
I161116 07:22:02.241688 31616 gossip/gossip.go:1133  [n5] node has connected to cluster via gossip
I161116 07:22:02.247014 31616 storage/stores.go:312  [n5] wrote 4 node addresses to persistent storage
I161116 07:22:02.260883 35653 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.037s
I161116 07:22:02.266131 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:3 store_id:3 replica_id:13 > next_replica_id:14 
I161116 07:22:02.324469 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:3 StoreID:3 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:02.334100 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:3 store_id:3 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:02.399095 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:13}]
I161116 07:22:02.417943 32270 storage/store.go:2986  [n5,s5,r1/12:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:02.436430 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 39c71f85 at index 103
I161116 07:22:02.469053 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 57, log entries: 93
I161116 07:22:02.499220 35610 storage/replica_raftstorage.go:587  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 103 (id=39c71f85, encoded size=16, 1 rocksdb batches, 93 log entries)
I161116 07:22:02.540285 35610 storage/replica_raftstorage.go:590  [n2,s2,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.041s
I161116 07:22:02.546918 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:14 
I161116 07:22:02.566142 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot aa41441e at index 80
I161116 07:22:02.570406 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 28, log entries: 70
I161116 07:22:02.572634 35692 storage/replica_raftstorage.go:587  [n4,s4,r10/?:{-}] applying preemptive snapshot at index 80 (id=aa41441e, encoded size=16, 1 rocksdb batches, 70 log entries)
I161116 07:22:02.607668 35692 storage/replica_raftstorage.go:590  [n4,s4,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.035s
I161116 07:22:02.617284 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:2 store_id:2 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:13 
I161116 07:22:02.675607 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:02.714290 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:02.717851 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:13}: [{NodeID:3 StoreID:3 ReplicaID:11} {NodeID:2 StoreID:2 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:4 StoreID:4 ReplicaID:13}]
I161116 07:22:02.745868 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:3 store_id:3 replica_id:11 > replicas:<node_id:2 store_id:2 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:4 store_id:4 replica_id:13 > next_replica_id:14 
I161116 07:22:02.822799 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13}]
I161116 07:22:02.852457 31586 storage/store.go:2986  [n3,s3,r3/12:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:02.866113 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:11}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:02.877603 34933 storage/store.go:2986  [n3,s3,r10/11:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:22:02.893159 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 0584a531 at index 546
I161116 07:22:02.937109 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1223, log entries: 105
I161116 07:22:02.959280 35744 storage/replica_raftstorage.go:587  [n4,s4,r4/?:{-}] applying preemptive snapshot at index 546 (id=0584a531, encoded size=16, 1 rocksdb batches, 105 log entries)
I161116 07:22:03.022882 35744 storage/replica_raftstorage.go:590  [n4,s4,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.063s
I161116 07:22:03.059330 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:5 store_id:5 replica_id:12 > next_replica_id:14 
I161116 07:22:03.061474 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 1 4 9]
I161116 07:22:03.117618 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:5 StoreID:5 ReplicaID:12} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:03.127708 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:5 store_id:5 replica_id:12 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:15 
I161116 07:22:03.211624 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:12}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:03.252235 32270 storage/store.go:2986  [n5,s5,r4/12:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:03.256306 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 511fb5fc at index 117
I161116 07:22:03.263699 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 34, log entries: 2
I161116 07:22:03.266033 35795 storage/replica_raftstorage.go:587  [n4,s4,r2/?:{-}] applying preemptive snapshot at index 117 (id=511fb5fc, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:22:03.267306 35795 storage/replica_raftstorage.go:590  [n4,s4,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.001s
I161116 07:22:03.269560 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:03.318420 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:03.335909 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:03.454915 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:03.473278 32270 storage/store.go:2986  [n5,s5,r2/13:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:03.489757 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 85c0c499 at index 110
I161116 07:22:03.499392 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 59, log entries: 100
I161116 07:22:03.500937 35781 storage/replica_raftstorage.go:587  [n4,s4,r3/?:{-}] applying preemptive snapshot at index 110 (id=85c0c499, encoded size=16, 1 rocksdb batches, 100 log entries)
I161116 07:22:03.510357 35781 storage/replica_raftstorage.go:590  [n4,s4,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.009s
I161116 07:22:03.512799 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:15 
I161116 07:22:03.587615 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:03.613432 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:03.697476 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:03.716342 32270 storage/store.go:2986  [n5,s5,r3/13:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:03.720933 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 2d2ab438 at index 109
I161116 07:22:03.755178 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 34, log entries: 99
I161116 07:22:03.762477 35828 storage/replica_raftstorage.go:587  [n4,s4,r5/?:{-}] applying preemptive snapshot at index 109 (id=2d2ab438, encoded size=16, 1 rocksdb batches, 99 log entries)
I161116 07:22:03.771909 35828 storage/replica_raftstorage.go:590  [n4,s4,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.009s
I161116 07:22:03.788995 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:03.829240 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:03.840542 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:03.945679 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:03.960270 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot b56ff57a at index 2309
I161116 07:22:04.004814 32270 storage/store.go:2986  [n5,s5,r5/13:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:04.032808 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1551, log entries: 47
I161116 07:22:04.039407 35777 storage/replica_raftstorage.go:587  [n4,s4,r1/?:{-}] applying preemptive snapshot at index 2309 (id=b56ff57a, encoded size=16, 1 rocksdb batches, 47 log entries)
I161116 07:22:04.050139 35777 storage/replica_raftstorage.go:590  [n4,s4,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.011s
I161116 07:22:04.058299 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:13 > next_replica_id:15 
I161116 07:22:04.061987 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 1 8 5]
I161116 07:22:04.118043 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:04.142889 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:04.186194 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:04.205881 31586 storage/store.go:2986  [n3,s3,r1/13:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:04.212926 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 100ab392 at index 99
I161116 07:22:04.248183 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 34, log entries: 89
I161116 07:22:04.262693 35890 storage/replica_raftstorage.go:587  [n4,s4,r9/?:{-}] applying preemptive snapshot at index 99 (id=100ab392, encoded size=16, 1 rocksdb batches, 89 log entries)
I161116 07:22:04.272686 35890 storage/replica_raftstorage.go:590  [n4,s4,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.010s
I161116 07:22:04.275669 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:15 
I161116 07:22:04.330701 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:04.345296 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:04.414378 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:04.437511 32270 storage/store.go:2986  [n5,s5,r9/13:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:04.443143 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 6a739884 at index 95
I161116 07:22:04.458833 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 32, log entries: 85
I161116 07:22:04.465008 35922 storage/replica_raftstorage.go:587  [n4,s4,r6/?:{-}] applying preemptive snapshot at index 95 (id=6a739884, encoded size=16, 1 rocksdb batches, 85 log entries)
I161116 07:22:04.480827 35922 storage/replica_raftstorage.go:590  [n4,s4,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.016s
I161116 07:22:04.488477 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > next_replica_id:15 
I161116 07:22:04.576732 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:04.610310 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:04.699660 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:04.729524 32270 storage/store.go:2986  [n5,s5,r6/13:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:05.067854 30998 storage/replicate_queue_test.go:98  not balanced: [7 10 0 10 3]
I161116 07:22:05.299143 31787 storage/replica_proposal.go:381  [n5,s5,r7/9:/Table/5{1-2}] range [n5,s5,r7/9:/Table/5{1-2}]: transferring raft leadership to replica ID 14
I161116 07:22:05.306043 31629 storage/replica_proposal.go:332  [n4,s4,r7/14:/Table/5{1-2}] new range lease replica {4 4 14} 2016-11-16 07:22:04.52582069 +0000 UTC 10.004427893s following replica {5 5 9} 2016-11-16 07:21:54.88776614 +0000 UTC 9.63805455s [physicalTime=2016-11-16 07:22:05.305900782 +0000 UTC]
I161116 07:22:05.313497 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/14:/Table/5{1-2}] generated snapshot 77aaad1b at index 105
I161116 07:22:05.336508 31643 storage/store.go:3134  [n4,replicate,s4,r7/14:/Table/5{1-2}] streamed snapshot: kv pairs: 32, log entries: 95
I161116 07:22:05.338862 35932 storage/replica_raftstorage.go:587  [n1,s1,r7/?:{-}] applying preemptive snapshot at index 105 (id=77aaad1b, encoded size=16, 1 rocksdb batches, 95 log entries)
I161116 07:22:05.346686 35932 storage/replica_raftstorage.go:590  [n1,s1,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.008s
I161116 07:22:05.349651 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:15 
I161116 07:22:05.446643 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:15}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:1 StoreID:1 ReplicaID:15}]
I161116 07:22:05.464265 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:1 store_id:1 replica_id:15 > next_replica_id:16 
I161116 07:22:05.550054 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 1cb309e3 at index 104
I161116 07:22:05.561054 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 34, log entries: 94
I161116 07:22:05.576657 35959 storage/replica_raftstorage.go:587  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 104 (id=1cb309e3, encoded size=16, 1 rocksdb batches, 94 log entries)
I161116 07:22:05.590746 31221 storage/replica_proposal.go:332  [n2,s2,r8/14:/Table/5{2-3}] new range lease replica {2 2 14} 2016-11-16 07:22:04.484115928 +0000 UTC 10.346498684s following replica {4 4 3} 2016-11-16 07:21:37.894993179 +0000 UTC 26.589122749s [physicalTime=2016-11-16 07:22:05.590601762 +0000 UTC]
I161116 07:22:05.592342 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r8/14:/Table/5{2-3}] generated snapshot 32de4140 at index 98
I161116 07:22:05.596736 31621 storage/replica_proposal.go:381  [n4,s4,r8/3:/Table/5{2-3}] range [n4,s4,r8/3:/Table/5{2-3}]: transferring raft leadership to replica ID 14
I161116 07:22:05.599469 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:13}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:05.600478 35959 storage/replica_raftstorage.go:590  [n3,s3,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.024s
E161116 07:22:05.602384 31119 storage/queue.go:575  [n2,replicate,s2,r8/14:/Table/5{2-3}] [n2,s2,r8/14:/Table/5{2-3}]: change replicas aborted due to failed preemptive snapshot: range=8: remote declined snapshot: reservation rejected
I161116 07:22:05.606467 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:05.627486 32321 storage/store.go:2986  [n2,s2,r7/13:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:05.632696 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/14:/Table/5{1-2}] generated snapshot 1f1864c9 at index 110
I161116 07:22:05.643869 31643 storage/store.go:3134  [n4,replicate,s4,r7/14:/Table/5{1-2}] streamed snapshot: kv pairs: 35, log entries: 100
I161116 07:22:05.670297 35952 storage/replica_raftstorage.go:587  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 110 (id=1f1864c9, encoded size=16, 1 rocksdb batches, 100 log entries)
I161116 07:22:05.679050 35952 storage/replica_raftstorage.go:590  [n3,s3,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.005s
I161116 07:22:05.681614 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:16 
I161116 07:22:05.717179 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:05.746676 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:05.823670 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:05.846740 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:5 StoreID:5 ReplicaID:9} {NodeID:1 StoreID:1 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:05.859699 31378 storage/store.go:2986  [n2,s2,r6/14:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:05.865205 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot db163f47 at index 590
I161116 07:22:05.871747 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:5 store_id:5 replica_id:9 > replicas:<node_id:1 store_id:1 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:05.956368 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1325, log entries: 45
I161116 07:22:05.978939 36067 storage/replica_raftstorage.go:587  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 590 (id=db163f47, encoded size=16, 1 rocksdb batches, 45 log entries)
I161116 07:22:05.991281 36067 storage/replica_raftstorage.go:590  [n3,s3,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.012s
I161116 07:22:05.999101 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:15 
I161116 07:22:06.035202 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:9}: [{NodeID:3 StoreID:3 ReplicaID:16} {NodeID:1 StoreID:1 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:06.039421 31498 gossip/gossip.go:1133  [n4] node has connected to cluster via gossip
I161116 07:22:06.040004 31498 storage/stores.go:312  [n4] wrote 4 node addresses to persistent storage
I161116 07:22:06.057876 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:15}]
I161116 07:22:06.060690 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot e710fed8 at index 87
I161116 07:22:06.064532 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 30, log entries: 77
I161116 07:22:06.066258 36059 storage/replica_raftstorage.go:587  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 87 (id=e710fed8, encoded size=16, 1 rocksdb batches, 77 log entries)
I161116 07:22:06.069805 30998 storage/replicate_queue_test.go:98  not balanced: [8 8 4 10 3]
I161116 07:22:06.096460 36059 storage/replica_raftstorage.go:590  [n3,s3,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.030s
I161116 07:22:06.099418 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:14 
I161116 07:22:06.100277 32708 storage/store.go:2986  [n5,s5,r7/9:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:06.127433 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:15 > next_replica_id:16 
I161116 07:22:06.235417 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:13}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:06.260598 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:14}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:12} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:3 StoreID:3 ReplicaID:14}]
I161116 07:22:06.270491 31378 storage/store.go:2986  [n2,s2,r4/13:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:06.281212 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 94c7af43 at index 125
I161116 07:22:06.284126 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 36, log entries: 10
I161116 07:22:06.286643 36089 storage/replica_raftstorage.go:587  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 125 (id=94c7af43, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:22:06.302720 36089 storage/replica_raftstorage.go:590  [n3,s3,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.016s
I161116 07:22:06.308699 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:12 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:3 store_id:3 replica_id:14 > next_replica_id:15 
I161116 07:22:06.326907 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:16 
I161116 07:22:06.506956 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:06.536779 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:06.555477 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:12}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:06.675013 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:06.689978 31378 storage/store.go:2986  [n2,s2,r2/14:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:06.697550 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 117cdfc7 at index 106
I161116 07:22:06.723359 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 37, log entries: 96
I161116 07:22:06.726118 36129 storage/replica_raftstorage.go:587  [n3,s3,r9/?:{-}] applying preemptive snapshot at index 106 (id=117cdfc7, encoded size=16, 1 rocksdb batches, 96 log entries)
I161116 07:22:06.732516 36129 storage/replica_raftstorage.go:590  [n3,s3,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.006s
I161116 07:22:06.737297 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:16 
I161116 07:22:06.782968 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:06.795255 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:06.879093 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:14}]
I161116 07:22:06.893909 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 5dc11634 at index 118
I161116 07:22:06.920327 31939 storage/store.go:2986  [n4,s4,r9/15:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:06.939244 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 61, log entries: 5
I161116 07:22:06.947300 36211 storage/replica_raftstorage.go:587  [n3,s3,r3/?:{-}] applying preemptive snapshot at index 118 (id=5dc11634, encoded size=16, 1 rocksdb batches, 5 log entries)
I161116 07:22:06.949655 36211 storage/replica_raftstorage.go:590  [n3,s3,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.002s
I161116 07:22:06.958233 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:07.013064 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r8/14:/Table/5{2-3}] generated snapshot fb24f3fc at index 99
I161116 07:22:07.023382 31119 storage/store.go:3134  [n2,replicate,s2,r8/14:/Table/5{2-3}] streamed snapshot: kv pairs: 32, log entries: 89
I161116 07:22:07.027706 36164 storage/replica_raftstorage.go:587  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 99 (id=fb24f3fc, encoded size=16, 1 rocksdb batches, 89 log entries)
I161116 07:22:07.030517 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.035314 36164 storage/replica_raftstorage.go:590  [n3,s3,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.007s
I161116 07:22:07.039312 31119 storage/replica_command.go:3245  [n2,replicate,s2,r8/14:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:3 > next_replica_id:15 
I161116 07:22:07.047202 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:07.075795 30998 storage/replicate_queue_test.go:98  not balanced: [8 5 8 9 2]
I161116 07:22:07.159967 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:15}]
I161116 07:22:07.165833 31119 storage/replica.go:2066  [n2,s2,r8/14:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:15}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:3} {NodeID:3 StoreID:3 ReplicaID:15}]
I161116 07:22:07.168580 31378 storage/store.go:2986  [n2,s2,r3/14:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:07.176833 31119 storage/replica_command.go:3245  [n2,replicate,s2,r8/14:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:3 > replicas:<node_id:3 store_id:3 replica_id:15 > next_replica_id:16 
I161116 07:22:07.184262 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot dea8c4a8 at index 2577
I161116 07:22:07.246634 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1587, log entries: 81
I161116 07:22:07.249239 36250 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 2577 (id=dea8c4a8, encoded size=16, 1 rocksdb batches, 81 log entries)
I161116 07:22:07.267300 36250 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.018s
I161116 07:22:07.278192 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:16 
I161116 07:22:07.306509 31119 storage/replica.go:2066  [n2,s2,r8/14:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:3}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:15}]
I161116 07:22:07.327166 32347 storage/store.go:2986  [n4,s4,r8/3:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:07.348646 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.366714 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:07.394916 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.401606 31939 storage/store.go:2986  [n4,s4,r1/15:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:07.411913 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 45867ba1 at index 126
I161116 07:22:07.421998 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 63, log entries: 13
I161116 07:22:07.433491 36240 storage/replica_raftstorage.go:587  [n5,s5,r3/?:{-}] applying preemptive snapshot at index 126 (id=45867ba1, encoded size=16, 1 rocksdb batches, 13 log entries)
I161116 07:22:07.435648 36240 storage/replica_raftstorage.go:590  [n5,s5,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.002s
I161116 07:22:07.438607 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:17 
I161116 07:22:07.470367 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:07.484969 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:07.522900 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:07.552879 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 2a4fad82 at index 2600
I161116 07:22:07.562784 31939 storage/store.go:2986  [n4,s4,r3/15:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:07.563912 31939 storage/store.go:2986  [n4,s4,r3/15:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:07.653877 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1597, log entries: 104
I161116 07:22:07.655877 36191 storage/replica_raftstorage.go:587  [n5,s5,r1/?:{-}] applying preemptive snapshot at index 2600 (id=2a4fad82, encoded size=16, 1 rocksdb batches, 104 log entries)
I161116 07:22:07.665595 36191 storage/replica_raftstorage.go:590  [n5,s5,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.010s
I161116 07:22:07.667863 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:07.694881 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:07.712876 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:07.773456 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.790120 31378 storage/store.go:2986  [n2,s2,r1/14:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:07.792194 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot 2b8505cd at index 117
I161116 07:22:07.818690 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 36, log entries: 2
I161116 07:22:07.819991 36332 storage/replica_raftstorage.go:587  [n3,s3,r5/?:{-}] applying preemptive snapshot at index 117 (id=2b8505cd, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:22:07.821293 36332 storage/replica_raftstorage.go:590  [n3,s3,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.001s
I161116 07:22:07.824714 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:16 
I161116 07:22:07.873541 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.913194 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:07.961635 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:07.970484 31378 storage/store.go:2986  [n2,s2,r5/14:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:07.971192 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 220a5c49 at index 638
I161116 07:22:08.010380 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1427, log entries: 93
I161116 07:22:08.012706 36311 storage/replica_raftstorage.go:587  [n5,s5,r4/?:{-}] applying preemptive snapshot at index 638 (id=220a5c49, encoded size=16, 1 rocksdb batches, 93 log entries)
I161116 07:22:08.028676 36311 storage/replica_raftstorage.go:590  [n5,s5,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.016s
I161116 07:22:08.031649 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:16 
I161116 07:22:08.057747 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:16}]
I161116 07:22:08.073966 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:16 > next_replica_id:17 
I161116 07:22:08.076210 30998 storage/replicate_queue_test.go:98  not balanced: [8 2 10 6 5]
I161116 07:22:08.100125 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:16}]
I161116 07:22:08.113834 31939 storage/store.go:2986  [n4,s4,r4/14:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:08.118696 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r5/1:/Table/{14-50}] generated snapshot ef00f23a at index 124
I161116 07:22:08.135880 31107 storage/store.go:3134  [n1,replicate,s1,r5/1:/Table/{14-50}] streamed snapshot: kv pairs: 38, log entries: 9
I161116 07:22:08.138249 36347 storage/replica_raftstorage.go:587  [n5,s5,r5/?:{-}] applying preemptive snapshot at index 124 (id=ef00f23a, encoded size=16, 1 rocksdb batches, 9 log entries)
I161116 07:22:08.139756 36347 storage/replica_raftstorage.go:590  [n5,s5,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.001s
I161116 07:22:08.153159 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:08.192063 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:08.200471 31107 storage/replica_command.go:3245  [n1,replicate,s1,r5/1:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:08.232621 31107 storage/replica.go:2066  [n1,s1,r5/1:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:08.473430 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 94084e4b at index 132
I161116 07:22:08.478659 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 38, log entries: 17
I161116 07:22:08.480917 36369 storage/replica_raftstorage.go:587  [n5,s5,r2/?:{-}] applying preemptive snapshot at index 132 (id=94084e4b, encoded size=16, 1 rocksdb batches, 17 log entries)
I161116 07:22:08.482846 36369 storage/replica_raftstorage.go:590  [n5,s5,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.002s
I161116 07:22:08.486965 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:17 
I161116 07:22:08.526987 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:08.595500 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:08.688609 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:08.716859 31939 storage/store.go:2986  [n4,s4,r2/15:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:08.745480 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 68f259af at index 115
I161116 07:22:08.753322 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 39, log entries: 3
I161116 07:22:08.754925 36379 storage/replica_raftstorage.go:587  [n5,s5,r9/?:{-}] applying preemptive snapshot at index 115 (id=68f259af, encoded size=16, 1 rocksdb batches, 3 log entries)
I161116 07:22:08.756436 36379 storage/replica_raftstorage.go:590  [n5,s5,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.001s
I161116 07:22:08.759509 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:14 > next_replica_id:17 
I161116 07:22:08.822253 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:08.873055 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:08.959015 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:08.987211 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 4eded6ab at index 112
I161116 07:22:08.988687 31378 storage/store.go:2986  [n2,s2,r9/14:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:08.993437 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 36, log entries: 2
I161116 07:22:08.995986 36427 storage/replica_raftstorage.go:587  [n5,s5,r6/?:{-}] applying preemptive snapshot at index 112 (id=4eded6ab, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:22:08.997566 36427 storage/replica_raftstorage.go:590  [n5,s5,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.001s
I161116 07:22:09.011452 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:15 > next_replica_id:17 
I161116 07:22:09.076644 30998 storage/replicate_queue_test.go:98  not balanced: [8 1 10 3 9]
I161116 07:22:09.099998 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:09.150674 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:09.220835 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:09.239556 31939 storage/store.go:2986  [n4,s4,r6/15:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:09.343741 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/14:/Table/5{1-2}] generated snapshot 63d61e5c at index 121
I161116 07:22:09.356329 31643 storage/store.go:3134  [n4,replicate,s4,r7/14:/Table/5{1-2}] streamed snapshot: kv pairs: 36, log entries: 2
I161116 07:22:09.359633 36432 storage/replica_raftstorage.go:587  [n5,s5,r7/?:{-}] applying preemptive snapshot at index 121 (id=63d61e5c, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:22:09.361563 36432 storage/replica_raftstorage.go:590  [n5,s5,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.002s
I161116 07:22:09.376482 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:1 store_id:1 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:17 
I161116 07:22:09.460739 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:3 StoreID:3 ReplicaID:16} {NodeID:1 StoreID:1 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:09.516688 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:1 store_id:1 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:09.654719 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:15}: [{NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:09.665475 31758 storage/store.go:2986  [n1,s1,r7/15:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:09.671892 31758 storage/store.go:2986  [n1,s1,r7/15:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:10.077421 30998 storage/replicate_queue_test.go:98  not balanced: [7 1 10 2 10]
I161116 07:22:10.529307 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 2b8537c3 at index 122
I161116 07:22:10.535036 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 41, log entries: 10
I161116 07:22:10.536450 36552 storage/replica_raftstorage.go:587  [n2,s2,r9/?:{-}] applying preemptive snapshot at index 122 (id=2b8537c3, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:22:10.538093 36552 storage/replica_raftstorage.go:590  [n2,s2,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.002s
I161116 07:22:10.544320 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:10.602814 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:10.619408 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:10.718920 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:10.732218 31586 storage/store.go:2986  [n3,s3,r9/16:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:10.761217 31643 storage/replica_raftstorage.go:443  [n4,replicate,s4,r7/14:/Table/5{1-2}] generated snapshot 2ba6585b at index 128
I161116 07:22:10.762311 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 4dd56af5 at index 143
I161116 07:22:10.765977 31643 storage/store.go:3134  [n4,replicate,s4,r7/14:/Table/5{1-2}] streamed snapshot: kv pairs: 38, log entries: 9
I161116 07:22:10.800282 36447 storage/replica_raftstorage.go:587  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 128 (id=2ba6585b, encoded size=16, 1 rocksdb batches, 9 log entries)
I161116 07:22:10.803845 36447 storage/replica_raftstorage.go:590  [n2,s2,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.003s
I161116 07:22:10.809754 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:18 
I161116 07:22:10.827280 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 40, log entries: 28
I161116 07:22:10.830435 36536 storage/replica_raftstorage.go:587  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 143 (id=4dd56af5, encoded size=16, 1 rocksdb batches, 28 log entries)
I161116 07:22:10.836558 36536 storage/replica_raftstorage.go:590  [n2,s2,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.006s
I161116 07:22:10.839159 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:18 
I161116 07:22:10.880773 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:10.889832 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:10.904339 31643 storage/replica_command.go:3245  [n4,replicate,s4,r7/14:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:10.919545 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:11.001558 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:11.043360 31586 storage/store.go:2986  [n3,s3,r2/16:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:11.054626 31643 storage/replica.go:2066  [n4,s4,r7/14:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:11.073251 31446 storage/replica_proposal.go:332  [n3,s3,r5/16:/Table/{14-50}] new range lease replica {3 3 16} 2016-11-16 07:22:10.942609923 +0000 UTC 9.354443308s following replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h22m10.942609923s [physicalTime=2016-11-16 07:22:11.073098544 +0000 UTC]
I161116 07:22:11.074805 31356 storage/replica_raftstorage.go:443  [n3,replicate,s3,r5/16:/Table/{14-50}] generated snapshot 4d47584e at index 132
I161116 07:22:11.077673 31356 storage/store.go:3134  [n3,replicate,s3,r5/16:/Table/{14-50}] streamed snapshot: kv pairs: 41, log entries: 17
I161116 07:22:11.078135 30998 storage/replicate_queue_test.go:98  not balanced: [7 5 9 2 10]
I161116 07:22:11.079079 36573 storage/replica_raftstorage.go:587  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 132 (id=4d47584e, encoded size=16, 1 rocksdb batches, 17 log entries)
I161116 07:22:11.081432 30992 storage/replica_proposal.go:381  [n1,s1,r5/1:/Table/{14-50}] range [n1,s1,r5/1:/Table/{14-50}]: transferring raft leadership to replica ID 16
I161116 07:22:11.083115 36573 storage/replica_raftstorage.go:590  [n2,s2,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:22:11.086749 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:18 
I161116 07:22:11.170494 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:11.179703 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:11.281164 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:1 StoreID:1 ReplicaID:1}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:11.319583 31372 storage/store.go:2986  [n1,s1,r5/1:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:11.373374 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 163a45c8 at index 2921
I161116 07:22:11.432080 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1635, log entries: 10
I161116 07:22:11.436666 36677 storage/replica_raftstorage.go:587  [n2,s2,r1/?:{-}] applying preemptive snapshot at index 2921 (id=163a45c8, encoded size=16, 1 rocksdb batches, 10 log entries)
I161116 07:22:11.458220 36677 storage/replica_raftstorage.go:590  [n2,s2,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.021s
I161116 07:22:11.461043 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:18 
I161116 07:22:11.502379 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:11.515391 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:11.563838 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:11.575720 31586 storage/store.go:2986  [n3,s3,r1/16:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:11.580146 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot a0da72d6 at index 132
I161116 07:22:11.587327 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 65, log entries: 19
I161116 07:22:11.588708 36655 storage/replica_raftstorage.go:587  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 132 (id=a0da72d6, encoded size=16, 1 rocksdb batches, 19 log entries)
I161116 07:22:11.591144 36655 storage/replica_raftstorage.go:590  [n2,s2,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.002s
I161116 07:22:11.596778 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:11.644986 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:11.654065 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:11.712564 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17}]
I161116 07:22:11.729167 31586 storage/store.go:2986  [n3,s3,r3/16:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:11.770929 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot ba176181 at index 94
I161116 07:22:11.777082 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 32, log entries: 84
I161116 07:22:11.780206 36771 storage/replica_raftstorage.go:587  [n2,s2,r10/?:{-}] applying preemptive snapshot at index 94 (id=ba176181, encoded size=16, 1 rocksdb batches, 84 log entries)
I161116 07:22:11.781786 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot c75672e6 at index 692
I161116 07:22:11.783973 36771 storage/replica_raftstorage.go:590  [n2,s2,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.004s
I161116 07:22:11.794223 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:15 
I161116 07:22:11.836100 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1544, log entries: 42
I161116 07:22:11.838454 36773 storage/replica_raftstorage.go:587  [n2,s2,r4/?:{-}] applying preemptive snapshot at index 692 (id=c75672e6, encoded size=16, 1 rocksdb batches, 42 log entries)
I161116 07:22:11.848742 36773 storage/replica_raftstorage.go:590  [n2,s2,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.010s
I161116 07:22:11.853006 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:16 > next_replica_id:17 
I161116 07:22:11.870719 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:15}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:2 StoreID:2 ReplicaID:15}]
I161116 07:22:11.882959 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:2 store_id:2 replica_id:15 > next_replica_id:16 
I161116 07:22:11.927721 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:17}]
I161116 07:22:11.949077 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:17 > next_replica_id:18 
I161116 07:22:12.026426 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:14}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:12.048919 34933 storage/store.go:2986  [n3,s3,r10/14:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:22:12.063196 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:15}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:5 StoreID:5 ReplicaID:16}]
I161116 07:22:12.080969 30998 storage/replicate_queue_test.go:98  not balanced: [6 9 5 2 10]
I161116 07:22:12.092763 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot b0f0691c at index 119
I161116 07:22:12.109390 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 38, log entries: 9
I161116 07:22:12.110790 36822 storage/replica_raftstorage.go:587  [n2,s2,r6/?:{-}] applying preemptive snapshot at index 119 (id=b0f0691c, encoded size=16, 1 rocksdb batches, 9 log entries)
I161116 07:22:12.112331 36822 storage/replica_raftstorage.go:590  [n2,s2,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.001s
I161116 07:22:12.119124 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:18 
I161116 07:22:12.122996 31119 storage/replica_raftstorage.go:443  [n2,replicate,s2,r8/14:/Table/5{2-3}] generated snapshot 37888c34 at index 106
I161116 07:22:12.128050 31119 storage/store.go:3134  [n2,replicate,s2,r8/14:/Table/5{2-3}] streamed snapshot: kv pairs: 34, log entries: 96
I161116 07:22:12.129901 36824 storage/replica_raftstorage.go:587  [n4,s4,r8/?:{-}] applying preemptive snapshot at index 106 (id=37888c34, encoded size=16, 1 rocksdb batches, 96 log entries)
I161116 07:22:12.142706 36824 storage/replica_raftstorage.go:590  [n4,s4,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.013s
I161116 07:22:12.146313 31119 storage/replica_command.go:3245  [n2,replicate,s2,r8/14:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:15 > next_replica_id:16 
I161116 07:22:12.220039 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:12.233966 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:12.276446 31119 storage/replica.go:2066  [n2,s2,r8/14:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:16}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:15} {NodeID:4 StoreID:4 ReplicaID:16}]
I161116 07:22:12.290095 31356 storage/replica_raftstorage.go:443  [n3,replicate,s3,r5/16:/Table/{14-50}] generated snapshot 62223ff5 at index 142
I161116 07:22:12.300441 31356 storage/store.go:3134  [n3,replicate,s3,r5/16:/Table/{14-50}] streamed snapshot: kv pairs: 44, log entries: 27
I161116 07:22:12.302507 36752 storage/replica_raftstorage.go:587  [n4,s4,r5/?:{-}] applying preemptive snapshot at index 142 (id=62223ff5, encoded size=16, 1 rocksdb batches, 27 log entries)
I161116 07:22:12.315531 31119 storage/replica_command.go:3245  [n2,replicate,s2,r8/14:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:3 store_id:3 replica_id:15 > replicas:<node_id:4 store_id:4 replica_id:16 > next_replica_id:17 
I161116 07:22:12.315659 36752 storage/replica_raftstorage.go:590  [n4,s4,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.013s
I161116 07:22:12.318359 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:19 
I161116 07:22:12.323089 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:12.349799 32270 storage/store.go:2986  [n5,s5,r6/17:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:12.350874 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 499eccb2 at index 125
I161116 07:22:12.357387 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 41, log entries: 15
I161116 07:22:12.359053 36860 storage/replica_raftstorage.go:587  [n4,s4,r6/?:{-}] applying preemptive snapshot at index 125 (id=499eccb2, encoded size=16, 1 rocksdb batches, 15 log entries)
I161116 07:22:12.365853 36860 storage/replica_raftstorage.go:590  [n4,s4,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.007s
I161116 07:22:12.392508 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:12.418346 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:12.484958 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:12.566814 31119 storage/replica.go:2066  [n2,s2,r8/14:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:15}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:16}]
I161116 07:22:12.606953 32396 storage/store.go:2986  [n3,s3,r8/15:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:12.608455 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:12.638873 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:12.668431 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:12.699865 34848 storage/store.go:2986  [n5,s5,r5/17:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:12.728104 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:3 StoreID:3 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:12.758977 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot c2122aa1 at index 128
I161116 07:22:12.762843 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 43, log entries: 16
I161116 07:22:12.765514 36873 storage/replica_raftstorage.go:587  [n4,s4,r9/?:{-}] applying preemptive snapshot at index 128 (id=c2122aa1, encoded size=16, 1 rocksdb batches, 16 log entries)
I161116 07:22:12.767783 36873 storage/replica_raftstorage.go:590  [n4,s4,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.002s
I161116 07:22:12.775423 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:19 
I161116 07:22:12.780884 31586 storage/store.go:2986  [n3,s3,r6/16:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:12.874863 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:12.905838 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:13.025562 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:13.069563 32270 storage/store.go:2986  [n5,s5,r9/17:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:13.075130 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot 43b05be7 at index 140
I161116 07:22:13.081378 30998 storage/replicate_queue_test.go:98  not balanced: [6 10 1 6 8]
I161116 07:22:13.087649 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 67, log entries: 27
I161116 07:22:13.090847 36921 storage/replica_raftstorage.go:587  [n4,s4,r3/?:{-}] applying preemptive snapshot at index 140 (id=43b05be7, encoded size=16, 1 rocksdb batches, 27 log entries)
I161116 07:22:13.095399 36921 storage/replica_raftstorage.go:590  [n4,s4,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.004s
I161116 07:22:13.099871 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > next_replica_id:19 
I161116 07:22:13.180702 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:13.224947 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:13.293351 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:13.302681 32270 storage/store.go:2986  [n5,s5,r3/17:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:13.307926 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot f1d363c9 at index 3079
I161116 07:22:13.353517 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1665, log entries: 64
I161116 07:22:13.355186 36971 storage/replica_raftstorage.go:587  [n4,s4,r1/?:{-}] applying preemptive snapshot at index 3079 (id=f1d363c9, encoded size=16, 1 rocksdb batches, 64 log entries)
I161116 07:22:13.371916 36971 storage/replica_raftstorage.go:590  [n4,s4,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.012s
I161116 07:22:13.374601 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:13.394892 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:13.418420 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:13.450818 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:13.463614 32270 storage/store.go:2986  [n5,s5,r1/17:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:13.468784 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot d10ddcb4 at index 150
I161116 07:22:13.472704 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 42, log entries: 35
I161116 07:22:13.476559 37032 storage/replica_raftstorage.go:587  [n4,s4,r2/?:{-}] applying preemptive snapshot at index 150 (id=d10ddcb4, encoded size=16, 1 rocksdb batches, 35 log entries)
I161116 07:22:13.480579 37032 storage/replica_raftstorage.go:590  [n4,s4,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.004s
I161116 07:22:13.486047 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:19 
I161116 07:22:13.513793 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:13.585787 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:13.646037 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:13.667765 32270 storage/store.go:2986  [n5,s5,r2/17:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:13.668916 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 58212cbc at index 736
I161116 07:22:13.731542 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1651, log entries: 86
I161116 07:22:13.735011 36957 storage/replica_raftstorage.go:587  [n4,s4,r4/?:{-}] applying preemptive snapshot at index 736 (id=58212cbc, encoded size=16, 1 rocksdb batches, 86 log entries)
I161116 07:22:13.746827 36957 storage/replica_raftstorage.go:590  [n4,s4,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.012s
I161116 07:22:13.749571 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:5 store_id:5 replica_id:16 > next_replica_id:18 
I161116 07:22:13.779068 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:4 StoreID:4 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:5 StoreID:5 ReplicaID:16} {NodeID:4 StoreID:4 ReplicaID:18}]
I161116 07:22:13.792589 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:5 store_id:5 replica_id:16 > replicas:<node_id:4 store_id:4 replica_id:18 > next_replica_id:19 
I161116 07:22:13.837401 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:5 StoreID:5 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:18}]
I161116 07:22:13.844420 32270 storage/store.go:2986  [n5,s5,r4/16:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:14.081843 30998 storage/replicate_queue_test.go:98  not balanced: [6 10 1 10 3]
I161116 07:22:14.914808 31356 storage/replica_raftstorage.go:443  [n3,replicate,s3,r5/16:/Table/{14-50}] generated snapshot 38062481 at index 149
I161116 07:22:14.935097 31356 storage/store.go:3134  [n3,replicate,s3,r5/16:/Table/{14-50}] streamed snapshot: kv pairs: 46, log entries: 34
I161116 07:22:14.936518 37110 storage/replica_raftstorage.go:587  [n1,s1,r5/?:{-}] applying preemptive snapshot at index 149 (id=38062481, encoded size=16, 1 rocksdb batches, 34 log entries)
I161116 07:22:14.940840 37110 storage/replica_raftstorage.go:590  [n1,s1,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:22:14.945813 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:20 
I161116 07:22:15.005794 31218 storage/replica_proposal.go:381  [n2,s2,r8/14:/Table/5{2-3}] range [n2,s2,r8/14:/Table/5{2-3}]: transferring raft leadership to replica ID 13
I161116 07:22:15.006953 31811 storage/replica_proposal.go:332  [n5,s5,r8/13:/Table/5{2-3}] new range lease replica {5 5 13} 2016-11-16 07:22:14.830614612 +0000 UTC 9.420996141s following replica {2 2 14} 2016-11-16 07:22:04.484115928 +0000 UTC 10.346498684s [physicalTime=2016-11-16 07:22:15.006797635 +0000 UTC]
I161116 07:22:15.010933 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r8/13:/Table/5{2-3}] generated snapshot d4d4ead0 at index 114
I161116 07:22:15.021547 31828 storage/store.go:3134  [n5,replicate,s5,r8/13:/Table/5{2-3}] streamed snapshot: kv pairs: 36, log entries: 104
I161116 07:22:15.027823 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:20}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:1 StoreID:1 ReplicaID:20}]
I161116 07:22:15.028088 37123 storage/replica_raftstorage.go:587  [n1,s1,r8/?:{-}] applying preemptive snapshot at index 114 (id=d4d4ead0, encoded size=16, 1 rocksdb batches, 104 log entries)
I161116 07:22:15.032370 37123 storage/replica_raftstorage.go:590  [n1,s1,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.004s
I161116 07:22:15.035932 31828 storage/replica_command.go:3245  [n5,replicate,s5,r8/13:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:16 > next_replica_id:17 
I161116 07:22:15.041123 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:1 store_id:1 replica_id:20 > next_replica_id:21 
I161116 07:22:15.083450 30998 storage/replicate_queue_test.go:98  not balanced: [8 10 1 10 3]
I161116 07:22:15.143944 31828 storage/replica.go:2066  [n5,s5,r8/13:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:17}: [{NodeID:2 StoreID:2 ReplicaID:14} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:16} {NodeID:1 StoreID:1 ReplicaID:17}]
I161116 07:22:15.156474 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:20} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:15.164842 32452 storage/store.go:2986  [n2,s2,r5/18:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:15.166072 31828 storage/replica_command.go:3245  [n5,replicate,s5,r8/13:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:2 store_id:2 replica_id:14 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:16 > replicas:<node_id:1 store_id:1 replica_id:17 > next_replica_id:18 
I161116 07:22:15.302716 31828 storage/replica.go:2066  [n5,s5,r8/13:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:17} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:16}]
I161116 07:22:15.321033 32480 storage/store.go:2986  [n2,s2,r8/14:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:15.327289 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot cdf22948 at index 103
I161116 07:22:15.347908 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 34, log entries: 93
I161116 07:22:15.357337 37234 storage/replica_raftstorage.go:587  [n1,s1,r10/?:{-}] applying preemptive snapshot at index 103 (id=cdf22948, encoded size=16, 1 rocksdb batches, 93 log entries)
I161116 07:22:15.361968 37234 storage/replica_raftstorage.go:590  [n1,s1,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.005s
I161116 07:22:15.364658 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:16 
I161116 07:22:15.420724 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:16}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:2 StoreID:2 ReplicaID:15} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:1 StoreID:1 ReplicaID:16}]
I161116 07:22:15.434340 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:2 store_id:2 replica_id:15 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:1 store_id:1 replica_id:16 > next_replica_id:17 
I161116 07:22:15.513160 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:15}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:1 StoreID:1 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:15.523755 32480 storage/store.go:2986  [n2,s2,r10/15:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:22:15.527164 31621 storage/replica_proposal.go:381  [n4,s4,r7/14:/Table/5{1-2}] range [n4,s4,r7/14:/Table/5{1-2}]: transferring raft leadership to replica ID 17
I161116 07:22:15.531488 31810 storage/replica_proposal.go:332  [n5,s5,r7/17:/Table/5{1-2}] new range lease replica {5 5 17} 2016-11-16 07:22:14.530248583 +0000 UTC 10.242785548s following replica {4 4 14} 2016-11-16 07:22:04.52582069 +0000 UTC 10.004427893s [physicalTime=2016-11-16 07:22:15.531336722 +0000 UTC]
I161116 07:22:15.534102 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/17:/Table/5{1-2}] generated snapshot 309c1972 at index 135
I161116 07:22:15.537961 31828 storage/store.go:3134  [n5,replicate,s5,r7/17:/Table/5{1-2}] streamed snapshot: kv pairs: 40, log entries: 16
I161116 07:22:15.543237 37248 storage/replica_raftstorage.go:587  [n1,s1,r7/?:{-}] applying preemptive snapshot at index 135 (id=309c1972, encoded size=16, 1 rocksdb batches, 16 log entries)
I161116 07:22:15.546141 37248 storage/replica_raftstorage.go:590  [n1,s1,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.003s
I161116 07:22:15.549544 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:19 
I161116 07:22:15.616824 31828 storage/replica.go:2066  [n5,s5,r7/17:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:1 StoreID:1 ReplicaID:19}: [{NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:1 StoreID:1 ReplicaID:19}]
I161116 07:22:15.628678 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:1 store_id:1 replica_id:19 > next_replica_id:20 
I161116 07:22:15.674672 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot 5da210d9 at index 158
I161116 07:22:15.678612 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 44, log entries: 43
I161116 07:22:15.680321 37289 storage/replica_raftstorage.go:587  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 158 (id=5da210d9, encoded size=16, 1 rocksdb batches, 43 log entries)
I161116 07:22:15.685546 37289 storage/replica_raftstorage.go:590  [n3,s3,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.005s
I161116 07:22:15.688105 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:20 
I161116 07:22:15.695556 31828 storage/replica.go:2066  [n5,s5,r7/17:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14}]
I161116 07:22:15.713191 32480 storage/store.go:2986  [n2,s2,r7/18:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:15.777086 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:15.803998 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:15.862652 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:15.887892 31378 storage/store.go:2986  [n2,s2,r2/18:/Table/1{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:15.900346 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot 3491fbc2 at index 3275
I161116 07:22:15.962147 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1693, log entries: 51
I161116 07:22:15.964557 37279 storage/replica_raftstorage.go:587  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 3275 (id=3491fbc2, encoded size=16, 1 rocksdb batches, 51 log entries)
I161116 07:22:15.991886 37279 storage/replica_raftstorage.go:590  [n3,s3,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.027s
I161116 07:22:15.997329 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:20 
I161116 07:22:16.018054 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.034383 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:16.057505 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.072506 31378 storage/store.go:2986  [n2,s2,r1/18:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:16.079706 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot e3f24d7b at index 148
I161116 07:22:16.086208 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 69, log entries: 35
I161116 07:22:16.086346 30998 storage/replicate_queue_test.go:98  not balanced: [10 5 3 10 3]
I161116 07:22:16.091329 37329 storage/replica_raftstorage.go:587  [n3,s3,r3/?:{-}] applying preemptive snapshot at index 148 (id=e3f24d7b, encoded size=16, 1 rocksdb batches, 35 log entries)
I161116 07:22:16.095481 37329 storage/replica_raftstorage.go:590  [n3,s3,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.004s
I161116 07:22:16.100146 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:16.132449 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.156680 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:16.227319 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:4 StoreID:4 ReplicaID:19}]
I161116 07:22:16.241737 31378 storage/store.go:2986  [n2,s2,r3/18:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:16.611281 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/17:/Table/5{1-2}] generated snapshot 1ab73116 at index 143
I161116 07:22:16.616765 31828 storage/store.go:3134  [n5,replicate,s5,r7/17:/Table/5{1-2}] streamed snapshot: kv pairs: 42, log entries: 24
I161116 07:22:16.618270 37442 storage/replica_raftstorage.go:587  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 143 (id=1ab73116, encoded size=16, 1 rocksdb batches, 24 log entries)
I161116 07:22:16.620397 37442 storage/replica_raftstorage.go:590  [n3,s3,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.002s
I161116 07:22:16.622825 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > next_replica_id:20 
I161116 07:22:16.685562 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot 7da1d98b at index 137
I161116 07:22:16.690790 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 45, log entries: 25
I161116 07:22:16.692854 37450 storage/replica_raftstorage.go:587  [n3,s3,r9/?:{-}] applying preemptive snapshot at index 137 (id=7da1d98b, encoded size=16, 1 rocksdb batches, 25 log entries)
I161116 07:22:16.713243 37450 storage/replica_raftstorage.go:590  [n3,s3,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.020s
I161116 07:22:16.720466 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:20 
I161116 07:22:16.733269 31828 storage/replica.go:2066  [n5,s5,r7/17:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:14} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.744046 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:14 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:16.776430 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.791051 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:16.873737 31828 storage/replica.go:2066  [n5,s5,r7/17:/Table/5{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:14}: [{NodeID:1 StoreID:1 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.883480 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:16.891904 32639 storage/store.go:2986  [n4,s4,r7/14:/Table/5{1-2}] added to replica GC queue (peer suggestion)
I161116 07:22:16.894827 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r10/8:/{Table/54-Max}] generated snapshot b132168f at index 110
I161116 07:22:16.903468 31828 storage/store.go:3134  [n5,replicate,s5,r10/8:/{Table/54-Max}] streamed snapshot: kv pairs: 36, log entries: 100
I161116 07:22:16.908872 37438 storage/replica_raftstorage.go:587  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 110 (id=b132168f, encoded size=16, 1 rocksdb batches, 100 log entries)
I161116 07:22:16.917185 37438 storage/replica_raftstorage.go:590  [n3,s3,r10/?:/{Table/54-Max}] applied preemptive snapshot in 0.008s
I161116 07:22:16.922946 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:1 store_id:1 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:8 > next_replica_id:17 
I161116 07:22:17.003232 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:17}: [{NodeID:4 StoreID:4 ReplicaID:13} {NodeID:1 StoreID:1 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:8} {NodeID:3 StoreID:3 ReplicaID:17}]
I161116 07:22:17.018438 31828 storage/replica_command.go:3245  [n5,replicate,s5,r10/8:/{Table/54-Max}] change replicas: read existing descriptor range_id:10 start_key:"\276" end_key:"\377\377" replicas:<node_id:4 store_id:4 replica_id:13 > replicas:<node_id:1 store_id:1 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:8 > replicas:<node_id:3 store_id:3 replica_id:17 > next_replica_id:18 
I161116 07:22:17.087581 30998 storage/replicate_queue_test.go:98  not balanced: [10 3 7 8 3]
I161116 07:22:17.090869 31828 storage/replica.go:2066  [n5,s5,r10/8:/{Table/54-Max}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:13}: [{NodeID:3 StoreID:3 ReplicaID:17} {NodeID:1 StoreID:1 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:8}]
I161116 07:22:17.102129 32639 storage/store.go:2986  [n4,s4,r10/13:/{Table/54-Max}] added to replica GC queue (peer suggestion)
I161116 07:22:17.104025 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r8/13:/Table/5{2-3}] generated snapshot 82aa459b at index 122
I161116 07:22:17.114575 31828 storage/store.go:3134  [n5,replicate,s5,r8/13:/Table/5{2-3}] streamed snapshot: kv pairs: 38, log entries: 2
I161116 07:22:17.115983 37516 storage/replica_raftstorage.go:587  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 122 (id=82aa459b, encoded size=16, 1 rocksdb batches, 2 log entries)
I161116 07:22:17.120227 37516 storage/replica_raftstorage.go:590  [n3,s3,r8/?:/Table/5{2-3}] applied preemptive snapshot in 0.004s
I161116 07:22:17.124772 31828 storage/replica_command.go:3245  [n5,replicate,s5,r8/13:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:17 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:16 > next_replica_id:18 
I161116 07:22:17.207059 31828 storage/replica.go:2066  [n5,s5,r8/13:/Table/5{2-3}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:17} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:4 StoreID:4 ReplicaID:16} {NodeID:3 StoreID:3 ReplicaID:18}]
I161116 07:22:17.214728 31828 storage/replica_command.go:3245  [n5,replicate,s5,r8/13:/Table/5{2-3}] change replicas: read existing descriptor range_id:8 start_key:"\274" end_key:"\275" replicas:<node_id:1 store_id:1 replica_id:17 > replicas:<node_id:5 store_id:5 replica_id:13 > replicas:<node_id:4 store_id:4 replica_id:16 > replicas:<node_id:3 store_id:3 replica_id:18 > next_replica_id:19 
I161116 07:22:17.301702 31828 storage/replica.go:2066  [n5,s5,r8/13:/Table/5{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:16}: [{NodeID:1 StoreID:1 ReplicaID:17} {NodeID:5 StoreID:5 ReplicaID:13} {NodeID:3 StoreID:3 ReplicaID:18}]
I161116 07:22:17.319905 32639 storage/store.go:2986  [n4,s4,r8/16:/Table/5{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:17.493406 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 7f7a8542 at index 791
I161116 07:22:17.532607 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1768, log entries: 40
I161116 07:22:17.536927 37638 storage/replica_raftstorage.go:587  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 791 (id=7f7a8542, encoded size=16, 1 rocksdb batches, 40 log entries)
I161116 07:22:17.553083 37638 storage/replica_raftstorage.go:590  [n3,s3,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.016s
I161116 07:22:17.566225 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:18 > next_replica_id:19 
I161116 07:22:17.574771 31356 storage/replica_raftstorage.go:443  [n3,replicate,s3,r5/16:/Table/{14-50}] generated snapshot 3cf86494 at index 156
I161116 07:22:17.577858 31356 storage/store.go:3134  [n3,replicate,s3,r5/16:/Table/{14-50}] streamed snapshot: kv pairs: 48, log entries: 41
I161116 07:22:17.581551 37622 storage/replica_raftstorage.go:587  [n5,s5,r5/?:{-}] applying preemptive snapshot at index 156 (id=3cf86494, encoded size=16, 1 rocksdb batches, 41 log entries)
I161116 07:22:17.586008 37622 storage/replica_raftstorage.go:590  [n5,s5,r5/?:/Table/{14-50}] applied preemptive snapshot in 0.004s
I161116 07:22:17.588546 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:20 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:16 > next_replica_id:21 
I161116 07:22:17.635368 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:4 StoreID:4 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:19}]
I161116 07:22:17.676439 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:4 store_id:4 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:19 > next_replica_id:20 
I161116 07:22:17.717958 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:20} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:16} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:17.727409 31356 storage/replica_command.go:3245  [n3,replicate,s3,r5/16:/Table/{14-50}] change replicas: read existing descriptor range_id:5 start_key:"\226" end_key:"\272" replicas:<node_id:1 store_id:1 replica_id:20 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:16 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:17.762464 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:19}]
I161116 07:22:17.782956 31939 storage/store.go:2986  [n4,s4,r4/18:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:17.787767 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 76b1eccf at index 135
I161116 07:22:17.820821 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 42, log entries: 25
I161116 07:22:17.822399 37650 storage/replica_raftstorage.go:587  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 135 (id=76b1eccf, encoded size=16, 1 rocksdb batches, 25 log entries)
I161116 07:22:17.836774 37650 storage/replica_raftstorage.go:590  [n3,s3,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.014s
I161116 07:22:17.839321 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:20 
I161116 07:22:17.857101 31356 storage/replica.go:2066  [n3,s3,r5/16:/Table/{14-50}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21} {NodeID:3 StoreID:3 ReplicaID:16}]
I161116 07:22:17.867668 32418 storage/store.go:2986  [n4,s4,r5/19:/Table/{14-50}] added to replica GC queue (peer suggestion)
I161116 07:22:17.890587 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:3 StoreID:3 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:17.942396 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:18.011537 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:2 StoreID:2 ReplicaID:18}]
I161116 07:22:18.041824 31939 storage/store.go:2986  [n4,s4,r6/19:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:18.054067 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r4/1:/Table/1{3-4}] generated snapshot 59ac4012 at index 806
I161116 07:22:18.085424 31107 storage/store.go:3134  [n1,replicate,s1,r4/1:/Table/1{3-4}] streamed snapshot: kv pairs: 1805, log entries: 55
I161116 07:22:18.092339 37584 storage/replica_raftstorage.go:587  [n5,s5,r4/?:{-}] applying preemptive snapshot at index 806 (id=59ac4012, encoded size=16, 1 rocksdb batches, 55 log entries)
I161116 07:22:18.120324 37584 storage/replica_raftstorage.go:590  [n5,s5,r4/?:/Table/1{3-4}] applied preemptive snapshot in 0.028s
I161116 07:22:18.123095 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:19 > next_replica_id:20 
I161116 07:22:18.123280 30998 storage/replicate_queue_test.go:98  not balanced: [10 3 10 3 5]
I161116 07:22:18.211512 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:20}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:20}]
I161116 07:22:18.234033 31107 storage/replica_command.go:3245  [n1,replicate,s1,r4/1:/Table/1{3-4}] change replicas: read existing descriptor range_id:4 start_key:"\225" end_key:"\226" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:20 > next_replica_id:21 
I161116 07:22:18.315360 31107 storage/replica.go:2066  [n1,s1,r4/1:/Table/1{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:17}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:20} {NodeID:3 StoreID:3 ReplicaID:19}]
I161116 07:22:18.336673 31378 storage/store.go:2986  [n2,s2,r4/17:/Table/1{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:18.351803 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r6/1:/Table/5{0-1}] generated snapshot 7160fb37 at index 144
I161116 07:22:18.392199 31107 storage/store.go:3134  [n1,replicate,s1,r6/1:/Table/5{0-1}] streamed snapshot: kv pairs: 44, log entries: 34
I161116 07:22:18.397362 37719 storage/replica_raftstorage.go:587  [n5,s5,r6/?:{-}] applying preemptive snapshot at index 144 (id=7160fb37, encoded size=16, 1 rocksdb batches, 34 log entries)
I161116 07:22:18.400120 37719 storage/replica_raftstorage.go:590  [n5,s5,r6/?:/Table/5{0-1}] applied preemptive snapshot in 0.003s
I161116 07:22:18.403439 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:2 store_id:2 replica_id:18 > next_replica_id:21 
I161116 07:22:18.471887 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:18.485458 31107 storage/replica_command.go:3245  [n1,replicate,s1,r6/1:/Table/5{0-1}] change replicas: read existing descriptor range_id:6 start_key:"\272" end_key:"\273" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:18.572192 31107 storage/replica.go:2066  [n1,s1,r6/1:/Table/5{0-1}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:18.593225 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r3/1:/Table/1{2-3}] generated snapshot c85d8eb6 at index 154
I161116 07:22:18.594280 31378 storage/store.go:2986  [n2,s2,r6/18:/Table/5{0-1}] added to replica GC queue (peer suggestion)
I161116 07:22:18.596676 31107 storage/store.go:3134  [n1,replicate,s1,r3/1:/Table/1{2-3}] streamed snapshot: kv pairs: 71, log entries: 41
I161116 07:22:18.601114 37473 storage/replica_raftstorage.go:587  [n5,s5,r3/?:{-}] applying preemptive snapshot at index 154 (id=c85d8eb6, encoded size=16, 1 rocksdb batches, 41 log entries)
I161116 07:22:18.612083 37473 storage/replica_raftstorage.go:590  [n5,s5,r3/?:/Table/1{2-3}] applied preemptive snapshot in 0.011s
I161116 07:22:18.616091 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:4 store_id:4 replica_id:19 > next_replica_id:21 
I161116 07:22:18.768849 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:18.795043 31107 storage/replica_command.go:3245  [n1,replicate,s1,r3/1:/Table/1{2-3}] change replicas: read existing descriptor range_id:3 start_key:"\224" end_key:"\225" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:18.872245 31107 storage/replica.go:2066  [n1,s1,r3/1:/Table/1{2-3}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:18.902780 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r2/1:/Table/1{1-2}] generated snapshot fc6f11a2 at index 166
I161116 07:22:18.904400 31939 storage/store.go:2986  [n4,s4,r3/19:/Table/1{2-3}] added to replica GC queue (peer suggestion)
I161116 07:22:18.916543 31107 storage/store.go:3134  [n1,replicate,s1,r2/1:/Table/1{1-2}] streamed snapshot: kv pairs: 47, log entries: 51
I161116 07:22:18.926471 37676 storage/replica_raftstorage.go:587  [n5,s5,r2/?:{-}] applying preemptive snapshot at index 166 (id=fc6f11a2, encoded size=16, 1 rocksdb batches, 51 log entries)
I161116 07:22:18.929852 37676 storage/replica_raftstorage.go:590  [n5,s5,r2/?:/Table/1{1-2}] applied preemptive snapshot in 0.003s
I161116 07:22:18.933666 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:18.994641 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:19.017133 31107 storage/replica_command.go:3245  [n1,replicate,s1,r2/1:/Table/1{1-2}] change replicas: read existing descriptor range_id:2 start_key:"\223" end_key:"\224" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:19.079797 31107 storage/replica.go:2066  [n1,s1,r2/1:/Table/1{1-2}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:21} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:19.124340 30998 storage/replicate_queue_test.go:98  not balanced: [10 1 10 1 8]
I161116 07:22:19.363918 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r1/1:/{Min-Table/11}] generated snapshot c1276861 at index 3555
I161116 07:22:19.384246 31107 storage/store.go:3134  [n1,replicate,s1,r1/1:/{Min-Table/11}] streamed snapshot: kv pairs: 1732, log entries: 20
I161116 07:22:19.388083 37739 storage/replica_raftstorage.go:587  [n5,s5,r1/?:{-}] applying preemptive snapshot at index 3555 (id=c1276861, encoded size=16, 1 rocksdb batches, 20 log entries)
I161116 07:22:19.396745 37739 storage/replica_raftstorage.go:590  [n5,s5,r1/?:/{Min-Table/11}] applied preemptive snapshot in 0.009s
I161116 07:22:19.399038 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:19.424403 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:4 StoreID:4 ReplicaID:19} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:19.442149 31107 storage/replica_command.go:3245  [n1,replicate,s1,r1/1:/{Min-Table/11}] change replicas: read existing descriptor range_id:1 start_key:"" end_key:"\223" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:4 store_id:4 replica_id:19 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:19.482694 31107 storage/replica.go:2066  [n1,s1,r1/1:/{Min-Table/11}] proposing REMOVE_REPLICA {NodeID:4 StoreID:4 ReplicaID:19}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:21} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:19.513745 31939 storage/store.go:2986  [n4,s4,r1/19:/{Min-Table/11}] added to replica GC queue (peer suggestion)
I161116 07:22:19.565018 31107 storage/replica_raftstorage.go:443  [n1,replicate,s1,r9/1:/Table/5{3-4}] generated snapshot e22fddae at index 144
I161116 07:22:19.570538 37744 storage/replica_raftstorage.go:587  [n5,s5,r9/?:{-}] applying preemptive snapshot at index 144 (id=e22fddae, encoded size=16, 1 rocksdb batches, 32 log entries)
I161116 07:22:19.572929 37744 storage/replica_raftstorage.go:590  [n5,s5,r9/?:/Table/5{3-4}] applied preemptive snapshot in 0.002s
I161116 07:22:19.573875 31107 storage/store.go:3134  [n1,replicate,s1,r9/1:/Table/5{3-4}] streamed snapshot: kv pairs: 47, log entries: 32
I161116 07:22:19.577474 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:19.619958 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing ADD_REPLICA {NodeID:5 StoreID:5 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:2 StoreID:2 ReplicaID:18} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:5 StoreID:5 ReplicaID:21}]
I161116 07:22:19.631014 31107 storage/replica_command.go:3245  [n1,replicate,s1,r9/1:/Table/5{3-4}] change replicas: read existing descriptor range_id:9 start_key:"\275" end_key:"\276" replicas:<node_id:1 store_id:1 replica_id:1 > replicas:<node_id:2 store_id:2 replica_id:18 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:5 store_id:5 replica_id:21 > next_replica_id:22 
I161116 07:22:19.672225 31107 storage/replica.go:2066  [n1,s1,r9/1:/Table/5{3-4}] proposing REMOVE_REPLICA {NodeID:2 StoreID:2 ReplicaID:18}: [{NodeID:1 StoreID:1 ReplicaID:1} {NodeID:5 StoreID:5 ReplicaID:21} {NodeID:3 StoreID:3 ReplicaID:20}]
I161116 07:22:19.689545 31378 storage/store.go:2986  [n2,s2,r9/18:/Table/5{3-4}] added to replica GC queue (peer suggestion)
I161116 07:22:19.917737 31828 storage/replica_raftstorage.go:443  [n5,replicate,s5,r7/17:/Table/5{1-2}] generated snapshot 244cbd49 at index 150
I161116 07:22:19.921685 31828 storage/store.go:3134  [n5,replicate,s5,r7/17:/Table/5{1-2}] streamed snapshot: kv pairs: 44, log entries: 31
I161116 07:22:19.922832 37775 storage/replica_raftstorage.go:587  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 150 (id=244cbd49, encoded size=16, 1 rocksdb batches, 31 log entries)
I161116 07:22:19.925600 37775 storage/replica_raftstorage.go:590  [n2,s2,r7/?:/Table/5{1-2}] applied preemptive snapshot in 0.003s
I161116 07:22:19.928237 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:20 > next_replica_id:21 
I161116 07:22:20.026907 31828 storage/replica.go:2066  [n5,s5,r7/17:/Table/5{1-2}] proposing ADD_REPLICA {NodeID:2 StoreID:2 ReplicaID:21}: [{NodeID:1 StoreID:1 ReplicaID:19} {NodeID:5 StoreID:5 ReplicaID:17} {NodeID:3 StoreID:3 ReplicaID:20} {NodeID:2 StoreID:2 ReplicaID:21}]
I161116 07:22:20.049791 31828 storage/replica_command.go:3245  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas: read existing descriptor range_id:7 start_key:"\273" end_key:"\274" replicas:<node_id:1 store_id:1 replica_id:19 > replicas:<node_id:5 store_id:5 replica_id:17 > replicas:<node_id:3 store_id:3 replica_id:20 > replicas:<node_id:2 store_id:2 replica_id:21 > next_replica_id:22 
I161116 07:22:20.124794 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.126436 37861 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
W161116 07:22:20.126538 32319 storage/raft_transport.go:443  [n2] raft transport stream to node 4 failed: EOF
W161116 07:22:20.127272 32268 storage/raft_transport.go:443  [n5] raft transport stream to node 1 failed: EOF
W161116 07:22:20.127763 32420 storage/raft_transport.go:443  [n3] raft transport stream to node 4 failed: EOF
W161116 07:22:20.128373 31312 storage/raft_transport.go:443  [n2] raft transport stream to node 1 failed: EOF
W161116 07:22:20.128761 31498 gossip/gossip.go:1119  [n4] no incoming or outgoing connections
I161116 07:22:20.130679 37865 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      storage/intent_resolver.go:383
1      kv/txn_coord_sender.go:918
1      gossip/infostore.go:301
W161116 07:22:20.132137 32573 storage/raft_transport.go:443  [n5] raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.133541 32345 storage/raft_transport.go:443  [n4] raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.133814 31584 storage/raft_transport.go:443  [n3] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.134385 31756 storage/raft_transport.go:443  [n1] raft transport stream to node 4 failed: EOF
W161116 07:22:20.135553 32637 storage/raft_transport.go:443  [n4] raft transport stream to node 5 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.135964 37823 storage/intent_resolver.go:380  could not GC completed transaction anchored at /Local/Range/"\xbb"/RangeDescriptor: context canceled
W161116 07:22:20.136326 31761 storage/raft_transport.go:443  [n4] raft transport stream to node 1 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.137874 32394 storage/raft_transport.go:443  [n3] raft transport stream to node 2 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.139230 34931 storage/raft_transport.go:443  [n3] raft transport stream to node 5 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.139814 31199 storage/raft_transport.go:443  [n1] raft transport stream to node 2 failed: EOF
W161116 07:22:20.140377 32450 storage/raft_transport.go:443  [n2] raft transport stream to node 3 failed: EOF
W161116 07:22:20.140749 31370 storage/raft_transport.go:443  [n1] raft transport stream to node 3 failed: EOF
W161116 07:22:20.142143 31616 gossip/gossip.go:1119  [n5] no incoming or outgoing connections
E161116 07:22:20.150371 31828 internal/client/txn.go:331  [n5,replicate,s5,r7/17:/Table/5{1-2}] failure aborting transaction: writing transaction timed out or ran on multiple coordinators; abort caused by: context canceled
E161116 07:22:20.150922 31828 storage/queue.go:575  [n5,replicate,s5,r7/17:/Table/5{1-2}] change replicas of range 7 failed: context canceled
W161116 07:22:20.150994 34846 storage/raft_transport.go:443  [n5] raft transport stream to node 3 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.151447 32365 storage/raft_transport.go:443  [n4] raft transport stream to node 3 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.167271 32263 storage/raft_transport.go:443  [n1] raft transport stream to node 5 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.168220 32706 storage/raft_transport.go:443  [n5] raft transport stream to node 4 failed: rpc error: code = 13 desc = transport is closing
W161116 07:22:20.168500 31142 gossip/gossip.go:1119  [n2] no incoming or outgoing connections
W161116 07:22:20.170343 31110 storage/replica.go:1810  [n1,timeSeriesMaintenance,s1,r1/1:/{Min-Table/11}] shutdown cancellation of command DeleteRange [/System/tsd/insufficient bytes to decode uvarint value,/System/tsd/cr.node.sql.misc.count//10s/2016-10-17T07:00:00Z)
W161116 07:22:20.171548 32464 storage/raft_transport.go:443  [n2] raft transport stream to node 5 failed: rpc error: code = 13 desc = transport is closing
E161116 07:22:20.171617 31110 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r1/1:/{Min-Table/11}] result is ambiguous
I161116 07:22:20.171796 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.172178 30925 kv/transport_race.go:71  transport race promotion: ran 160 iterations on up to 7738 requests
E161116 07:22:20.193983 31173 storage/node_liveness.go:141  [n2,hb] failed liveness heartbeat: node unavailable; try another peer
I161116 07:22:20.197243 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.202641 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.207635 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.217412 30998 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- FAIL: TestReplicateQueueRebalance (51.75s)
	<autogenerated>:12: storage/replicate_queue_test.go:103, condition failed to evaluate within 45s: not balanced: [10 1 10 1 8]
=== RUN   TestEagerReplication
I161116 07:22:20.236010 37786 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:22:20.237200 37786 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:22:20.237296 37786 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:22:20.237489 37786 base/node_id.go:62  NodeID set to 1
I161116 07:22:20.237636 37786 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:22:20.251432 37786 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:22:20.253705 37793 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000124ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]
I161116 07:22:20.257170 37947 storage/split_queue.go:103  [split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:22:20.261677 37947 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:22:20.270502 37947 storage/replica_command.go:2361  [s1,r2/1:/{Table/11-Max}] initiating a split of this range at key /Table/12 [r3]
E161116 07:22:20.274407 37948 storage/queue.go:586  [replicate,s1,r1/1:/{Min-Table/11}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
W161116 07:22:20.286042 37947 storage/stores.go:218  range not contained in one range: [/Meta2/Table/12,/Table/12/NULL), but have [/Min,/Table/11)
W161116 07:22:20.298709 37955 storage/intent_resolver.go:314  [n1,s1,r1/1:/{Min-Table/11}]: failed to push during intent resolution: failed to push "storage/replica_command.go:2440 (*Replica).AdminSplit" id=5bc4a683 key=/Local/Range/"\x93"/RangeDescriptor rw=true pri=0.01191776 iso=SERIALIZABLE stat=PENDING epo=0 ts=0.000000123,62 orig=0.000000123,62 max=0.000000123,62 wto=false rop=false
E161116 07:22:20.306200 37948 storage/queue.go:586  [replicate,s1,r2/1:/Table/1{1-2}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.311586 37947 storage/replica_command.go:2361  [s1,r3/1:/{Table/12-Max}] initiating a split of this range at key /Table/13 [r4]
E161116 07:22:20.354838 37948 storage/queue.go:586  [replicate,s1,r3/1:/Table/1{2-3}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.356879 37947 storage/replica_command.go:2361  [s1,r4/1:/{Table/13-Max}] initiating a split of this range at key /Table/14 [r5]
E161116 07:22:20.370834 37948 storage/queue.go:586  [replicate,s1,r4/1:/Table/1{3-4}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
E161116 07:22:20.371643 37948 storage/queue.go:586  [replicate,s1,r5/1:/{Table/14-Max}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.392348 37786 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestEagerReplication (0.17s)
=== RUN   TestTimeSeriesMaintenanceQueue
I161116 07:22:20.411628 37867 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:22:20.416782 37867 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:22:20.418015 37867 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:22:20.418152 37867 base/node_id.go:62  NodeID set to 1
I161116 07:22:20.419699 37867 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"" address_field:"" > attrs:<> locality:<> 
I161116 07:22:20.430944 37867 storage/store.go:1188  [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I161116 07:22:20.437930 37977 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h22m21.331213482s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:22:20.437802712 +0000 UTC]
I161116 07:22:20.445274 37867 storage/replica_command.go:2361  [s1,r1/1:/M{in-ax}] initiating a split of this range at key "c" [r2]
E161116 07:22:20.454727 37918 storage/queue.go:586  [replicate,s1,r1/1:{/Min-"c"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.456106 37867 storage/replica_command.go:2361  [s1,r1/1:{/Min-"c"}] initiating a split of this range at key "b" [r3]
E161116 07:22:20.474578 37918 storage/queue.go:586  [replicate,s1,r3/1:"{b"-c"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.475776 37867 storage/replica_command.go:2361  [s1,r1/1:{/Min-"b"}] initiating a split of this range at key "a" [r4]
E161116 07:22:20.488123 37918 storage/queue.go:586  [replicate,s1,r4/1:"{a"-b"}] purgatory: 0 of 0 stores with an attribute matching []; likely not enough nodes in cluster
I161116 07:22:20.489833 37867 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: TestTimeSeriesMaintenanceQueue (0.14s)
=== RUN   TestTimeSeriesMaintenanceQueueServer
I161116 07:22:20.553090 37802 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:22:20.553190 37802 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
W161116 07:22:20.635090 37802 server/status/runtime.go:116  Could not parse build timestamp: parsing time "" as "2006/01/02 15:04:05": cannot parse "" as "2006"
I161116 07:22:20.636766 37802 storage/engine/rocksdb.go:340  opening in memory rocksdb instance
I161116 07:22:20.637555 37802 server/config.go:443  1 storage engine initialized
I161116 07:22:20.638758 37802 server/node.go:421  [n?] store [n0,s0] not bootstrapped
I161116 07:22:20.647193 38047 storage/replica_proposal.go:332  [s1,r1/1:/M{in-ax}] new range lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 410911h22m29.645280986s following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0s [physicalTime=2016-11-16 07:22:20.647069148 +0000 UTC]
I161116 07:22:20.650423 37802 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:20.651812 37802 server/node.go:350  [n?] **** cluster f89c17a7-ba0a-413d-89e4-06fab1701a94 has been created
I161116 07:22:20.651865 37802 server/node.go:351  [n?] **** add additional nodes by specifying --join=127.0.0.1:56969
I161116 07:22:20.652936 37802 base/node_id.go:62  [n1] NodeID set to 1
I161116 07:22:20.663056 37802 server/node.go:434  [n1] initialized store [n1,s1]: {Capacity:536870912 Available:536870912 RangeCount:0 LeaseCount:0}
I161116 07:22:20.663198 37802 server/node.go:319  [n1] node ID 1 initialized
I161116 07:22:20.664479 37802 gossip/gossip.go:283  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"127.0.0.1:56969" > attrs:<> locality:<> 
I161116 07:22:20.665472 38099 storage/split_queue.go:103  [n1,split,s1,r1/1:/M{in-ax}] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I161116 07:22:20.665826 37802 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I161116 07:22:20.666403 37802 server/node.go:564  [n1] connecting to gossip network to verify cluster ID...
I161116 07:22:20.666488 37802 server/node.go:584  [n1] node connected via gossip and verified as part of cluster "f89c17a7-ba0a-413d-89e4-06fab1701a94"
I161116 07:22:20.666858 37802 server/node.go:369  [n1] node=1: started with [[]=] engine(s) and attributes []
I161116 07:22:20.667405 37802 server/server.go:630  [n1] starting https server at 127.0.0.1:52449
I161116 07:22:20.667438 37802 server/server.go:631  [n1] starting grpc/postgres server at 127.0.0.1:56969
I161116 07:22:20.667467 37802 server/server.go:632  [n1] advertising CockroachDB node at 127.0.0.1:56969
I161116 07:22:20.687188 38099 storage/replica_command.go:2361  [n1,split,s1,r1/1:/M{in-ax}] initiating a split of this range at key /Table/11 [r2]
I161116 07:22:20.708713 37900 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:56969} Attrs: Locality:} ClusterID:f89c17a7-ba0a-413d-89e4-06fab1701a94 StartedAt:1479280940666563531}
I161116 07:22:20.789698 38099 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/12 [r3]
I161116 07:22:20.841765 38099 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/13 [r4]
I161116 07:22:21.034639 38099 storage/replica_command.go:2361  [n1,split,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /Table/14 [r5]
I161116 07:22:21.198453 37802 storage/replica_command.go:2361  [n1,s1,r1/1:/{Min-Table/11}] initiating a split of this range at key /System/tsd/test.metric/source1/10s/2016-08-18T07:00:00Z [r6]
I161116 07:22:23.815324 37802 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
I161116 07:22:23.815477 37802 util/stop/stopper.go:468  quiescing; tasks left:
1      storage/queue.go:477
1      server/node.go:854
W161116 07:22:23.816383 38103 storage/replica.go:1810  [n1,timeSeriesMaintenance,s1,r6/1:/{System/tsd/t-Table/11}] shutdown cancellation of command DeleteRange [/System/tsd/test.metric/source1/10s/2016-08-18T07:00:00Z,/System/tsd/test.metric//10s/2016-10-17T07:00:00Z)
E161116 07:22:23.817160 38103 storage/queue.go:575  [n1,timeSeriesMaintenance,s1,r6/1:/{System/tsd/t-Table/11}] result is ambiguous
I161116 07:22:23.847300 38115 kv/transport_race.go:71  transport race promotion: ran 30 iterations on up to 1195 requests
--- PASS: TestTimeSeriesMaintenanceQueueServer (3.31s)
=== RUN   Example_rebalancing
I161116 07:22:23.850763 1 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:22:23.850899 1 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:22:23.851114 1 base/node_id.go:62  NodeID set to 1
I161116 07:22:24.810051 1 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: Example_rebalancing (0.96s)
=== RUN   Example_rebalancingWithRuleSolver
I161116 07:22:24.810915 1 gossip/gossip.go:241  [n?] initial resolvers: []
W161116 07:22:24.811005 1 gossip/gossip.go:1117  [n?] no resolvers found; use --join to specify a connected node
I161116 07:22:24.811149 1 base/node_id.go:62  NodeID set to 1
I161116 07:22:25.822308 1 util/stop/stopper.go:396  stop has been called, stopping or quiescing all running tasks
--- PASS: Example_rebalancingWithRuleSolver (1.01s)
FAIL


ERROR: exit status 1

make: *** [stress] Error 1
8 runs completed, 1 failures, over 2m3s
FAIL
Makefile:128: recipe for target 'stress' failed
