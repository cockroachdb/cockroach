// Copyright 2019 The Cockroach Authors.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package main

import (
	"context"
	"fmt"
	"io/ioutil"
	"math"
	"path/filepath"
	"strings"
	"time"

	"github.com/cockroachdb/cockroach/pkg/util/search"
	"github.com/cockroachdb/cockroach/pkg/workload/histogram"
	"github.com/cockroachdb/ttycolor"
	"github.com/codahale/hdrhistogram"
	"github.com/pkg/errors"
)

// kvBenchKeyDistribution represents the distribution of keys generated by `workload`.
type kvBenchKeyDistribution int

const (
	sequential kvBenchKeyDistribution = iota
	random
	zipfian
)

type kvBenchSpec struct {
	Nodes                  int
	CPUs                   int
	KeyDistribution        kvBenchKeyDistribution
	EstimatedMaxThroughput int
	LatencyThresholdMs     float64
	// Number of shards that the primary key `k` is sharded with.
	NumShards int
	// If true, we manually pre-split the `kv` table to create exactly as many splits as
	// there are shards. This should, in theory, split a sequential write load evenly
	// across all the shards. Note that a hash-sharded index combined with our load-based
	// splitting mechanism should achieve something similar to this, but that would take
	// too long for it to be feasibly relied upon for the purposes of this benchmark.
	ShouldPreSplitTable bool
	SecondaryIndex      bool
	RampDurationSecs    int
	LoadDurationSecs    int
	MinVersion          string
	Tags                []string
}

func registerKVBenchSpec(r *testRegistry, b kvBenchSpec) {
	nameParts := []string{
		"kvbench",
		fmt.Sprintf("nodes=%d", b.Nodes),
		fmt.Sprintf("cpu=%d", b.CPUs),
		fmt.Sprintf("shards=%d", b.NumShards),
	}

	opts := []createOption{cpu(b.CPUs)}
	switch b.KeyDistribution {
	case sequential:
		nameParts = append(nameParts, "sequential")
	case random:
		nameParts = append(nameParts, "random")
	case zipfian:
		nameParts = append(nameParts, "zipfian")
	default:
		panic("unexpected")
	}

	switch b.SecondaryIndex {
	case true:
		nameParts = append(nameParts, "with_secondary")
	case false:
		nameParts = append(nameParts, "without_secondary")
	}

	name := strings.Join(nameParts, "/")
	nodes := makeClusterSpec(b.Nodes+1, opts...)
	r.Add(testSpec{
		Name:       name,
		Cluster:    nodes,
		MinVersion: b.MinVersion,
		Tags:       b.Tags,
		Run: func(ctx context.Context, t *test, c *cluster) {
			runKVBench(ctx, t, c, b)
		},
	})
}

func registerKVBench(r *testRegistry) {
	specs := []kvBenchSpec{
		{
			Nodes:                  5,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 30000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              10,
			ShouldPreSplitTable:    true,
		},
		{
			Nodes:                  5,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 20000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              0,
			ShouldPreSplitTable:    false,
		},
		{
			Nodes:                  10,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 60000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              20,
			ShouldPreSplitTable:    true,
		},
		{
			Nodes:                  10,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 20000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              0,
			ShouldPreSplitTable:    false,
		},
		{
			Nodes:                  20,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 110000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              40,
			ShouldPreSplitTable:    true,
		},
		{
			Nodes:                  20,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 20000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         false,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              0,
			ShouldPreSplitTable:    false,
		},
		{
			Nodes:                  5,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 10000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         true,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              10,
			ShouldPreSplitTable:    true,
		},
		{
			Nodes:                  5,
			CPUs:                   8,
			KeyDistribution:        sequential,
			EstimatedMaxThroughput: 5000,
			LatencyThresholdMs:     10.0,
			SecondaryIndex:         true,
			RampDurationSecs:       300,
			LoadDurationSecs:       300,
			NumShards:              0,
			ShouldPreSplitTable:    false,
		},
	}

	for _, b := range specs {
		registerKVBenchSpec(r, b)
	}
}

func makeKVLoadGroup(c *cluster, numRoachNodes, numLoadNodes int) loadGroup {
	return loadGroup{
		roachNodes: c.Range(1, numRoachNodes),
		loadNodes:  c.Range(numRoachNodes+1, numRoachNodes+numLoadNodes),
	}
}

// KVBench is a benchmarking tool that runs the `kv` workload against CockroachDB based on
// various configuration settings (see `kvBenchSpec`). The tool searches for the maximum
// throughput that can be sustained while maintaining an average latency below a certain
// threshold (as described in the configuration).
//
// This tool was primarily written with the objective of demonstrating the write
// performance characteristics of using hash sharded indexes, for sequential workloads
// which would've otherwise created a single-range hotspot.
func runKVBench(ctx context.Context, t *test, c *cluster, b kvBenchSpec) {
	loadGroup := makeKVLoadGroup(c, b.Nodes, 1)
	roachNodes := loadGroup.roachNodes
	loadNodes := loadGroup.loadNodes

	c.PutE(ctx, t.l, cockroach, "./cockroach", roachNodes)
	c.PutE(ctx, t.l, workload, "./workload", loadNodes)

	const restartWait = 15 * time.Second
	// TODO(aayush): I do not have a good reasoning for why I chose this precision value.
	precision := int(math.Max(1.0, float64(b.EstimatedMaxThroughput/50)))
	initStepSize := 2 * precision
	// Search between 100 and 10000000 for the max throughput that can be maintained while
	// sustaining an avg latency of less than `LatencyThresholdMs`.
	// TODO(aayush): `avg` here is just an arbitrary statistic, should I make the
	// concerned statistic a config option?
	resultsDir, err := ioutil.TempDir("", "roachtest-kvbench")
	if err != nil {
		t.Fatal(errors.Wrapf(err, `failed to create temp results dir`))
	}
	s := search.NewLineSearcher(100, 10000000, b.EstimatedMaxThroughput, initStepSize, precision)
	searchPredicate := func(maxrate int) (bool, error) {
		m := newMonitor(ctx, c, roachNodes)
		// Restart
		m.ExpectDeaths(int32(len(roachNodes)))
		c.Stop(ctx, roachNodes)
		c.Start(ctx, t, []option{roachNodes}...)
		time.Sleep(restartWait)

		// We currently only support one loadGroup.
		resultChan := make(chan *result, 1)
		m.Go(func(ctx context.Context) error {
			db := c.Conn(ctx, 1)

			initCmd := strings.Builder{}
			// Remove the `kv` table from the last run, if it exists, in order to maintain
			// isolation among separate runs. This is important due to factors like
			// load-based splitting, which can significantly change the underlying layout
			// of the table and affect benchmark results.
			fmt.Fprintf(&initCmd, `./workload init kv --drop --num-shards=%d {pgurl%s}`,
				b.NumShards, roachNodes)
			if b.SecondaryIndex {
				initCmd.WriteString(` --secondary-index`)
			}
			if err := c.RunE(ctx, loadNodes, initCmd.String()); err != nil {
				return err
			}

			if b.NumShards == 0 && b.ShouldPreSplitTable {
				// We could be silent here and ignore the 'splitting' if `NumShards` is 0
				// but failing seems like a better idea since this is almost certainly a
				// configuration error.
				panic(`ShouldPreSplitTable only applies to sharded` +
					`kv schemas (ie NumShards > 0)`)
			}
			splitCmd := strings.Builder{}
			if b.NumShards > 0 && b.ShouldPreSplitTable {
				// TODO(aayush): Change this to use the "easier" hash sharded index syntax
				// once that is in.
				splitCmd.WriteString(`USE kv; ALTER TABLE kv SPLIT AT VALUES `)

				for i := 0; i < b.NumShards; i++ {
					if i != 0 {
						splitCmd.WriteString(`,`)
					}
					fmt.Fprintf(&splitCmd, `(%d)`, i)
				}
				splitCmd.WriteString(`;`)
			}
			if _, err := db.Exec(splitCmd.String()); err != nil {
				t.l.Printf(splitCmd.String())
				return err
			}

			workloadCmd := strings.Builder{}
			clusterHistPath := fmt.Sprintf("%s/kvbench/maxrate=%d/stats.json",
				perfArtifactsDir, maxrate)

			// The number of workers running on the loadGen node must be high enough to
			// fully saturate the loadGen node since the free variable here is the value
			// of the `--max-rate` flag passed to workload and not the level of
			// concurrency.
			//
			// To understand why this is needed, note that if this concurrency value were
			// too low, we would be searching indefinitely since we would never hit
			// throughput values that are greater than or equal to `maxrate`, and this
			// would lead to the `searchPredicate` always returning true as long as the
			// latency at this throughput ceiling was below the configured threshold.
			const loadConcurrency int = 128

			fmt.Fprintf(&workloadCmd,
				`./workload run kv --ramp=%ds --duration=%ds {pgurl%s}`+
					` --concurrency=%d --histograms=%s --max-rate=%d --num-shards=%d`,
				b.RampDurationSecs, b.LoadDurationSecs, roachNodes,
				b.CPUs*loadConcurrency, clusterHistPath, maxrate, b.NumShards)
			switch b.KeyDistribution {
			case sequential:
				workloadCmd.WriteString(` --sequential`)
			case zipfian:
				workloadCmd.WriteString(` --zipfian`)
			case random:
				// Nothing, since random is the default.
			default:
				panic(`unexpected`)
			}

			err := c.RunE(ctx, loadNodes, workloadCmd.String())
			if err != nil {
				return errors.Wrapf(err, `error running workload`)
			}

			localHistPath := filepath.Join(resultsDir, fmt.Sprintf(`kvbench-%d-stats.json`, maxrate))
			if err := c.Get(ctx, t.l, clusterHistPath, localHistPath, loadNodes); err != nil {
				t.Fatal(err)
			}

			snapshots, err := histogram.DecodeSnapshots(localHistPath)
			if err != nil {
				return errors.Wrapf(err, `failed to decode histogram snapshots`)
			}

			res := newResultFromSnapshots(maxrate, snapshots)
			resultChan <- res
			return nil
		})

		if err := m.WaitE(); err != nil {
			return false, err
		}
		close(resultChan)
		res := <-resultChan
		failErr := res.failureError(b)
		if failErr == nil {
			ttycolor.Stdout(ttycolor.Green)
			t.l.Printf(`--- PASS: kv workload maintained an average latency of %0.1fms`+
				` with avg throughput of %d`, res.latency(), res.throughput())
		} else {
			ttycolor.Stdout(ttycolor.Red)
			t.l.Printf(`--- FAIL: kv workload maintained an average latency of %0.1fms (threshold: %0.1fms)`+
				` with avg throughput of %d`, res.latency(), b.LatencyThresholdMs, res.throughput())
		}
		ttycolor.Stdout(ttycolor.Reset)
		return failErr == nil, nil
	}
	if res, err := s.Search(searchPredicate); err != nil {
		t.Fatal(err)
	} else {
		ttycolor.Stdout(ttycolor.Green)
		t.l.Printf("-------\nMAX THROUGHPUT = %d\n--------\n\n", res)
		ttycolor.Stdout(ttycolor.Reset)
	}
}

type result struct {
	Cumulative map[string]*hdrhistogram.Histogram
	Elapsed    time.Duration
}

// TODO(aayush): The result related logic below is similar to `workload/tpcc/result.go`,
// so this could definitely be cleaner and better abstracted.
func newResultFromSnapshots(maxrate int, snapshots map[string][]histogram.SnapshotTick) *result {
	var start time.Time
	var end time.Time
	ret := make(map[string]*hdrhistogram.Histogram, len(snapshots))
	for n, snaps := range snapshots {
		var cur *hdrhistogram.Histogram
		for _, s := range snaps {
			h := hdrhistogram.Import(s.Hist)
			if cur == nil {
				cur = h
			} else {
				cur.Merge(h)
			}
			if start.IsZero() || s.Now.Before(start) {
				start = s.Now
			}
			if sEnd := s.Now.Add(s.Elapsed); end.IsZero() || sEnd.After(end) {
				end = sEnd
			}
		}
		ret[n] = cur
	}
	return &result{
		Cumulative: ret,
		Elapsed:    end.Sub(start),
	}
}

func (r result) latency() float64 {
	return time.Duration(r.Cumulative[`write`].Mean()).Seconds() * 1000
}

func (r result) throughput() int {
	// Currently the `kv` workload does not track histograms purely for throughput. We can
	// compute the average throughput here but not much more than that.
	return int(float64(r.Cumulative[`write`].TotalCount()) / r.Elapsed.Seconds())
}

func (r result) failureError(b kvBenchSpec) error {
	if r.latency() <= b.LatencyThresholdMs {
		return nil
	}
	return errors.Errorf(`average latency is too high %0.1fms`, r.latency())
}
