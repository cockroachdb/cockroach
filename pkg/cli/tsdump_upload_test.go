// Copyright 2025 The Cockroach Authors.
//
// Use of this software is governed by the CockroachDB Software License
// included in the /LICENSE file.

package cli

import (
	"compress/gzip"
	"encoding/csv"
	"encoding/gob"
	"fmt"
	"io"
	"net/http"
	"net/http/httptest"
	"os"
	"strconv"
	"strings"
	"testing"
	"time"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
	"github.com/cockroachdb/cockroach/pkg/roachpb"
	"github.com/cockroachdb/cockroach/pkg/testutils"
	"github.com/cockroachdb/cockroach/pkg/ts"
	"github.com/cockroachdb/cockroach/pkg/ts/tspb"
	"github.com/cockroachdb/cockroach/pkg/util/leaktest"
	"github.com/cockroachdb/cockroach/pkg/util/log"
	"github.com/cockroachdb/datadriven"
	"github.com/stretchr/testify/require"
)

// TestTSDumpUploadE2E tests the end-to-end functionality of uploading a time
// series dump to Datadog from a user perspective. This runs the tsdump command
// externally. The datadog API is mocked to capture the request and verify the
// uploaded data.
func TestTSDumpUploadE2E(t *testing.T) {
	defer leaktest.AfterTest(t)()
	defer log.Scope(t).Close(t)
	defer testutils.TestingHook(&getCurrentTime, func() time.Time {
		return time.Date(2024, 11, 14, 0, 0, 0, 0, time.UTC)
	})()
	defer testutils.TestingHook(&getHostname, func() string {
		return "hostname"
	})()

	datadriven.RunTest(t, "testdata/tsdump_upload_e2e", func(t *testing.T, d *datadriven.TestData) string {
		var buf strings.Builder
		server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			reader, err := gzip.NewReader(r.Body)
			require.NoError(t, err)
			body, err := io.ReadAll(reader)
			require.NoError(t, err)
			fmt.Fprintln(&buf, string(body))
			w.WriteHeader(http.StatusOK)
		}))
		defer testutils.TestingHook(&hostNameOverride, server.Listener.Addr().String())()
		defer server.Close()

		c := NewCLITest(TestCLIParams{})
		defer c.Cleanup()

		switch d.Cmd {
		case "upload-datadog":
			debugTimeSeriesDumpOpts.clusterLabel = "test-cluster"
			debugTimeSeriesDumpOpts.clusterID = "test-cluster-id"
			debugTimeSeriesDumpOpts.zendeskTicket = "zd-test"
			debugTimeSeriesDumpOpts.organizationName = "test-org"
			debugTimeSeriesDumpOpts.userName = "test-user"
			dumpFilePath := generateMockTSDumpFromCSV(t, d.Input)

			var clusterLabel, apiKey string
			if d.HasArg("cluster-label") {
				d.ScanArgs(t, "cluster-label", &clusterLabel)
			} else {
				clusterLabel = "test-cluster"
			}
			if d.HasArg("api-key") {
				d.ScanArgs(t, "api-key", &apiKey)
			} else {
				apiKey = "dd-api-key"
			}

			// Run the command
			_, err := c.RunWithCapture(fmt.Sprintf(
				`debug tsdump --format=datadog --dd-api-key="%s" --cluster-label="%s" %s`,
				apiKey, clusterLabel, dumpFilePath,
			))
			require.NoError(t, err)
			return strings.TrimSpace(buf.String())

		default:
			t.Fatalf("unknown command: %s", d.Cmd)
			return ""
		}
	})
}

// generateMockTSDumpFromCSV creates a mock tsdump file from CSV input string.
// CSV format: metric_name,timestamp,source,value
// Example: cr.node.admission.admitted.elastic-cpu,2025-05-26T08:32:00Z,1,1
// NOTE: this is the same format generated by the `cockroach tsdump` command
// when --format=csv is used.
func generateMockTSDumpFromCSV(t *testing.T, csvInput string) string {
	t.Helper()

	// Parse CSV data from input string
	reader := csv.NewReader(strings.NewReader(csvInput))
	csvData, err := reader.ReadAll()
	require.NoError(t, err)
	require.Greater(t, len(csvData), 0, "CSV input must have at least one data row")

	// Create temporary file
	tmpFile, err := os.CreateTemp("", "mock_tsdump_*.gob")
	require.NoError(t, err)
	defer tmpFile.Close()

	// Create gob encoder
	encoder := gob.NewEncoder(tmpFile)

	// Process each row (no header expected)
	for i, row := range csvData {
		require.Len(t, row, 4, "CSV row %d must have 4 columns: metric_name,timestamp,source,value", i+1)

		metricName := row[0]
		timestampStr := row[1]
		source := row[2]
		valueStr := row[3]

		// Parse timestamp (RFC3339 format)
		timestamp, err := time.Parse(time.RFC3339, timestampStr)
		require.NoError(t, err, "invalid timestamp format in row %d: %s (expected RFC3339)", i+1, timestampStr)
		timestampNanos := timestamp.UnixNano()

		// Parse value
		value, err := strconv.ParseFloat(valueStr, 64)
		require.NoError(t, err, "invalid value in row %d: %s", i+1, valueStr)

		// Create KeyValue entry for this data point
		kv, err := createMockTimeSeriesKV(metricName, source, timestampNanos, value)
		require.NoError(t, err)

		// Encode to gob format
		err = encoder.Encode(kv)
		require.NoError(t, err)
	}

	t.Cleanup(func() {
		require.NoError(t, os.Remove(tmpFile.Name()), "failed to remove temporary file")
	})
	return tmpFile.Name()
}

// createMockTimeSeriesKV creates a roachpb.KeyValue entry containing time series data
func createMockTimeSeriesKV(
	name, source string, timestamp int64, value float64,
) (roachpb.KeyValue, error) {
	// Create TimeSeriesData
	tsData := tspb.TimeSeriesData{
		Name:   name,
		Source: source,
		Datapoints: []tspb.TimeSeriesDatapoint{
			{TimestampNanos: timestamp, Value: value},
		},
	}

	// Convert to internal format using 10s resolution
	resolution := ts.Resolution10s
	idatas, err := tsData.ToInternal(
		resolution.SlabDuration(),   // 1 hour (3600 * 10^9 ns)
		resolution.SampleDuration(), // 10 seconds (10 * 10^9 ns)
		true,                        // columnar format
	)
	if err != nil {
		return roachpb.KeyValue{}, err
	}

	// Should only be one internal data entry for a single datapoint
	if len(idatas) != 1 {
		return roachpb.KeyValue{}, fmt.Errorf("expected 1 internal data entry, got %d", len(idatas))
	}

	idata := idatas[0]

	// Create the key
	key := ts.MakeDataKey(name, source, resolution, idata.StartTimestampNanos)

	// Create the value (protobuf-encoded internal data)
	var roachValue roachpb.Value
	if err := roachValue.SetProto(&idata); err != nil {
		return roachpb.KeyValue{}, err
	}

	return roachpb.KeyValue{Key: key, Value: roachValue}, nil
}

// TestDeltaCalculationForCounters tests the delta calculation functionality
// for counter metrics across multiple dump calls.
func TestDeltaCalculationForCounters(t *testing.T) {
	defer leaktest.AfterTest(t)()
	defer log.Scope(t).Close(t)

	// Create a datadogWriter with delta calculator
	writer, err := makeDatadogWriter("us5", false, "test-api-key", 100, "", 1)
	require.NoError(t, err)

	testCases := []struct {
		name           string
		metricName     string
		source         string
		values         []float64
		expectedValues []float64
	}{
		{
			name:           "counter with incrementing values",
			metricName:     "cr.node.test-counter-count",
			source:         "1",
			values:         []float64{100, 150, 200},
			expectedValues: []float64{100, 50, 50}, // first value, then deltas
		},
		{
			name:           "counter starting from zero",
			metricName:     "cr.node.zero-start-count",
			source:         "2",
			values:         []float64{0, 25, 75},
			expectedValues: []float64{0, 25, 50},
		},
		{
			name:           "counter with no jumps",
			metricName:     "cr.node.large-jump-count",
			source:         "3",
			values:         []float64{1000, 1000, 1000},
			expectedValues: []float64{1000, 0, 0},
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			timestamp := time.Date(2024, 11, 14, 0, 0, 0, 0, time.UTC).UnixNano()

			for i, value := range tc.values {
				// Create mock KeyValue for this metric value
				kv, err := createMockTimeSeriesKV(tc.metricName, tc.source, timestamp+int64(i)*1e10, value)
				require.NoError(t, err)

				// Call dump function
				series, err := writer.dump(&kv)
				require.NoError(t, err)

				// Verify the metric type is COUNT for counter metrics
				require.NotNil(t, series.Type)
				require.Equal(t, *series.Type, datadogV2.METRICINTAKETYPE_COUNT)

				// Verify we got the expected value (first value or delta)
				require.Len(t, series.Points, 1)
				actualValue := *series.Points[0].Value
				expectedValue := tc.expectedValues[i]
				require.Equal(t, expectedValue, actualValue,
					"Call %d: expected %f, got %f", i+1, expectedValue, actualValue)
			}
		})
	}
}

// TestDeltaCalculationResetDetection tests that the delta calculator
// properly handles counter resets (when counter goes backwards due to process restart).
func TestDeltaCalculationResetDetection(t *testing.T) {
	defer leaktest.AfterTest(t)()
	defer log.Scope(t).Close(t)

	writer, err := makeDatadogWriter("us5", false, "test-api-key", 100, "", 1)
	require.NoError(t, err)

	metricName := "cr.node.reset-test-count"
	source := "1"
	timestamp := time.Date(2024, 11, 14, 0, 0, 0, 0, time.UTC).UnixNano()

	// First call with value 100
	kv1, err := createMockTimeSeriesKV(metricName, source, timestamp, 100)
	require.NoError(t, err)
	series1, err := writer.dump(&kv1)
	require.NoError(t, err)
	require.Equal(t, 100.0, *series1.Points[0].Value)

	// Second call with value 150 (normal increment)
	kv2, err := createMockTimeSeriesKV(metricName, source, timestamp+1e10, 150)
	require.NoError(t, err)
	series2, err := writer.dump(&kv2)
	require.NoError(t, err)
	require.Equal(t, 50.0, *series2.Points[0].Value) // delta: 150 - 100

	// Third call with value 50 (reset detected - should handle gracefully)
	kv3, err := createMockTimeSeriesKV(metricName, source, timestamp+2e10, 50)
	require.NoError(t, err)
	series3, err := writer.dump(&kv3)
	require.NoError(t, err)
	require.Equal(t, 50.0, *series3.Points[0].Value) // reset: use current value as delta

	// Fourth call with value 75 (normal increment after reset)
	kv4, err := createMockTimeSeriesKV(metricName, source, timestamp+3e10, 75)
	require.NoError(t, err)
	series4, err := writer.dump(&kv4)
	require.NoError(t, err)
	require.Equal(t, 25.0, *series4.Points[0].Value) // delta: 75 - 50
}

// TestDeltaCalculationCrossBatchPersistence tests that delta calculation
// state persists correctly when the same metric appears in different batches.
func TestDeltaCalculationCrossBatchPersistence(t *testing.T) {
	defer leaktest.AfterTest(t)()
	defer log.Scope(t).Close(t)

	writer, err := makeDatadogWriter("us5", false, "test-api-key", 100, "", 1)
	require.NoError(t, err)

	metricName := "cr.node.cross-batch-test-count"
	source := "1"

	timestamp := time.Date(2025, 6, 26, 22, 49, 24, 0, time.UTC).UnixNano()

	// Simulate first batch
	kv1, err := createMockTimeSeriesKV(metricName, source, timestamp, 100)
	require.NoError(t, err)
	series1, err := writer.dump(&kv1)
	require.NoError(t, err)
	require.Equal(t, 100.0, *series1.Points[0].Value) // first value

	// Simulate processing other metrics (different batch)
	otherKv, err := createMockTimeSeriesKV("cr.node.other-metric-count", "2", timestamp+5e9, 50)
	require.NoError(t, err)
	_, err = writer.dump(&otherKv)
	require.NoError(t, err)

	// Simulate second batch with same metric - state should persist
	kv2, err := createMockTimeSeriesKV(metricName, source, timestamp+1e10, 180)
	require.NoError(t, err)
	series2, err := writer.dump(&kv2)
	require.NoError(t, err)
	require.Equal(t, 80.0, *series2.Points[0].Value) // delta: 180 - 100

	// Third batch - should still remember previous value
	kv3, err := createMockTimeSeriesKV(metricName, source, timestamp+2e10, 220)
	require.NoError(t, err)
	series3, err := writer.dump(&kv3)
	require.NoError(t, err)
	require.Equal(t, 40.0, *series3.Points[0].Value) // delta: 220 - 180
}
