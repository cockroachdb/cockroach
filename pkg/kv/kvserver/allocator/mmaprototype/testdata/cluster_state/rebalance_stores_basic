# Basic test that rebalanceStores issues a lease transfer when seeing a single replica
# contributing to overload on the first out of three single-store nodes.

set-store
  store-id=1 node-id=1 attrs=purple locality-tiers=region=us-west-1,zone=us-west-1a
  store-id=2 node-id=2 attrs=yellow locality-tiers=region=us-east-1,zone=us-east-1a
  store-id=3 node-id=3 attrs=green locality-tiers=region=us-central-1,zone=us-central-1a
----
node-id=1 locality-tiers=region=us-west-1,zone=us-west-1a,node=1
  store-id=1 attrs=purple locality-code=1:2:3:
node-id=2 locality-tiers=region=us-east-1,zone=us-east-1a,node=2
  store-id=2 attrs=yellow locality-code=4:5:6:
node-id=3 locality-tiers=region=us-central-1,zone=us-central-1a,node=3
  store-id=3 attrs=green locality-code=7:8:9:

store-load-msg
  store-id=1 node-id=1 load=[80,0,0] capacity=[100,100,100] secondary-load=0 load-time=0s
----

store-load-msg
  store-id=2 node-id=2 load=[10,0,0] capacity=[100,100,100] secondary-load=0 load-time=0s
----

store-load-msg
  store-id=3 node-id=3 load=[10,0,0] capacity=[100,100,100] secondary-load=0 load-time=0s
----

get-load-info
----
store-id=1 node-id=1 status=ok accepting all reported=[cpu:80, write-bandwidth:0, byte-size:0] adjusted=[cpu:80, write-bandwidth:0, byte-size:0] node-reported-cpu=80 node-adjusted-cpu=80 seq=1
store-id=2 node-id=2 status=ok accepting all reported=[cpu:10, write-bandwidth:0, byte-size:0] adjusted=[cpu:10, write-bandwidth:0, byte-size:0] node-reported-cpu=10 node-adjusted-cpu=10 seq=1
store-id=3 node-id=3 status=ok accepting all reported=[cpu:10, write-bandwidth:0, byte-size:0] adjusted=[cpu:10, write-bandwidth:0, byte-size:0] node-reported-cpu=10 node-adjusted-cpu=10 seq=1

store-leaseholder-msg
store-id=1
  range-id=1 load=[60,0,0] raft-cpu=20 config=(num_replicas=3 constraints={} voter_constraints={})
    store-id=1 replica-id=1 type=VOTER_FULL leaseholder=true
    store-id=2 replica-id=2 type=VOTER_FULL
    store-id=3 replica-id=3 type=VOTER_FULL
----

ranges
----
range-id=1 local-store=1 load=[cpu:60, write-bandwidth:0, byte-size:0] raft-cpu=20
  store-id=1 replica-id=1 type=VOTER_FULL leaseholder=true
  store-id=2 replica-id=2 type=VOTER_FULL
  store-id=3 replica-id=3 type=VOTER_FULL

get-load-info
----
store-id=1 node-id=1 status=ok accepting all reported=[cpu:80, write-bandwidth:0, byte-size:0] adjusted=[cpu:80, write-bandwidth:0, byte-size:0] node-reported-cpu=80 node-adjusted-cpu=80 seq=1
  top-k-ranges (local-store-id=1) dim=CPURate: r1
store-id=2 node-id=2 status=ok accepting all reported=[cpu:10, write-bandwidth:0, byte-size:0] adjusted=[cpu:10, write-bandwidth:0, byte-size:0] node-reported-cpu=10 node-adjusted-cpu=10 seq=1
  top-k-ranges (local-store-id=1) dim=WriteBandwidth: r1
store-id=3 node-id=3 status=ok accepting all reported=[cpu:10, write-bandwidth:0, byte-size:0] adjusted=[cpu:10, write-bandwidth:0, byte-size:0] node-reported-cpu=10 node-adjusted-cpu=10 seq=1
  top-k-ranges (local-store-id=1) dim=WriteBandwidth: r1

# s1 is overloaded and local, so rebalanceStores should try and succeed to shed
# a lease from it. The gc duration for lease shedding is 1min.
rebalance-stores store-id=1
----
[mmaid=1] cluster means: (stores-load [cpu:33, write-bandwidth:0, byte-size:0]) (stores-capacity [cpu:100, write-bandwidth:100, byte-size:100]) (nodes-cpu-load 33) (nodes-cpu-capacity 100)
[mmaid=1] overload-continued s1 ((store=overloadUrgent worst=CPURate cpu=overloadUrgent writes=loadNormal bytes=loadNormal node=overloadUrgent high_disk=false frac_pending=0.00,0.00(true))) - within grace period
[mmaid=1] start processing shedding store s1: cpu node load overloadUrgent, store load overloadUrgent, worst dim CPURate
[mmaid=1] top-K[CPURate] ranges for s1 with lease on local s1: r1:[cpu:60, write-bandwidth:0, byte-size:0]
[mmaid=1] result(success): shedding r1 lease from s1 to s2 [change:r1=[transfer_to=2 cids=1,2]] with resulting loads source:[cpu:40, write-bandwidth:0, byte-size:0] target:[cpu:54, write-bandwidth:0, byte-size:0] (means: [cpu:33, write-bandwidth:0, byte-size:0]) (frac_pending: (src:0.00,target:0.50) (src:4.40,target:0.00))
pending(2)
change-id=1 store-id=1 node-id=1 range-id=1 load-delta=[cpu:-40, write-bandwidth:0, byte-size:0] start=0s gc=1m0s
  prev=(replica-id=1 type=VOTER_FULL leaseholder=true)
  next=(replica-id=1 type=VOTER_FULL)
change-id=2 store-id=2 node-id=2 range-id=1 load-delta=[cpu:44, write-bandwidth:0, byte-size:0] start=0s gc=1m0s
  prev=(replica-id=2 type=VOTER_FULL)
  next=(replica-id=2 type=VOTER_FULL leaseholder=true)
