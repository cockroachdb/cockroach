# This test verifies the allocator's behavior with opposing CPU and write load
# distributions, complicated by the presence of many "cold" (idle) ranges that
# prevent count-based rebalancing from "accidentally" fixing the load imbalance.
#
#   Keyspace          Ranges   Placement   Load
#   ─────────────────────────────────────────────────────────────
#   [1, 10000)         36      s1-s3       read-heavy
#   [10001, 20000)     36      s4-s6       write-heavy
#   [20001, 30000)    100      s1-s3       (cold)
#   [30001, 40000)    100      s4-s6       (cold)
#   ─────────────────────────────────────────────────────────────
#
# The cold ranges are important to prevent count-based rebalancing from
# "accidentally" fixing the write imbalance (after CPU-based rebalancing
# has created a count-imbalance).
#
# Expected outcome:
#
# MMA balances both CPU and writes intentionally, reaching a stable equilibrium
# where both metrics are evenly distributed. It moves the hot ranges (both read
# and write) to achieve this, ignoring the cold ranges.
#
# SMA (sma-count) only optimizes for CPU and has no visibility into write load.
# It balances CPU but leaves writes heavily skewed on s4-s6. The high thrash
# (~1500% CPU) comes from the store rebalancer (optimizing CPU) and the
# replicate/lease queues (optimizing counts) working against each other.
gen_cluster nodes=6 node_cpu_cores=5
----

# Hot read ranges on s1-s3: high CPU, no writes
gen_ranges ranges=36 min_key=1 max_key=10000 placement_type=replica_placement
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

gen_load rate=1000 rw_ratio=1.0 request_cpu_per_access=5000000 min_key=1 max_key=10000
----
5.00 access-vcpus

# Cold ranges co-located with the hot read ranges on s1-s3.
#
# These raise the absolute threshold for count-based rebalancing, preventing
# small movements from triggering fixes that might accidentally redistribute
# the hot ranges and fix IO imbalance.
gen_ranges ranges=100 min_key=20001 max_key=30000 placement_type=replica_placement
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

# Hot write ranges on s4-s6: high write throughput, minimal CPU
gen_ranges ranges=36 min_key=10001 max_key=20000 placement_type=replica_placement
{s4,s5,s6}:1
----
{s4:*,s5,s6}:1

# raft_cpu_per_write=1 makes writes contribute negligible CPU. This isolates the
# two dimensions: s1-s3 are CPU-hot (reads), and s4-s6 are write-hot but
# CPU-cold.
gen_load rate=20000 rw_ratio=0 min_block=1000 max_block=1000 raft_cpu_per_write=1 min_key=10001 max_key=20000
----
0.00 raft-vcpus, 19 MiB/s goodput

# Cold ranges co-located with the hot write ranges on s4-s6 (same principle).
gen_ranges ranges=100 min_key=30001 max_key=40000 placement_type=replica_placement
{s4,s5,s6}:1
----
{s4:*,s5,s6}:1

setting split_queue_enabled=false
----

eval duration=25m samples=1 seed=42 cfgs=(sma-count,mma-only,mma-count) metrics=(cpu_util,write_bytes_per_second,replicas,leases)
----
sma-count:
cpu_util#1: last:  [s1=0.17, s2=0.17, s3=0.19, s4=0.17, s5=0.17, s6=0.14] (stddev=0.02, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=317%, s2=139%, s3=420%, s4=230%, s5=181%, s6=204%]  (sum=1490%)
leases#1: first: [s1=136, s2=0, s3=0, s4=136, s5=0, s6=0] (stddev=64.11, mean=45.33, sum=272)
leases#1: last:  [s1=42, s2=44, s3=41, s4=51, s5=48, s6=46] (stddev=3.45, mean=45.33, sum=272)
leases#1: thrash_pct: [s1=86%, s2=49%, s3=103%, s4=68%, s5=46%, s6=49%]  (sum=401%)
replicas#1: first: [s1=136, s2=136, s3=136, s4=136, s5=136, s6=136] (stddev=0.00, mean=136.00, sum=816)
replicas#1: last:  [s1=135, s2=129, s3=135, s4=138, s5=139, s6=140] (stddev=3.65, mean=136.00, sum=816)
replicas#1: thrash_pct: [s1=0%, s2=245%, s3=13%, s4=115%, s5=103%, s6=66%]  (sum=543%)
write_bytes_per_second#1: last:  [s1=0, s2=2772297, s3=0, s4=18336933, s5=20000880, s6=18892529] (stddev=9136363.37, mean=10000439.83, sum=60002639)
write_bytes_per_second#1: thrash_pct: [s1=0%, s2=2%, s3=0%, s4=89%, s5=100%, s6=101%]  (sum=292%)
hash: bbe8bd0a4c78e7a1
==========================
mma-only:
cpu_util#1: last:  [s1=0.17, s2=0.17, s3=0.17, s4=0.17, s5=0.17, s6=0.17] (stddev=0.00, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=7%, s2=29%, s3=45%, s4=14%, s5=14%, s6=10%]  (sum=119%)
leases#1: first: [s1=136, s2=0, s3=0, s4=136, s5=0, s6=0] (stddev=64.11, mean=45.33, sum=272)
leases#1: last:  [s1=106, s2=14, s3=14, s4=125, s5=7, s6=6] (stddev=50.01, mean=45.33, sum=272)
leases#1: thrash_pct: [s1=0%, s2=4%, s3=7%, s4=10%, s5=2%, s6=2%]  (sum=24%)
replicas#1: first: [s1=136, s2=136, s3=136, s4=136, s5=136, s6=136] (stddev=0.00, mean=136.00, sum=816)
replicas#1: last:  [s1=138, s2=153, s3=151, s4=125, s5=125, s6=124] (stddev=12.27, mean=136.00, sum=816)
replicas#1: thrash_pct: [s1=66%, s2=14%, s3=26%, s4=36%, s5=58%, s6=48%]  (sum=247%)
write_bytes_per_second#1: last:  [s1=7810565, s2=10580836, s3=10580705, s4=10522780, s5=10524200, s6=9967180] (stddev=1001444.35, mean=9997711.00, sum=59986266)
write_bytes_per_second#1: thrash_pct: [s1=16%, s2=6%, s3=26%, s4=2%, s5=127%, s6=121%]  (sum=297%)
hash: bc8ab9c1ef320818
==========================
mma-count:
cpu_util#1: last:  [s1=0.17, s2=0.17, s3=0.17, s4=0.17, s5=0.17, s6=0.17] (stddev=0.00, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=11%, s2=48%, s3=44%, s4=11%, s5=20%, s6=11%]  (sum=145%)
leases#1: first: [s1=136, s2=0, s3=0, s4=136, s5=0, s6=0] (stddev=64.11, mean=45.33, sum=272)
leases#1: last:  [s1=46, s2=50, s3=45, s4=47, s5=43, s6=41] (stddev=2.87, mean=45.33, sum=272)
leases#1: thrash_pct: [s1=16%, s2=18%, s3=18%, s4=21%, s5=24%, s6=19%]  (sum=116%)
replicas#1: first: [s1=136, s2=136, s3=136, s4=136, s5=136, s6=136] (stddev=0.00, mean=136.00, sum=816)
replicas#1: last:  [s1=138, s2=135, s3=139, s4=136, s5=138, s6=130] (stddev=3.00, mean=136.00, sum=816)
replicas#1: thrash_pct: [s1=181%, s2=212%, s3=224%, s4=221%, s5=234%, s6=121%]  (sum=1192%)
write_bytes_per_second#1: last:  [s1=8924579, s2=8863057, s3=10583672, s4=10526641, s5=10574221, s6=10522571] (stddev=782091.11, mean=9999123.50, sum=59994741)
write_bytes_per_second#1: thrash_pct: [s1=44%, s2=32%, s3=57%, s4=232%, s5=240%, s6=221%]  (sum=824%)
hash: 89671d52ea3fc14a
==========================
