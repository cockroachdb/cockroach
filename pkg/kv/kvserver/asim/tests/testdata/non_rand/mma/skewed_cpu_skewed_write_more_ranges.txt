# This test is similar to skewed_cpu_skewed_write.txt, but with more ranges 300. 
# To have the same amount of total load, bytes per range is reduced to 26 MiB.
# 
# Expected outcome: The allocator should rebalance both cpu and write load across
# all stores, with mma achieving better results than sma. 
gen_cluster nodes=6 node_cpu_rate_capacity=5000000000
----

# The placement will be skewed, s.t. n1/s1, n2/s2 and n3/s3 will have all the
# replicas initially and n1/s1 will have every lease. Each range is initially
# 26 MiB.
gen_ranges ranges=300 min_key=1 max_key=10000 placement_type=replica_placement bytes_mib=26
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

gen_load rate=1000 rw_ratio=1.0 request_cpu_per_access=5000000 min_key=1 max_key=10000
----
5.00 access-vcpus

# Write only workload, which generates little CPU and 100_000 (x replication
# factor) write bytes per second over the second half of the keyspace.
gen_ranges ranges=300 min_key=10001 max_key=20000 placement_type=replica_placement bytes_mib=26
{s4,s5,s6}:1
----
{s4:*,s5,s6}:1

gen_load rate=20000 rw_ratio=0 min_block=1000 max_block=1000 raft_cpu_per_write=1 min_key=10001 max_key=20000
----
0.00 raft-vcpus, 19 MiB/s goodput

setting split_queue_enabled=false
----

eval duration=75m samples=1 seed=42 cfgs=(mma-only,mma-count) metrics=(cpu,cpu_util,write_bytes_per_second,replicas,leases)
----
cpu#1: last:  [s1=905649679, s2=905578767, s3=906078274, s4=759232319, s5=760362610, s6=760385616] (stddev=72888856.82, mean=832881210.83, sum=4997287265)
cpu#1: thrash_pct: [s1=9%, s2=53%, s3=53%, s4=26%, s5=26%, s6=27%]  (sum=195%)
cpu_util#1: last:  [s1=0.18, s2=0.18, s3=0.18, s4=0.15, s5=0.15, s6=0.15] (stddev=0.01, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=9%, s2=53%, s3=53%, s4=26%, s5=26%, s6=27%]  (sum=195%)
leases#1: first: [s1=300, s2=0, s3=0, s4=300, s5=0, s6=0] (stddev=141.42, mean=100.00, sum=600)
leases#1: last:  [s1=56, s2=128, s3=115, s4=209, s5=46, s6=46] (stddev=58.68, mean=100.00, sum=600)
leases#1: thrash_pct: [s1=1%, s2=22%, s3=19%, s4=32%, s5=0%, s6=0%]  (sum=75%)
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300, s6=300] (stddev=0.00, mean=300.00, sum=1800)
replicas#1: last:  [s1=309, s2=429, s3=432, s4=209, s5=210, s6=211] (stddev=98.70, mean=300.00, sum=1800)
replicas#1: thrash_pct: [s1=59%, s2=23%, s3=21%, s4=34%, s5=36%, s6=36%]  (sum=208%)
write_bytes_per_second#1: last:  [s1=6346467, s2=10497642, s3=10498564, s4=10962160, s5=10829076, s6=10886325] (stddev=1645354.05, mean=10003372.33, sum=60020234)
write_bytes_per_second#1: thrash_pct: [s1=1%, s2=9%, s3=9%, s4=3%, s5=71%, s6=94%]  (sum=189%)
artifacts[mma-only]: db04e7e6e867b516
==========================
cpu#1: last:  [s1=789898567, s2=777699920, s3=793023723, s4=889209327, s5=891927515, s6=859481227] (stddev=48037105.53, mean=833540046.50, sum=5001240279)
cpu#1: thrash_pct: [s1=15%, s2=65%, s3=74%, s4=42%, s5=32%, s6=33%]  (sum=262%)
cpu_util#1: last:  [s1=0.16, s2=0.16, s3=0.16, s4=0.18, s5=0.18, s6=0.17] (stddev=0.01, mean=0.17, sum=1)
cpu_util#1: thrash_pct: [s1=15%, s2=65%, s3=74%, s4=42%, s5=32%, s6=33%]  (sum=262%)
leases#1: first: [s1=300, s2=0, s3=0, s4=300, s5=0, s6=0] (stddev=141.42, mean=100.00, sum=600)
leases#1: last:  [s1=104, s2=115, s3=108, s4=71, s5=99, s6=103] (stddev=13.88, mean=100.00, sum=600)
leases#1: thrash_pct: [s1=67%, s2=81%, s3=88%, s4=64%, s5=81%, s6=87%]  (sum=468%)
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300, s6=300] (stddev=0.00, mean=300.00, sum=1800)
replicas#1: last:  [s1=310, s2=309, s3=305, s4=304, s5=286, s6=286] (stddev=10.12, mean=300.00, sum=1800)
replicas#1: thrash_pct: [s1=365%, s2=498%, s3=511%, s4=390%, s5=390%, s6=414%]  (sum=2569%)
write_bytes_per_second#1: last:  [s1=7327695, s2=10297801, s3=10166844, s4=10897136, s5=10763064, s6=10564986] (stddev=1222293.88, mean=10002921.00, sum=60017526)
write_bytes_per_second#1: thrash_pct: [s1=59%, s2=79%, s3=89%, s4=177%, s5=182%, s6=196%]  (sum=782%)
artifacts[mma-count]: 3f9d7793d88bb993
==========================
