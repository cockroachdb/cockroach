skip_under_ci
----

# This test can now roughly equalize both cpu and write bandwidth. It didn't
# use to be able to do this, because the highest cpu node had the lowest write
# bandwidth and vice versa, so neither was able to shed to the other. The
# ignoreLevel logic in rebalanceStores with the grace duration to start
# shedding more aggressively and other related changes have made this much
# better.

gen_cluster nodes=6 node_cpu_rate_capacity=50000
----
WARNING: node CPU capacity of â‰ˆ0.00 cores is likely accidental

# The placement will be skewed, s.t. n1/s1, n2/s2 and n3/s3 will have all the
# replicas initially and n1/s1 will have every lease. Each range is initially
# 26 MiB.
gen_ranges ranges=300 min_key=1 max_key=10000 placement_type=replica_placement bytes=26843545
{s1,s2,s3}:1
----
{s1:*,s2,s3}:1

gen_load rate=1000 rw_ratio=1.0 request_cpu_per_access=500000 min_key=1 max_key=10000
----

# Write only workload, which generates little CPU and 100_000 (x replication
# factor) write bytes per second over the second half of the keyspace.
gen_ranges ranges=300 min_key=10001 max_key=20000 placement_type=replica_placement bytes=26843545
{s4,s5,s6}:1
----
{s4:*,s5,s6}:1

gen_load rate=20000 rw_ratio=0 min_block=1000 max_block=1000 raft_cpu_per_write=1 min_key=10001 max_key=20000
----

setting split_queue_enabled=false
----

eval duration=90m samples=1 seed=42 cfgs=(mma-only) metrics=(cpu,write_bytes_per_second,replicas,leases)
----
cpu#1: last:  [s1=90629232, s2=90891770, s3=90720435, s4=76036553, s5=76098830, s6=75795916] (stddev=7386001.42, mean=83362122.67, sum=500172736)
cpu#1: thrashing: [max(s3)=(freq=5381, mag=4.73) (s1=(freq=5216, mag=1.00), s2=(freq=5278, mag=4.69), s3=(freq=5381, mag=4.73), s4=(freq=5084, mag=4.63), s5=(freq=5168, mag=5.74), s6=(freq=5059, mag=5.97))]
leases#1: first: [s1=300, s2=0, s3=0, s4=300, s5=0, s6=0] (stddev=141.42, mean=100.00, sum=600)
leases#1: last:  [s1=55, s2=129, s3=115, s4=209, s5=46, s6=46] (stddev=58.88, mean=100.00, sum=600)
leases#1: thrashing: [max(s4)=(freq=268, mag=1.28) (s1=(freq=258, mag=1.70), s2=(freq=52, mag=0.51), s3=(freq=52, mag=0.57), s4=(freq=268, mag=1.28), s5=(freq=0, mag=0.00), s6=(freq=0, mag=0.00))]
replicas#1: first: [s1=300, s2=300, s3=300, s4=300, s5=300, s6=300] (stddev=0.00, mean=300.00, sum=1800)
replicas#1: last:  [s1=283, s2=430, s3=430, s4=209, s5=211, s6=237] (stddev=95.10, mean=300.00, sum=1800)
replicas#1: thrashing: [max(s4)=(freq=268, mag=1.28) (s1=(freq=166, mag=0.63), s2=(freq=52, mag=0.12), s3=(freq=52, mag=0.12), s4=(freq=268, mag=1.28), s5=(freq=174, mag=0.84), s6=(freq=214, mag=0.78))]
write_bytes_per_second#1: last:  [s1=4565462, s2=10497859, s3=10497096, s4=10961474, s5=10895186, s6=12602252] (stddev=2533989.43, mean=10003221.50, sum=60019329)
write_bytes_per_second#1: thrashing: [max(s5)=(freq=5374, mag=3.45) (s1=(freq=1548, mag=7.37), s2=(freq=5232, mag=1.42), s3=(freq=5319, mag=1.28), s4=(freq=5322, mag=2.55), s5=(freq=5374, mag=3.45), s6=(freq=5358, mag=2.68))]
artifacts[mma-only]: 7e2ef8861fdf2e81
