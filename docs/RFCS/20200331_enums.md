- Feature Name: Enum Data Types in CockroachDB
- Status: draft
- Start Date: 2020-03-31
- Authors: Rohan Yadav, Lucy Zhang, Andrew Werner, Jordan Lewis
- RFC PR: #TODO (rohany): Fill this out.
- Cockroach Issue: #24873

# Summary

This RFC proposes adding enum types to CockroachDB. 

# Background

Enum types are a class of user defined types where the values in 
the type are constrained to a fixed set
of user specified values. The system then ensures type safety over operations
on this type. This includes ensuring that only values that are members of the 
enum can be inserted into a column of the enum type, and that enums can only
be compared to other values of the same enum type. For example, consider an
application that needs to store events and the days of the week that they happen.
This application could use an enum to represent the days of the week.

```sql
CREATE TYPE day ENUM AS ('monday', 'tuesday', 'wednesday'...);
CREATE TABLE events (id INT, dayofweek day);
INSERT INTO events VALUES (1, 'monday');
```


# Overview

To implement enum types in CockroachDB, we have to touch many layers
of the system. In particular, we need to introduce a way of storing 
metadata about enums durably in the database. We then need a way to 
cache this metadata so that lookups on this metadata is fast, as well 
as a way to invalidate this cache when enum metadata changes. When 
enum metadata changes, we need to ensure that these changes do not
result in some nodes in the cluster entering a situation where 
they are unable to process enum values they find. Lastly, we need
to define a physical layout for enums and integrate enums within
the type system and SQL execution stack.

# Detailed Explanation

## Metadata Storage

We propose storing the metadata about an enum in a new descriptor called 
an `EnumDescriptor`. This descriptor will be added to the descriptor union
along side Table and Database descriptors and will reuse the same leasing
and versioning system. The descriptor will store meta information about 
the enum such as its parent database ID, parent schema ID, a unique ID for the enum, 
and the enum's name and value components. 

Another option is to build off of
`TableDescriptor` and add the necessary fields for describing enums there.
This has the benefit of allowing us to reuse all existing infrastructure
relating to versioning/leasing without any code change. The con of this
approach is that it clutters the `TableDescriptor` more with specialized 
information.

## Caching and Name Resolution

The SQL Schema team is working on building a schema leasing system.
Using this leasing system, we can cache enum descriptors in memory
and invalidate entries when the lease is invalidated. 

Enums are scoped within a database and a schema. However, enums 
cannot be accessed from other databases.
Types can be optionally annotated with a schema, so name resolution
for enum types will need to share caching of schema information 
with the work being done on user defined schemas.

To proceed on this work without being blocked by the work on 
schema leasing and user defined schemas, we propose a prototype
implementation that either uses a simple, incoherent cache for 
enum type resolution, or just don't cache data at all. After
the schema team has made progress on these features, they can
be integrated into the system for enums.

## Changing Enum Definitions

There are a few ways that enums can change over time.
* The name can change.
* The schema the enum is in can change.
* A new enum member can be added to the set of values.
* A member in the enum can be renamed.

In order to rename an enum or a value in an enum can be done with a write
to the enum descriptor and then waiting for all nodes to agree on the new value.

The case of adding a new enum element is more difficult. The key difficulty comes 
from ensuring that a node does not attempt to translate a physical layout that it
does not know about yet into a user facing representation of the enum. If we naively
just add the new enum value to the enum metadata, it is possible that another node 
reads a newly written enum from disk and is unsure how to decode it. Consider the
following sequence of events:
* Node 1 receives a new enum element `foo` to its enum descriptor and blocks on
  `WaitForOneVersion`
* Node 2 receives the new enum descriptor update and writes a value with `foo`
* Node 3 tries to read the value of `foo` before receiving the update to 
  its enum descriptor.

In order to avoid these situations, we propose an extension of the strategy 
used for performing online schema changes. As a reminder, when we add a new
schema object to a table, it moves through a series of states before becoming
usable. As the object moves through these states, the types of operations 
that are allowed upon the object change. Between each state, we require that
all nodes in the cluster agree on the new version of the schema object.
For more details, refer to the 
[online schema changes RFC](https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20151014_online_schema_change.md).
We propose a similar state 
progression to adding new elements to an enum type. 
1. When a new value is added
to an enum, it is instead placed into a "read only" state. 
2. After all nodes agree on the "read only" state, the new enum value 
is promoted into the set of writeable values in the enum. 

This process ensures that all nodes know
about all potential enum values before they have a chance to be written.
This approach has the drawback of not being able to add an enum value and
then insert that value in the same transaction. This drawback is similar
to our existing limitation of not being able to add a column and insert
into it in the same transaction. Depending on how we represent the metadata
for an enum, we can either reuse the existing schema change infrastructure 
or write a simpler variant for managing changes on enums.

## Physical Layout 

At first, it may seem that a valid implementation of enum values is
to map each to an integer, and then store these integers on disk.
This implementation seems like it would supply all the ordering 
guarantees needed of enums. However, Postgres allows for adding
new enums and specifying the order of the newly created enum
with respect to an existing value of the enum. This looks like:
```sql
CREATE TYPE t ENUM AS ('v1', 'v2');
ALTER TYPE t ADD VALUE 'v1.5' AFTER 'v2'
```
This means add the value `v1.5` to the enum `t` and order it
after the value `v1`. Using just integers as the backing value
for enums would not allow us to handle this sort of case.
Postgres implements this feature on enums by storing a sorting
order for enums as a float. When a new value is added like this,
Postgres takes the sort orders of the enums that the new enum is
being inserted in between, and creates a float that bisects the
range between the two orders. Concretely, if `v1` had a sort order
of `1.5` and `v2` had a sort order of `2.0`, then `v1.5` would be 
inserted with a sort order of `1.75`. However, once the floating
point precision limit has been reached, Postgres rewrites all
sort orders to integral values. Postgres can do this because it
doesn't require a stable disk encoding for enums. In our case,
we need to have a stable encoding to store data on disk if an enum
is used in an index, and cannot afford to rewrite all tables using an
enum if the enum sort order has changed.

We propose a different strategy that is related to this idea of
bisecting ranges, but doesn't suffer from problems due to floating
point arithmetic precision. The general idea is to use byte arrays
to hold the sort order of our enums, and reserve some bytes in the
arrays to create the ordering that we need. In particular we reserve
the minimum byte (`0`) and have a maximum allowed byte. In practice
this will be `255`. An example of the encoding scheme is below.

Assume we started with 3 elements (`a`, `b`, `c`), and let the maximum byte value be 3.
The sort order byte arrays for each element would be:
```
a 1/
b 2/
c 3/
```
To add an element after `b` we can create a new key that sits in the middle of the range
between `b` and `c`.
```
a 1/
b 2/
d 2/2/
c 3/
```
Now lets add more values before `d`. The first one is easy:
```
a 1/
b 2/
e 2/1/
d 2/2/
c 3/
```
The tricky case is adding a value before `e`. Because we reserved the minimum byte, we can
append it and then bisect the range again.
```
a 1/
b 2/
f 2/0/2
e 2/1/
d 2/2/
c 3/
```
This strategy can be extended indefinitely as long as this pattern is followed to reserve
the minimum byte. A prototype of the exact algorithm is included as part of the RFC PR.

This sort order byte array will be the physical layout and identifier of the enum. We expect
that for small enums only a byte or two will be used to hold all the values, and that our
compression strategies at the storage layer will compress this data well.

An additional strategy is to represent enum values as a tuple of an integer and 
this byte array.
The ordering of the enums will be first on the integer, then on the byte array. An advantage
of this approach is that adding a new enum to the beginning or end of the set requires only
an increment/decrement of the integer rather than creating a new and possibly longer byte array.
Adding to the beginning or end of the existing enum value set is the most
common operation, and is the "worst case" for the pure byte array algorithm.
A drawback of this strategy is that more space is used in the case where there are not many enum
values. 

## Type System Changes

To update the type system to handle enums, we will introduce a new enum type
which holds onto the ID of the enum. Using this, only enums of the same type
can be compared etc. A new `Datum` `DEnum` will be introduced that holds 
onto the ID of the enum that it represents as well as the physical layout 
discussed above. Operations on two `DEnum` datums will succeed only if the
two `DEnum`s have the same enum ID.

## Optimizer Changes

The optimizer will need to be taught about the check constraint implied by
a column being of an enum type. Additionally, it will need to be taught how
to convert enum values from their input string representation into their
`Datum` physical representation. Having access to this information involves
the leasing system discussed earlier.

# Alternatives

One alternative approach to this physical layout was to store just an
enum ID on disk, and store ordering and representation information in
a separate lookup table. When operations like on enums would involve
joining or rendering the enums, a join would be produced against this
reference table. This allows for easy changing of enum data, but
results in a variety of complexity during planning.

# Unresolved questions

It is unclear what interactions will arise between this work and the
planned/ongoing work with user defined schemas.
