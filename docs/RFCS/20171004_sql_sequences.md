- Feature Name: Sequences
- Status: draft
- Start Date: 2017-10-09
- Authors: Pete Vilter
- RFC PR: (PR # after acceptance of initial draft)
- Cockroach Issue: [5811](https://github.com/cockroachdb/cockroach/issues/5811)

**Remember, you can submit a PR with your RFC before the text is complete. Refer
to the [README](README.md#rfc-process) for details.**

# Summary

This RFC proposes a design for implementing standard SQL sequences in Cockroach.
Sequences allow users to have auto-incrementing primary keys for their tables,
which some in the community prefer to our `serial` type. The syntax proposed
matches the Postgres syntax, which is similar to what Oracle and SQL Server
support and to the SQL standard. Sequence metadata is stored on a table
descriptor, and the sequence value is stored in a special KV pair which is
updated atomically but outside of a SQL transaction.

# Motivation

Many customers could probably make do with using our `serial` type instead of
sequences for keys, but have existing applications which use sequences and/or
prefer incrementing integers to the random-looking ones generated by our
existing `unique_rowid()` function.

# Guide-level explanation

A *sequence* is a named database object which exists in a schema alongside
tables, views and other sequences, and is used to hold an integer value which
can be read and incremented atomically, usually for the purpose of giving out
unique ids as rows are inserted into a table.

Example:

```sql
CREATE SEQUENCE blog_posts_id_seq;
CREATE TABLE blog_posts (
  id INT PRIMARY KEY DEFAULT nextval('blog_posts_id_seq'),
  -- ^ in Postgres, `id SERIAL` expands to the above
  title text,
  body text
);
INSERT INTO blog_posts (title, body) VALUES ('Sequences', 'Whooo') RETURNING (id);
-- => id: 0
INSERT INTO blog_posts (title, body) VALUES ('They''re awesome', 'Yep') RETURNING (id);
-- => id: 1
-- etc
```

A workaround for the lack of sequences is to use a row in a table to store the
sequence value:

```sql
CREATE TABLE sequences (
  name text PRIMARY KEY,
  value int
);
INSERT INTO sequences VALUES ('blog_posts_id_seq', 0);
-- when you want a new value:
INSERT INTO sequences (name) VALUES ('blog_posts_id_seq')
ON CONFLICT (name) DO UPDATE SET value = sequences.value + 1
RETURNING value AS nextval;
```

This works, but has a significant drawback (besides incompatibility with
applications which are set up to use builtin sequences): the update to the row
in the sequences table locks that row until its transaction has committed. Thus,
any transactions which create records in the table for which the sequence is
being used contend on that one row in the sequence table.

The sequence implementations in [Postgres][postgres-create-seq],
[Oracle][oracle-create-seq], and [SQL Server][sql-server-create-seq] avoid this
by taking place outside of a SQL transaction: updates to the sequence are
atomic, but are never rolled back. As soon as a new sequence value is given out,
the next transaction can access the sequence, regardless of whether the first
transaction aborts or commits. This may create gaps in the table which is using
the sequence, but the performance win seems worth it. (If not, customers can use
the table strategy.) I propose that we follow in their footsteps and implement
this atomic but non-transactional behavior.

Sequences are part of the SQL standard, and are implemented with nearly the same
syntax in Postgres, MySQL, and Microsoft SQL Server. The `CREATE SEQUENCE`
statement is nearly identical between them, but the syntax for getting the next
value is different. This proposal mirrors the Postgres approach closely.

Some users may not care that sequences exist and happily continue using `serial`
(which would be faster since it doesn't create contention), but their existence
may make migration to Cockroach easier for users who are used to them. 

The feature is relatively low-impact for Cockroach internals, since it adds a
few new SQL statements and functions, adds sequence information to table
descriptors, and uses the existing KV store to store the sequence value.

# Reference-level explanation

To support this feature, I propose the following changes:

### SQL interface additions

- Introduce new DDL statements:
  - `CREATE SEQUENCE <sequence name> <sequence settings>`
  - `ALTER SEQUENCE <sequence name> <sequence settings>`
  - `DROP SEQUENCE <sequence name>`
- Introduce functions which access, increment, and set the sequence value:
  ([Postgres Docs][postgres-seq-functions]): 
  - `nextval(sequence_name)`
  - `currval(sequence_name)`
  - `lastval()` (Not very useful; may be left out)
  - `setval(sequence_name, value, is_called)`
  - _Note:_ Oracle and SQL Server implement these differently.
    - In Oracle, you get the next value of a sequence with `SELECT
      my_sequence.next_val FROM dual` (`dual` is a builtin one-row table in
      Oracle used when a table isn't needed).
    - In SQL Server, you use `NEXT VALUE FOR my_sequence` (This is what's
      specified in the SQL standard).
- Make `information_schema.sequences` show the sequences (it's currently there
  but empty)
- Record dependencies by columns on sequences (in the column and sequence
  descriptors), such that:
  - Deletion of a sequence is not allowed if a column depends on it.
  - Dropping a column which depends on a sequence (either by removing the column
    or dropping its table) results in the sequence being deleted if no other
    columns depend on it.
  - _Note:_ These dependencies will have to be recorded on `CREATE TABLE`,
    `ALTER TABLE`, `ALTER COLUMN`, and `ADD COLUMN`.
  - _Note:_ In Postgres, creating a table with a `serial` column automatically
    creates a sequence and records the dependency. Since our `serial` type
    is not based on sequences, our users will have to manually create sequences,
    with `CREATE SEQUENCE`, unless we add new syntax.
- Add checks to disallow schema and data changes to sequences via `INSERT`/
  `UPDATE`, `ALTER TABLE`, etc. They should be like information schema tables:
  their contents can only be affected by other means.
- (Possibly, see open questions section): Add a new `planNode` which allows
  `SELECT * FROM my_sequence` to work. This allows users to introspect the
  sequence value and settings, and may be relied upon by PG tools.

### Internal representation and operations

I propose that sequences be represented internally as a type of
`TableDescriptor`. Just as a `TableDescriptor` has fields which are popuplated
only for views, it will have a field (`sequence_settings` or similar) which is
only populated when a table descriptor represents a sequence. The
`sequence_settings` field on the table descriptor will include sequence settings
such as `increment`, `minvalue`, `maxvalue`, `start`, and `cycle`. `INSERT`s,
`UPDATE`s, and schema changes to the sequence will be disallowed based on the
presence of the `sequence_settings` field.

`CREATE SEQUENCE` will use the same machinery as table and view creation,
including:
- Allocating a descriptor ID by incrementing the descriptor ID allocation key.
- Adding an entry to the `system.namespace` table or erroring if the name is
  already taken, since sequences exist in the same namespace as tables.
- Writing table descriptor to the `system.descriptor` table.
- Allocating a range for the table.

There will only be one key in the sequence's range: the key which holds the
sequence's value. Reads and writes to the sequence value (via the functions
`nextval`, `currval`, etc.), will be implemented by direct calls to the KV
layer's `Get`, `Inc`, and `Set` functions.

Since the sequence value is stored in its own range, it will always be in a
different range than the other row in the transaction which is being written to
using the value it gives out. However, since the sequence update takes place
outside of the SQL transaction, this should not trigger the 2PC commit protocol.

### Corner cases

- *Reducing max value as sequence value goes above it*:
  - Scenario:
    - A sequence's max value setting is 10; current value is 5
    - User runs `ALTER SEQUENCE my_sequence MAXVALUE 5`. `my_sequence` is now
      at its maximum; any calls to `nextval` should error out or wrap around.
    - User runs `nextval('my_sequence')` on a different node
  - Problem: The node running `nextval` may not yet have received word of the
    schema change, since schema changes are scheduled and gossipped. Thus,
    a value higher than the sequence's maximum could be given out if `nextval`
    and the schema change are running concurrently.
  - Evaluation: This is not a big problem, since most users will leave the
    max value at its default (2^64), and either error out when they hit it,
    or wrap around (according to their `CYCLE` setting).

### Sequence settings details

The sequence functions must respect several optional settings (see [Postgres
docs][postgres-seq-functions]):

- `INCREMENT BY <increment>`: how much to increment by. A negative number
  creates a descending sequence; a positive number creates an ascending
  sequence.
- `MINVALUE <minvalue> | NO MINVALUE` (defaults apply if clause not specified or
  you say `NO MINVALUE`)
  - default for ascending: 1
  - default for descending: MIN_INT
- `MAXVALUE <maxvalue> | NO MAXVALUE`
  - default for ascending: MAX_INT
  - default for descending: -1
- `START WITH start`: default 1 for ascending; -1 for descending.
- `CACHE <cache>`: how many values to allocate in memory, for faster access. I
  propose not implementing this until it becomes evident that it's a performance
  problem, since allocating blocks of ids across different nodes would add
  complexity, and if users really want to go fast, they should just use
  `SERIAL` and `unique_rowid()`. It defaults to 1 in Postgres anyway, so most
  users probably aren't even using it.
- `CYCLE | NO CYCLE`: whether or not to wrap around when the sequence value hits
  the max or min.
- `OWNED BY <table_name.column_name> | OWNED BY NONE`: Records a dependency
  on this sequence from the column. We would also create this association
  if we see a call to `nextval` with a sequence name in the `DEFAULT` expression
  of a column.

## Drawbacks

Users might not understand that this type creates more contention than the
`serial` type, and be frustrated that their app is slow. Maybe we shouldn't
give them this option, and direct everyone toward `serial`.

- Mitigation: `serial` is still there to use. The documentation for sequences
  should just warn that `serial` is faster.
- Mitigation: Rails's scaffold generator (don't know about other ORMs) creates
  a primary key column of type `bigserial` by default.

## Rationale and Alternatives

### SQL Interface

The `CREATE SEQUENCE` statement, other DDL statements, and sequence manipulation
functions mirror Postgres. Oracle and SQL Server have different syntax for
getting sequence values (`my_sequence.nextval` and `NEXT VALUE FOR my_sequence`)
respectively, but these don't have clear advantages over PG's syntax. MySQL
is significantly different in that you can only mark a single column as
`AUTO_INCREMENT`, and there is no separate sequence object and thus no
`CREATE SEQUENCE`. Again this would likely be fine, but we should match
Postgres, as we do elsewhere.

However, there is the question of whether to add early-binding via a `regclass`
type. (See the Unresolved questions section).

### Internal Representation

The sequence settings need to be in the table descriptor for fast in-memory
access, and the sequence value needs to be in the KV store for atomicity.

### Impact of not doing this

Users who prefer sequences or who have applications which use them will have
an obstacle in moving to Cockroach.

## Unresolved questions

### Design / scope issues

- Should we implement the `CACHE` setting? As I said above, it seems
  unnecessary. I'm interested in other's thoughts.
- Should we add a `regclass` type and use it as the argument to the sequence
  functions? `regclass` is a Postgres type that is an OID, but with a input
  converter which looks up a schema object by name (e.g. `'my_table'::regclass`)
  becomes the OID for `my_table` when the expression is parsed.
  
  In Postgres, this allows for two useful things: (a) table
  creation fails if the sequence in `DEFAULT nextval('sequence')` doesn't
  exist (instead of failing at runtime) and (b) makes the `DEFAULT` expression
  resilient to renaming of the sequence.

  My preference is to stick with simple strings as sequence name arguments,
  since sequence renames seem rare. We could make table creation fail if
  a column references a nonexistent sequence, because we'll be looking at the
  sequence name to record the dependency anyway.
- Should we make `SELECT * FROM my_sequence` work? XXX

### Implementation issues

Currently, functions don't have access to the KV layer or the `Session`; the
`EvalContext` they get only lets them run SQL (via its `EvalPlanner` member).
This will have to be refactored to give the functions the capabilities they
need.

[postgres-dependencies]:
https://www.postgresql.org/docs/9.0/static/catalog-pg-depend.html
[postgres-seq-functions]:
https://www.postgresql.org/docs/8.1/static/functions-sequence.html
[postgres-create-seq]:
https://www.postgresql.org/docs/9.5/static/sql-createsequence.html
[oracle-create-seq]:
https://docs.oracle.com/cd/B28359_01/server.111/b28286/statements_6015.htm#SQLRF01314
[sql-server-create-seq]:
https://docs.microsoft.com/en-us/sql/t-sql/statements/create-sequence-transact-sql
