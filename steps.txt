roachprod create -n 10 --os-volume-size 100 --clouds aws --local-ssd=false tobias-lsm
roachprod extend --lifetime 240h tobias-lsm

deploy master with #80702 and #80648

# NB: setting this too high causes snaps to fail since we won't be going much
# faster than 100mb/s ever due to IO limitations.
roachprod sql tobias-lsm:5 -- -e "
set cluster setting kv.snapshot_recovery.max_rate = '120mb';
set cluster setting kv.snapshot_rebalance.max_rate = '120mb';
ALTER RANGE default CONFIGURE ZONE USING gc.ttlseconds = 600;
"

# wait for replication

time roachprod sql tobias-lsm:1 -- -e "
select crdb_internal.force_retry('3100ms') from crdb_internal.ranges_no_leases where array_length(replicas, 1) < 3;
select count(range_id) from crdb_internal.ranges_no_leases where array_length(replicas, 1) >= 3;
"

roachprod run tobias-lsm:1 ./cockroach workload init kv

# 10 hotspots. Use different prometheus port.
# I actually disabled this one later on, since with it the p99.999 is >= 10s
# and so it's hard to tell when the decommissioning makes anything worse..
roachprod ssh tobias-lsm -- sudo systemd-run -p LimitNOFILE=65535 --unit kv-seq -- ./cockroach workload run kv --read-percent 0 --concurrency 10 --min-block-bytes 10000 --max-block-bytes 10000 --sequential --tolerate-errors --prometheus-port 2113

# Spray entire keyspace with writes too, so that "all" memtables on ranges overlap
# as a workload alone, this runs into admission control already.
# at 1000 block bytes, admission control didn't kick in but LSM was still fairly bad. Hundreds of files on some nodes, 10 sublevels. However, it felt a lot less choppy and we got "straight lines" in the grapsh for throughout, latency, etc.
# At 100 block bytes, get a lot more qps and it's somehow.. choppy, workload goes through waves. The LSMs are pretty idle. So here we're probably getting more CPU bound (CPU is higher, up to 50+%) due to the fixed cost per request. Going back to 1000.
roachprod ssh tobias-lsm -- sudo systemd-run -p LimitNOFILE=65535 --unit kv-rand -- ./cockroach workload run kv --read-percent 0 --concurrency 10 --min-block-bytes 10000 --max-block-bytes 10000 --tolerate-errors

# periodically clean up to not run out of disk, also it might trigger
# something interesting.
roachprod ssh tobias-lsm:1 -- sudo systemd-run --unit truncate-kv --on-calendar '\*-\*-\*\ 11:00:00' -- ./cockroach sql --insecure -e 'TRUNCATE TABLE kv.kv;'

# At this point, get L0Files shooting up past 600 and L0Sublevels heading straight to 20, within 10 minutes

# admission control kicks in and keeps it stable

# let it run for a few hours

# Decommission every 0+4h
roachprod ssh tobias-lsm:1 -- sudo systemd-run --unit decommission --on-calendar '0/4:00:00' -- ./cockroach node decommission --insecure --wait=none 1 2 3 4

# Recommission every 2+4h
roachprod ssh tobias-lsm:1 -- sudo systemd-run --unit recommission --on-calendar '2/4:00:00' -- ./cockroach node recommission --insecure 1 2 3 4

# 2TB import
roachprod ssh tobias-lsm:1 -- ./cockroach workload fixtures import bank --payload-bytes=10240 --ranges=20000 --rows=65104166 --seed=0 --db=bigbank

dashboard:

http://tobias-lsm-0001.roachprod.crdb.io:26258/#/debug/chart?charts=%5B%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A3%2C%22aggregator%22%3A3%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.storage.l0-num-files%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.storage.l0-sublevels%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A2%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.range.snapshots.rcvd-bytes%22%7D%2C%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A2%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.range.snapshots.sent-bytes%22%7D%5D%2C%22axisUnits%22%3A1%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A1%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.raft.rcvd.dropped_bytes%22%7D%5D%2C%22axisUnits%22%3A1%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.raft.rcvd.queued_bytes%22%7D%2C%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A2%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.raft.rcvd.stepped_bytes%22%7D%5D%2C%22axisUnits%22%3A1%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.replicas%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A3%2C%22aggregator%22%3A3%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.exec.latency-p50%22%7D%2C%7B%22downsampler%22%3A3%2C%22aggregator%22%3A3%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.exec.latency-p90%22%7D%2C%7B%22downsampler%22%3A3%2C%22aggregator%22%3A3%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.exec.latency-p99.9%22%7D%2C%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.admission.wait_durations.kv-p99%22%7D%5D%2C%22axisUnits%22%3A2%7D%5D&start=1651610479&end=1651611079


snapshot repro at:

http://tobias-lsm-0001.roachprod.crdb.io:26258/#/debug/chart?charts=%5B%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.replicas%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.storage.l0-sublevels%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Atrue%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.storage.l0-num-files%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.exec.latency-p50%22%7D%2C%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.exec.latency-p99%22%7D%5D%2C%22axisUnits%22%3A2%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.node.sys.runnable.goroutines.per.cpu%22%7D%5D%2C%22axisUnits%22%3A0%7D%2C%7B%22metrics%22%3A%5B%7B%22downsampler%22%3A1%2C%22aggregator%22%3A2%2C%22derivative%22%3A0%2C%22perNode%22%3Afalse%2C%22source%22%3A%22%22%2C%22metric%22%3A%22cr.store.livebytes%22%7D%5D%2C%22axisUnits%22%3A1%7D%5D&start=1651753975&end=1651775575
